{
    "Shader": {
        "info": {
            "date": "1710406170",
            "description": "Test of a depth aware upscaling algorithm, bilinear 3d interpolation. Left to right, top to bottom: linear interpolation, reference, bilateral (exp weights), bilinear 3d.",
            "flags": 32,
            "hasliked": 0,
            "id": "4XXSWS",
            "likes": 16,
            "name": "Novel depth aware upscaling",
            "published": 3,
            "tags": [
                "upscaling",
                "depthawareupscaling"
            ],
            "usePreview": 0,
            "username": "Suslik",
            "viewed": 578
        },
        "renderpass": [
            {
                "code": "//Left to right, top to bottom: linear interpolation, reference, bilateral (exp weights), bilinear 3d.\n\n//Change the DOWNSAMPLE parameter in Common to see varying dowsampling rates.\n\n//The main idea of depth aware upscaling is to render some expensive to calculate data (in this case fake ao) in a low resolution, and then use higher resolution\n//depth buffer to upscale it.\n\n//Typically depth aware upscaling works with bilateral filtering (see GetBilateralInterp(), bottom left rectangle). It produces typical horizontal striations\n//as an aritfact.\n\n//The point of the demo is to showcase a new approach that I called depth aware bilinear 3d interpolation.\n\n//The main idea of a bilinear 3d interpolation is to pick 4 samples that are normally used for bilinear interpolation in screenspace,\n//and then find for them bilinear interpolation coefficients that result in interpolated world position that's as close as possible to the target in world space.\n//Note that in 2d bilinear interpolation coefficients are trivially calculated as fract(index2f), but finding the best coefficients for 3d is trickier.\n\n//GetAdvBilateralWeights() is a reference naive implementation that just iterates over different bilinear ratios and finds the best one. Slow, proof of concept.\n//GetAdvBilateralWeights2() does a bunch of newton iterations. Seems to converge in 1-3 iterations just fine.\n\nvec4 GetBilateralInterp(sampler2D tex, vec4 src_screen_aabb, vec2 dst_screen_pos, float depth, Camera cam)\n{\n    ivec2 tex_size = textureSize(tex, 0);\n    vec2 src_pixel_index2f = ScreenCoordToPixelIndex2f(dst_screen_pos, tex_size, src_screen_aabb);\n    BilinearSamples samples = GetBilinearSamples(src_pixel_index2f);\n    vec4 weights= GetBilinearWeights(samples.ratio);\n    \n    vec4 res_color = vec4(0.0f);\n    float total_weight = 0.0f;\n    for(int i = 0; i < 4; i++)\n    {\n        vec4 samp = texelFetch(tex, samples.base_index + GetBilinearOffset(i), 0);\n        float weight = weights[i];\n        weight *= exp(-100.0f * abs(samp.w - depth));\n        res_color += samp * weight;\n        total_weight += weight;\n    }\n    return res_color / total_weight;\n}\n\n//Reference/naive implementation of the novel approach\nvec2 GetBilinear3dRatioNaive(vec3 src_points[4], vec3 dst_point)\n{\n    ivec2 idx;\n    int count = 50;\n    float best_dist = 1e5f;\n    vec2 best_ratio = vec2(1.0f, 0.0f);\n    \n    for(idx.y = 0; idx.y < count + 1; idx.y++)\n    {\n        for(idx.x = 0; idx.x < count + 1; idx.x++)\n        {\n            vec2 ratio = (vec2(idx)) / vec2(count);\n            vec4 bilinear_weights = GetBilinearWeights(ratio);\n            vec3 sample_point = vec3(0.0f);\n            for(int i = 0; i < 4; i++)\n            {\n                sample_point += src_points[i] * bilinear_weights[i];\n            }\n            float d = length(sample_point - dst_point);\n            if(d < best_dist)\n            {\n                best_dist = d;\n                best_ratio = ratio;\n            }\n        }\n    }\n    return best_ratio;\n}\n\n//More advanced implementation that runs newton iterations to find the optimal coefficients\nvec2 GetBilinear3dRatioNewton(vec3 src_points[4], vec3 dst_point, vec2 init_ratio, const int it_count)\n{\n    vec2 ratio = init_ratio;\n    for(int i = 0; i < it_count; i++)\n    {\n        vec3 bilinear_point = \n            src_points[0] * (1.0f - ratio.x) * (1.0f - ratio.y) +\n            src_points[1] * ratio.x * (1.0f - ratio.y) + \n            src_points[2] * (1.0f - ratio.x) * ratio.y +\n            src_points[3] * ratio.x * ratio.y;\n            \n        vec3 x_grad = \n            (src_points[1] - src_points[0]) * (1.0f - ratio.y) + \n            (src_points[3] - src_points[2]) * ratio.y;\n\n        vec3 y_grad = \n            (src_points[2] - src_points[0]) * (1.0f - ratio.x) + \n            (src_points[3] - src_points[1]) * ratio.x;\n            \n        mat3 basis_to_world = mat3(x_grad, y_grad, cross(x_grad, y_grad));\n        mat3 world_to_basis = inverse(basis_to_world);\n        vec3 basis_delta = world_to_basis * (dst_point - bilinear_point);\n        ratio = saturate(ratio + basis_delta.xy);\n    }\n    return ratio;\n}\n\nfloat ProjectLinePerp(vec3 A, vec3 B, vec3 p)\n{\n\tvec3 BA = B - A;\n\treturn dot(p - A, BA) / dot(BA, BA);\n}\n\nvec2 GetBilinear3dRatioIter(vec3 src_points[4], vec3 dst_point, vec2 init_ratio, const int it_count)\n{\n\tvec2 ratio = init_ratio;\n\tfor(int i = 0; i < it_count; i++)\n\t{\n\t\tratio.x = saturate(ProjectLinePerp(mix(src_points[0], src_points[2], ratio.y), mix(src_points[1], src_points[3], ratio.y), dst_point));\n\t\tratio.y = saturate(ProjectLinePerp(mix(src_points[0], src_points[1], ratio.x), mix(src_points[2], src_points[3], ratio.x), dst_point));\n\t}\n\treturn ratio;\n}\n\nvec4 GetBilinear3dInterp(sampler2D tex, vec4 src_screen_aabb, vec2 dst_screen_pos, float depth, Camera cam)\n{\n    ivec2 tex_size = textureSize(tex, 0);\n    vec2 src_pixel_index2f = ScreenCoordToPixelIndex2f(dst_screen_pos, tex_size, src_screen_aabb);\n    BilinearSamples samples = GetBilinearSamples(src_pixel_index2f);\n    \n    vec3 src_points[4];\n    for(int i = 0; i < 4; i++)\n    {\n        vec2 sample_screen_pos = PixelIndexToScreenCoord(samples.base_index + GetBilinearOffset(i), tex_size, src_screen_aabb);\n        Ray cam_ray = GetCamRay(cam, sample_screen_pos);\n        vec4 samp = texelFetch(tex, samples.base_index + GetBilinearOffset(i), 0);\n        src_points[i] = cam_ray.origin + cam_ray.dir * samp.a;\n    }\n    \n    Ray dst_ray = GetCamRay(cam, dst_screen_pos);\n    vec3 dst_point = dst_ray.origin + dst_ray.dir * depth;\n    //vec4 adv_weights = GetBilinearWeights(GetBilinear3dRatioNaive(src_points, dst_point));\n    //vec4 adv_weights = GetBilinearWeights(GetBilinear3dRatioNewton(src_points, dst_point, samples.ratio, 2));\n    vec4 adv_weights = GetBilinearWeights(GetBilinear3dRatioIter(src_points, dst_point, samples.ratio, 2));\n\n    vec4 res_color = vec4(0.0f);\n    for(int i = 0; i < 4; i++)\n    {\n        res_color += texelFetch(tex, samples.base_index + GetBilinearOffset(i), 0) * adv_weights[i];\n    }\n    return res_color;\n}\n\n\nvec4 GetBilinearInterp(sampler2D tex, vec4 src_screen_aabb, vec2 dst_screen_pos)\n{\n    ivec2 tex_size = textureSize(tex, 0);\n    vec2 src_pixel_index2f = ScreenCoordToPixelIndex2f(dst_screen_pos, tex_size, src_screen_aabb);\n    BilinearSamples samples = GetBilinearSamples(src_pixel_index2f);\n    vec4 weights = GetBilinearWeights(samples.ratio);\n    vec4 res_color = vec4(0.0f);\n    for(int i = 0; i < 4; i++)\n        res_color += texelFetch(tex, samples.base_index + GetBilinearOffset(i), 0) * weights[i];\n    return res_color;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    Camera cam = GetCamera(iMouse, iResolution);\n    Ray cam_ray = GetCamRay(cam, uv);\n    \n    if(uv.x < 0.5f)\n    {\n        if(uv.y > 0.5f)\n        {\n            fragColor = texture(iChannel0, uv / DOWNSAMPLE);\n        }\n        else\n        {\n            fragColor = GetBilateralInterp(iChannel0, GetTestAabb(), uv, TraceRadiance(cam_ray).depth, cam);\n        }\n    }else\n    {\n        if(uv.y > 0.5f)\n        {\n        fragColor = vec4(TraceRadiance(cam_ray).color, 1.0);\n        }\n        else\n        {\n            fragColor = GetBilinear3dInterp(iChannel0, GetTestAabb(), uv, TraceRadiance(cam_ray).depth, cam);\n        }\n    }\n    float g = saturate(1.0f - min(abs(uv.x - 0.5f) * iResolution.x, abs(uv.y - 0.5f) * iResolution.y));\n    fragColor = mix(fragColor, vec4(1.0f), g);\n    //fragColor = texture(iChannel0, uv);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "#define DOWNSAMPLE 8.0f\n\nfloat saturate(float v)\n{\n    return clamp(v, 0.0f, 1.0f);\n}\n\nvec2 saturate(vec2 v)\n{\n    return clamp(v, vec2(0.0f), vec2(1.0f));\n}\n\nfloat checkerboard(vec3 v)\n{\n    return fract((floor(v.x) + floor(v.y) + floor(v.z)) / 2.0f) < 0.5f ? 1.0f : 0.0f;\n}\nstruct Coords\n{\n    vec3 pos;\n    mat3 to_global;\n};\n\nCoords BuildEulerCoords(vec3 pos, vec2 angs, float dist)\n{\n    Coords cam;\n    \n    cam.to_global[2] = vec3(-sin(angs.x) * cos(angs.y), sin(angs.y), cos(angs.x) * cos(angs.y));\n    cam.to_global[0] = normalize(cross(vec3(0.0f, 1.0f, 0.0f), cam.to_global[2]));\n    cam.to_global[1] = cross(cam.to_global[2], cam.to_global[0]);\n    \n    cam.pos = pos + cam.to_global * vec3(0.0f, 0.0f, -dist);\n    return cam;\n}\n\nstruct Camera\n{\n    Coords coords;\n    vec2 half_fov_tan;\n};\nstruct Ray\n{\n    vec3 origin;\n    vec3 dir;\n};\n\nRay GetCamRay(Camera cam, vec2 uv)\n{\n    vec3 local_ray = normalize(vec3((uv.x - 0.5f) * 2.0f * cam.half_fov_tan.x,  (uv.y - 0.5f) * 2.0f * cam.half_fov_tan.y, 1.0f));\n    Ray ray;\n    ray.dir = cam.coords.to_global * local_ray;\n    ray.origin = cam.coords.pos;\n    return ray;\n}\n\nstruct Map\n{\n    float dist;\n    vec4 orbit;\n};\n\n//maths from https://www.shadertoy.com/view/4ds3zn\nMap GetApollonianMap( vec3 pos, float param, const int count )\n{\n\tfloat scale = 1.0;\n\n    Map map;\n\tmap.orbit = vec4(1e7f); \n\t\n\tfor(int i = 0; i < count; i++)\n\t{\n\t\tpos = -1.0f + 2.0f * fract(0.5 * pos + 0.5);\n\n\t\tfloat r2 = dot(pos, pos);\n\t\t\n        map.orbit = min( map.orbit, vec4(abs(pos), r2) );\n\t\t\n\t\tfloat k = param / r2;\n\t\tpos   *= k;\n\t\tscale *= k;\n\t}\n\t\n\tmap.dist = 0.25f * abs(pos.y) / scale;\n    return map;\n}\n\n//sdf normal from \nvec3 GetMapNormal( vec3 pos, float param, int count, float eps )\n{\n    vec2 e = vec2(1.0,-1.0)*eps;\n    return normalize( e.xyy*GetApollonianMap( pos + e.xyy, param, count ).dist + \n\t\t\t\t\t  e.yyx*GetApollonianMap( pos + e.yyx, param, count ).dist + \n\t\t\t\t\t  e.yxy*GetApollonianMap( pos + e.yxy, param, count ).dist + \n                      e.xxx*GetApollonianMap( pos + e.xxx, param, count ).dist );\n}\n\nstruct Surface\n{\n    vec3 pos;\n    vec3 normal;\n    vec3 albedo;\n    float ratio;\n    float ao;\n};\n\nSurface TraceSurface(Ray ray, float min_dist)\n{\n    float param = 1.3f;\n    int count = 6;\n    float max_dist = 1e3f;\n    vec3 curr_pos = ray.origin;\n    Map map;\n    map.dist = (min_dist + max_dist) * 0.5f;\n    int max_it = 128;\n    int i = 0;\n    for(i = 0; i < max_it && map.dist > min_dist && map.dist < max_dist; i++)\n    {\n        map = GetApollonianMap(curr_pos, param, count);\n        curr_pos += ray.dir * map.dist;\n    }\n    Surface surface;\n    surface.pos = curr_pos;\n    surface.normal = GetMapNormal( curr_pos, param, count, 1e-3f );\n    surface.albedo = vec3(1.0f);//vec3(checkerboard(curr_pos.xyz * 3.0f) * 0.8f + 0.2f);\n    surface.ao = 1.0f - pow(saturate(1.0f - map.orbit.a * 2.0f), 2.0f);\n    surface.ratio = float(i) / float(max_it);\n    return surface;\n}\n\nstruct Radiance\n{\n    vec3 color;\n    float depth;\n};\n\nRadiance TraceRadiance(Ray ray)\n{\n    float min_dist = 1e-3f;\n    Surface surface = TraceSurface(ray, min_dist);\n    vec3 light_dir = vec3(1.0f, 1.0f, 1.0f);\n    Ray shadow_ray;\n    shadow_ray.origin = surface.pos;// + light_dir * 1e-2f;\n    shadow_ray.dir = light_dir;\n    Surface shadow_surface = TraceSurface(shadow_ray, 0.5f * min_dist);\n    \n    float light_amount = 1.0f - exp(-0.8f * length(shadow_surface.pos - shadow_ray.origin));\n    \n    Radiance radiance;\n    radiance.color = vec3(0.0f);\n    //radiance.color += surface.albedo * max(0.0f, dot(light_dir, surface.normal)) * light_amount * 0.5f;\n    radiance.color += surface.albedo * vec3(surface.ao * 0.9f);\n    radiance.color *= exp(-0.1f * length(ray.origin - surface.pos));\n    //radiance.color *= 1.0f - surface.ratio;\n    radiance.depth = length(ray.origin - surface.pos);\n    return radiance;\n}\n\nCamera GetCamera(vec4 mouse_pos, vec3 resolution)\n{\n    Camera cam;\n    \n    vec2 angs = vec2(0.25, -0.15f) * 3.1315f + (mouse_pos.xy/resolution.xy) * vec2(-6.5f, 6.5f);\n    cam.coords = BuildEulerCoords(vec3(0.0f, 0.2f, 0.0f), angs, 1.3f);\n    cam.half_fov_tan.x = 1.0f;\n    cam.half_fov_tan.y = cam.half_fov_tan.x * resolution.y / resolution.x;\n    return cam;\n}\n\nvec4 GetTestAabb()\n{\n    return vec4(0.0f, 0.0f, vec2(1.0f) / float(DOWNSAMPLE));\n}\n//http://www.jcgt.org/published/0009/03/02/paper.pdf\nuvec3 hash33UintPcg(uvec3 v)\n{\n    v = v * 1664525u + 1013904223u;\n    v.x += v.y*v.z; v.y += v.z*v.x; v.z += v.x*v.y;\n    //v += v.yzx * v.zxy; //swizzled notation is not exactly the same because components depend on each other, but works too\n\n    v ^= v >> 16u;\n    v.x += v.y*v.z; v.y += v.z*v.x; v.z += v.x*v.y;\n    //v += v.yzx * v.zxy;\n    return v;\n}\n\nvec3 hash3i3f(ivec3 seed)\n{\n    uvec3 hash_uvec3 = hash33UintPcg(uvec3(seed));\n    return vec3(hash_uvec3) * (1.0f / float(~0u));\n}\n\nstruct BilinearSamples\n{\n    ivec2 base_index;\n    vec2 ratio;\n};\n\nvec4 GetBilinearWeights(vec2 ratio)\n{\n    return vec4(\n        (1.0f - ratio.x) * (1.0f - ratio.y),\n        ratio.x * (1.0f - ratio.y),\n        (1.0f - ratio.x) * ratio.y,\n        ratio.x * ratio.y);\n}\n\nivec2 GetBilinearOffset(int offset_index)\n{\n    ivec2 offsets[4] = ivec2[4](ivec2(0, 0), ivec2(1, 0), ivec2(0, 1), ivec2(1, 1));\n    return offsets[offset_index];\n}\nBilinearSamples GetBilinearSamples(vec2 pixel_index2f)\n{\n    BilinearSamples samples;\n    samples.base_index = ivec2(floor(pixel_index2f));\n    samples.ratio = fract(pixel_index2f);\n    return samples;\n}\n\nvec2 WorldToAabb(vec2 world_pos, vec4 aabb)\n{\n    return (world_pos - aabb.xy) / (aabb.zw - aabb.xy);\n}\n\nvec2 AabbToWorld(vec2 aabb_pos, vec4 aabb)\n{\n    return aabb.xy + aabb_pos * (aabb.zw - aabb.xy);\n}\n\nvec2 PixelIndexToUv(ivec2 pixel_index, ivec2 tex_size)\n{\n    return (vec2(pixel_index) + vec2(0.5f)) / vec2(tex_size);\n}\n\nvec2 UvToPixelIndex2f(vec2 uv, ivec2 tex_size)\n{\n    return uv * vec2(tex_size) - vec2(0.5f);\n}\n\nvec2 PixelIndexToScreenCoord(ivec2 pixel_index, ivec2 tex_size, vec4 screen_aabb)\n{\n    return WorldToAabb(PixelIndexToUv(pixel_index, tex_size), screen_aabb);\n}\n\nvec2 ScreenCoordToPixelIndex2f(vec2 screen_coord, ivec2 tex_size, vec4 screen_aabb)\n{\n    return UvToPixelIndex2f(AabbToWorld(screen_coord, screen_aabb), tex_size);\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 pixel_index = ivec2(fragCoord.xy);\n    vec2 screen_pos = PixelIndexToScreenCoord(pixel_index, ivec2(iResolution.xy), GetTestAabb());\n    Camera cam = GetCamera(iMouse, iResolution);\n    if(screen_pos.x > 0.0f && screen_pos.y > 0.0f && screen_pos.x < 1.0f && screen_pos.y < 1.0f)\n    {\n        Ray cam_ray = GetCamRay(cam, screen_pos);\n        Radiance rad = TraceRadiance(cam_ray);\n        fragColor = vec4(rad.color, rad.depth);\n    }else\n    {\n        fragColor = vec4(0.0f);\n    }\n}",
                "description": "",
                "inputs": [],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}