{
    "Shader": {
        "info": {
            "date": "1631374061",
            "description": "Show case volumetric path tracing with ratio and spectral tracking. Simpler version of https://www.shadertoy.com/view/NdcGzl\n\nhttps://twitter.com/SebHillaire\nhttps://sebh.github.io/",
            "flags": 48,
            "hasliked": 0,
            "id": "7dVGWR",
            "likes": 114,
            "name": "Volume Path Tracing on Bunny",
            "published": 3,
            "tags": [
                "volume",
                "cloud",
                "pathtracing",
                "bunny"
            ],
            "usePreview": 1,
            "username": "SebH",
            "viewed": 7896
        },
        "renderpass": [
            {
                "code": "/*\nWelcome to this volumetric path tracing demo!\n\nIt presents volumetric path tracing with ratio and spectral tracking to respectively estimate transmittance and scattering for multiple wavelength at the same time.\n\nThe cloud data comes from Disney https://www.disneyanimation.com/data-sets/?drawer=/resources/clouds/. See BufferA for more details as to how it is achieved.\n\n!!!\n==> I am so SORRY the cloud data generateion shader in BufferA takes so long to compile. It would be smarter to do some block compression for instance to improve that situation.\nTo change that you can set USE_CLOUD to 0.\n\n==> By default, you should expect 5fp on a 1080. To improve framerate, you can reduce the scattering or path depth available at the top of BufferC code.\n!!!\n\nBufferB: the states of the scene+camera\nBufferC: current frame tracing result\nBufferD: accumulated result\n\nKeys:\n- click+mouse to look around\n- press left arrow + mouse to move the sun around\n- press up to reset accumulation history\n\nThanks to https://www.shadertoy.com/user/morimea for the many fixes for the OpenGL backend.\n\nhttps://twitter.com/SebHillaire\nhttps://sebh.github.io/\n*/\n\n\n\n\n\n\n\n\n\n\n// Final image output through sRGB\n\nfloat sRGB(float x)\n{\n\tif (x <= 0.00031308)\n\t\treturn 12.92 * x;\n\telse\n\t\treturn 1.055*pow(x, (1.0 / 2.4)) - 0.055;\n}\n\nvoid mainImage( out float4 fragColor, in float2 fragCoord )\n{    \n\tfloat2 uv = fragCoord.xy / iResolution.xy;\n    float time = iTime;\n    \n    float4 RGBSampleCount = texture(iChannel0, uv);\n    fragColor = float4(sRGB(RGBSampleCount.r / RGBSampleCount.a), sRGB(RGBSampleCount.g / RGBSampleCount.a), sRGB(RGBSampleCount.b / RGBSampleCount.a), 1.0);\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "\n// GLSL to HLSL\n\n#define float1 float\n#define float2 vec2\n#define float3 vec3\n#define float4 vec4\n#define int2   ivec2\n#define int3   ivec3\n#define int4   ivec4\n#define uint2  uvec2\n#define uint3  uvec3\n#define uint4  uvec4\n\n#define lerp mix\n#define frac fract\n#define saturate(x) clamp(x, 0.0, 1.0)\n\n#define PI 3.1415926535897932384626433832795f\n\n/*vec3 my_normalize(vec3 v){\n    float len = length(v);\n    if(len==0.0)return vec3(0.,1.,0.);\n    return v/len;\n}\n#define normalize(a) my_normalize(a)*/\n\n#define pow(a,b) pow(abs(a),b)\n#define sqrt(a) sqrt(abs(a))\n\n\n// Bunny data properties\n\n#define SRC_SIZE_X 32\n#define SRC_SIZE_Y 32\n#define SRC_SIZE_Z 32\n\n\n\n\n// States stored in BufferB\n\n#define PIX_MOUSEPOS         float2(0.5, 0.5)\n#define PIX_RESETACCUM       float2(1.5, 0.5)\n\n#define PIX_CAMPOS           float2(2.5, 0.5)\n#define PIX_CAMUP            float2(3.5, 0.5)\n#define PIX_CAMLEFT          float2(4.5, 0.5)\n#define PIX_CAMFORWARD       float2(5.5, 0.5)\n\n#define PIX_SUNDIRPOW        float2(6.5, 0.5)\n\n#define PIX_CAMYP            float2(7.5, 0.5)\n\n\n// Keyboard keys\n\n#define KEY_LEFT             37\n#define KEY_UP               38\n#define KEY_RIGHT            39\n#define KEY_DOWN             40\n\n\nbool FullResetImpl(int iFrame)\n{\n    return iFrame < 4; \n}\n#define FullReset FullResetImpl(iFrame)\n\n\n\n\n////////////////////////////////////////////////////////////\n// Sky (single scattering)\n////////////////////////////////////////////////////////////\n\n// Translated to HLSL From https://github.com/wwwtyro/glsl-atmosphere/blob/master/index.glsl. Not perfect but does a good job.\n// Also modified to return transmittance.\n\n#define iSteps 16\n#define jSteps 8\n\nfloat2 rsi(float3 r0, float3 rd, float sr) \n{\n\t// ray-sphere intersection that assumes\n\t// the sphere is centered at the origin.\n\t// No intersection when result.x > result.y\n\tfloat a = dot(rd, rd);\n\tfloat b = 2.0 * dot(rd, r0);\n\tfloat c = dot(r0, r0) - (sr * sr);\n\tfloat d = (b*b) - 4.0*a*c;\n\tif (d < 0.0) return float2(1e5,-1e5);\n\treturn float2(\n\t\t(-b - sqrt(d))/(2.0*a),\n\t\t(-b + sqrt(d))/(2.0*a)\n\t);\n}\n\nfloat3 atmosphere(\n\tfloat3 r, float3 r0, float3 pSun, float iSun, float rPlanet, float rAtmos, float3 kRlh, float kMie, float shRlh, float shMie, float g,\n\tout float3 transmittance\n) \n{\n#if 0\n\ttransmittance = float3(1.0)\n    ; return float3(0.03, 0.07, 0.23);\n#endif\n\n\t// Normalize the sun and view directions.\n\tpSun = normalize(pSun);\n\tr = normalize(r);\n\n\t// Calculate the step size of the primary ray.\n\tfloat2 p = rsi(r0, r, rAtmos);\n\tif (p.x > p.y) return float3(0,0,0);\n\tp.y = min(p.y, rsi(r0, r, rPlanet).x);\n\tfloat iStepSize = (p.y - p.x) / float(iSteps);\n\n\t// Initialize the primary ray time.\n\tfloat iTime = 0.0;\n\n\t// Initialize accumulators for Rayleigh and Mie scattering.\n\tfloat3 totalRlh = float3(0,0,0);\n\tfloat3 totalMie = float3(0,0,0);\n\n\t// Initialize optical depth accumulators for the primary ray.\n\tfloat iOdRlh = 0.0;\n\tfloat iOdMie = 0.0;\n\n\t// Calculate the Rayleigh and Mie phases.\n\tfloat mu = dot(r, pSun);\n\tfloat mumu = mu * mu;\n\tfloat gg = g * g;\n\tfloat pRlh = 3.0 / (16.0 * PI) * (1.0 + mumu);\n\tfloat pMie = 3.0 / (8.0 * PI) * ((1.0 - gg) * (mumu + 1.0)) / (pow(max(0.0, 1.0 + gg - 2.0 * mu * g), 1.5) * (2.0 + gg));\n\n\t// Sample the primary ray.\n\tfor (int i = 0; i < iSteps; i++) {\n\n\t\t// Calculate the primary ray sample position.\n\t\tfloat3 iPos = r0 + r * (iTime + iStepSize * 0.5);\n\n\t\t// Calculate the height of the sample.\n\t\tfloat iHeight = length(iPos) - rPlanet;\n\n\t\t// Calculate the optical depth of the Rayleigh and Mie scattering for this step.\n\t\tfloat odStepRlh = exp(-iHeight / shRlh) * iStepSize;\n\t\tfloat odStepMie = exp(-iHeight / shMie) * iStepSize;\n\n\t\t// Accumulate optical depth.\n\t\tiOdRlh += odStepRlh;\n\t\tiOdMie += odStepMie;\n\n\t\t// Calculate the step size of the secondary ray.\n\t\tfloat jStepSize = rsi(iPos, pSun, rAtmos).y / float(jSteps);\n\n\t\t// Initialize the secondary ray time.\n\t\tfloat jTime = 0.0;\n\n\t\t// Initialize optical depth accumulators for the secondary ray.\n\t\tfloat jOdRlh = 0.0;\n\t\tfloat jOdMie = 0.0;\n\n\t\t// Sample the secondary ray.\n\t\tfor (int j = 0; j < jSteps; j++) {\n\n\t\t\t// Calculate the secondary ray sample position.\n\t\t\tfloat3 jPos = iPos + pSun * (jTime + jStepSize * 0.5);\n\n\t\t\t// Calculate the height of the sample.\n\t\t\tfloat jHeight = length(jPos) - rPlanet;\n\n\t\t\t// Accumulate the optical depth.\n\t\t\tjOdRlh += exp(-jHeight / shRlh) * jStepSize;\n\t\t\tjOdMie += exp(-jHeight / shMie) * jStepSize;\n\n\t\t\t// Increment the secondary ray time.\n\t\t\tjTime += jStepSize;\n\t\t}\n\n\t\t// Calculate attenuation.\n\t\tfloat3 attn = exp(-(kMie * (iOdMie + jOdMie) + kRlh * (iOdRlh + jOdRlh)));\n\n\t\t// Accumulate scattering.\n\t\ttotalRlh += odStepRlh * attn;\n\t\ttotalMie += odStepMie * attn;\n\n\t\t// Increment the primary ray time.\n\t\tiTime += iStepSize;\n\n\t}\n\n\t// transmittance within atmosphere\n\ttransmittance = exp(-(kMie*iOdMie + kRlh*iOdRlh));\n\n\t// Calculate and return the final color.\n\treturn iSun * (pRlh * kRlh * totalRlh + pMie * kMie * totalMie);\n}\n\nfloat3 getAtmosphereInScattering(\n\tfloat3 rayDir, float3 sunDir, float sunIntensity,\n\tout float3 transmittance1\n)\n{\n    float3 transmittance;\n    float3 ret = atmosphere(\n\t\trayDir,\t\t\t\t\t\t\t\t// normalized ray direction\n\t\tfloat3(0,6371e3 + 5e3,0),\t\t\t// ray origin (in meters)\n\t\tsunDir,\t\t\t\t\t\t\t\t// position of the sun\n\t\tsunIntensity,\t\t\t\t\t\t// intensity of the sun\n\t\t6371e3,\t\t\t\t\t\t\t\t// radius of the planet in meters\n\t\t6471e3,\t\t\t\t\t\t\t\t// radius of the atmosphere in meters\n\t\tfloat3(5.5e-6, 13.0e-6, 22.4e-6),\t// Rayleigh scattering coefficient\n\t\t21e-6,\t\t\t\t\t\t\t\t// Mie scattering coefficient\n\t\t8e3,\t\t\t\t\t\t\t\t// Rayleigh scale height\n\t\t1.2e3,\t\t\t\t\t\t\t\t// Mie scale height\n\t\t0.758,\t\t\t\t\t\t\t\t// Mie preferred scattering direction\n\n\t\ttransmittance\n\t);\n    transmittance1=transmittance;\n    return ret;\n}\n\n\n\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "\n// Manage keyboard and mouse input for setting up the scene and camera\n// the state data are stored into BufferB.\n\n#define PIX_ARE_EQUAL(a, b)  (int(a.x)==int(b.x) && int(a.y)==int(b.y) ? true : false)\n\nvoid mainImage( out float4 fragColor, in float2 fragCoord )\n{\n\tfloat2 uv = fragCoord.xy / iResolution.xy;\n    float time = iTime;\n\tfloat2 MouseUV = iMouse.xy / iResolution.xy;\n\tfloat2 MouseClickUV = iMouse.zw / iResolution.xy;\n    \n    float3 PrevCamPos = texelFetch(iChannel0, ivec2(PIX_CAMPOS), 0).xyz;\n    float2 PrevMousePos = texelFetch(iChannel0, ivec2(PIX_MOUSEPOS), 0).xy;\n\tfloat2 PrevMouseUV = PrevMousePos / iResolution.xy;\n    \n    float2 CamYawPitch = texelFetch(iChannel0, ivec2(PIX_CAMYP), 0).xy;\n    \n    bool bFullReset = FullReset;\n    \n    // View diretion in camera space\n    float3 viewDir = normalize(float3((fragCoord.xy - iResolution.xy*0.5) / iResolution.y, 1.0));\n    \n    // Reset accumulation by default\n    bool ResetAccum = bFullReset || (int(iMouse.x)!=int(PrevMousePos.x) && int(iMouse.y)!=int(PrevMousePos.y)) || texelFetch(iChannel1, ivec2(KEY_UP,0), 0).x > 0.0;\n    \n    // Sun light control\n    float SunPower = 4.0f;\n    float4 SunDirPow = bFullReset ? float4(normalize(float3(0,0.1,1)), SunPower) : texelFetch(iChannel0, ivec2(PIX_SUNDIRPOW), 0).xyzw;\n    bool bControlSun = texelFetch(iChannel1, ivec2(KEY_LEFT,0), 0).x > 0.0;\n    if(bControlSun)\n    {\n        ResetAccum = true;\n        float HorizonAngle = MouseUV.x*2.0*PI;\n        float VerticalAngle = (MouseUV.y-0.05)*PI;\n        SunDirPow = float4(normalize(float3(cos(HorizonAngle)*cos(VerticalAngle), sin(VerticalAngle), sin(HorizonAngle)*cos(VerticalAngle))), SunPower);\n    }\n    \n    \n    \n    // Compute camera properties\n    float  camDist = 3.3;\n    float  CamHeight= 0.0;\n    float3 camUp = float3(0, 1.0, 0);\n    if(bFullReset)\n    {\n        CamYawPitch.x = 0.0;\n        CamYawPitch.y = 0.5;\n    }\n    if(!bControlSun)\n    {\n        CamYawPitch.x += (MouseUV.x - PrevMouseUV.x) * 10.0;\n        CamYawPitch.y += (MouseUV.y - PrevMouseUV.y) * 5.0;\n        \n        CamYawPitch.y = clamp(CamYawPitch.y, -PI*0.45, PI*0.45);\n    }\n    float HorizonAngle = CamYawPitch.x; //MouseUV.x*2.0*PI;\n    float VerticalAngle = CamYawPitch.y;//-(MouseUV.y-0.5)*PI;\n    float3 camPos = float3(camDist*cos(HorizonAngle)*cos(VerticalAngle), CamHeight+camDist*sin(VerticalAngle), camDist*sin(HorizonAngle)*cos(VerticalAngle));\n    float3 camTarget = float3(0, -0.0, 0);\n    \n    // And from them evaluated ray direction in world space\n    float3 forward = normalize(camTarget - camPos);\n    float3 left = normalize(cross(forward, camUp));\n    float3 up = cross(left, forward);\n    \n    fragColor = float4(0.0);\n    \n    if(PIX_ARE_EQUAL(PIX_MOUSEPOS, fragCoord.xy))\n    {\n        fragColor = float4(iMouse.xy, 0.0, 0.0);\n    }\n    if(PIX_ARE_EQUAL(PIX_RESETACCUM, fragCoord.xy))\n    {\n        fragColor = float4(ResetAccum ? 1.0 : 0.0, 0.0, 0.0, 0.0);\n    }\n    \n    if(PIX_ARE_EQUAL(PIX_CAMPOS, fragCoord.xy))\n    {\n        fragColor = float4(camPos, 0.0);\n    }\n    if(PIX_ARE_EQUAL(PIX_CAMUP, fragCoord.xy))\n    {\n        fragColor = float4(up, 0.0);\n    }\n    if(PIX_ARE_EQUAL(PIX_CAMLEFT, fragCoord.xy))\n    {\n        fragColor = float4(left, 0.0);\n    }\n    if(PIX_ARE_EQUAL(PIX_CAMFORWARD, fragCoord.xy))\n    {\n        fragColor = float4(forward, 0.0);\n    }\n\n    if(PIX_ARE_EQUAL(PIX_SUNDIRPOW, fragCoord.xy))\n    {\n        fragColor = SunDirPow;\n    }\n\n    if(PIX_ARE_EQUAL(PIX_CAMYP, fragCoord.xy))\n    {\n        fragColor = float4(CamYawPitch, 0.0, 0.0);\n    }\n\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "\n// State of the art\n//  - https://graphics.pixar.com/\n//  - https://cs.dartmouth.edu/wjarosz/publications/no\n\n// This demo relised particularly on:\n// Ratio tracking,    see https://cs.dartmouth.edu/wjarosz/publications/novak14residual.html\n// Spectral tracking, see https://jannovak.info/publications/SDTracking/index.html\n// Both are important for tracing multiple waveleght along a path at the same time when evaluating tranmsittance and scattered radiance.\n\n#define gAmbientLightEnable 1.0\n#define gSunLightEnable 1.0\n\n#define gScattering (vec3(1.0, 1.0, 1.0)*200.0)\n#define gAbsorption vec3(0.0, 0.0, 0.0)\n\n#define gMaxPathDepth 20\n\n\n//////////////////////////////////////////////////\n// Volume data\n//////////////////////////////////////////////////\n\n#define HIGHBOUND (float3(SRC_SIZE_X, SRC_SIZE_Y, SRC_SIZE_Z) / float3(SRC_SIZE_Z))\n#define LOWBOUND  (-HIGHBOUND)\n\n// A low res volume version of the Stanford bunny https://en.wikipedia.org/wiki/Stanford_bunny \n#define BUNNY_VOLUME_SIZE 32\nconst uint packedBunny[1024] = uint[1024](0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,917504u,917504u,917504u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,1966080u,12531712u,16742400u,16742400u,16723968u,16711680u,8323072u,4128768u,2031616u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,6144u,2063360u,16776704u,33553920u,33553920u,33553920u,33553920u,33520640u,16711680u,8323072u,8323072u,2031616u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,268435456u,402653184u,134217728u,201326592u,67108864u,0u,0u,7168u,2031104u,16776960u,33554176u,33554176u,33554304u,33554176u,33554176u,33554176u,33553920u,16744448u,8323072u,4128768u,1572864u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,805306368u,939524096u,402653184u,478150656u,260046848u,260046848u,260046848u,125832192u,130055680u,67108608u,33554304u,33554304u,33554304u,33554304u,33554304u,33554304u,33554304u,33554176u,16776704u,8355840u,4128768u,917504u,0u,0u,0u,0u,0u,0u,0u,0u,0u,805306368u,1056964608u,1056964608u,528482304u,528482304u,260046848u,260046848u,260046848u,130039296u,130154240u,67108739u,67108807u,33554375u,33554375u,33554370u,33554368u,33554368u,33554304u,33554304u,16776960u,8330240u,4128768u,393216u,0u,0u,0u,0u,0u,0u,0u,0u,939524096u,1040187392u,1040187392u,520093696u,251658240u,251658240u,260046848u,125829120u,125829120u,130088704u,63045504u,33554375u,33554375u,33554375u,33554407u,33554407u,33554370u,33554370u,33554374u,33554310u,16776966u,4144642u,917504u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,15360u,130816u,262017u,4194247u,33554383u,67108847u,33554415u,33554407u,33554407u,33554375u,33554375u,33554318u,2031502u,32262u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,31744u,130816u,262019u,2097151u,134217727u,134217727u,67108863u,33554415u,33554407u,33554415u,33554383u,2097102u,982926u,32262u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,31744u,130816u,524263u,117964799u,127926271u,134217727u,67108863u,16777215u,4194303u,4194303u,2097151u,1048574u,65422u,16134u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,3u,31751u,130951u,524287u,252182527u,261095423u,261095423u,59768830u,2097150u,1048574u,1048575u,262143u,131070u,65534u,16134u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,7u,31751u,130959u,503840767u,520617982u,529530879u,261095423u,1048575u,1048574u,1048574u,524286u,524287u,131070u,65534u,16134u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,3u,1799u,32527u,134348750u,1040449534u,1057488894u,520617982u,51380223u,1048575u,1048575u,524287u,524287u,524287u,131070u,65534u,15886u,6u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,1536u,3968u,8175u,65535u,1006764030u,1040449534u,1057488894u,50855934u,524286u,524286u,524287u,524287u,524286u,262142u,131070u,65534u,32270u,14u,6u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,3968u,8160u,8191u,805371903u,2080505854u,2114191358u,101187582u,34078718u,524286u,524286u,524286u,524286u,524286u,524286u,262142u,131070u,32766u,8078u,3590u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,8128u,8176u,16383u,2013331455u,2080505854u,235143166u,101187582u,524286u,1048574u,1048574u,1048574u,1048574u,524286u,524286u,262142u,131070u,32766u,16382u,8070u,1024u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,8160u,8184u,1879064574u,2013331455u,470024190u,67371006u,524286u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,524286u,524286u,262142u,65534u,16382u,8160u,1024u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,8128u,8184u,805322750u,402718719u,134479870u,524286u,524286u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,524286u,262142u,65534u,16382u,16368u,1792u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,3968u,8184u,16382u,131071u,262142u,524286u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,524286u,262142u,65534u,16382u,16368u,1792u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,1792u,8184u,16380u,65535u,262143u,524286u,524286u,1048574u,1048574u,1048575u,1048574u,1048574u,1048574u,1048574u,524286u,262142u,65534u,16376u,16368u,1792u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,8176u,16376u,32767u,262143u,524286u,1048574u,1048574u,1048575u,1048575u,1048575u,1048575u,1048574u,1048574u,524286u,262142u,32766u,16376u,8176u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,4032u,8184u,32766u,262142u,524286u,524286u,1048575u,1048574u,1048574u,1048574u,1048574u,1048574u,1048574u,524286u,262142u,32766u,16376u,8176u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,384u,8184u,32766u,131070u,262142u,524286u,1048575u,1048574u,1048574u,1048574u,1048574u,1048574u,524286u,524286u,131070u,32766u,16368u,1920u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,4080u,32764u,65534u,262142u,524286u,524286u,524286u,1048574u,1048574u,524286u,524286u,524286u,262142u,131070u,32764u,8160u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,256u,16376u,32760u,131068u,262140u,262142u,524286u,524286u,524286u,524286u,524286u,262142u,131070u,65532u,16368u,3840u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,3968u,32752u,65528u,131068u,262142u,262142u,262142u,262142u,262142u,262142u,262140u,131064u,32752u,7936u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,8064u,32736u,65528u,131070u,131070u,131070u,131070u,131070u,131070u,65532u,32752u,8160u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,3456u,16376u,32764u,65534u,65534u,65534u,32766u,32764u,16380u,4048u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,48u,2680u,8188u,8188u,8188u,8188u,4092u,120u,16u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,120u,248u,508u,508u,508u,248u,240u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,96u,240u,504u,504u,504u,240u,96u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,224u,224u,224u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u,0u);\n\nfloat SampleVolume(float3 P)\n{\n    // Normalize uvs to 0-1\n    float3 uvs = (P - LOWBOUND) / (HIGHBOUND - LOWBOUND);\n    \n    float3 voxelUvs = max(float3(0.0),min(uvs*float3(BUNNY_VOLUME_SIZE), float3(BUNNY_VOLUME_SIZE)-1.0));\n    uint3 intCoord = uint3(voxelUvs);\n    uint arrayCoord = intCoord.x + intCoord.z*uint(BUNNY_VOLUME_SIZE);\n\t\n    // Very simple clamp to edge. It would be better to do it for each texture sample\n    // before the filtering but that would be more expenssive...\n    // Also adding small offset to catch cube intersection floating point error\n    if(uvs.x<-0.001 || uvs.y<-0.001 || uvs.z<-0.001 ||\n      uvs.x>1.001 || uvs.y>1.001 || uvs.z>1.001)\n    \treturn 0.0;\n   \n    uint3 intCoord2 = min(intCoord+uint3(1), uint3(BUNNY_VOLUME_SIZE-1));\n    \n    uint arrayCoord00 = intCoord.x  + intCoord.z *uint(BUNNY_VOLUME_SIZE);\n    uint arrayCoord01 = intCoord.x  + intCoord2.z*uint(BUNNY_VOLUME_SIZE);\n    uint arrayCoord10 = intCoord2.x + intCoord.z *uint(BUNNY_VOLUME_SIZE);\n    uint arrayCoord11 = intCoord2.x + intCoord2.z*uint(BUNNY_VOLUME_SIZE);\n    \n    uint bunnyDepthData00 = packedBunny[arrayCoord00];\n    uint bunnyDepthData01 = packedBunny[arrayCoord01];\n    uint bunnyDepthData10 = packedBunny[arrayCoord10];\n    uint bunnyDepthData11 = packedBunny[arrayCoord11];\n        \n    float voxel000 = (bunnyDepthData00 & (1u<<intCoord.y)) > 0u ? 1.0 : 0.0;\n    float voxel001 = (bunnyDepthData01 & (1u<<intCoord.y)) > 0u ? 1.0 : 0.0;\n    float voxel010 = (bunnyDepthData10 & (1u<<intCoord.y)) > 0u ? 1.0 : 0.0;\n    float voxel011 = (bunnyDepthData11 & (1u<<intCoord.y)) > 0u ? 1.0 : 0.0;\n    float voxel100 = (bunnyDepthData00 & (1u<<intCoord2.y)) > 0u ? 1.0 : 0.0;\n    float voxel101 = (bunnyDepthData01 & (1u<<intCoord2.y)) > 0u ? 1.0 : 0.0;\n    float voxel110 = (bunnyDepthData10 & (1u<<intCoord2.y)) > 0u ? 1.0 : 0.0;\n    float voxel111 = (bunnyDepthData11 & (1u<<intCoord2.y)) > 0u ? 1.0 : 0.0;\n    \n    float3 d = voxelUvs - float3(intCoord);\n    \n    voxel000 = mix(voxel000,voxel100, d.y);\n    voxel001 = mix(voxel001,voxel101, d.y);\n    voxel010 = mix(voxel010,voxel110, d.y);\n    voxel011 = mix(voxel011,voxel111, d.y);\n    \n    voxel000 = mix(voxel000,voxel010, d.x);\n    voxel001 = mix(voxel001,voxel011, d.x);\n    \n    float voxel = mix(voxel000,voxel001, d.z);\n    \n    return voxel;\n}\n\n\n\n//////////////////////////////////////////////////\n// Cube intersection\n//////////////////////////////////////////////////\n\nbool slabs(float3 p0, float3 p1, float3 rayOrigin, float3 invRaydir, out float outTMin, out float outTMax) \n{\n\tfloat3 t0 = (p0 - rayOrigin) * invRaydir;\n\tfloat3 t1 = (p1 - rayOrigin) * invRaydir;\n\tfloat3 tmin = min(t0,t1), tmax = max(t0,t1);\n\tfloat maxtmin = max(max(tmin.x, tmin.y), tmin.z);\n\tfloat mintmax = min(min(tmax.x, tmax.y), tmax.z);\n\toutTMin = maxtmin;\n\toutTMax = mintmax;\n\treturn maxtmin <= mintmax;\n}\n\n\n\n//////////////////////////////////////////////////\n// Dual lobe phase function as in https://media.contentapi.ea.com/content/dam/eacom/frostbite/files/s2016-pbs-frostbite-sky-clouds-new.pdf, page 39\n//////////////////////////////////////////////////\n\nfloat hgPhase(float g, float cosTheta)\n{\n\t// Reference implementation (i.e. not schlick approximation). \n\t// See http://www.pbr-book.org/3ed-2018/Volume_Scattering/Phase_Functions.html\n\tfloat numer = 1.0f - g*g;\n\tfloat denom = 1.0f + g*g + 2.0f * g * cosTheta;\n\treturn numer / (4.0f * PI * denom * sqrt(denom) );\n}\nfloat dualLobPhase(float g0, float g1, float w, float cosTheta)\n{\n\treturn lerp(hgPhase(g0, cosTheta), hgPhase(g1, cosTheta), w);\n}\n\nfloat uniformPhase()\n{\n\treturn 1.0f / (4.0f * PI);\n}\n\n\n\n//////////////////////////////////////////////////\n// Some noise\n//////////////////////////////////////////////////\n\nfloat whangHashNoise(uint u, uint v, uint s)\n{\n    // https://www.reedbeta.com/blog/quick-and-easy-gpu-random-numbers-in-d3d11/\n    // https://www.shadertoy.com/view/ldjczd\n\tuint seed = (u*1664525u + v) + s;\n\tseed  = (seed ^ 61u) ^(seed >> 16u);\n\tseed *= 9u;\n\tseed  = seed ^(seed >> 4u);\n\tseed *= uint(0x27d4eb2d);\n\tseed  = seed ^(seed >> 15u);\n\tfloat value = float(seed) / (4294967296.0);\n\treturn value;\n}\n\nfloat badNoise(float2 uv)\n{\n\treturn frac(sin(dot(uv, float2(12.9898, 78.233))) * 43758.5453);\n}\n\n\n\n////////////////////////////////////////////////////////////\n// Ray related tools\n////////////////////////////////////////////////////////////\n\n#define RAYDPOS      0.00001f\n#define VOL_SAF_DIST 0.00000001f\n\nstruct Ray\n{\n\tfloat3 o;\n\tfloat3 d;\n};\n\nRay createRay(in float3 p, in float3 d)\n{\n\tRay r;\n\tr.o = p;\n\tr.d = d;\n\treturn r;\n}\n\n\n////////////////////////////////////////////////////////////\n// Path tracing context used by the integrator\n////////////////////////////////////////////////////////////\n\nstruct PathTracingContext\n{\n\tRay ray;\n\tfloat3 P;\n\tfloat3 V;\t// not always the view: sometimes it is the opposite of ray.d when one bounce has happened.\n\n\tfloat scatteringMajorant;\n\tfloat absorptionMajorant;\n\tfloat extinctionMajorant;\n\tfloat albedo;\t\t\t// name ScatteringAlbedo in Pixar's course note\n\n\tfloat3 wavelengthMask;\t// This is ok while we deal with only RGB. It will become a problem when doing real wavelength rendering...\n\n\t//\tThis is used to say \"ray did not terminated/interact in a volume and we are going out of it without any mateiral interaction\". \n\t// For instance if a media is used in a glass layer then the Bxdf should be evaluated on output (for reflection, refraction, etc.).\n\t// This is enough for the simple volume use case we have today.\n\t// It is only used in the multi scattering light integrator.\n\t//\tIn a real path tracer, one would set the Bxdf on the ouput to use as next event.\n\tbool nullMaterial;\n\n\tuint2 screenPixelPos;\n\tfloat randomState;\n};\n\nfloat random01(inout PathTracingContext ptc)\n{\n\t// Trying to do the best noise here with simple function.\n\t// See https://www.shadertoy.com/view/ldjczd.\n\t// TODO: have a look at the best noise solution for this case\n\tfloat rnd = whangHashNoise(uint(ptc.randomState), uint(ptc.screenPixelPos.x), uint(ptc.screenPixelPos.y));\n\n\t//ptc.randomState++; return rnd;\n\n#if 1\n\tptc.randomState += float(iFrame) + iTime;\n#else\n\tuint animation = uint(gTime*123456.0);\n\tptc.randomState += float((animation*12345u)%256u);\n#endif\n\n\treturn rnd;\n}\n\n\n\n\n\n////////////////////////////////////////////////////////////\n// Forward declaration of function used at different places\n////////////////////////////////////////////////////////////\n\n//float Transmittance( inout PathTracingContext ptc, in float3 P0, in float3 P1);\n\n\n\n////////////////////////////////////////////////////////////\n// Intersection & tests functions\n////////////////////////////////////////////////////////////\n\nbool insideAnyVolume(in Ray ray)\n{\n#if 0\n\tfloat3 p = ray.o;\n\n\tfloat3 halfSize = float3(0.5) / gVolumeSamplingScale;\n\tif (all(p<(halfSize + VOL_SAF_DIST) && p>(-halfSize - VOL_SAF_DIST)))\n\t{\n\t\treturn true;\n\t}\n\treturn false;\n#else\n    const float3 LowB  = LOWBOUND - VOL_SAF_DIST;\n    const float3 HighB = HIGHBOUND+ VOL_SAF_DIST;\n\tfloat3 P = ray.o;\n    return P.x>=LowB.x && P.y>=LowB.y && P.z>=LowB.z && P.x<=HighB.x && P.y<=HighB.y && P.z<=HighB.z;\n#endif\n}\n\nbool intersectVolume(in Ray ray, inout float2 ts)\n{\n#if 0\n\tconst float3 volumeP0 = -0.5 * 1.0 / gVolumeSamplingScale;\n\tconst float3 volumeP1 = 0.5 * 1.0 / gVolumeSamplingScale;\n\treturn slabs(volumeP0, volumeP1, ray.o, 1.0 / ray.d, ts.x, ts.y);\n#else\n    float3 D = normalize(ray.d);\n    D += 0.0001 * (1.0 - abs(sign(D)));\n    return slabs(LOWBOUND, HIGHBOUND, ray.o, 1.0/D, ts.x, ts.y);\n#endif\n}\n\n// This is to intersect the entire media volume (6 planes only).\n// It would be good to get rid of it as it is a special case (assuming a single volume, but ok if it aggregates all volumes otherwise)\nbool getNearestIntersectionFullVolume(in Ray ray, inout float3 P)\n{\n\t// No triangles in this scene so only intersect with the volume.\n\tfloat2 ts=vec2(0.);\n\tif (intersectVolume(ray, ts))\n\t{\n\t\tif (ts.x <= 0.0f && ts.y <= 0.0f)\n\t\t\treturn false;\n\n\t\t// Now handle single point behind ray origin, otherwise take the minimum. Can be float t = ts.x<0.0 ? ts.y : (ts.y<0.0 ? ts.x : min(ts.x, ts.y));\n\t\tfloat t = ts.x < 0.0 ? ts.y : ts.x; // Optimised since we always have ts.x<=ts.y\n\t\tP = ray.o + t * ray.d;\n\t\treturn true;\n\t}\n\treturn false;\n}\n\n\n\n////////////////////////////////////////////////////////////\n// Sampling functions\n////////////////////////////////////////////////////////////\n\nbool importanceSampleLightning_Warping(inout PathTracingContext ptc, inout float sx, inout float sy);\nbool importanceSampleLightning_Texel(inout PathTracingContext ptc, inout float sx, inout float sy);\n\n// Generates a uniform distribution of directions over a sphere.\n// Random zetaX and zetaY values must be in [0, 1].\n// Top and bottom sphere pole (+-zenith) are along the Y axis.\nfloat3 getUniformSphereSample(float zetaX, float zetaY)\n{\n\tfloat phi = 2.0f * PI * zetaX;\n\tfloat theta = 2.0f * acos(sqrt(1.0f - zetaY));\n\tfloat3 dir = float3(sin(theta)*cos(phi), cos(theta), sin(theta)*sin(phi)); \n\treturn dir;\n}\n\n// Generate a sample (using importance sampling) along an infinitely long path with a given constant extinction.\n// Zeta is a random number in [0,1]\nfloat infiniteTransmittanceIS(float extinction, float zeta)\n{\n\treturn - log(1.0f - zeta) / extinction;\n}\n\nstruct DistantLightSample\n{\n\tfloat3 transmittance;\n\tfloat3 radiance;\n};\n\n\n\n////////////////////////////////////////////////////////////\n// [Jendersie and d'Eon 2023] Sampling functions\n////////////////////////////////////////////////////////////\n\n/*\n * SPDX-FileCopyrightText: Copyright (c) <2023> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n * SPDX-License-Identifier: MIT\n *\n * Permission is hereby granted, free of charge, to any person obtaining a\n * copy of this software and associated documentation files (the \"Software\"),\n * to deal in the Software without restriction, including without limitation\n * the rights to use, copy, modify, merge, publish, distribute, sublicense,\n * and/or sell copies of the Software, and to permit persons to whom the\n * Software is furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n * DEALINGS IN THE SOFTWARE.\n */\n\n// [Jendersie and d'Eon 2023]\n//   SIGGRAPH 2023 Talks\n//   https://doi.org/10.1145/3587421.3595409\n\n// EVAL and SAMPLE for the Draine (and therefore Cornette-Shanks) phase function\n//   g = HG shape parameter\n//   a = \"alpha\" shape parameter\n\n// Warning: these functions don't special case isotropic scattering and can numerically fail for certain inputs\n\n// eval:\n//   u = dot(prev_dir, next_dir)\nfloat evalDraine(in float u, in float g, in float a)\n{\n    return ((1.0 - g*g)*(1.0 + a*u*u))/(4.0*(1.0 + (a*(1.0 + 2.0*g*g))/3.) * PI * pow(1.0 + g*g - 2.0*g*u,1.5));\n}\n\n// sample: (sample an exact deflection cosine)\n//   xi = a uniform random real in [0,1]\nfloat sampleDraineCos(in float xi, in float g, in float a)\n{\n    float g2 = g * g;\n\tfloat g3 = g * g2;\n\tfloat g4 = g2 * g2;\n\tfloat g6 = g2 * g4;\n\tfloat pgp1_2 = (1.0 + g2) * (1.0 + g2);\n\tfloat T1 = (-1.0 + g2) * (4.0 * g2 + a * pgp1_2);\n\tfloat T1a = -a + a * g4;\n\tfloat T1a3 = T1a * T1a * T1a;\n\tfloat T2 = -1296.0 * (-1.0 + g2) * (a - a * g2) * (T1a) * (4.0 * g2 + a * pgp1_2);\n\tfloat T3 = 3.0 * g2 * (1.0 + g * (-1.0 + 2.0 * xi)) + a * (2.0 + g2 + g3 * (1.0 + 2.0 * g2) * (-1.0 + 2.0 * xi));\n\tfloat T4a = 432.0 * T1a3 + T2 + 432.0 * (a - a * g2) * T3 * T3;\n\tfloat T4b = -144.0 * a * g2 + 288.0 * a * g4 - 144.0 * a * g6;\n\tfloat T4b3 = T4b * T4b * T4b;\n\tfloat T4 = T4a + sqrt(-4.0 * T4b3 + T4a * T4a);\n\tfloat T4p3 = pow(T4, 1.0 / 3.0);\n\tfloat T6 = (2.0 * T1a + (48.0 * pow(2.0, 1.0 / 3.0) *\n\t\t(-(a * g2) + 2.0 * a * g4 - a * g6)) / T4p3 + T4p3 / (3.0 * pow(2.0, 1.0 / 3.0))) / (a - a * g2);\n\tfloat T5 = 6.0 * (1.0 + g2) + T6;\n\treturn (1.0 + g2 - pow(-0.5 * sqrt(T5) + sqrt(6.0 * (1.0 + g2) - (8.0 * T3) / (a * (-1.0 + g2) * sqrt(T5)) - T6) / 2.0, 2.0)) / (2.0 * g);\n}\n\n\n\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// Spectral tracking\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n////////////////////////////////////////////////////////////\n// Path tracing context used by the integrator\n////////////////////////////////////////////////////////////\n\nstruct SpectralPathTracingContext\n{\n\tRay ray;\n\tfloat3 P;\n\tfloat3 V;\t// not always the view direction: sometimes it is the opposite of ray.d when one bounce has happened.\n\n    float4 SunDirPow;\n\n\t\n\t// Extinction majorant accross all wavelength\n\tfloat extinctionMajorant;\n\n\tfloat3 pathWeight;\n\n\t//\tThis is used to say \"ray did not terminated/interact in a volume and we are going out of it without any mateiral interaction\". \n\t// For instance if a media is used in a glass layer then the Bxdf should be evaluated on output (for reflection, refraction, etc.).\n\t// This is enough for the simple volume use case we have today.\n\t// It is only used in the multi scattering light integrator.\n\t//\tIn a real path tracer, one would set the Bxdf on the ouput to use as next event.\n\tbool nullMaterial;\n\n\tuint2 screenPixelPos;\n\tfloat randomState;\n};\n\n\n\n////////////////////////////////////////////////////////////\n// Re implemnted function for SpectralPathTracingContext and RGB spectral content\n////////////////////////////////////////////////////////////\n\nfloat random01(inout SpectralPathTracingContext ptc)\n{\n\t// Trying to do the best noise here with simple function.\n    // This is ok for the first step but has dimentionality increase further down the path, something smarter should be done to better explore the space. But surprisingly fine for this demo.\n\tfloat rnd = whangHashNoise(uint(ptc.randomState), uint(ptc.screenPixelPos.x), uint(ptc.screenPixelPos.y));\n\n\t//ptc.randomState++; return rnd;\n\n#if 1\n\tptc.randomState += float(iFrame) + iTime;\n#else\n\tuint animation = uint(iTime*123456.0);\n\tptc.randomState += float((animation * 12345u) % 256u);\n#endif\n\n\treturn rnd;\n}\n\nfloat3 getAlbedo(float3 scattering, float3 extinction)\n{\n\treturn scattering / max(float3(0.001), extinction);\n}\n\n// Sample the volume material at ptc.P\nstruct MediumSample3\n{\n\tfloat3 scattering;\n\tfloat3 absorption;\n\tfloat3 extinction;\n\tfloat3 albedo;\n};\nMediumSample3 sampleMedium(in SpectralPathTracingContext ptc)\n{\n\tfloat3 P = ptc.P;\n\n    float3 noiseRGB= (textureLod(iChannel1, P*30.0/32.0, 0.).rgb-0.5)*4.0f\n                   + (textureLod(iChannel1, P*60.0/32.0, 0.).rgb-0.5)*2.0f\n                   + (textureLod(iChannel1, P*120.0/32.0, 0.).rgb-0.5)*1.0f;\n\n    float3 Puv = P + 1.0*noiseRGB*0.02f;\n\n    float Density = SampleVolume(Puv);\n    \n\tfloat3 scatteringCoef = gScattering;\n\tfloat3 absorptionCoef = gAbsorption;\n\tfloat3 extinctionCoef = scatteringCoef + absorptionCoef;\n    \n\tMediumSample3 s;\n\ts.scattering = Density * scatteringCoef;\n\ts.absorption = Density * absorptionCoef;\n\ts.extinction = Density * extinctionCoef;\n\ts.albedo = getAlbedo(s.scattering, s.extinction);\n\treturn s;\n}\n\n#if 1\n\n// Use uniform phase function\n\nvoid phaseEvaluateSample(in SpectralPathTracingContext ptc, in float3 direction, in float3 lightL, out float value, out float pdf)\n{\n\tpdf = uniformPhase();\n\tvalue = pdf;\n}\nvoid phaseGenerateSample(inout SpectralPathTracingContext ptc, out float3 direction, out float value, out float pdf)\n{\n\t// Evaluate a random direction\n\tdirection = getUniformSphereSample(random01(ptc), random01(ptc));\n\t// From direction, evaluate the phase value and pdf\n\tphaseEvaluateSample(ptc, direction, direction, value, pdf);\n}\n\n#else\n\n// Use [Jendersie and d'Eon 2023]\n// TODO select HG or Draine based on weight, update pdf, then lerp evaluation.\n\n#define A 1.0\n#define G 0.0\n\nvoid branchlessONB(in float3 n, out float3 b1, out float3 b2)\n{\n    // See https://graphics.pixar.com/library/OrthonormalB/paper.pdf\n    float signZ = n.z >= 0.0f ? 1.0f : -1.0f; // float sign = copysignf(1.0f, n.z);\n    float a = -1.0f / (signZ + n.z);\n    float b = n.x * n.y * a;\n    b1 = float3(1.0f + signZ * n.x * n.x * a, signZ * b, -signZ * n.x);\n    b2 = float3(b, signZ + n.y * n.y * a, -n.y);\n}\n\n\nvoid phaseEvaluateSample(in SpectralPathTracingContext ptc, in float3 direction, in float3 lightL, out float value, out float pdf)\n{\n    pdf = evalDraine(dot(direction, lightL), G, A);\n    value = pdf;\n}\nvoid phaseGenerateSample(inout SpectralPathTracingContext ptc, inout float3 direction, inout float value, inout float pdf)\n{\n#if 1\n    float3 b0 = direction;\n    float3 b1 = float3(0.0f, 0.0f, 0.0f);\n    float3 b2 = float3(0.0f, 0.0f, 0.0f);\n    branchlessONB(b0, b1, b2);\n    \n    float u = sampleDraineCos(random01(ptc), G, A);\n    \n\t// Evaluate a random direction\n\tfloat phi = 2.0f * PI * random01(ptc);  \n\tfloat theta = 2.0f * acos(sqrt(1.0f - u));\n\tfloat3 dir = float3(sin(theta)*cos(phi), cos(theta), sin(theta)*sin(phi)); \n\n    \n    // Project it out of the local basis\n    direction = b0 * dir.y + b1 * dir.x + b2 * dir.z;\n#else\n\tfloat3 NewDirection = getUniformSphereSample(random01(ptc), random01(ptc));\n    float u = dot(direction, NewDirection);\n    direction = NewDirection;\n#endif\n    \n\t// From direction, evaluate the phase value and pdf\n\tevalDraine(u, value, pdf);\n}\n\n#endif\n\n\n\n////////////////////////////////////////////////////////////\n// Transmittance estimation based on Residual Ratio Tracking for Estimating Attenuation in Participating Media\n// http://drz.disneyresearch.com/~jnovak/publications/RRTracking/index.html\n// Converted to RGB from vpt_transintegrator_ratiotracking.hlsl.\n////////////////////////////////////////////////////////////\n\nfloat3 Transmittance(\n\tinout SpectralPathTracingContext ptc,\n\tin float3 P0,\n\tin float3 P1)\n{\n\tfloat distance = length(P0 - P1);\n\tfloat3 dir = float3(P1 - P0) / distance;\n    \n\tfloat3 transmittance = float3(1.0f);\n    \n#if 1\n    // Ray marching\n    float StepCount = 70.0f;// This requires quite some stteps to not look too biased. But even with that, it is faster than unbiased ratio tracking.\n    float Step = 1.0f / StepCount;\n    float DistancePerStep = distance / StepCount;\n    for(float t = Step*0.5; t<1.0; t+=Step)\n    {\n\t\tfloat3 P = P0 + t * dir * distance;\n\t\tptc.P = P;\n\t\tfloat3 extinction = sampleMedium(ptc).extinction;\n\t\ttransmittance *= exp(- extinction * DistancePerStep);\n    }\n    \n#else\n\n\tbool terminated = false;\n\tfloat t = 0.0f;\n\n\n\t// Implements ratio tracking (non residual).\n    // See https://cs.dartmouth.edu/wjarosz/publications/novak14residual.html\n\tconst float globalMaxDensity = 1.0f;\n\tfloat globalExtinctionMajorant = globalMaxDensity * ptc.extinctionMajorant;\n\tdo\n\t{\n\t\tfloat zeta = random01(ptc);\n\t\tt = t + infiniteTransmittanceIS(globalExtinctionMajorant, zeta);\n\n\t\t// Update the shading context\n\t\tfloat3 P = P0 + t * dir;\n\t\tptc.P = P;\n\n\t\tif (t > distance)\n\t\t\tbreak; // Did not terminate in the volume\n\n\t\tfloat3 extinction = sampleMedium(ptc).extinction;\n\t\ttransmittance *= float3(1.0f) - max(float3(0.0f), extinction / globalExtinctionMajorant);\n\n\t\t// Russian roulette PBRT style, but not nice really...\n\t\t/*float rrThreshold = 0.1f;\n\t\tif (transmittance.x < rrThreshold && transmittance.y < rrThreshold && transmittance.z < rrThreshold)\n\t\t{\n\t\t\tfloat3 q = max(float3(0.05f), float3(1.0f) - transmittance);\n\t\t\tif (random01(ptc) < max(q.x, max(q.y, q.z))) return float3(0.0f);\n\t\t\ttransmittance /= float3(1.0) - q;\n\t\t}*/\n\t} while (true);\n    \n#endif\n\n\treturn transmittance;\n}\n\n\n\nfloat3 getSkyRadiance(float4 SunDirPow, float3 Direction)\n{\n\tDistantLightSample result;\n\tresult.transmittance = float3(1.0f);\n\tresult.radiance = float3(0.0f);\n\tif (gAmbientLightEnable > 0.0)\n\t{\n        float4 SunDirPow = texelFetch(iChannel3, ivec2(PIX_SUNDIRPOW), 0).xyzw;\n        result.radiance = getAtmosphereInScattering(Direction, SunDirPow.xyz, SunDirPow.w, result.transmittance);\n\t}\n\treturn result.radiance;\n}\nfloat3 getSkyTransmittance(float4 SunDirPow, float3 Direction)\n{\n\tDistantLightSample result;\n\tresult.transmittance = float3(1.0f);\n\tresult.radiance = float3(0.0f);\n\tif (gAmbientLightEnable > 0.0)\n\t{\n        float4 SunDirPow = texelFetch(iChannel3, ivec2(PIX_SUNDIRPOW), 0).xyzw;\n        result.radiance = getAtmosphereInScattering(Direction, SunDirPow.xyz, SunDirPow.w, result.transmittance);\n\t}\n\treturn result.transmittance;\n}\n\nfloat3 TransmittanceEstimation(in SpectralPathTracingContext ptc, in float3 direction)\n{\n\tfloat3 beamTransmittance = float3(1.0f);\n\tfloat3 P0 = ptc.P + direction * RAYDPOS;\n\tfloat3 P1 = float3(0.);\n\tif (getNearestIntersectionFullVolume(createRay(P0, direction), P1))\n\t\tbeamTransmittance = Transmittance(ptc, P0, P1);\n\treturn beamTransmittance;\n}\n\n\n\nvoid lightGenerateSample(inout SpectralPathTracingContext ptc, out float3 direction, out float3 value, out float pdf, out float3 beamTransmittance, out bool isDeltaLight)\n{\n\tbeamTransmittance = float3(1.0f);\n\tfloat sourceCount = gSunLightEnable + gAmbientLightEnable;\n\tif (sourceCount == 0.0f)\n\t{\n\t\tisDeltaLight = true;\n\t\tpdf = 0.0f;\n\t\tvalue = float3(0.0f);\n\t\tdirection = float3(1.0, 0.0, 0.0);\n\t\treturn;\n\t}\n\n\tfloat zeta = random01(ptc);\n\tif (zeta <= (gAmbientLightEnable / sourceCount))\n\t{\n\t\t// Evaluate a random direction\n\t\tdirection = getUniformSphereSample(random01(ptc), random01(ptc));\n\n\t\t// Evaluate the value and pdf\n\t\tpdf = (gAmbientLightEnable / sourceCount) * 1.0f / (4.0f * PI);\n\t\tvalue = getSkyRadiance(ptc.SunDirPow, direction);\n\n\t\t// Evaluate the transmittance\n\t\tbeamTransmittance = TransmittanceEstimation(ptc, direction);\n\n\t\tisDeltaLight = false;\n\t}\n\telse // if (zeta <= ((gAmbientLightEnable + gSunLightEnable) / sourceCount))\n\t{\n\t\t// Transmittance throught the sky\n\t\tfloat3 sunSkyTransmittance = getSkyTransmittance(ptc.SunDirPow, ptc.SunDirPow.xyz);\n\n\t\t// From direction, evaluate the beamTransmittance, value and pdf\n\t\tdirection = ptc.SunDirPow.xyz;\n\t\tvalue = ptc.SunDirPow.www * sunSkyTransmittance;\n\t\tpdf = gSunLightEnable / sourceCount;\n\n\t\t// Evaluate the transmittance\n\t\tbeamTransmittance = TransmittanceEstimation(ptc, direction);\n\n\t\tisDeltaLight = true;\n\t}\n}\n\n\n\n////////////////////////////////////////////////////////////\n// Misc functions\n////////////////////////////////////////////////////////////\n\n// From http://jcgt.org/published/0006/01/01/\nvoid CreateOrthonormalBasis(in float3 n, out float3 b1, out float3 b2)\n{\n\tfloat sign = n.z >= 0.0f ? 1.0f : -1.0f; // copysignf(1.0f, n.z);\n\tfloat a = -1.0f / (sign + n.z);\n\tfloat b = n.x * n.y * a;\n\tb1 = float3(1.0f + sign * n.x * n.x * a, sign * b, -sign * n.x);\n\tb2 = float3(b, sign + n.y * n.y * a, -n.y);\n}\n\nfloat mean(float3 v)\n{\n\treturn dot(v, float3(1.0f / 3.0f, 1.0f / 3.0f, 1.0f / 3.0f));\n}\n\n// Multiple importance sampling\nfloat mis(int nsample1, float pdf1, int nsample2, float pdf2)\n{\n#if 1\n\treturn (float(nsample1) * pdf1) / (float(nsample1) * pdf1 + float(nsample2) * pdf2);\n#else\n\tfloat factor1 = nsample1 * pdf1;\n\tfloat factor2 = nsample2 * pdf2;\n\treturn (factor1 * factor2) / (factor1 * factor1 + factor2 * factor2);\n#endif\n}\n\n\n\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// Volume integrator relying on spectral tracking\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// http://drz.disneyresearch.com/~jnovak/publications/SDTracking/index.html\n// https://twitter.com/yiningkarlli\n// https://twitter.com/_jannovak\n\n\nbool Integrate(\n\tinout SpectralPathTracingContext ptc,\n\tin Ray wi,\n\tinout float3 P, // closestHit\n\tout float3 transmittance,\n\tout float3 weight,\n\tinout Ray wo) \n{\n    transmittance = float3(0.);\n    weight = float3(0.);\n\tfloat3 P0 = ptc.P;\n\tif (!getNearestIntersectionFullVolume(createRay(P0, wi.d), P))\n\t\treturn false;\n\n\tfloat tMax = length(P - P0);\n\n\tbool eventScatter = false;\n\tbool eventAbsorb = false;\n\n\tconst float3 oneThird = float3(1.0f / 3.0f, 1.0f / 3.0f, 1.0f / 3.0f);\n\n\tfloat t = 0.0f;\n\tMediumSample3 medium;\n\tmedium.scattering = float3(0.0f);\n\tmedium.absorption = float3(0.0f);\n\tmedium.extinction = float3(0.0f);\n\tmedium.albedo = float3(0.0f);\n\tfloat3 pathVertexWeight = float3(0.0f);\n\tdo \n\t{\n\t\tif (ptc.extinctionMajorant == 0.0) break; // cannot importance sample, so stop right away\n\n\n\t\tfloat zeta = random01(ptc);\n\t\tt = t + infiniteTransmittanceIS(ptc.extinctionMajorant, zeta); // unbounded domain proportional with PDF to the transmittance\n\t\tif (t > tMax)\n\t\t\tbreak; // Did not terminate in the volume\n\n\t\t// Update the shading context\n\t\tfloat3 P1 = P0 + t * wi.d;\n\t\tptc.P = P1;\n\n\t\t// Recompute the local extinction after updating the shading context\n\t\tmedium = sampleMedium(ptc);\n\n        // Implements spectral tracking\n        // See https://jannovak.info/publications/SDTracking/index.html\n\n\t\t// Spectral tracking weights\n\t\tfloat3 Un = max(float3(0.0), ptc.extinctionMajorant - medium.absorption - medium.scattering);\n\t\tfloat avgUaW = dot(oneThird, medium.absorption * ptc.pathWeight);\n\t\tfloat avgUsW = dot(oneThird, medium.scattering * ptc.pathWeight);\n\t\tfloat avgUnW = dot(oneThird, Un                * ptc.pathWeight);\n\t\tfloat cInv = 1.0 / (avgUaW + avgUsW + avgUnW);\n\t\tfloat Pa = avgUaW * cInv;\n\t\tfloat Ps = avgUsW * cInv;\n\t\tfloat Pn = avgUnW * cInv;\n\n\n\t\tfloat xi = random01(ptc);\n\t\tif (xi <= Ps && Ps > 0.0) // Also check that probability>0.0 to avoid false positive test due to float accuracy and resulting Nan\n\t\t{\n\t\t\teventScatter = true;\n\t\t\tpathVertexWeight = medium.scattering / (ptc.extinctionMajorant * Ps);\n\t\t}\n\t\telse if (xi < (1.0 - Pn) && Pa>0.0)\n\t\t{\n\t\t\teventAbsorb = true;\n\t\t\tpathVertexWeight = medium.absorption / (ptc.extinctionMajorant * Pa);\t// TODOSTVPT apply that total path weight on emissive.\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpathVertexWeight = Un / (ptc.extinctionMajorant * Pn);\n\t\t\tptc.pathWeight *= pathVertexWeight; // always accumulate\n\t\t}\n\t\t\n\t} while (!(eventScatter || eventAbsorb));\n\n\t//if (eventScatter && all(medium.extinction > 0.0))\n\tif (eventScatter && medium.extinction.x > 0.0 && medium.extinction.y > 0.0 && medium.extinction.z > 0.0)\n\t{\n\t\tP = ptc.P;\n\n\t\ttransmittance = float3(1.0f);\n\t\tweight = float3(1.0f);\n\n\t\tptc.pathWeight *= pathVertexWeight;\n\t}\n\telse if (eventAbsorb)\n\t{\n\t\tP = ptc.P;\n\n\t\ttransmittance = float3(0.0f);\t// will set throughput to 0 and stop processing loop\n\t\tweight = float3(0.0f);\t\t\t// will remove lighting\n\n\t\tptc.pathWeight *= pathVertexWeight;\n\t}\n\telse\n\t{\n\t\tP = P0 + tMax * wi.d; // out of the volume range\n\n\t\ttransmittance = float3(1.0f);\n\t\tweight = float3(1.0f);\n\n\t\tptc.nullMaterial = true; // notify out of the volume\n\t\t//ptc.pathWeight *= pathVertexWeight;\tNot needed as this is already handled in the loop above each time a null event happen\n\t}\n\n\two = createRay( P + wi.d*RAYDPOS, wi.d );\n\n\treturn true;\n}\n\n\n\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n// Lighting integrator relying on spectral tracking\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n\n#define V_DEBUG_PHASE\t 0\n#define V_DEBUG_ONLYPATH 0\n\n\nvoid mainImage( out float4 fragColor, in float2 fragCoord )\n{    \n\tfloat2 uv = fragCoord.xy / iResolution.xy;\n    float time = iTime;\n    \n    fragColor = float4(0,0,0,0);\n    if(iFrame < 5)\n    {\n        return;\n    }\n    \n    \n\tvec2 mouseControl = iMouse.xy / iResolution.xy;\n    \n    // Load camera state\n    float3 camPos  = texelFetch(iChannel3, ivec2(PIX_CAMPOS), 0).xyz;\n    float3 up      = texelFetch(iChannel3, ivec2(PIX_CAMUP), 0).xyz;\n    float3 left    = texelFetch(iChannel3, ivec2(PIX_CAMLEFT), 0).xyz;\n    float3 forward = texelFetch(iChannel3, ivec2(PIX_CAMFORWARD), 0).xyz;\n    \n    // View diretion in camera space\n    float3 viewDir = normalize(float3((fragCoord.xy - iResolution.xy*0.5) / iResolution.y, 1.0));\n    viewDir.xy *= 0.7f;\n    viewDir = normalize(viewDir);\n    float3 worldDir = viewDir.x*left + viewDir.y*up + viewDir.z*forward;\n    \n\t// Global uniform participating media properties\n\tfloat3 scatteringCoef = gScattering;\n\tfloat3 absorptionCoef = gAbsorption;\n\tfloat3 extinctionCoef = scatteringCoef + absorptionCoef;\n\tfloat3 albedo         = getAlbedo(scatteringCoef, extinctionCoef);\n\n\n\n\t//\n\t// Initialise the tracing context\n\t//\n\tSpectralPathTracingContext ptc;\n\tptc.nullMaterial = false;\n\n\tptc.P = float3(0.0);\t\t// TODOSTVPT remove ptc.P and float3 P below? but carefullm used by sampleMedium for instance\n\tptc.V = float3(0.0);\n\tptc.ray = createRay(float3(0.0), float3(0.0));\n    \n    ptc.SunDirPow = texelFetch(iChannel3, ivec2(PIX_SUNDIRPOW), 0);\n\n\tptc.extinctionMajorant = max(extinctionCoef.r, max(extinctionCoef.g, extinctionCoef.b));\n\tptc.pathWeight = float3(1.0f);\n\n\tptc.screenPixelPos = uint2(fragCoord.xy);\n\tptc.randomState = (fragCoord.x + fragCoord.y*iResolution.x) + float(uint(uint(iFrame)*123u)%32768u);\n\n\t//\n\t// Trace the scene\n\t//\n\tfloat3 L = float3(0.0f);\n\t{\n\t\tfloat3 throughput = float3(1.0f);\n\t\tRay ray = createRay(camPos, worldDir); // ray from camera to pixel\n\n\t\tfloat3 P = camPos;\t\t\t\t\t\t\t// Default start point when the camera is inside a volume\n\t\tfloat3 prevDebugPos = P;\n\n\n\t\tint step = 0;\n\t\tbool hasScattered = false;\n\t\twhile (step < gMaxPathDepth && throughput.x>0.0 && throughput.y>0.0 && throughput.z>0.0)\n\t\t{\n\t\t\t// store current context: ray, intersection point P, etc.\n\t\t\tptc.ray = ray;\n\t\t\tptc.P = P + ray.d * RAYDPOS;\n\t\t\tptc.V = -ray.d;\n\n\t\t\t// Skipping all the solid surface BRDF code in our case...\n\t\t\tfloat3 sampleDirection = ray.d;\n\n\t\t\t// Compute next ray from last intersection.\n\t\t\t// From there, next ray is the reference ray for volumetric interactions.\n\t\t\tRay nextRay = createRay(P + sampleDirection * RAYDPOS, sampleDirection);\n\n\t\t\tif (insideAnyVolume(nextRay))\n\t\t\t{\n\t\t\t\tfloat3 transmittance = float3(0.0);\n\t\t\t\tfloat3 weight = float3(0.0);\n                \n                Ray nextRay_tmp;\n                nextRay_tmp.o = nextRay.o;\n                nextRay_tmp.d = nextRay.d;\n\t\t\t\tbool hasCollision = Integrate(ptc, nextRay_tmp, P, transmittance, weight, nextRay);\n\n\t\t\t\tif (hasCollision && !ptc.nullMaterial)\n\t\t\t\t{\n\t\t\t\t\tfloat3 lightL;\n\t\t\t\t\tfloat bsdfL;\n\t\t\t\t\tfloat3 beamTransmittance;\n\t\t\t\t\tfloat lightPdf, bsdfPdf;\n\t\t\t\t\tfloat misWeight;\n\t\t\t\t\tfloat3 sampleDirection;\n\t\t\t\t\tbool isDeltaLight;\n\n\t\t\t\t\t// The shading context has already been advanced to the scatter location. \n\t\t\t\t\t// Now compute direct lighting after evaluating the local scattering albedo and extinction.\n\n\t\t\t\t\t// There is not multiple importance sampling here. Either a sun or sky sample is taken during an event. The result matches PBRT perfectly.\n                    // TODO implement MIS as in my other non spectral volume path tracer\n\t\t\t\t\tlightGenerateSample(ptc, sampleDirection, lightL, lightPdf, beamTransmittance, isDeltaLight);\n\t\t\t\t\tphaseEvaluateSample(ptc, sampleDirection, lightL, bsdfL, bsdfPdf);\n\t\t\t\t\tfloat3 Lv = lightL * bsdfL * beamTransmittance / (lightPdf);\n\n\t\t\t\t\tL += weight * throughput * Lv * transmittance * ptc.pathWeight;\n\t\t\t\t\tthroughput *= transmittance;\n\n\t\t\t\t\tif (insideAnyVolume(nextRay))\n\t\t\t\t\t{\n\t\t\t\t\t\tfloat phaseValue;\n\t\t\t\t\t\tfloat phasePdf;\n\t\t\t\t\t\tphaseGenerateSample(ptc, nextRay.d, phaseValue, phasePdf);\n\t\t\t\t\t\thasScattered = true;\n\t\t\t\t\t\tthroughput *= phaseValue / phasePdf;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (insideAnyVolume(nextRay))\n\t\t\t\t{\n\t\t\t\t\t//step--;\t// to not have internal subdivision affect path depth\n\t\t\t\t\tptc.nullMaterial = false;\n\t\t\t\t}\n\t\t\t\telse // out of any volume\n\t\t\t\t{\n\t\t\t\t\t// In this case we are getting out of a volume in case of a nullmaterial. If the ray has not scattered we want to sample distance lighting.\n\t\t\t\t\t// Otherwise, if the ray has been scattered or absorbed, we should not sample the distance lighting (it is already correctly sampled on the path vertex)\n\t\t\t\t\t// This is tested with hasScattered and is mandatory to succesfully pass the furnace test correctly with multi scattering.\n\t\t\t\t\tif (!hasScattered)\n\t\t\t\t\t{\n\t\t\t\t\t\tL += getSkyRadiance(ptc.SunDirPow, ray.d) * ptc.pathWeight;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Exit if no more intersections are found (opaque or volume) then accumulate distant lighting. (outside of the medium bounding volume)\n\t\t\t\tif (!getNearestIntersectionFullVolume(nextRay, P))\n\t\t\t\t{\n\t\t\t\t\tL += getSkyRadiance(ptc.SunDirPow, ray.d) * ptc.pathWeight;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n                \n                \n\t\t\t}\n\n\t\t\tray = nextRay;\n\t\t\tstep++;\n\t\t}\n    \n\t}\n\n    \n    fragColor = float4(L, 1.0f);\n}\n\n\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "volume",
                        "id": 40,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/aea6b99da1d53055107966b59ac5444fc8bc7b3ce2d0bbb6a4a3cbae1d97f3aa.bin"
                    },
                    {
                        "channel": 3,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Combine the just traced BufferC with history BufferD\n// Reset accumulation if needed according to input\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tfloat2 uv = fragCoord.xy / iResolution.xy;\n    float time = iTime;\n    \n    bool bFullReset = FullReset;  \n    bFullReset = bFullReset || texelFetch(iChannel2, ivec2(PIX_RESETACCUM), 0).x > 0.0f;\n    \n    fragColor = texture(iChannel0, uv) + (bFullReset ? float4(0.0f) : texture(iChannel1, uv));\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Buffer D",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 260
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}