{
    "Shader": {
        "info": {
            "date": "1715962651",
            "description": "wip todo:\n-connect to nearest neighbours\n-random activation based on neural preferences\n-weights positive and negative\n-re-offset to other points\n-.. etc",
            "flags": 32,
            "hasliked": 0,
            "id": "4XcGRr",
            "likes": 3,
            "name": "Neural Avalanche Critical Point",
            "published": 3,
            "tags": [
                "neuralcriticalpointavalanche"
            ],
            "usePreview": 0,
            "username": "Chrisy",
            "viewed": 125
        },
        "renderpass": [
            {
                "code": "void mainImage( out vec4 fragColor, in vec2 U )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = U/iResolution.xy;\n    //Resolution\n    ivec2 iR = ivec2(iResolution.xy);\n\n    // neuron connects to right neighbour with same ID (U)\n    ivec2 iV = ivec2(U);\n    //time as integer\n    int iF = int(iFrame);\n\n    //loops till the edge of the Window\n    int iLoop = iF%iR.x;\n    // Time varying pixel color\n    vec3 col = 0.5 + 0.5*cos(iTime+uv.xyx+vec3(0,2,4));\n    vec4 a = texelFetch(iChannel0,ivec2(U),0);\n    // fetch right frame neural outputs and map to vertical bar chart\n    vec4 output_activation = texelFetch(iChannel0,ivec2(iResolution.x-1.0,uv.x*iResolution.y),0);\n    // fetch left frame neural inputs and map to vertical bar chart\n    vec4 input_activation = texelFetch(iChannel0,ivec2(0.0,uv.x*iResolution.y),0);\n    a.y*=1.;\n    a.x*=1.0;\n    col.xyz = a.xyz;\n    if(iV.x==iLoop){col.z=322222.0;}\n    \n    // output blue bars\n    col.z +=output_activation.x>uv.y?32222.0:0.0;\n    // input black bars\n    col *=input_activation.x>uv.y?0.7:1.0;\n    \n    // Output to screen\n    fragColor = vec4(col,1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "void mainImage( out vec4 o, vec2 U )\n{   \n\n    // LEGEND:\n    // input is a sensory activation is the very left of the window frame\n    // output is also an activation is the very right of the window frame\n    // point is a neuron, input or output.\n    // neuron is everything but input and output!\n    // o.y = offset to next connected neuron\n    // o.x = activation\n    // o.z = connection weight \n    \n    \n    \n    //CONSTANTS:\n     float energyLoss = 1.0-1.0/float(iResolution.x); // set energy loss to half the window so it decays for random neurons to take over\n    //const float randomActivationConstant = 0.00001;\n    const float randomActivationConstant = 0.00001;\n    const uint initSeed = 551u;\n    // Out color\n    o = vec4(0.0,0.0,0.0,1.0);\n\n    //Resolution\n    ivec2 iR = ivec2(iResolution.xy);\n\n    // neuron connects to right neighbour with same ID (U)\n    ivec2 iV = ivec2(U);\n    //time as integer\n    int iF = int(iFrame);\n\n    //loops till the edge of the Window\n    int iLoop = iF%iR.x;\n    \n    //random in U and V\n    float rand = hash( u(iV.x) + hashi(iV.y)+initSeed );\n    //random in U and V and Time\n    float randVT =  hash(u(iV.y) + hashi(iV.x) + hashi(iF));\n    \n    // current point index\n    int cIdx = getIDX(iV); // Center/ Current Index\n    \n\n    // get the nearest random right neighbour as an Index (ivec2). this is done by adding +1 to the time\n    //ivec2 randCoordNeighbour = limitU(ivec2(iV.x,randVT*float(iR.y))); // random right neighbour location\n \n    ivec2 randCoordNeighbour = limitU(ivec2(iV.x-1,iV.y+int((randVT*2.0-1.0)*8.0))); // random right neighbour location\n\n    // convert to index int1\n    int randNeighbourIDX =getIDX(randCoordNeighbour); // Random Neighbour Index\n    \n    // is left most! Meaning the input of the neural net and least abstract and absolute information\n    bool isInput = iV.x==0;\n    // is right most! Meaning the output of the neural net and will produce new information such as action (moving muscles etc)\n    bool isOutput = iV.x==iR.x;\n    //is abstraction/Neuron! everything that happens between input and output is an abstraction. the more to the center of the Neural net the more abstract!\n    bool isNeuron =  !isInput&&!isOutput;\n    // is the randomNeighbour that is connected to the current point\n    bool isRandNeighbour = randNeighbourIDX==cIdx;\n\n    //fetch some points only nearest so far.. should reach far to the right! North, East and West\n    vec4 c = texelFetch(iChannel0,limitU(iV),0);\n    vec4 n = texelFetch(iChannel0,limitU(iV+ivec2(0,1)),0);\n    vec4 s = texelFetch(iChannel0,limitU(iV+ivec2(0,-1)),0);\n    vec4 e = texelFetch(iChannel0,limitU(iV+ivec2(1,0)),0);\n    vec4 w = texelFetch(iChannel0,limitU(iV+ivec2(-1,0)),0);\n    // random connection of current point\n    vec4 randE = texelFetch(iChannel0,randCoordNeighbour,0);\n    vec4 randConnectionE=vec4(0.0);\n    \n    randConnectionE = texelFetch(iChannel0,limitU(ivec2(iV.x-1,iV.y+int((c.y*2.0-1.0)*8.0))),0);\n    //randConnectionE = randE;\n   \n    //vec2 ConnectionDirection = randConnectionE\n    bool isRandNeighbourPoint = abs(float(randConnectionE.y)-float(cIdx))>1.;\n\n   \n    // Write input to the neural Net! Constant for now. later on it has to simulate real world pulses\n    // such as light stimulation. on off etc or sound.\n    if(iF==0 || iMouse.x>=iResolution.x-4.0){\n    float randActiviation = rand<0.5&&isInput?1.0:-1.0; // random inputs activation\n    o.x = randActiviation;\n    o.y = randVT;\n    //if(c.y<0.51){o.y = randVT;}\n    // write current frame as lastFrame\n    }else{\n    o = c;\n    }\n\n    // decide where to put the connection based on time frame  for debuging\n    //float randConnection = rand<0.5&&iV.x==iLoop?1.0:-1.0; // random inputs activation\n\n    // get all connections as quick as possible\n    //float randConnection = rand<0.5&&iV.x==iLoop-1?1.0:-1.0; // random inputs activation\n    \n    \n    // create random neighbour connection only 1 for now. should be up to 10,000\n    // only create a connection if the point is unused\n    \n    \n        \n    float sumLocal = (n.x+s.x+e.x+w.x+c.x)/5.0;\n    \n    \n    // random neuron activation\n    \n    // all neuron logic\n    if(isNeuron){\n    \n    //if left is active and right is not then trigger  binary version\n    //if(w.x>c.x){o.x =1.0;}\n    \n     // if connection is 0 but current point is activated and spiking,\n     // then make the connected point active! branch version\n     //if(randConnectionE.x==0.0 &&c.x>1.0 && isRandNeighbourPoint ){o.x=1.0;}\n     \n     // smooth version only linear movement..  just for debuging.\n     o.x = (randConnectionE.x+c.x)*0.5;\n    \n    // just shows a blue line where the current time is\n       //o.x = (randConnectionE.x+c.x)*0.5;\n    \n    if(randVT<randomActivationConstant ){o.x = 5.0;}// activation strength is based on importance of that neuron such as the word \"Hate\"\n    // all neurons can't sustain fatigue. Everything is in pulses\n    o.x*=energyLoss; // energy loss\n    }\n     \n     \n     //debug\n     //o.z = randConnectionE.x>c.x?1.0:0.0;\n      \n  \n     \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "\n//#define hashi(x)   lowbias32(uint(x))\n  #define hashi(x)   triple32(uint(x)) \n #define limitU(a) min(max(a,ivec2(0)),iR)\n  #define hash(x)  ( float( hashi(x) ) / float( 0xffffffffU ) )\n  #define getIDX(v) ((v.x * iR.x) + v.y)\n  #define u(x) uint(x)\n  #define u2(x) uvec2(x)\n//bias: 0.17353355999581582 ( very probably the best of its kind )\nuint lowbias32(uint x)\n{\n   \n    x ^= x >> 16;\n    x *= 0x7feb352dU;\n    x ^= x >> 15;\n    x *= 0x846ca68bU;\n    x ^= x >> 16;\n    return x;\n}\n\n// bias: 0.020888578919738908 = minimal theoretic limit\nuint triple32(uint x)\n{\n\n    x ^= x >> 17;\n    x *= 0xed5ad4bbU;\n    x ^= x >> 11;\n    x *= 0xac4c1b51U;\n    x ^= x >> 15;\n    x *= 0x31848babU;\n    x ^= x >> 14;\n    return x;\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}