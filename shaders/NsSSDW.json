{
    "Shader": {
        "info": {
            "date": "1620736258",
            "description": "Constructing and applying a repeat 3D Turing pattern using a custom filtering method.",
            "flags": 32,
            "hasliked": 0,
            "id": "NsSSDW",
            "likes": 67,
            "name": "3D Turing Texture",
            "published": 3,
            "tags": [
                "3d",
                "dof",
                "diffusion",
                "turing"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 1247
        },
        "renderpass": [
            {
                "code": "/*\n\n    3D Turing Texture\n    -----------------\n\n    Constructing and applying a repeat 3D Turing pattern: Diffusion patterns are \n    nothing new, but I couldn't find any 3D wrappable ones, so I've put this up \n    as a reference. It's based on something I did years ago.\n    \n    There are a couple of things I needed to overcome before presenting it in\n    shader form. The main one was that diffusion patterns take a while to create, \n    and people get bored very quickly... OK, I mean, I get bored very quickly. :D\n    To get around this, I skipped over the usual dual concentration approach, and\n    took a custom filtered approach, which forms patterns much faster. Unfortunately, \n    the initial precalculation can be a little intensive, so I hid it behind an \n    oldschool waiting screen -- similar to the ones that people used to use in old \n    demos.\n    \n    It was also necessary to render the Turing pattern efficiently in realtime,\n    which meant it had to be relatively fast and smooth. Smooth rendering usually \n    requires eight texel reads per pass, which is a little slow. One unfiltered \n    texture read is fast, but not visually acceptable. I got around the problem by \n    storing four neighbor values in adjoining buffer channels, which meant only two \n    texel reads per pass. The problem with the dual concentrated solution diffusion \n    appraoch is that twice as many storage slots are required, which in turn requires \n    twice the reads at half the resolution. However, the filtered noise approach \n    that I've used bypasses that -- By the way, I have yet another filtering method \n    that is much nicer that I'll demonstrate in due course.\n    \n    The structure itself is just a few layers of transcendentals combined to make\n    something that looks geometric and natural at the same time. By warping the \n    structure, you can make it look more organic, but I wanted to keep it simple.\n \n    Anyway, the pattern here is only bump mapped, but it is fast enough to be used\n    via the distance function. I've applied a basic depth of field effect to round \n    things out. I have a few more traditional looking 3D Turing pattern surfaces \n    that I'll release a little later on.\n    \n    \n    \n    // Other examples:\n    \n    // I love this one.\n    3D diffusion limited aggregation - Mattz\n    https://www.shadertoy.com/view/XtSfRz\n    \n    // 2D, but really nice. Wyatt has heaps of diffusion (2D and 3D) related \n    // examples on here that are worth looking through.\n    Symbiosis - Wyatt\n    https://www.shadertoy.com/view/WssXW2\n    \n    \n*/\n\n\n// Just a very basic depth of field routine -- I find a lot of it is\n// common sense. Basically, you store the scene distance from the camera \n// in the fourth channel, then use it to determine how blurry you want\n// your image to be at that particular distance.\n//\n// For instance, in this case, I want pixels that are 12 units away from \n// the camera to be in focus (not blurred) and for things to get more \n// blurry as you move away from that point -- aptly named the focal point \n// for non camera people. :)\n//\n// I based this on old code of mine, but adopted things that I found in \n// IQ and Nesvi7's examples, which you can find here:\n//\n// Ladybug - IQ\n// https://www.shadertoy.com/view/4tByz3\n//\n// Cube surface II - Nesvi7\n// https://www.shadertoy.com/view/Mty3DV\n//\nvec3 DpthFld(sampler2D iCh, vec2 uv){\n\t\n    // Focal point and circle of confusion.\n    const float focD = 12., coc = 5.;\n    // Linear distance from either side of the focal point.\n    float l = abs(focD - texture(iCh, uv).w);\n    // Using it to calculate the DOF.\n    vec2 dof = clamp((l - coc)/(2.*coc), 0., 1.)/vec2(800, 450)*2.5; \n    \n    // Combine samples. Samples with a larger DOF value are taken further \n    // away from the original point, and appear blurrier.\n    vec3 acc = vec3(0);\n\n    for(int i = 0; i<49; i++){\n        // Accumulate samples.\n        acc += texture(iCh, uv + (vec2(i/7, i%7) - 3.)*dof).xyz;\n    }\n\n    // Return the new variably blurred value.\n    return acc /= 49.;\n    // Visual debug representation of DOF value.\n    //return vec3(length(dof)*450./2.5);\n}\n\n\n// This would normally be a very quick routine that displays\n// the scene and gives it a distance of field effect, but I \n// wanted to put in a little loading bar graphic just to let\n// people know that some precalculation is happening in the \n// background... and to give impatient people like me a visual \n// representation of the time it's going to take. :D\n//\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n\n    \n    \n    int tFrame = iFrame - frame0;\n    if(tFrame<300){\n    \n        // Precalculating and producing the Turing pattern can take \n        // a few seconds, so rather than present a stuttering mess to \n        // the user, I put together an oldschool demoscene waiting\n        // screen graphic... I was in a hurry, so the logic could be\n        // better, but it does the job.\n        \n        \n        vec2 uv = (fragCoord - iResolution.xy*.5)/iResolution.y;\n        float sf = 1./iResolution.y;\n        \n        float l = float(tFrame - 1)/300.*300./299.;\n        //l = floor(l*31.999)/31.;\n        float x = uv.x;//floor(uv.x*15.999)/15.;\n        \n        float back = max(abs(uv.x) - .25, abs(uv.y) - .02);\n        vec3 col = mix(vec3(0), vec3(1), 1. - smoothstep(0., sf, back - .01));\n        col = mix(col, vec3(0), 1. - smoothstep(0., sf*2., back - .005));\n        \n        uv = uv + vec2(.25*(1. - l), 0);\n        float bar = max(abs(uv.x) - .25*l, abs(uv.y) - .02);\n        \n        vec3 bCol = .5 + .5*cos(6.2831*x*.5 + vec3(0, 1, 2) + 4.);\n        bCol *= max((uv.y + .01)/.015, 0.) + .25;\n        \n        col = mix(col, bCol, 1. - smoothstep(0., sf, bar));\n        \n        fragColor = vec4(sqrt(max(col, 0.)), 1);\n        \n        // I prefer \"if-else\" statements, but sometimes GPUs will calculate the\n        // whole statement, which can be expensive. Hence the less readable \"return\"\n        // approach.\n        return;\n    }\n    \n    // If we're not precalculating (above), apply some depth of field, then present\n    // to the screen.\n    vec3 col = DpthFld(iChannel0, fragCoord/iResolution.xy);\n    \n\tfragColor = vec4(sqrt(max(col, 0.)), 1);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// The cubemap texture resultion.\n#define cubemapRes vec2(1024)\n\nint frame0 = 0;\n\n// If you use all four channels of one 1024 by 1024 cube face, that would be\n// 4096000 storage slots (1024*1024*4), which just so happens be 160 cubed.\n// In other words, you can store the isosurface values of a 160 voxel per side\n// cube into one cube face of the cubemap.\n//\n// The voxel cube dimensions: That's the one you'd change, but I don't really\n// see the point, since setting it to the maximum resolution makes the most\n// sense. For demonstrative purposes, dropping it to say, vec3(80), will show\n// how a decrease in resolution will affect things. Increasing it to above the\n// allowable resolution (for one cube face) to say, vec3(200), will display the\n// wrapping issues.\n//\n// On a side note, I'm going to put up an example later that uses four of the \n// cubemap faces, which should boost the resolution to 256... and hopefully,\n// not add too much to the complexity, and consequent lag that would follow.\nconst vec3 dimsVox = vec3(100); \nconst vec3 scale = vec3(1, 1, 1);\nconst vec3 dims = dimsVox/scale;\n\n \n// Reading into one of the cube faces, according to the face ID. To save on cycles,\n// I'd hardcode the face you're after into all but the least costly of situations.\n// This particular function is used just once for an update in the \"CubeA\" tab.\n//\n// The four cube sides - Left, back, right, front.\n// NEGATIVE_X, POSITIVE_Z, POSITIVE_X, NEGATIVE_Z\n// vec3(-.5, uv.yx), vec3(uv, .5), vec3(.5, uv.y, -uv.x), vec3(-uv.x, uv.y, -.5).\n//\n// Bottom and top.\n// NEGATIVE_Y, POSITIVE_Y\n// vec3(uv.x, -.5, uv.y), vec3(uv.x, .5, -uv.y).\nvec4 tx(samplerCube tx, vec2 p, int id){    \n\n    vec4 rTx;\n    \n    vec2 uv = fract(p) - .5;\n    // It's important to snap to the pixel centers. The people complaining about\n    // seam line problems are probably not doing this.\n    //p = (floor(p*cubemapRes) + .5)/cubemapRes; \n    \n    vec3[6] fcP = vec3[6](vec3(-.5, uv.yx), vec3(.5, uv.y, -uv.x), vec3(uv.x, -.5, uv.y),\n                          vec3(uv.x, .5, -uv.y), vec3(-uv.x, uv.y, -.5), vec3(uv, .5));\n \n    \n    return texture(tx, fcP[id]);\n}\n\n\nvec4 texMapCh(samplerCube tx, vec3 p){\n    \n    p *= dims;\n    int ch = (int(p.x*4.)&3);\n    p = mod(floor(p), dims);\n    float offset = dot(p, vec3(1, dims.x, dims.x*dims.y));\n    vec2 uv = mod(floor(offset/vec2(1, cubemapRes.x)), cubemapRes);\n    // It's important to snap to the pixel centers. The people complaining about\n    // seam line problems are probably not doing this.\n    uv = fract((uv + .5)/cubemapRes) - .5;\n    return vec4(1)*texture(tx, vec3(-.5, uv.yx))[ch];\n    \n}\n\n// Used in conjunction with the function below. When doing things eight times over, any \n// saving is important. If I could trim this down more, I would, but there's wrapping\n// and pixel snapping to consider. Having said that, I might take another look at it,\n// at some stage.\nvec4 txChSm(samplerCube tx, in vec3 p){\n   \n    p = mod(floor(p), dims);\n    //vec2 uv = mod(floor(dot(p, vec3(1, dims.x, dims.x*dims.y))/vec2(1, cubemapRes.x)), cubemapRes);\n    vec2 uv = floor(dot(p, vec3(1, dims.x, dims.x*dims.y))/vec2(1, cubemapRes.x));\n    // It's important to snap to the pixel centers. The people complaining about\n    // seam line problems are probably... definitely not doing this. :)\n    uv = fract((uv + .5)/cubemapRes) - .5;\n    return texture(tx, vec3(-.5, uv.yx));\n    \n}\n\n// Smooth texture interpolation that access individual channels: You really need this -- I \n// wish you didn't, but you do. I wrote it a while ago, and I'm pretty confident that it works. \n// The smoothing factor isn't helpful at all, which surprises me -- I'm guessing it molds things \n// to the shape of a cube. Anyway, it's written in the same way that you'd write any cubic \n// interpolation: 8 corners, then a linear interpolation using the corners as boundaries.\n//\n// It's possible to use more sophisticated techniques to achieve better smoothing, but as you \n// could imagine, they require more samples, and are more expensive, so you'd have to think about \n// it before heading in that direction -- Perhaps for texturing and bump mapping.\nvec4 texMapSmoothCh(samplerCube tx, vec3 p){\n\n    // Voxel corner helper vector.\n\t//const vec3 e = vec3(0, 1, 1./4.);\n\tconst vec2 e = vec2(0, 1);\n\n    // Technically, this will center things, but it's relative, and not necessary here.\n    //p -= .5/dimsVox.x;\n    \n    p *= dimsVox;\n    vec3 ip = floor(p);\n    p -= ip;\n\n    \n    //int ch = (int(ip.x)&3), chNxt = ((ch + 1)&3);  //int(mod(ip.x, 4.))\n    //ip.x /= 4.;\n/*\n    float c = mix(mix(mix(txChSm(tx, ip + e.xxx, ch).x, txChSm(tx, ip + e.yxx, chNxt).x, p.x),\n                     mix(txChSm(tx, ip + e.xyx, ch).x, txChSm(tx, ip + e.yyx, chNxt).x, p.x), p.y),\n                 mix(mix(txChSm(tx, ip + e.xxy, ch).x, txChSm(tx, ip + e.yxy, chNxt).x, p.x),\n                     mix(txChSm(tx, ip + e.xyy, ch).x, txChSm(tx, ip + e.yyy, chNxt).x, p.x), p.y), p.z);\n*/\n    \n     vec4 txA = txChSm(tx, ip + e.xxx);\n     vec4 txB = txChSm(tx, ip + e.yxx);\n\n     float c = mix(mix(mix(txA.x, txB.x, p.x), mix(txA.y, txB.y, p.x), p.y),\n                   mix(mix(txA.z, txB.z, p.x), mix(txA.w, txB.w, p.x), p.y), p.z);\n\n \n \t/*   \n    // For fun, I tried a straight up average. It didn't work. :)\n    vec4 c = (txChSm(tx, ip + e.xxx*sc, ch) + txChSm(tx, ip + e.yxx*sc, chNxt) +\n             txChSm(tx, ip + e.xyx*sc, ch) + txChSm(tx, ip + e.yyx*sc, chNxt) +\n             txChSm(tx, ip + e.xxy*sc, ch) + txChSm(tx, ip + e.yxy*sc, chNxt) +\n             txChSm(tx, ip + e.xyy*sc, ch) + txChSm(tx, ip + e.yyy*sc, chNxt) + txChSm(tx, ip + e.yyy*.5, ch))/9.;\n \t*/\n    \n    return vec4(c);\n\n}\n\n// If you want things to wrap, you need a wrapping scale. It's not so important\n// here, because we're performing a wrapped blur. Wrapping is not much different\n// to regular mapping. You just need to put \"p = mod(p, gSc)\" in the hash function\n// for anything that's procedurally generated with random numbers. If you're using\n// a repeat texture, then that'll have to wrap too.\nvec3 gSc;\n\n\n// Fabrice's concise, 2D rotation formula.\n//mat2 rot2(float th){ vec2 a = sin(vec2(1.5707963, 0) + th); return mat2(a, -a.y, a.x); }\n// Standard 2D rotation formula - Nimitz says it's faster, so that's good enough for me. :)\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, s, -s, c); }\n\n\n// 3x1 hash function.\n//float hash31(vec3 p){ return fract(sin(dot(p, vec3(21.471, 157.897, 113.243)))*45758.5453); }\n\n\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){\n    return fract(sin(dot(p, vec2(27.609, 157.583)))*43758.5453); \n}\n\n// David_Hoskins puts together some pretty reliable hash functions. This is \n// his unsigned integer based vec3 to vec3 version.\nvec3 hash33(vec3 p){\n\n    p = mod(p, gSc);\n\tuvec3 q = uvec3(ivec3(p))*uvec3(1597334673U, 3812015801U, 2798796415U);\n\tq = (q.x^q.y^q.z)*uvec3(1597334673U, 3812015801U, 2798796415U);\n\treturn -1. + 2. * vec3(q) * (1./float(0xffffffffU));\n}\n\n\n\n\n// Commutative smooth maximum function. Provided by Tomkh, and taken \n// from Alex Evans's (aka Statix) talk: \n// http://media.lolrus.mediamolecule.com/AlexEvans_SIGGRAPH-2015.pdf\n// Credited to Dave Smith @media molecule.\nfloat smax(float a, float b, float k){\n    \n   float f = max(0., 1. - abs(b - a)/k);\n   return max(a, b) + k*.25*f*f;\n}\n\n\n// Commutative smooth minimum function. Provided by Tomkh, and taken \n// from Alex Evans's (aka Statix) talk: \n// http://media.lolrus.mediamolecule.com/AlexEvans_SIGGRAPH-2015.pdf\n// Credited to Dave Smith @media molecule.\nfloat smin(float a, float b, float k){\n\n   float f = max(0., 1. - abs(b - a)/k);\n   return min(a, b) - k*.25*f*f;\n}\n\n\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// It can be a bit fiddly filling all four channels in at once, but thankfully, this is\n// all calculated at startup. The idea is to put the function you wish to use in the\n// middle of the loop here, instead of writing it out four times over.\nvec4 funcFace0(vec3 p){\n   \n    \n    vec4 col;\n    \n    for(int i = 0; i<4; i++){\n        \n        vec3 q = p + vec3(0, i&1, i>>1)/dims.x;\n        \n        vec3 rotF = vec3(0); // Rotation factor - Range: [0, 1].\n        \n        // Wrapped multilayer tertiary order Voronoi.\n        gSc = vec3(64);\n        vec3 sc = vec3(1);\n        float res = hash33(q*gSc).x*.5 + .5;\n        \n        //res = smoothstep(.4, .6, res);\n        \n        //float res = 1. - n3DT(q*gSc);\n    \n        // The pixel channel value: On a side note, setting it to \"v.y\" is interesting,\n        // but not the look we're going for here.\n        col[i] = res;//max(1. - res*.85 - res*res*.15, 0.);\n\n        \n    }\n    \n    // Return the four function values -- One for each channel.\n    return col;\n    \n}\n\n\n\n// 3D weighted blur routine. Not much different to a 2D one. \nvec4 blur3D(samplerCube iCh, vec3 p, int N, int faceID) {\n\n    vec4 col;\n\n    p *= dims;\n    \n    vec3 mid = floor(vec3(N) - .5)/2.;\n    vec4 res = vec4(0);\n    float sum = 0.;\n\n     \n    for(int k = 0; k<N; k++){ \n       for(int j = 0; j<N; j++){ \n            for(int i = 0; i<N; i++){\n                 \n                vec3 offs = vec3(i, j, k) - mid; // Pixel offset.\n                \n                // Weighted blur value.\n                float a = max(length(vec2(N)/2.) - length(offs), 0.); a *= a;\n                //float a = 1./(1. + dot(offs, offs));\n                //float a = exp(-(dot(offs, offs)/float(N*N))/2.);///float(N)*.39894;\n                \n                // Weighted texture value.\n                res += txChSm(iCh, p + offs)*a;\n\n                sum += a;\n            }\n        }\n    }\n\n\n    return res/sum;\n    \n}\n\n// Converting your UV coordinates to 3D coordinates. I've seen some pretty longwinded\n// obfuscated conversions out there, but it shouldn't require anything more than \n// the following. By the way, the figure \"dims.x\" is factored down by four to account\n// for the four pixel channels being utilized, but the logic is the same.\nvec3 convert2DTo3D(vec2 uv){\n    \n    // Converting the fract(uv) coordinates from the zero to one range to the whole\n    // number, zero to... 1023 range.\n    uv = floor(uv*cubemapRes);\n    \n    // Converting the UV coordinate to a linear representation. The idea is to convert the\n    // 2D UV coordinates to a linear value, then use that to represent the 3D coordinates.\n    // This way, you can effectively fit all kinds of 3D dimensions into a 2D texture array\n    // without having to concern yourself with 2D texture wrapping issues. In theory, so \n    // long as the dimensions fit, and the X dimension is a multiple of four, then anything\n    // goes. As mentioned, the maximum cubic dimension allowable for one cube face is \n    // 160 cubed. In that respect, rectangular dimensions, like vec3(160, 80, 320), etc, \n    // would also fit.\n    //\n    // For instance, the 137th pixel in the third row on a 1024 by 1024 cubemap face texture \n    // would be the number 2185 (2*1024 + 137).\n    float iPos = dot(uv, vec2(1, cubemapRes.x));\n    \n    // In this case the XY slices comprise of 160 pixels (or whatever number we choose) along \n    // X and Y, so the pixel position in any block would be modulo 160*160. The xyBlock position \n    // would have to be converted to X and Y positions, which would be xyBlock mod dimX, and \n    // floor(xyBlock/dimX) mod dimY respectively. The Z position would depend on how many \n    // 160 by 160 blocks deep we're in, which translates to floor(iPos/(dimX*dimY)).\n    //\n    // Anyway, that's what the following lines represent.\n    \n    // XY block (or slice) linear position.\n    float xyBlock = mod(iPos, dims.x*dims.y);\n    \n    // Converting to X, Y and Z position.\n    vec3 p = vec3(mod(floor(vec3(xyBlock, xyBlock, iPos)/vec3(1, dims.x, dims.x*dims.y)), dims));\n    \n    //vec3 p = vec3(mod(xySlice, dims.x), mod(floor((xySlice)/dims.x), dims.y),\n                  //floor((iPos)/(dims.x*dims.y)));\n    \n    // It's not necessary, but I'm converting the 3D coordinates back to the zero to one\n    // range... There'd be nothing stopping you from centralizing things (p/dims - .5), but \n    // this will do.\n    return p/dims;\n}\n\n\n\n\n\n// Cube mapping - Adapted from one of Fizzer's routines. \nint CubeFaceCoords(vec3 p){\n\n    // Elegant cubic space stepping trick, as seen in many voxel related examples.\n    vec3 f = abs(p); f = step(f.zxy, f)*step(f.yzx, f); \n    \n    ivec3 idF = ivec3(p.x<.0? 0 : 1, p.y<.0? 2 : 3, p.z<0.? 4 : 5);\n    \n    return f.x>.5? idF.x : f.y>.5? idF.y : idF.z; \n}\n\n\n\nvoid mainCubemap(out vec4 fragColor, in vec2 fragCoord, in vec3 rayOri, in vec3 rayDir){\n    \n    \n    // UV coordinates.\n    //\n    // For whatever reason (which I'd love expained), the Y coordinates flip each\n    // frame if I don't negate the coordinates here -- I'm assuming this is internal, \n    // a VFlip thing, or there's something I'm missing. If there are experts out there, \n    // any feedback would be welcome. :)\n    vec2 uv = fract(fragCoord/iResolution.y*vec2(1, -1));\n    \n    // Adapting one of Fizzer's old cube mapping routines to obtain the cube face ID \n    // from the ray direction vector.\n    int faceID = CubeFaceCoords(rayDir);\n  \n  \n    // Pixel storage.\n    vec4 col;\n    \n\n    // Initial conditions -- Performed upon initiation.\n    //if(abs(tx(iChannel0, uv, 5).w - iResolution.y)>.001){\n    //if(iFrame<1){\n    //\n    // Great hack, by IQ, to ensure that this loads either on the first frame, or in the\n    // event that the texture hasn't loaded (this happens a lot), wait, then do it...\n    // Well kind of. Either way, it works. It's quite clever, which means that it's something \n    // I never would have considered. :)\n    if(textureSize(iChannel0,0).x<2 || iFrame<1){\n        \n        // This is part of an ugly hack that attempts to force the GPU compiler\n        // to not unroll the Voronoi loops. Not sure if it'll work, but I'm \n        // trying it anyway, in the hope to get compiler times down on some\n        // machines. For the record, this takes about 3 seconds to compile on \n        // my machine.\n        frame0 = iFrame;\n        \n \n        \n        \n        // Fill the first cube face with a custom 3D function.\n        if(faceID==0){\n            \n            vec3 p = convert2DTo3D(uv);\n            \n            col = funcFace0(p);\n           \n        }\n\n        /*\n        // Last channel on the last face: Used to store the current \n        // resolution to ensure loading... Yeah, it's wasteful and it\n        // slows things down, but until there's a reliable initiation\n        // variable, I guess it'll have to do. :)\n        if(faceID==5){\n            \n            col.w = iResolution.y;\n        }\n        */\n\n        \n    }\n    else {\n    \n \n        //\n        if(faceID!=0 || (iFrame - frame0)>300) {\n            \n            \n            fragColor = tx(iChannel0, uv, faceID);\n            \n            // I couldn't understand why my frame rate was lagging after\n            // applying an \"if-else\" statement, then realized the GPU will\n            // still sometime calculate \"if\" and \"else\", even though only \n            // one is executed. Using a return gets around that.\n            return;\n        }\n        \n        \n        vec3 p = convert2DTo3D(uv);\n\n        \n        // Here's the quickest 3D Turing pattern tutorial you're ever going\n        // to get: Create some noise, then take the difference between the a \n        // large blur and a smaller one. You're welcome. :D\n        //\n        // Seriously though, this is just a huge shortcut that I kind of made\n        // up on the spot.\n        vec4 filt1 = blur3D(iChannel0, p, 3, faceID);\n        vec4 filt2 = blur3D(iChannel0, p, 5, faceID);\n\n        col = clamp(filt1*2. - filt2, -1., 1.);\n\n    }\n    \n    \n    // Update the cubemap faces.\n    fragColor = col;\n    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    }
                ],
                "name": "Cube A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 41
                    }
                ],
                "type": "cubemap"
            },
            {
                "code": "\n\n// Max ray distance.\n#define FAR 50. \n\n// Surface delta.\n#define DELTA .001\n\n// Just the two passes. If your computer doesn't enjoy running the program,\n// change the number of passes to 1.\n#define PASSES 2\n\n\n\n// Camera path. Arranged to coincide with the frequency of the lattice.\nvec3 path(float t){\n  \n    //return vec3(0, 0, t); // Straight path.\n    //return vec3(-sin(t/2.), sin(t/2.)*.5 + 1.57, t); // Windy path.\n    \n    //float s = sin(t/24.)*cos(t/12.);\n    //return vec3(s*12., 0., t);\n    \n    float a = sin(t*.11);\n    float b = cos(t*.14);\n    return vec3(a*4. - b*1.5, b*1.2 + a*1., t);\n    \n}\n\n\n\n// Tri-Planar blending function. Based on an old Nvidia tutorial by Ryan Geiss.\nvec3 tex3D(sampler2D t, in vec3 p, in vec3 n){ \n    \n    n = max(abs(n) - .2, .001); // max(n*n, .001), etc.\n    n /= dot(n, vec3(1)); \n    //n /= length(n);\n    \n\tvec3 tx = texture(t, p.yz).xyz;\n    vec3 ty = texture(t, p.zx).xyz;\n    vec3 tz = texture(t, p.xy).xyz;\n    \n    // Textures are stored in sRGB (I think), so you have to convert them to linear space \n    // (squaring is a rough approximation) prior to working with them... or something like that. :)\n    // Once the final color value is gamma corrected, you should see correct looking colors.\n    return (tx*tx*n.x + ty*ty*n.y + tz*tz*n.z);\n}\n\n\n// The 3D surface function. This one converts the 3D position to a 3D voxel \n// position in the cubemap, then reads the isovalue. Actually, one option does\n// that, and the other is forced to read out eight neighboring values to \n// produce a smooth interpolated value. As in real life, it looks nicer, but \n// costs more. :)\nfloat txFace0(in vec3 p){\n    \n    #if 0\n    \n    // One sample... Ouch. :D It's a shame this doesn't work, because it's \n    // clearly faster. Unfortunately, it's virtually pointless from an aesthetic\n    // aspect, as you can see, but there'd be times when you could get away with it.\n    vec3 col = texMapCh(iChannel0, p).xyz;\n    \n    #else\n    \n    // Eight samples, for smooth interpolation. Still not as good as the real \n    // thing -- and by that, I mean, calculating on the fly. However, it's \n    // good enough. I'd need to think about it, but I'm wondering whether a\n    // four or five point tetrahedral interpolation would work? It makes my\n    // head hurt thinking about it right now, but it might. :)\n    vec3 col = texMapSmoothCh(iChannel0, p).xyz;\n    \n    #endif\n    \n    return col.x;\n    \n}\n\n\n\n// 3D surface function.\nfloat surfFunc3D(in vec3 p){ \n\n    return txFace0(p/3.)*.5 + .5;\n    \n}//\n\n \n// A simple transcendental distance function upon which to apply \n// the Turing pattern.\nfloat map(vec3 p){\n   \n    // 3D Turing pattern.\n    //float sf = surfFunc3D(p);\n    //sf = smoothstep(-.3, .3, sf - .5);\n \n    \n    p.xy -= path(p.z).xy;\n \n    // Twist along Z.\n    //float  ang = -p.z*.1;\n    //p.xy *= rot2(ang);\n    // Perturbation.\n    //p += cos(p*1.57 + sin(p.yzx*3.14159)*3.14159)*.05;\n    //p.xz += cos(p.xy*1.57*6. + sin(p.yz*3.14159*6.)*3.14159)*.01;\n    \n    \n    // Mixing layers of transcendental functions. Only three are\n    // used here, but higher numbers can look interesting.\n    \n    float d = 1e5;\n    const int n = 3;\n    const float fn = float(n);\n    \n    for(int i = 0; i<n; i++){\n        \n        vec3 q = p;\n        float a = float(i)*fn*2.422; //*6.283/fn\n        a *= a;\n        q.z += float(i)*float(i)*1.67; //*3./fn\n        q.xy *= rot2(a);\n        d = smin(d, (length(length(sin(q.xy) + cos(q.yz))) - .15), 1.);\n        \n    }\n    \n    // Applying the Turing pattern.\n    //d += (.5 - sf)*.025;\n    //d = abs(d) + (.5 - sf)*.0125;\n    \n    return d;\n\t\n}\n\n/*\n// A fake, noisy looking field - cheaply constructed from a spherized sinusoidal\n// combination. I came up with it when I was bored one day. :) Lousy to hone in\n// on, but it has the benefit of being able to guide a camera through it.\nfloat map(vec3 p){\n\n     // 3D Turing pattern.\n    //float sf = surfFunc3D(p);\n    //sf = smoothstep(-.3, .3, sf - .5);\n \n    p.xy -= path(p.z).xy; \n     \n\tp = cos(p*.315*1.25 + sin(p.zxy*.875*1.25)); // 3D sinusoidal mutation.\n    \n    \n    float n = length(p); // Spherize. The result is some mutated, spherical blob-like shapes.\n\n    \n    // It's an easy field to create, but not so great to hone in one. The \"1.4\" fudge factor\n    // is there to get a little extra distance... Obtained by trial and error.\n    n = (n - 1.025)*1.5;\n    \n    // Applying the Turing pattern.\n    //n = abs(n) + (.5-sf)*.0125;\n    //n += (.5 - sf)*.025;\n    \n    return n;\n    \n}\n*/\n\n\n// Basic raymarcher.\nfloat trace(in vec3 ro, in vec3 rd){\n\n    float t = 0., d;\n    \n    for(int i=0; i<96; i++){\n    \n        d = map(ro + rd*t);\n        // Note the \"t*b + a\" addition. Basically, we're putting less emphasis on accuracy, as\n        // \"t\" increases. It's a cheap trick that works in most situations... Not all, though.\n        if(abs(d)<DELTA*(t*.05 + 1.) || t>FAR) break; // Alternative: 0.001*max(t*.25, 1.), etc.\n        \n        // Ray shortening.\n        t += d*.75;\n    }\n\n    // Cap to the far distance plane.\n    return min(t, FAR);\n}\n\n\n// Surface bump function..\nfloat bumpSurf3D( in vec3 p){\n \n    // The Turing pattern.\n    float sf = surfFunc3D(p);\n      \n    // Shaping the pattern a bit.\n    return smoothstep(-.35, .35, sf - .5);\n\n}\n\n// Standard function-based bump mapping routine: This is the cheaper four tap version. There's\n// a six tap version (samples taken from either side of each axis), but this works well enough.\nvec3 doBumpMap(in vec3 p, in vec3 nor, float bumpfactor){\n    \n    // Larger sample distances give a less defined bump, but can sometimes lessen the aliasing.\n    const vec2 e = vec2(.003, 0); \n    \n    // Gradient vector: vec3(df/dx, df/dy, df/dz);\n    float ref = bumpSurf3D(p);\n   \n    vec3 grad = (vec3(bumpSurf3D(p - e.xyy),\n                      bumpSurf3D(p - e.yxy),\n                      bumpSurf3D(p - e.yyx)) - ref)/e.x; \n    \n    /*\n    // Six tap version, for comparisson. No discernible visual difference, in a lot of cases.\n    vec3 grad = vec3(bumpSurf3D(p - e.xyy) - bumpSurf3D(p + e.xyy),\n                     bumpSurf3D(p - e.yxy) - bumpSurf3D(p + e.yxy),\n                     bumpSurf3D(p - e.yyx) - bumpSurf3D(p + e.yyx))/e.x*.5;\n    */ \n  \n    // Adjusting the tangent vector so that it's perpendicular to the normal. It's some kind \n    // of orthogonal space fix using the Gram-Schmidt process, or something to that effect.\n    grad -= nor*dot(nor, grad);          \n         \n    // Applying the gradient vector to the normal. Larger bump factors make things more bumpy.\n    return normalize(nor + grad*bumpfactor);\n\t\n}\n\n\n// Standard normal function. It's not as fast as the tetrahedral calculation, but more symmetrical.\nvec3 getNormal(in vec3 p) {\n\tconst vec2 e = vec2(.001, 0);\n\treturn normalize(vec3(map(p + e.xyy) - map(p - e.xyy), map(p + e.yxy) - map(p - e.yxy),\t\n                          map(p + e.yyx) - map(p - e.yyx)));\n}\n\n// Cheap shadows are hard. In fact, I'd almost say, shadowing particular scenes with limited \n// iterations is impossible... However, I'd be very grateful if someone could prove me wrong. :)\nfloat softShadow(vec3 ro, vec3 lp, vec3 n, float k){\n\n    // More would be nicer. More is always nicer, but not really affordable... Not on my slow test machine, \n    // anyway.\n    const int iter = 24; \n    \n    ro += n*.0015; // Bumping the shadow off the hit point.\n    \n    vec3 rd = lp - ro; // Unnormalized direction ray.\n\n    float shade = 1.;\n    float t = 0.; \n    float end = max(length(rd), .0001);\n    //float stepDist = end/float(maxIterationsShad);\n    rd /= end;\n    \n    //rd = normalize(rd + (hash33R(ro + n) - .5)*.03);\n    \n\n    // Max shadow iterations - More iterations make nicer shadows, but slow things down. Obviously, the lowest \n    // number to give a decent shadow is the best one to choose. \n    for (int i = 0; i<iter; i++){\n\n        float d = map(ro + rd*t);\n        shade = min(shade, k*d/t);\n        //shade = min(shade, smoothstep(0., 1., k*h/dist)); // Subtle difference. Thanks to IQ for this tidbit.\n        // So many options here, and none are perfect: dist += min(h, .2), dist += clamp(h, .01, stepDist), etc.\n        t += clamp(d, .01, .25); \n        \n        \n        // Early exits from accumulative distance function calls tend to be a good thing.\n        if (d<0. || t>end) break; \n    }\n\n    // Sometimes, I'll add a constant to the final shade value, which lightens the shadow a bit --\n    // It's a preference thing. Really dark shadows look too brutal to me. Sometimes, I'll add \n    // AO also just for kicks. :)\n    return max(shade, 0.); \n}\n\n\n// I keep a collection of occlusion routines... OK, that sounded really nerdy. :)\n// Anyway, I like this one. I'm assuming it's based on IQ's original.\nfloat calcAO(in vec3 p, in vec3 n){\n\n\tfloat sca = 2., occ = 0.;\n    for( int i = min(iFrame, 0); i<5; i++ ){\n    \n        float hr = float(i + 1)*.15/5.;        \n        float d = map(p + n*hr);\n        occ += (hr - d)*sca;\n        sca *= .7;\n        \n        // Deliberately redundant line that may or may not stop the \n        // compiler from unrolling.\n        if(sca>1e5) break;\n    }\n    \n    return clamp(1. - occ, 0., 1.);\n}\n\n\nvoid mainImage(out vec4 e, in vec2 v){\n\n\n    // When precalculating on the cube map tab, return a black screen.\n    if (iFrame - frame0<=300) {\n        e = vec4(0);\n        return;\n    }\n    \n    \n    // Aspect correct UV coordinates. Only translation and scaling is required.\n    vec2 uv = (v - iResolution.xy*.5)/iResolution.y;\n    \n\t// Camera Setup.\n    float speed = 2.;\n    vec3 ro = path(iTime*speed); // Camera position, doubling as the ray origin.\n    vec3 lk = path(iTime*speed + .25);  // \"Look At\" position.\n    vec3 lp = path(iTime*speed + 5.); // Light position, somewhere near the moving camera.\n\t\n    // Light postion offset. Since the lattice structure is rotated about the XY plane, the light\n    // has to be rotated to match. See the \"map\" equation.\n    vec3 loffs =  vec3(0, 0, 0);\n    //vec2 a = sin(vec2(1.57, 0) - lp.z*1.57/10.);\n    //loffs.xy = mat2(a, -a.y, a.x)*loffs.xy; \n    lp += loffs;\n\n    // Using the above to produce the unit ray-direction vector.\n    float FOV = 1.;//3./3.14159; ///3. FOV - Field of view.\n    vec3 fwd = normalize(lk - ro);\n    vec3 rgt = normalize(vec3(fwd.z, 0., -fwd.x )); \n    vec3 up = cross(fwd, rgt);\n\n    // Unit direction ray.\n    vec3 rd = normalize(fwd/FOV + uv.x*rgt + uv.y*up);\n    // Lens distortion.\n    //vec3 r = fwd + FOV*(u.x*rgt + u.y*up);\n    //r = normalize(vec3(r.xy, (r.z - length(r.xy)*.25)));\n    \n    // Swiveling the camera from left to right when turning corners.\n    rd.xy = rot2(-path(lk.z).x/16. )*rd.xy;\n\n    // Set the initial position to the camera position.\n    vec3 sp = ro;\n    vec3 oRd;\n    \n    \n    \n    // Overall scene color.\n    vec3 col = vec3(0);\n    \n   \n    // Alpha, reflective factor, and fog distance.\n    float alpha = 1.;\n    float refFact = 1.;\n    float fogDist = 1e5;\n    \n    // Bouncing the ray around and collecting color along the way.\n    for(int j = min(0, iFrame); j<PASSES; j++){\n    \n        \n        // Color for this particular pass.\n        vec3 colL = vec3(0); \n        \n        float distanceFactor = 1.;\n\n        float freS = 1., fre2 = 1.;\n\n        // Raymarching.\n        float t = trace(sp, rd);\n         \n        // Fog distance.\n        if(j==0) fogDist = t;\n\n        // Advance the ray to the surface hit postion.\n        sp += rd*t;\n        \n        // Unit direction vector copy.\n        oRd = rd;\n\n        if(t<FAR){\n\n            // Surface normal.\n            vec3 sn = getNormal(sp)*distanceFactor;\n            \n            // Function based bump mapping.\n            sn = doBumpMap(sp, sn, .5/(1. + fogDist*fogDist*.03));///\n            \n            vec3 reflection = reflect(rd, sn);\n\n            // Light direction, vector.\n            vec3 ld = lp - sp;\n            float lDist = length(ld); // Light distance.\n            ld /= max(lDist, .0001);\n\n            // Light attenuation.\n            float att = 2./(1. + lDist*lDist*.03);\n            \n            \n            // Very, very cheap shadows -- Not used here.\n            //float sh = min(min(map(sp + ld*.08), map(sp + ld*.16)), \n            //           min(map(sp + ld*.24), map(sp + ld*.32)))/.08*1.5;\n            //sh = clamp(sh, 0., 1.);\n            float sh = softShadow(sp, lp, sn, 12.); // Shadows.\n            float ao = calcAO(sp, sn); // Ambient occlusion.\n\n            float dif = max(dot(ld, sn), 0.); // Diffuse value.\n            float spe = pow(max(dot(reflection, ld), 0.), 16.);\n            float fre = clamp(1. + dot(rd, sn), 0., 1.); // Fresnel reflection term.\n            fre2 = clamp(1. - abs(dot(rd, sn))*.5, 0., 1.); // Fresnel reflection term.\n            \n            // Ramping up the diffuse component for more of a metallic look.\n            dif = pow(dif, 4.)*2.;\n\n            //float Schlick = pow( 1. - max(dot(rd, normalize(rd + ld)), 0.), 5.);\n            //freS = mix(.25, 1., Schlick);  //F0 = .2 - Glass... or close enough.\n\n            // Surface texture.\n            vec3 tx = tex3D(iChannel1, sp/2., sn);\n            tx = smoothstep(0., .5, tx);\n            vec3 oCol = tx;\n            \n            // The Turing pattern.\n            float sf = surfFunc3D(sp);\n            \n            // Applying the Turing pattern.\n            oCol *= mix(vec3(.45, .5, .55), vec3(.15), 1. - smoothstep(-.03, .03, (sf - .5)));\n            // Edge highlighting or sorts.\n            oCol = mix(oCol, oCol*4., 1. - smoothstep(-.03, .03, abs(sf - .5) - .1));\n           \n            // Reflective factor: The idea is to reflect the darker part of the pattern less. \n            refFact = mix(1., .5, 1. - smoothstep(-.03, .03, (sf - .5)));\n            //refFact *= mix(1., 4., 1. - smoothstep(-.03, .03, abs(sf - .5) - .1));\n           \n           \n \n             \n            // Applying the above to color the suface.\n            colL = oCol*(dif*sh + .15 + vec3(1, .6, .3)*spe*sh*refFact*4.);\n            \n            // Attenuation and ambient occlusion.\n            colL *= att*ao;\n            \n            // Reflect off the surface.\n            rd = reflection; \n            \n            // Move just off the surface to avoid self collisions.\n            sp += sn*DELTA*1.1; \n\n        }\n\n        // Applying fog.\n        vec3 fogCol = mix( vec3(1.2, .7, .4).zyx, vec3(1), oRd.y*.5 + .5)*2.;\n        float td = min(length(sp - ro), FAR);\n        colL = mix(colL, fogCol, smoothstep(0., .99, td/FAR));\n\n        // Adding the color for this pass.\n        col += colL/float(PASSES)*alpha;\n        //col = mix(col, colL, alpha/float(j + 1));//*freS;\n        \n        // Overall reflective reduction.\n        alpha -= .25/float(PASSES);\n        // Individual reflective reduction.\n        alpha *= refFact;\n        \n    }\n    \n    \n    \n    e = vec4((max(col, 0.)), fogDist);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 3,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/95b90082f799f48677b4f206d856ad572f1d178c676269eac6347631d4447258.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}