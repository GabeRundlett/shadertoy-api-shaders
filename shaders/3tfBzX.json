{
    "Shader": {
        "info": {
            "date": "1597363196",
            "description": "Per-cell cubic interpolation on a regular grid of values and partial derivatives.\nReference function (red) overlayed with bicubically resampled version (cyan).\nApproximation error results in chromatic aberration.",
            "flags": 0,
            "hasliked": 0,
            "id": "3tfBzX",
            "likes": 17,
            "name": "Cubic Reconstruction",
            "published": 3,
            "tags": [
                "filter",
                "filtering",
                "bicubic",
                "convolution",
                "cubic",
                "interpolation",
                "tricubic",
                "reconstruction"
            ],
            "usePreview": 0,
            "username": "TinyTexel",
            "viewed": 690
        },
        "renderpass": [
            {
                "code": "// Lincense: CC0 (https://creativecommons.org/publicdomain/zero/1.0/)\n\n/*\n\tPer-cell cubic interpolation on a regular grid of values and partial derivatives.\n*/\n\n#define DISPLAY 0\n/*\n\t0 - reference function (red) overlayed with bicubically resampled version (cyan)\n\t1 - analytic normals | abs(laplacian) of bicubic approximation\n*/\n\n/*\nDerivation:\n\nOn a cartesian grid (tri-/bi-)linear interpolation is a popular reconstruction scheme as \nit requires data to only be read from a minimal neighborhood of grid vertices.\n\nIn the following we show how to generalize (tri-/bi-)linear interpolation in the case that we\nhave (partial) derivatives available at each grid vertex (in addition to scalar function values).\n\nFirst, we will derive the 1d interpolation scheme formulated as a convolution.\nGeneralizing the 1d result to higher dimensions is then similarly straightforward as it is in the case of linear interpolation.\n\nLet's consider the interpolation on the interval [0,1] and in particular the kernel positioned at the origin.\nFor linear interpolation this kernel is 1-x, i.e. a degree 1 polynomial:\n\n1\n|◣\n|▩◣\n|▩▩◣\n|▩▩▩◣\n0------1\n\nAdding derivatives at 0 and 1 as additional constrains requires us to raise this degree to 3\n(assuming we don't want to use piecwise quadratic polynomials, which, let's just assume, we don't).\n\nNow one might expect that we have to use the derivatives to somehow parametrize the shape of the\nreconstruction kernel, making the whole procedure quite a bit more complicated then it is when working with scalar sample values.\n\nFortunately this is not the case. Since the sum of two polynomials of a given degree is a polynomial of the same degree,\nwe can derive two complementary kernels of which the scaled contributions are additively combined to the final recontrucion result: \none kernel, kern_v, that ensures that the function values are correct at the sample positions while not affecting the derivatives, \nand another kernel, kern_d, that does the exact opposite, i.e. taking care of the derivatives while not affecting the values.\n\nThe constraints for kern_v and kern_d are therefore:\n\nkern_v(0)  = 1,\nkern_v(1)  = 0,\n\nkern_v(0)' = 0,\nkern_v(1)' = 0,\n\nkern_d(0)  = 0,\nkern_d(1)  = 0,\n\nkern_d(0)' = 1,\nkern_d(1)' = 0.\n\nThe resulting cubic polynomials are then:\n\nkern_v(x) = 1-x²(3-2x),\nkern_d(x) = x(x-1)².\n\nkern_v:\n1\n|▩◣\n|▩▩◣\n|▩▩▩\n|▩▩▩◣\n|▩▩▩▩◣▂\n0---------1\t\n\nkern_d:\n1\n|\n|\n|  \n|  ◢◣\n|◢▩▩▩◣▂\n0---------1\n\n(A proper plot of these kernels can be found here: https://www.shadertoy.com/view/wlsfzX)\n\nUsually it's more convenient to work with kernel definitions that are valid on the interval [-1,1].\nGeneralizing the equations of kern_v and kern_d accordingly requires only minor modifications:\n\nkern_v(x) = 1-x²(3-2|x|),\nkern_d(x) = x(|x|-1)².\n\n\nFor example, the reconstrution on the interval [0,1] is now performed as follows:\n\nf(x) = value(0) * kern_v(x  ) + derivative(0) * kern_d(x  ) + \n       value(1) * kern_v(x-1) + derivative(1) * kern_d(x-1).\n\nHere are two observations regarding kern_v and kern_d:\n1. kern_v is the cubic s-curve commonly referred to as smoothstep (just flipped upside down here).\n2. kern_d is a linear ramp x windowed by an offset parabola (x-1)².\n   This is similar to the surfel definition used by perlin noise. \n   However, the original perlin noise used smoothstep as the windowing function, resulting in a degree 4 polynomial.\n\n\nAs mentioned earlier, generalizing cubic to bi-cubic interpolation is relatively straightforward.\nSince we now have to deal with two partial derivatives, we need one more kernel.\nLet's write down the constraints for the kernel trio positioned at the origin (we are working on the 2d interval [0,1]x[0,1] now):\n\nkern_v(0,0) = 1,\nkern_v(1,0) = 0,\nkern_v(0,1) = 0,\nkern_v(1,1) = 0,\n\nkern_v(0,0)'x = 0,\nkern_v(1,0)'x = 0,\nkern_v(0,1)'x = 0,\nkern_v(1,1)'x = 0,\n\nkern_v(0,0)'y = 0,\nkern_v(1,0)'y = 0,\nkern_v(0,1)'y = 0,\nkern_v(1,1)'y = 0,\n\n\nkern_dx(0,0) = 0,\nkern_dx(1,0) = 0,\nkern_dx(0,1) = 0,\nkern_dx(1,1) = 0,\n\nkern_dx(0,0)'x = 1,\nkern_dx(1,0)'x = 0,\nkern_dx(0,1)'x = 0,\nkern_dx(1,1)'x = 0,\n\nkern_dx(0,0)'y = 0,\nkern_dx(1,0)'y = 0,\nkern_dx(0,1)'y = 0,\nkern_dx(1,1)'y = 0,\n\n\nkern_dy(0,0) = 0,\nkern_dy(1,0) = 0,\nkern_dy(0,1) = 0,\nkern_dy(1,1) = 0,\n\nkern_dy(0,0)'x = 0,\nkern_dy(1,0)'x = 0,\nkern_dy(0,1)'x = 0,\nkern_dy(1,1)'x = 0,\n\nkern_dy(0,0)'y = 1,\nkern_dy(1,0)'y = 0,\nkern_dy(0,1)'y = 0,\nkern_dy(1,1)'y = 0,\n\n\nLuckily it is not necessary to actually solve the resulting system of equations to figure out the polynomials.\nInstead we can just use our 1d results as building blocks to easily satisfy all of the constrains listed above:\n\nkern_v (x, y) = kern_v(x) * kern_v(y),\nkern_dx(x, y) = kern_d(x) * kern_v(y),\nkern_dy(x, y) = kern_d(y) * kern_v(x).\n\n\nGeneralizing further to 3d we get:\n\nkern_v (x, y, z) = kern_v(x) * kern_v(y) * kern_v(z),\nkern_dx(x, y, z) = kern_d(x) * kern_v(y) * kern_v(z),\nkern_dy(x, y, z) = kern_v(x) * kern_d(y) * kern_v(z),\nkern_dz(x, y, z) = kern_v(x) * kern_v(y) * kern_d(z).\n\n\nWhat I originally did not consider was that we can, and usually want to, include higher order partial derivatives \nin the reconstruction process. The reason for that is that the kernels have higher polynomial degrees in the diagonal directions.\nTo get the complete set of kernels for a given dimension we simply include all possible combinations of kern_v and kern_d: \n\nIn 2d we only need to add one missing kernel, kern_d2xy:\n\nkern_v   (x, y) = kern_v(x) * kern_v(y),\nkern_dx  (x, y) = kern_d(x) * kern_v(y),\nkern_dy  (x, y) = kern_v(x) * kern_d(y),\nkern_d2xy(x, y) = kern_d(x) * kern_d(y).\n\n\nIn 3d, however, we missed quite a few combinations:\n\nkern_v    (x, y, z) = kern_v(x) * kern_v(y) * kern_v(z),\nkern_dx   (x, y, z) = kern_d(x) * kern_v(y) * kern_v(z),\nkern_dy   (x, y, z) = kern_v(x) * kern_d(y) * kern_v(z),\nkern_dz   (x, y, z) = kern_v(x) * kern_v(y) * kern_d(z),\n\nkern_d2xy (x, y, z) = kern_d(x) * kern_d(y) * kern_v(z),\nkern_d2xz (x, y, z) = kern_d(x) * kern_v(y) * kern_d(z),\nkern_d2yz (x, y, z) = kern_v(x) * kern_d(y) * kern_d(z),\nkern_d3xyz(x, y, z) = kern_d(x) * kern_d(y) * kern_d(z),\n\n\nWhether we truncate our set of kernels or use the complete one mostly boils down to a performance-quality trade-off.\n\n\nWe can extent our evaluation scheme to also compute the partial derivatives.\nFor that we need the derivatives of the 1d kernels:\n\nkern_v(x)' = x(|x|6-6),\nkern_d(x)' = (|x|-1)(|x|3-1).\n\nIn 1d this is all we need: simply perform another reconstruction using these kernels.\n\nFor the kernel composition in multiple dimensions applying the chain rule will lead us to the realization that differentiating \nany kernel in a given direction simplifies to replacing the respective 1d kernel in the multiplication chain with its derivative.\n\nIn 2d, the kernels used to reconstruct the x and y partial derivatives are therefore\n\nkern_v   (x, y)'x = kern_v(x)' * kern_v(y),\nkern_dx  (x, y)'x = kern_d(x)' * kern_v(y),\nkern_dy  (x, y)'x = kern_v(x)' * kern_d(y),\nkern_d2xy(x, y)'x = kern_d(x)' * kern_d(y),\n\nand \n\nkern_v   (x, y)'y = kern_v(x) * kern_v(y)',\nkern_dx  (x, y)'y = kern_d(x) * kern_v(y)',\nkern_dy  (x, y)'y = kern_v(x) * kern_d(y)',\nkern_d2xy(x, y)'y = kern_d(x) * kern_d(y)',\n\nand if we need the xy derivative also\n\nkern_v   (x, y)'x'y = kern_v(x)' * kern_v(y)',\nkern_dx  (x, y)'x'y = kern_d(x)' * kern_v(y)',\nkern_dy  (x, y)'x'y = kern_v(x)' * kern_d(y)',\nkern_d2xy(x, y)'x'y = kern_d(x)' * kern_d(y)'.\n\n\nThe kernel construction in 3d works analogously.\n\n\nRelated:\n\n- https://www.shadertoy.com/view/WtsBDH | \"Bicubic C2 cont. Interpolation\"  (practical application)\n- https://www.shadertoy.com/view/wtByDt | \"Single Sample Bicubic Sampling\"  (performance optimization via approximation)\n- https://www.shadertoy.com/view/wlsfzX | \"Cubic Reconstruction Kernels\"    (plot of kern_v and kern_d)\n- https://www.shadertoy.com/view/wtByDt | \"Single Sample Bicubic Sampling\"  (approximating the reconstruction with a single sample in 2d)\n- https://www.shadertoy.com/view/tdtyzj | \"Single Sample Tricubic Sampling\" (approximating the reconstruction with a single sample in 3d)\n\n*/\n\nfloat kern_v(float x) { return 1.0-x*x*(3.0-2.0*abs(x)); }\nfloat kern_d(float x) { float o = abs(x)-1.0; return x*(o*o); }\n\nfloat kern_vD1(float x) { return x*(abs(x)*6.0-6.0); }\nfloat kern_dD1(float x) { return (abs(x)-1.0)*(abs(x)*3.0-1.0); }\n\nfloat kern_vD2(float x) { return abs(x) * 12.0 - 6.0; }\nfloat kern_dD2(float x) { return x * 6.0 + (x > 0.0 ? -4.0 : 4.0); }\n\n\nvec4 kern(vec2 p)\n{\n    return vec4(kern_d(p.x) * kern_v(p.y),\n                kern_v(p.x) * kern_d(p.y),\n                kern_d(p.x) * kern_d(p.y),\n                kern_v(p.x) * kern_v(p.y));\n}\n\nmat4 kern4x4(vec2 p)\n{\n    vec2 v   = vec2(kern_v  (p.x), kern_v  (p.y));\n    vec2 d   = vec2(kern_d  (p.x), kern_d  (p.y));\n    \n    vec2 vD1 = vec2(kern_vD1(p.x), kern_vD1(p.y));\n    vec2 dD1 = vec2(kern_dD1(p.x), kern_dD1(p.y));\n    \n    mat4 m = mat4\n    (\n        /*   kernDx       |  kernDy       |  kernDxy        |  kern    */\n        vec4(dD1.x * v.y  ,  d.x * vD1.y  ,  dD1.x * vD1.y  ,  d.x * v.y),\n        vec4(vD1.x * d.y  ,  v.x * dD1.y  ,  vD1.x * dD1.y  ,  v.x * d.y),\n        vec4(dD1.x * d.y  ,  d.x * dD1.y  ,  dD1.x * dD1.y  ,  d.x * d.y),\n        vec4(vD1.x * v.y  ,  v.x * vD1.y  ,  vD1.x * vD1.y  ,  v.x * v.y)\n    );\n    \n    return m;\n}\n\nvoid kern4x4(vec2 p, out mat4 mA, out mat4 mB)\n{\n    vec2 v   = vec2(kern_v  (p.x), kern_v  (p.y));\n    vec2 d   = vec2(kern_d  (p.x), kern_d  (p.y));\n    \n    vec2 vD1 = vec2(kern_vD1(p.x), kern_vD1(p.y));\n    vec2 dD1 = vec2(kern_dD1(p.x), kern_dD1(p.y));\n    \n    vec2 vD2 = vec2(kern_vD2(p.x), kern_vD2(p.y));\n    vec2 dD2 = vec2(kern_dD2(p.x), kern_dD2(p.y));\n    \n    mA = mat4\n    (\n        /*   kernDx       |  kernDy       |  kernDxy        |  kern    */\n        vec4(dD1.x * v.y  ,  d.x * vD1.y  ,  dD1.x * vD1.y  ,  d.x * v.y),\n        vec4(vD1.x * d.y  ,  v.x * dD1.y  ,  vD1.x * dD1.y  ,  v.x * d.y),\n        vec4(dD1.x * d.y  ,  d.x * dD1.y  ,  dD1.x * dD1.y  ,  d.x * d.y),\n        vec4(vD1.x * v.y  ,  v.x * vD1.y  ,  vD1.x * vD1.y  ,  v.x * v.y)\n    );\n\n    mB = mat4\n    (\n        /*   kernDxx      |  kernDyy      |  kernDxxy       |  kernDxyy    */\n        vec4(dD2.x * v.y  ,  d.x * vD2.y  ,  dD2.x * vD1.y  ,  dD1.x * vD2.y),\n        vec4(vD2.x * d.y  ,  v.x * dD2.y  ,  vD2.x * dD1.y  ,  vD1.x * dD2.y),\n        vec4(dD2.x * d.y  ,  d.x * dD2.y  ,  dD2.x * dD1.y  ,  dD1.x * dD2.y),\n        vec4(vD2.x * v.y  ,  v.x * vD2.y  ,  vD2.x * vD1.y  ,  vD1.x * vD2.y)\n    );\n}\n\n\nfloat Map(vec2 uv)\n{\n    vec2 p = vec2(7.1, 4.3);\n    p += vec2(cos(iTime), sin(iTime*0.37));\n\n    p.x +=     cos((uv.x + uv.y*0.5 )*2.0 + iTime);\n    p.y += 4.0*cos((uv.y + uv.x*0.25) + iTime*0.627);\n    \n    float res = dot(uv-p, uv-p) - 8.0;\n\n     res += 16.0 * (sin(uv.x * Pi*0.5) * sin(uv.y * Pi*0.5));// add some ddxy heavy stuff\n    \n    return res;\n}\n\n#if 1\nvec4 Map2(vec2 uv)\n{\n    float o = 1.0/32.0;// using a power of 2 is good for retaining precision\n    \n    float v[4];\n    for(int j = 0; j < 2; ++j)\n    for(int i = 0; i < 2; ++i)\n        v[i + 2 * j] = Map(uv + (vec2(i, j) - 0.5) * o);\n        \n    // | 2 | 3 |\n    // | 0 | 1 |\n    \n    float dx = ((v[3]+v[1]) - (v[2]+v[0])) / (2.0 * o);\n    float dy = ((v[2]+v[3]) - (v[0]+v[1])) / (2.0 * o);\n    \n    float ddxy = ((v[3] - v[1]) - \n                  (v[2] - v[0])) / (o*o);\n    \n    return vec4(dx, dy, ddxy, (v[0]+v[1]+v[2]+v[3])*0.25);\n}\n#else\nvec4 Map2(vec2 uv)\n{\n    float o = 1.0/64.0;\n    \n    float v[9];\n    for(int j = 0; j < 3; ++j)\n    for(int i = 0; i < 3; ++i)\n        v[i + 3 * j] = Map(uv + (vec2(i, j) - 1.0) * o);\n        \n    // | 6 | 7 | 8 |\n    // | 3 | 4 | 5 |\n    // | 0 | 1 | 2 |\n    \n    float dx = (v[5] - v[3]) / (2.0 * o);\n    float dy = (v[7] - v[1]) / (2.0 * o);\n    \n    float ddxy = ((v[8] - v[6]) - \n                  (v[2] - v[0])) / (4.0 * o*o);\n    \n    return vec4(dx, dy, ddxy, v[4]);\n}\n#endif\n\n\nfloat SampleBicubic(vec2 p)\n{\n    vec2 p0 = floor(p);\n    vec2 l  = p - p0;\n    \n    float f = 0.0;\n\tfor (float y = 0.0; y < 2.0; ++y)\n\tfor (float x = 0.0; x < 2.0; ++x)\n    {\n        vec4 n = Map2(p0 + vec2(x, y));\n        \n        f += dot(kern(l - vec2(x, y)), n);\n    }\n    \n    return f;\n}\n\nvec4 SampleBicubic2(vec2 p)\n{\n    vec2 p0 = floor(p);\n    vec2 l  = p - p0;\n    \n    vec4 r = vec4(0.0);\n\tfor (float y = 0.0; y < 2.0; ++y)\n\tfor (float x = 0.0; x < 2.0; ++x)\n    {\n        vec4 n = Map2(p0 + vec2(x, y));\n        \n        r += kern4x4(l - vec2(x, y)) * n;\n    }\n    \n    return r;\n}\n\nvec4 SampleBicubic3(vec2 p, out vec4 d2)\n{\n    vec2 p0 = floor(p);\n    vec2 l  = p - p0;\n    \n    vec4 r = vec4(0.0);\n\tfor (float y = 0.0; y < 2.0; ++y)\n\tfor (float x = 0.0; x < 2.0; ++x)\n    {\n        vec4 n = Map2(p0 + vec2(x, y));\n        \n        mat4 mA, mB;\n        kern4x4(l - vec2(x, y), /*out*/ mA, mB);\n        \n        r  += mA * n;\n        d2 += mB * n;\n    }\n    \n    return r;\n}\n\nvoid mainImage( out vec4 outCol, in vec2 uv0 )\n{\n    vec2 uv = uv0 - 0.5;\n\tvec2 tex = (uv0 - vec2((iResolution.x-iResolution.y) * 0.5, 0.0)) / iResolution.yy;\n    \n    vec3 col = vec3(0.0);\n    \n    //vec2 p = uv0.xy*0.02;\n    float s = iResolution.x / 16.0;\n    vec2 p = uv0 / s;\n    \n#if DISPLAY == 0\n   \n    float base = 0.012;\n    \n   #if 1\n    vec2 grid0 = quintic(clamp01((abs(fract(p.xy + 0.5) - 0.5)-0.01)*0.75*s));\n    \n    base *= mix(0.5, 1.0, min(grid0.x, grid0.y));\n   #endif\n    \n    vec4 approx = SampleBicubic2(p);\n    {\n    \tvec4 c = approx;\n    \tfloat line = 1.0 - quintic(clamp01((abs(c.w / length(c.xy)) - 0.01)*0.5*s));\n    \tcol.gb = vec2(mix(c.w < 0.0 ? 0.0 : clamp01(1.0-c.w*0.25) * 0.25 + base, 1.0, line));\n    }\n    \n    vec4 ref = Map2(p);\n    {\n    \tvec4 c = ref;\n    \tfloat line = 1.0 - quintic(clamp01((abs(c.w / length(c.xy)) - 0.01)*0.5*s));\n    \tcol.r = mix(c.w < 0.0 ? 0.0 : clamp01(1.0-c.w*0.25) * 0.25 + base, 1.0, line);\n    }\n    \n    col = sRGB_EOTF(clamp01(col));\n    \n#else\n    \n    vec4 d2;\n    vec4 approx = SampleBicubic3(p, /*out*/ d2);\n    \n    if(uv0.x < iResolution.x*0.5)\n    {\n        col = normalize(vec3(-approx.xy*0.1, 1.0))*0.5+0.5;\n    }\n    else\n    {\n    \tcol = vec3(abs(d2.x + d2.y)*0.005);\n      //col = vec3(abs(d2.x + d2.y + d2.z + d2.w)*0.005);\n    }\n    \n#endif\n    \n\toutCol = vec4(col, 1.0);\n}\n\n\n\n\n",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "#define rsqrt inversesqrt\n#define clamp01(x) clamp(x, 0.0, 1.0)\n#define If(cond, resT, resF) mix(resF, resT, cond)\n\nconst float Pi = 3.141593;\nconst float Pi05 = Pi * 0.5;\nconst float Pi2 = Pi * 2.0;\n\nfloat Pow2(float x) {return x*x;}\nfloat Pow3(float x) {return x*x*x;}\nfloat Pow4(float x) {return Pow2(Pow2(x));}\n\nvec2 CosSin(float ang) {return vec2(cos(ang), sin(ang));}\n\nfloat SqrLen(float v) {return v * v;}\nfloat SqrLen(vec2  v) {return dot(v, v);}\nfloat SqrLen(vec3  v) {return dot(v, v);}\nfloat SqrLen(vec4  v) {return dot(v, v);}\n\nfloat GammaEncode(float x) {return pow(x, 1.0 / 2.2);}\nvec2 GammaEncode(vec2 x) {return pow(x, vec2(1.0 / 2.2));}\nvec3 GammaEncode(vec3 x) {return pow(x, vec3(1.0 / 2.2));}\nvec4 GammaEncode(vec4 x) {return pow(x, vec4(1.0 / 2.2));}\n\nfloat sRGB_EOTF(float c)\n{\n    return c > 0.0031308 ? pow(c, 1.0/2.4) * 1.055 - 0.055 : c * 12.92;\n}\n\nvec3 sRGB_EOTF(vec3 rgb)\n{\n    return If(greaterThan(rgb, vec3(0.0031308)), pow(rgb, vec3(1.0/2.4)) * 1.055 - 0.055, rgb * 12.92);\n}\n\nfloat ddxyLen(float v) { return length(vec2(dFdx(v), dFdy(v))); }\nfloat ddxyRcpLen(float v) { return rsqrt( Pow2(dFdx(v)) + Pow2(dFdy(v)) ); }\n\nfloat rescale(float v) { return v * ddxyRcpLen(v); }\n\nfloat Graph(float f, float b)\n{\n    return clamp01(1.0 - (abs(rescale(f))-0.5-b)); \n}\n\nfloat cubic(float x) {return x*x*(3.-2.*x);}\nvec2  cubic(vec2  x) {return x*x*(3.-2.*x);}\nvec3  cubic(vec3  x) {return x*x*(3.-2.*x);}\nvec4  cubic(vec4  x) {return x*x*(3.-2.*x);}\n\nfloat quintic(float x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\nvec2  quintic(vec2  x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\nvec3  quintic(vec3  x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\nvec4  quintic(vec4  x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}