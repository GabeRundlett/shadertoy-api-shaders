{
    "Shader": {
        "info": {
            "date": "1712958436",
            "description": "A shader to downsample from a high resolution source to a pentile pixel display\n\nMove the mouse up and down to switch between the hd source and the pentile display.\nMove the mouse left and right to change the test pattern and source resolution.",
            "flags": 0,
            "hasliked": 0,
            "id": "4cGGzV",
            "likes": 3,
            "name": "Pentile OLED Downsample",
            "published": 3,
            "tags": [
                "sampling",
                "pentile",
                "oled"
            ],
            "usePreview": 0,
            "username": "sboys3",
            "viewed": 155
        },
        "renderpass": [
            {
                "code": "// number of virtual pentile pixels to place across the screen\n#define PentileMultiplier 20.0f\n\n// what factor the dimensions of the input image downsampled by, 2.25 is about 500%\n//#define DownscaleMultiplier 2.25f\n#define DownscaleMultiplier (3.0f - min(fract(iMouse.x / iResolution.x * 2.0f) * 2.5f, 2.0f))\n\n// number of times to tile the scene across the display\n#define SceneDivisions 1.0f\n\n// show grid lines between pixels for input and output\n#define ShowPixelGrids 0\n\n// sample using one bilinear sample instead of five\n// WARNING: disabling this can lead to over 100 second compile times\n// something with the singlePixels function causes that\n#define SampleBilinear 1\n\n// disable virtual oled shader and display for a real pentile display\n#define RealOutput 0\n\n\n\n\n\n\n// function for finding out what qualifies as a pixel on a real oled display\n// this displays a test pattern with single lit pixels\nvec4 singlePixels(vec2 fragCoord){\n    if(int(fragCoord.x) % 19 == 10 && int(fragCoord.y) % 19 == 10){\n        return vec4(1.0f);\n    }\n    if(int(fragCoord.x) % 19 == 10 && int(fragCoord.y) % 19 == 10){\n        return vec4(1.0f);\n    }\n    int movinX = int(round(max(cos(iTime) / 2.0f, 0.0f) * 19.0f));\n    int movinY = int(round(max(sin(iTime) / 2.0f, 0.0f) * 19.0f));\n    if(int(fragCoord.x) % 19 == movinX && int(fragCoord.y) % 19 == movinY){\n        return vec4(1.0f);\n    }\n    return vec4(0.5f,0.7f,0.5f,1) * 0.5f;\n}\n\n// test scene to test display \nvec3 scene(vec2 uv){\n    \n    float time = iTime;\n    \n    // colored background\n    //vec3 fragColor = 0.5* cos(time + uv.xyx * 2.0f + vec3(0,2,4));\n    vec3 fragColor = vec3(0);\n    \n    float rotation = time;\n    vec2 uvRotated = vec2(\n        cos(rotation) * (uv.x - 0.5f) + sin(rotation) * (uv.y - 0.5f),\n        cos(rotation) * (uv.y - 0.5f) - sin(rotation) * (uv.x - 0.5f)\n    ) + 0.5f;\n    \n    //fragColor = vec3(fract(uvRotated * 2.0f), 0);\n    uvRotated = fract(uvRotated * 2.5f);\n    fragColor = vec3(max(uvRotated.x,uvRotated.y));\n    \n    return fragColor;\n}\n\n\n// sample a scene given the pixel coordinate\nvec3 sampleScene(vec2 inputPixelUV){\n    inputPixelUV = floor(inputPixelUV) + 0.5f;\n    #if RealOutput\n    vec2 uv = inputPixelUV / min(iResolution.x, iResolution.y) / DownscaleMultiplier;\n    uv = fract(uv);\n    #else\n    vec2 uv = inputPixelUV / DownscaleMultiplier / PentileMultiplier * SceneDivisions;\n    uv = fract(uv);\n    #endif\n    \n    // select the scene\n    if(iMouse.x / iResolution.x < 0.5){\n        return scene(uv);\n    }else{\n        return singlePixels(inputPixelUV).xyz;\n    }\n}\n\n\n\n\n// bilinear should not be significantly undersampling even at 500% resolution on the input\n// because on average every subpixel is about the size of 4 input pixels.\n// if a bilinear texture sampler is available that would be equivalent to this\nvec3 downsampleToPointBilinear(vec2 inputPixelUV){\n    // sample between 4 pixels\n    inputPixelUV -= 0.5f;\n    vec2 base = floor(inputPixelUV);\n    vec2 delta = inputPixelUV - base;\n    vec2 pixelLoc = base;\n    vec3 pixel11 = sampleScene(pixelLoc);\n    pixelLoc.x += 1.0f;\n    vec3 pixel12 = sampleScene(pixelLoc);\n    vec3 pixel1 = mix(pixel11, pixel12, delta.x);\n    \n    pixelLoc.y += 1.0f;\n    vec3 pixel22 = sampleScene(pixelLoc);\n    pixelLoc.x -= 1.0f;\n    vec3 pixel21 = sampleScene(pixelLoc);\n    vec3 pixel2 = mix(pixel21, pixel22, delta.x);\n    \n    return mix(pixel1, pixel2, delta.y);\n}\n\n// take multiple samples from a specific area to downsample\n// samples 5 times in a diamond pattern which works well for the pentile pattern\n// uses the bilinear function because most scenarios have a bilinear sampler available\n// only really usefull for very high downsampling amounts\nvec3 downsampleDiamond(vec2 inputPixelUV, float radius){\n    vec3 colour = downsampleToPointBilinear(inputPixelUV);\n    colour += downsampleToPointBilinear(vec2(inputPixelUV.x + radius, inputPixelUV.y));\n    colour += downsampleToPointBilinear(vec2(inputPixelUV.x - radius, inputPixelUV.y));\n    colour += downsampleToPointBilinear(vec2(inputPixelUV.x, inputPixelUV.y + radius));\n    colour += downsampleToPointBilinear(vec2(inputPixelUV.x, inputPixelUV.y - radius));\n    colour *= 0.2f;\n    return colour;\n}\n\n\n// this function is run for every pixel in the output\n// just like a frag function outputting to a pentile display \nvec3 samplePentilePixel(vec2 outputPixelUV){\n    outputPixelUV = floor(outputPixelUV);\n    ivec2 outputPixelUVOdd2D = ivec2(fract(outputPixelUV/2.0f)*2.0f) % 2;\n    // the != can be replaced with == if the red and blue pixels are reversed\n    float outputPixelUVOdd = float(outputPixelUVOdd2D.x != outputPixelUVOdd2D.y);\n    \n    // highlight certain pixels to test the display\n    //ivec2 outputPixelUVInt = ivec2(outputPixelUV) % 3;\n    //return vec3(outputPixelUVInt.x == 0 && outputPixelUVInt.y == 0);\n    //return singlePixels(outputPixelUV).xyz;\n    \n    // for the htc vive there is one green subpixel per pixel\n    // it shares the red and blue subpixels above it to form a logical pixel\n    // this samples each subpixel separately based on the physical location\n    \n    // in a more performant version there should be a version of the \n    // downsampleToPointBilinear function for each color\n    \n    // this assumes that the input UV is aligned with the screen UV,\n    // if they are not then the derivitive of the UVs need to be used to\n    // scale the offsets\n    \n    // if the green pixel lights up with the red and blue pixels below it\n    // instead of above, flip 0.75 and 0.25 in the code below\n    #if SampleBilinear\n    return vec3(\n        downsampleToPointBilinear(vec2(outputPixelUV.x + 1.0f - outputPixelUVOdd,\n            outputPixelUV.y + 0.75) * DownscaleMultiplier).r,\n        downsampleToPointBilinear(vec2(outputPixelUV.x + 0.5,\n            outputPixelUV.y + 0.25) * DownscaleMultiplier).g,\n        downsampleToPointBilinear(vec2(outputPixelUV.x + outputPixelUVOdd,\n            outputPixelUV.y + 0.75) * DownscaleMultiplier).b\n    );\n    #else\n    return vec3(\n        downsampleDiamond(vec2(outputPixelUV.x + 1.0f - outputPixelUVOdd,\n            outputPixelUV.y + 0.75) * DownscaleMultiplier, DownscaleMultiplier * 0.25f).r,\n        downsampleDiamond(vec2(outputPixelUV.x + 0.5,\n            outputPixelUV.y + 0.25) * DownscaleMultiplier, DownscaleMultiplier * 0.25f).g,\n        downsampleDiamond(vec2(outputPixelUV.x + outputPixelUVOdd,\n            outputPixelUV.y + 0.75) * DownscaleMultiplier, DownscaleMultiplier * 0.25f).b\n    );\n    #endif\n}\n\nvec3 displayVirtualPentile(vec2 outputPixelUV){\n    vec2 outputPixelUVFrac = fract(outputPixelUV);\n    vec2 outputPixelUVFloor = floor(outputPixelUV);\n    // the point of this code is to render a simulated pentile array of pixels\n    // and also to find the center of the physical pixels\n    vec2 pentileUVRender = outputPixelUV - vec2(0.0f, 0.25f);\n    vec2 pentileUVRenderFract = fract(pentileUVRender);\n    vec2 pentileUVRenderFloor = floor(pentileUVRender);\n    vec3 fragColor = vec3(pentileUVRenderFract, 0);\n    //return fragColor;\n    ivec2 pentileUVRenderOdd2D = ivec2(fract(pentileUVRender/2.0f)*2.0f) % 2;\n    bool pentileUVRenderOdd = pentileUVRenderOdd2D.x != pentileUVRenderOdd2D.y;\n    // focus point is the point in pixel output space where the pixel should be sampled from\n    // matches up with where the center of the physical pixel is on the display\n    vec2 focusPoint = outputPixelUV;\n    if(abs(pentileUVRenderFract.x - 0.5f) + 1.0f - pentileUVRenderFract.y < 0.4f){\n    \n        // bottom of green subpixel\n        focusPoint = outputPixelUV - outputPixelUVFrac + vec2(0.5,0.25);\n        fragColor = samplePentilePixel(pentileUVRenderFloor + vec2(0,1));\n        fragColor *= vec3(0,1,0);\n        \n    }else if(abs(pentileUVRenderFract.x - 0.5f) + pentileUVRenderFract.y < 0.4f){\n    \n        // top of green pixel\n        // the green pixel is split simply becauses pentileUVRender wraps in the middle of it\n        focusPoint = outputPixelUV - outputPixelUVFrac + vec2(0.5,0.25);\n        fragColor = samplePentilePixel(pentileUVRenderFloor);\n        fragColor *= vec3(0,1,0);\n        \n    }else if((pentileUVRenderFract.x > 0.5f) != pentileUVRenderOdd){\n    \n        // red pixel\n        focusPoint = outputPixelUV - outputPixelUVFrac + \n            vec2(pentileUVRenderOdd ? 0.0 : 1.0,0.75);\n        // shared between pixels so average the two samplePentilePixel calls\n        fragColor = samplePentilePixel(pentileUVRenderFloor +\n            vec2(pentileUVRenderOdd ? 0.0 : 1.0,0)) * 0.5f;\n        fragColor += samplePentilePixel(pentileUVRenderFloor +\n            vec2(pentileUVRenderOdd ? -1.0 : 0.0,0)) * 0.5f;\n        fragColor *= vec3(1,0,0);\n        \n    }else{\n    \n        // blue pixel\n        focusPoint = outputPixelUV - outputPixelUVFrac + \n            vec2(!pentileUVRenderOdd ? 0.0 : 1.0,0.75);\n        // shared between pixels so average the two samplePentilePixel calls\n        fragColor = samplePentilePixel(pentileUVRenderFloor +\n            vec2(pentileUVRenderOdd ? 1.0 : 0.0,0)) * 0.5f;\n        fragColor += samplePentilePixel(pentileUVRenderFloor +\n            vec2(pentileUVRenderOdd ? 0.0 : -1.0,0)) * 0.5f;\n        fragColor *= vec3(0,0,1);\n        \n    }\n    if(distance(outputPixelUV, focusPoint) > 0.1){\n        fragColor *= 0.9;\n        if(distance(outputPixelUV, focusPoint) > 0.2){\n            //fragColor = vec4(0);\n            fragColor *= 0.4f;\n        }\n    }\n    //fragColor *= sampleScene(outputPixelUV * DownscaleMultiplier) + 0.1;\n    //fragColor *= sampleScene(focusPoint * DownscaleMultiplier) + 0.1;\n    return fragColor;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/min(iResolution.x, iResolution.y);\n    \n    \n    // uncomment this if you want to use this to figure out how \n    // a real oled display's subpixels are layed out\n    //fragColor = singlePixels(fragCoord);\n    //return;\n    \n    \n    // for the htc vive there is one green subpixel per pixel\n    // it shares the red and blue subpixels above it to form a logical pixel\n    // these values represent shader pixel position in the display output buffer\n    // they are resolution dependent\n    // I will refer to this as pixel output space\n    vec2 outputPixelUV = uv * PentileMultiplier;\n    vec2 outputPixelUVFrac = fract(outputPixelUV);\n    #if !RealOutput\n    // show as thick black lines\n    if((outputPixelUVFrac.x < 0.03f || outputPixelUVFrac.y < 0.03f) && bool(ShowPixelGrids)){\n        fragColor = vec4(0.05);\n        return;\n    }\n    #endif\n    \n    #if RealOutput\n    outputPixelUV = fragCoord;\n    #endif\n    \n    // pixel position of higher resolution input image to downsample\n    // they are resolution dependent\n    // I will refer to this as input pixel space\n    vec2 inputPixelUV = outputPixelUV * DownscaleMultiplier;\n    #if !RealOutput\n    // show as thin grey lines\n    vec2 inputPixelUVFrac = fract(inputPixelUV);\n    if((inputPixelUVFrac.x < 0.02f || inputPixelUVFrac.y < 0.02f) && bool(ShowPixelGrids)){\n        fragColor = vec4(0.3);\n        return;\n    }\n    #endif\n    \n    \n    // click on the top or bottom of the display to switch between pentile and source\n    if(iMouse.y / iResolution.y < 0.5){\n        #if RealOutput\n        fragColor = vec4(samplePentilePixel(outputPixelUV), 1);\n        #else\n        fragColor = vec4(displayVirtualPentile(outputPixelUV), 1);\n        #endif\n    }else{\n        fragColor = vec4(sampleScene(inputPixelUV), 1);\n        #if !RealOutput\n        fragColor.xyz *= 0.5;\n        #endif\n    }\n    \n}\n\n",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}