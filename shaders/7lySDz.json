{
    "Shader": {
        "info": {
            "date": "1642166189",
            "description": "Path tracing and lighting up a very basic scene.",
            "flags": 32,
            "hasliked": 0,
            "id": "7lySDz",
            "likes": 70,
            "name": "Glossy Reflections",
            "published": 3,
            "tags": [
                "global",
                "illumination",
                "tracing",
                "path",
                "glossy",
                "emissive"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 1123
        },
        "renderpass": [
            {
                "code": "void mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    // The other buffer has a maximum Y-resolution of 540 set, which \n    // means any pixels outside that are not rendered. On a 1980x1080\n    // fullscreen resolution, this means roughly a quarter of the pixels\n    // are rendered, which is a huge saving. Of course, this also means\n    // that the scene needs to be upscaled, which will make things less\n    // crisp, but you can't have everything. :)\n    //\n    // By the way, this tip came from Shadertoy user, spalmer, who has\n    // a heap of interesting work for anyone interested:\n    // https://www.shadertoy.com/user/spalmer\n    //\n    float maxRes = 540.;\n    vec2 uv = fragCoord/iResolution.xy;\n    // If the resolution exceeds the maximum, upscale.\n    if(iResolution.y>maxRes) uv = (fragCoord/iResolution.xy - .5)*maxRes/iResolution.y + .5;\n    \n    // Retrieving the stored color.\n    vec4 col = texture(iChannel0, uv);\n\n    // Rough gamma correction and screen presentation.\n    fragColor = pow(col, vec4(1./2.2));\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\n\n    Glossy Reflections\n    ------------------\n    \n    I do a bit of path tracing in the background, but noticed that I haven't\n    put a 3D one up on Shadertoy yet, so I dug up a very old example and \n    prettied it up a bit, just to get one on the board, as they say. I'll put\n    up some more interesting examples in due course.\n    \n    People say realtime path tracing is here... I'm not entirely convinced, \n    but I've seen some mind blowing examples out there. Either way, it's\n    definitely possible to trace out some inexpensive rudimentary geometry \n    and produce a simple but nicely lit scene. \n    \n    This particular scene comprises one sphere, four walls and some pattern \n    generated emitters. With the spare cycles, I've attempted to produce some \n    glossy reflections. Due to the limited number of samples, the results \n    aren't perfect by any stretch, but I can remember being utterly amazed by \n    a realtime raytraced Phong-lit white sphere on a brown background running \n    at under 10 FPS back in the 90s, so it's an improvement. :) \n    \n\n*/\n\n\n// Sample number and blend number: The trick is to find a balance between the\n// two, or use a faster computer. :)\n\n// Number of samples: My computer can handle more. If yours is struggling, you \n// can lower this. Naturally, sample number is proportional to noise quality.\n#define sampNum 32\n\n// The blended samples per frame: Higher numbers give the impression of more\n// samples, which boosts quality. However, there's a price to pay, and that's \n// ghosting effects. Any more than 2 or 3 will result in noticeable ghosting.\n#define blendNum 2.\n\n\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){  return fract(sin(dot(p, vec2(27.619, 57.583)))*43758.5453); }\n\nfloat hash31(in vec3 p){\n    return fract(sin(dot(p, vec3(91.537, 151.761, 72.453)))*435758.5453);\n}\n\n\n// Commutative smooth maximum function. Provided by Tomkh, and taken \n// from Alex Evans's (aka Statix) talk: \n// http://media.lolrus.mediamolecule.com/AlexEvans_SIGGRAPH-2015.pdf\n// Credited to Dave Smith @media molecule.\nfloat smax(float a, float b, float k){\n    \n   float f = max(0., 1. - abs(b - a)/k);\n   return max(a, b) + k*.25*f*f;\n}\n\n\n/*\n// Tone mapping: There are so many to choose from, and which one you use depends on\n// what you're after, but I prefer the Uncharted 2 tone map since it works as advertised,\n// which is tone down values in the high dynamic range and leave the others alone.\nfloat A = .22, B = .3, C = .1, D = .2, E = .01, F = .22;//.3;\n//float W = 11.2;\n\nvec3 Un2Tone(vec3 x){\n\n   return ((x*(A*x + C*B) + D*E)/(x*(A*x + B) + D*F))-E/F;\n}\nvec4 Uncharted2Tonemap(vec4 col){\n\n   float ExposureBias = 1.;\n   col.xyz = Un2Tone(ExposureBias*col.xyz);\n\n   col.w = 2.2;//1./dot(col, vec4(.299, .587, .114, 0));\n   vec3 whiteScale = 1./Un2Tone(vec3(col.w));//col.www\n   \n   return vec4(col.xyz*whiteScale, col.w); \n}\n*/\n\n/////\nvec2 seed = vec2(.183, .257);\n\n/*\nvec2 hash22() {\n    \n    seed += fract(seed + vec2(.7123, .6247));\n     \n    return fract(sin(vec2(dot(seed.xy, vec2(12.989, 78.233)), \n                          dot(seed.xy, vec2(41.898, 57.263))))\n                          *vec2(43758.5453, 23421.6361));\n}\n*/\n\n// A slight variation on a function from Nimitz's hash collection, here: \n// Quality hashes collection WebGL2 - https://www.shadertoy.com/view/Xt3cDn\nvec2 hash22(){\n\n    // I should probably use a \"uvec2\" seed, but I hacked this from an old\n    // example. I'll update it later.\n    seed = fract(seed + vec2(.7123, .6457));\n    uvec2 p = floatBitsToUint(seed);\n    \n    // Modified from: iq's \"Integer Hash - III\" (https://www.shadertoy.com/view/4tXyWN)\n    // Faster than \"full\" xxHash and good quality.\n    p = 1103515245U*((p>>1U)^(p.yx));\n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    uint n = h32^(h32>>16);\n\n    uvec2 rz = uvec2(n, n*48271U);\n    // Standard uvec2 to vec2 conversion with wrapping and normalizing.\n    return vec2((rz>>1)&uvec2(0x7fffffffU))/float(0x7fffffff);\n}\n\n\n// IQ's box routine.\nfloat sBox(in vec2 p, in vec2 b, float r){\n\n  vec2 d = abs(p) - b + r;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - r;\n}\n\n\n/////////\n// A concatinated spherical coordinate to world coordinate conversion.\nvec3 sphericalToWorld(vec3 sphCoord){\n   \n    vec4 cs = vec4(cos(sphCoord.xy), sin(sphCoord.xy));\n    return vec3(cs.w*cs.x, cs.y, cs.w*cs.z)*sphCoord.z;\n}\n  \n\n// Useful polyhedron constants. \n#define PI 3.14159265359\n#define TAU 6.2831853\n#define PHI 1.618033988749895 \n\n//\n// Since all triangles are the same size, etc, any triangles on\n// a known icosahedron will do. The angles we need to determine are\n// the angle from the top point to one of the ones below, the top\n// point to the mid point below, and the angle from the top point\n// to the center (centroid) of the triangle.\nconst vec3 triV0 = normalize(vec3(-1, PHI,  0));\nconst vec3 triV1 = normalize(vec3(-PHI, 0,  1));//0,  1,  PHI\nconst vec3 triV2 = normalize(vec3(0,  1,  PHI));//0,  1,  PHI\nconst vec3 mid = normalize(mix(triV1, triV2, .5));\nconst vec3 cntr = normalize(triV0 + triV1 + triV2);\n\n// Angle between vectors: cos(a) = u.v/|u||v|. \n// U and V are normalized. Therefore, a = acos(u.v).\nconst float ang = acos(dot(triV0, triV1)); // Side length angle.\nconst float mAng = acos(dot(triV0, mid)); // Height angle.\nconst float cAng = acos(dot(triV0, cntr)); // Centroid angle.\n\n// The latitude (in radians) of each of the top and bottom blocks is\n// the angle between the top point (north pole) and one of the points below, \n// or the bottom point (south pole) and one of the ones above.\nconst float latBlock = ang;\nconst vec2 lat = vec2(cAng, mAng*2. - cAng);\n\n//\n\n// Returns the local world coordinates to the nearest triangle and the three\n// triangle vertices in spherical coordinates.\nvec3 getIcosTri(inout vec3 p, inout vec3[3] gVertID, const float rad){\n       \n \n    // Longitudinal scale.\n    const float scX = 5.;\n\n\n    // The sphere is broken up into two sections. The top section \n    // consists of the top row, and half the triangle in the middle\n    // row that sit directly below. The bottom section is the same,\n    // but on the bottome and rotated at PI/5 relative to the top. \n    // The half triangle rows perfectly mesh together to form the \n    // middle row or section.\n\n    // Top and bottom section coordinate systems.The bottom section is \n    // rotated by PI/5 about the equator.\n    vec3 q = p; // Top section coordinates.\n    //vec3 q2 = vec3(rot2(-PI/scX)*p.xz, p.y).xzy; // Bottom section coordinates.\n\n    // Converting to spherical coordinates.\n    // X: Longitudinal angle -- around XZ, in this case.\n    // Y: Latitudinal angle -- rotating around XY.\n    // Z: The radius, if you need it.\n\n    // Longitudinal angle for the top and bottom sections.\n    ////vec4 sph = mod(a + vec4(0, 0, PI/5., PI/5.), TAU);\n    vec4 sph = mod(atan(q.z, q.x) + vec4(0, 0, PI/5., PI/5.), TAU);\n    sph = mod((floor(sph*scX/TAU) + vec4(.5, .5, 0, 0))/scX*TAU, TAU);\n\n\n    float dist = 1e5;\n\n\n    // Top and bottom block latitudes for each of the four groups of triangle to test.\n    vec4 ayT4 = vec4(0, PI - latBlock, PI, latBlock);\n    vec4 ayB4 = vec4(latBlock, latBlock, PI - latBlock, PI - latBlock);\n    float ayT, ayB;\n\n    int id;\n\n    // Iterating through the four triangle group strips and determining the \n    // closest one via the closest central triangle point.\n    for(int i = 0; i<4; i++){\n\n\n        // Central vertex postion for this triangle.        \n        int j = i/2;\n        // The spherical coordinates of the central vertex point for this \n        // triangle. The middle mess is the lattitudes for each strip. In order,\n        // they are: lat[0], lat[1], PI - lat[0], PI - lat[1]. The longitudinal\n        // are just the polar coordinates. The bottom differ by PI/5. The final\n        // spherical coordinate ranges from the sphere core to the surface.\n        // On the surface, all distances are set to the radius.                \n        vec3 sc = vec3(sph[i], float(j)*PI - float(j*2 - 1)*lat[i%2], rad);\n \n        // Spherical to world, or cartesian, coordinates.\n        vec3 wc = sphericalToWorld(sc);\n\n\n        float vDist = length(q - wc);\n        if(vDist<dist){\n           dist = vDist;\n           ayT = ayT4[i]; // Top triangle vertex latitude.\n           ayB = ayB4[i]; // Bottom triangle vertex latitude.\n           id = i;\n        }\n\n\n    }\n\n\n    float ax = sph[id];\n    // Flip base vertex postions on two blocks for clockwise order.\n    float baseFlip = (id==0 || id==3)? 1. : - 1.;\n\n    // The three vertices in spherical coordinates. I can't remember why\n    // I didn't convert these to world coordinates prior to returning, but\n    // I think it had to do with obtaining accurate IDs... or something. :)\n    gVertID[0] = vec3(ax, ayT, rad);\n    gVertID[1] = vec3(mod(ax - PI/5.*baseFlip, TAU), ayB, rad);\n    gVertID[2] = vec3(mod(ax + PI/5.*baseFlip, TAU), ayB, rad);\n\n    // Top and bottom poles have a longitudinal coordinate of zero.\n    if (id%2==0) gVertID[0].x = 0.;\n\n\n    return q;\n}\n\n\n/////////\n\n \n// A nice random hemispherical routine taken out of one of IQ's examples.\n// The routine itself was written by Fizzer.\nvec3 cosDir( in float seed, in vec3 n){\n\n    vec2 rnd = hash22();\n    float u = rnd.x;\n    float v = rnd.y;\n    \n    // Method 1 and 2 first generate a frame of reference to use with an arbitrary\n    // distribution, cosine in this case. Method 3 (invented by fizzer) specializes \n    // the whole math to the cosine distribution and simplfies the result to a more \n    // compact version that does not depend on a full frame of reference.\n\n    // Method by fizzer: http://www.amietia.com/lambertnotangent.html\n    float a = 6.2831853*v;\n    u = 2.*u - 1.;\n    return normalize(n + vec3(sqrt(1. - u*u)*vec2(cos(a), sin(a)), u));\n    \n}\n/////\n\n// Sphere normal.\nvec3 sphereNorm(vec3 p, float id, vec4 sph){\n   \n    return (p - sph.xyz)/sph.w; \n    \n}\n\n\n \n// Hitting a number of walls from the inside: You could simply raytrace four\n// planes, but this is a little more concise. I was too lazy to write my own\n// routine, so quickly adapted a working one (sadly, not many of those around) \n// from one of PublicIntI's examples. At some stage, I'll get in amongst it and \n// rewrite one, or find one of my older routines. Alternatively, if someone\n// knows of a concise reliable function or sees a way to tidy the following up, \n// feel free to let me know. :)\n//\n// crystal exhibit(pathtraced) - public_int_i \n// https://www.shadertoy.com/view/wljSRz\n//\n// Ray-box intersection: The function take in the ray origin (offset if needed)\n// the unit direction ray and the box dimensions, then returns the distance and \n// normal.\n//\nvec4 boxIntersect(vec3 ro, vec3 rd, vec3 dim) {\n\n    const float maxT = 1e8;\n \n    vec3 minD = (ro + dim)/rd, maxD = (ro - dim)/rd;\n\tminD = -(minD - step(vec3(-1e-6), minD)*(minD + maxT));\n\tmaxD = -(maxD - step(vec3(-1e-6), maxD)*(maxD + maxT));\n\tminD = min(minD, maxD);\n    \n    // Result: Distance and normal.\n    vec4 res;\n\n    // Performing some ray-plane intersections, modified to handle\n    // two planes at once. I'd imagine you could cleverly combine this\n    // into just one test, but I'm not clever, so I'll leave that to \n    // someone else. :D\n     \n    // We don't need the left and right walls for this example.\n    //if (minD.x<maxT){\n        //vec2 pd = abs(ro.zy + rd.zy*minD.x) - dim.zy;\n        //if (max(pd.x, pd.y) < 0.) res = vec4(minD.x, -sign(rd.x), 0, 0);\n    //}\n    \n    // Top and bottom surfaces, or ceiling and floor, if you prefer.\n    if (minD.y<maxT){\n        vec2 pd = abs(ro.xz + rd.xz*minD.y) - dim.xz;\n        if (max(pd.x, pd.y) < 0.) res = vec4(minD.y, 0, -sign(rd.y), 0.);\n    }\n    \n    // Front and back walls.\n    if (minD.z<maxT){\n        vec2 pd = abs(ro.xy + rd.xy*minD.z) - dim.xy;\n        if (max(pd.x, pd.y) < 0.) res = vec4(minD.z, 0, 0, -sign(rd.z));\n    }\n    \n    // Return the distance and normal.\n    return res;\n}\n \n \n// Sphere intersection: Pretty standard, and adapted from one\n// of IQ's formulae.\nvec2 sphereIntersect(in vec3 ro, in vec3 rd, in vec4 sph){\n\n    vec3 oc = ro - sph.xyz;\n\tfloat b = dot(oc, rd);\n    if(b > 0.) return vec2(1e8, 0.);\n\tfloat c = dot(oc, oc) - sph.w*sph.w;\n\tfloat h = b*b - c;\n\tif(h<0.) return vec2(1e8, 0.);\n\treturn vec2(-b - sqrt(h), 1.); \n    \n}\n\n\n// Sphere position and radius.\nconst vec4 sph4 = vec4(0, -.5, 1., .5);\n\n// Hacking in a normal for the box equation.\nvec3 boxNrm;\n\n// Scene normal logic: Not that exciting for this example. :)\nvec3 getNorm(vec3 p, float id){\n    \n    return (id<.5)? sphereNorm(p, id, sph4) : boxNrm; \n}\n\n\n// Intersection logic for all objects.\nvec3 intersect(vec3 ro, vec3 rd){\n    \n    // Containers for two objects. Usually there'd be more.\n    vec2[2] q;\n    \n    // The sphere.\n    q[0] = sphereIntersect(ro, rd, sph4);\n \n    // The box tube object, or 4 walls at once, if you prefer. :)\n    vec4 bx = boxIntersect(ro - vec3(0, 1, -.5), rd, vec3(1e8, 2, 3.5));\n    q[1] = vec2(bx.x, 1);\n    boxNrm = bx.yzw; \n   \n    \n    // Returning the object distance, a hit ID (inside surface, etc, and redundant \n    // for this example) and the object ID used for materials and so forth.\n    return q[0].x<q[1].x? vec3(q[0], 0) : vec3(q[1], 1);\n    \n    /*\n    // For more objects, you need to do a little more work.\n    vec3 d = vec3(1e5);\n    \n    for(int i = 0; i<2; i++){\n       if(q[i].x< d.x) d = vec3(q[i], i);\n    }\n        \n    return d;\n    */\n    \n}\n\n// The wall and floor pattern, which is just something quick and effective.\n// Since it's a path traced example, I went with a cliche rounded\n// quarter circle arrangement.\nvec3 distField(vec2 p){\n    \n    // Scale.\n    const float sc = 1.5;\n    \n    // Edge width.\n    const float ew = .05;\n    \n    // Partitioning into cells and providing the local cell ID\n    // and local coordinates.\n    p *= sc;\n    p += .5;\n    vec2 ip = floor(p);\n    p -= ip + .5;\n    \n    \n    // Rounded square.\n    float sq = sBox(p, vec2((1. - ew)/2.), .125);\n    \n    // Randomly rotate each cell.\n    p = rot2(floor(hash21(ip)*8.)*6.2831/4.)*p;\n       \n    // A circle, offset to one of the corners.    \n    float cir = length(p - .5 + ew*.7) - (1. - ew);\n \n    // Producing a rounded circle.\n    float d = max(cir, sq);\n    \n    // Putting a hole in it just to break things up.\n    d = max(d, -(length(p - .07) - .1));\n    \n    //d = abs(d + .1) - .1;\n    \n    // Returning the distance and local cell ID. Note that the \n    // distance has been rescaled by the scaling factor.\n    return vec3(d/sc, ip);\n}\n \n\n\n\n// mat3 rotation... I did this in a hurry, but I think it's right. :)\n// I have a much better version of this that I'll have to find.\nmat3 rot(vec3 ang){\n    \n    vec3 c = cos(ang), s = sin(ang);\n\n    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,\n                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,\n                c.y*s.z, -s.y, c.y*c.z);\n    \n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    \n    // Setting a maximum resolution, then upscaling. I picked up this tip when\n    // looking at one of spalmer's examples, here:\n    // https://www.shadertoy.com/view/sdKXD3\n    float maxRes = 540.;\n    float iRes = min(iResolution.y, maxRes);\n    //ivec2 iR = ivec2(fragCoord);\n    //if(iR.y > 0 || iR.x>3){\n    fragColor = vec4(0, 0, 0, 1);\n    vec2 uv2 = abs(fragCoord - iResolution.xy*.5) - iRes/2.*vec2(iResolution.x/iResolution.y, 1.);\n    if(any(greaterThan(uv2, vec2(0)))) return;  // if(uv2.x>0. || uv2.y>0.) return;\n    //} \n        \n    // Screen pixel coordinates.\n    vec2 seed0 = fract(iTime/vec2(111.13, 57.61))*vec2(-.143, .457);\n    vec2 uv0 = (fragCoord - iResolution.xy*.5)/iRes;\n    \n  \n    float FOV = 1.; // FOV - Field of view.\n    vec3 ro = vec3(0, 0, -2);\n    // \"Look At\" position.\n    vec3 lk = ro + vec3(0, 0, .25);\n    vec3 fwd = normalize(lk - ro);\n    vec3 rgt = normalize(vec3(fwd.z, 0., -fwd.x )); \n    // \"right\" and \"forward\" are perpendicular, due to the dot product being zero. Therefore, I'm \n    // assuming no normalization is necessary? The only reason I ask is that lots of people do \n    // normalize, so perhaps I'm overlooking something?\n    vec3 up = cross(fwd, rgt); \n    \n    // Camera.\n    mat3 mCam = mat3(rgt, up, fwd);\n    mCam *= rot(vec3(0, .05, 0)); \n    mCam *= rot(vec3(0, 0, -sin(iTime/4.)*.25)); \n    \n    \n    vec3 aCol = vec3(0);\n    \n    \n    for(int j = min(0, iFrame); j<sampNum; j++){\n        \n        // Seed value and jitter.\n        seed = uv0 + seed0 + vec2(j*57, j*27)/1321.;\n        vec2 jit = hash22()*2. - 1.;\n        \n        // Jittered UV coordinate.\n        vec2 uv = uv0 - jit/iResolution.y;\n\n        // Using the above to produce the unit ray-direction vector.\n        vec3 rd = mCam*normalize(vec3(uv, 1./FOV));\n\n        // Camera position. Initially set to the ray origin.\n        vec3 cam = ro;\n        // Surface postion. Also initially set to the ray origin.\n        vec3 sp = ro;\n\n        vec3 col = vec3(0);\n        \n        // Emissive, throughput and sample colors.\n        vec3 emissive = vec3(0);\n        vec3 through = vec3(1);\n        vec3 sCol = vec3(0);\n        \n        // Fog.\n        float fogD = 1e8;\n       \n        \n        // Just three bounces. More looks better, but the extra randomess\n        // requires more samples. For static scenes, that's not a problem,\n        // but this is a realtime one.\n        for(int i = min(0, iFrame); i<3; i++){\n\n            \n            vec3 scene = intersect(sp, rd); // Scene intersection.\n\n            float t = scene.x; // Scene distance.\n            float retVal = scene.y; // Redundant here, but used when refraction is involved.\n            float id = scene.z;// Object ID.\n            \n            // Set the fog distance on the first pass.\n            if(i==0) fogD = t;\n\n            sp += rd*t; // Advance the ray position.\n\n  \n            if(t<1e8){\n\n                \n                vec3 sn = getNorm(sp, id); // Normal.\n\n                vec3 oCol = vec3(0); // Object color.\n\n                emissive = vec3(0);\n                float rough = .9;\n\n               \n                if(id<.5) { \n                   \n                    // The sphere.\n                    oCol = vec3(1); \n                    \n                    // Texture position. Rotating the texture instead of the sphere\n                    // is cheating, but we can get away with it here.\n                    vec3 tSp = sp - sph4.xyz;\n                    tSp.xz *= rot2(-iTime/2.);\n                    tSp.xy *= rot2(-3.14159/6.);\n\n                    // Texturing the sphere with an icosahedral mapping.\n                    //\n                    // Obtaining the local cell coordinates and spherical coordinates\n                    // for the icosahedron cell.\n                    vec3[3] gV, gVID;\n\n                    const float rad = .5;\n                    vec3 lq = getIcosTri(tSp, gVID, rad);\n\n                    gV[0] = sphericalToWorld(gVID[0]); \n                    gV[1] = sphericalToWorld(gVID[1]);\n                    gV[2] = sphericalToWorld(gVID[2]); \n                    \n                    // The cell center, which doubles as a cell ID,\n                    // due to its uniqueness.\n                    vec3 ctr = normalize((gV[0] + gV[1] + gV[2]))*rad;\n \n                    // Sphere triangles. \n                    mat3 edge = mat3(cross(gV[0], gV[1]), cross(gV[1], gV[2]), cross(gV[2], gV[0]));\n                    vec3 ep = (normalize(lq)*edge)/length(gV[0] - gV[1]);  \n                    float tri = smax(smax(ep.x, ep.y, .07), ep.z, .07) + .025;\n                    tri = max(tri, -(length(lq - ctr) - .05));\n                    //tri = abs(tri + .01) - .02;\n \n                    // Object color, random for each triangle.\n                    vec3 dCol = mix(vec3(1, .4, .2), vec3(1), hash31(ctr + .02));\n \n                    // Random blinking.\n                    float rndV = hash31(ctr + .08);\n                    rndV = sin(rndV*6.2831 + iTime)*.5 + .5;\n                    rndV = smoothstep(.25, .75, sin(rndV*6.2831 + iTime)*.5 + .5);\n                    //\n                    dCol = mix(dCol/16., dCol*4., rndV);\n\n                    // Emissivity.\n                    emissive = mix(emissive, dCol, 1. - smoothstep(0., .005, tri));\n                    \n                    // Roughness.\n                    //rough = .1;\n                    rough = mix(.1, .9, 1. - smoothstep(0., .005, tri));\n               \n               }\n               else {\n\n                   \n                    // Producing a wall and floor pattern, coloring it, and using\n                    // parts to act as emitters.\n                    \n                    // Back wall or not.\n                    float sgn = (abs(sn.z)>.5)? 1. : -1.;\n                    \n                    // UV coordinates for the walls and floors.\n                    vec2 uv = sgn>.5? sp.xy : abs(sn.x)>.5? sp.yz : sp.xz;\n\n                    // Distance field pattern:\n                    // Returns the distance field and cell ID.\n                    vec3 d3 = distField(uv);\n \n                    // Random color.\n                    vec3 dCol = mix(vec3(1, .4, .2), vec3(1), hash21(d3.yz));\n\n                    // Render the pattern on the walls, or the reverse on the floor and ceiling.\n                    oCol = mix(vec3(.25), vec3(.5), 1. - smoothstep(0., .005, sgn*(d3.x + .02)));\n                    //sgn*(abs((d3.x + .02+.02)) - .035)\n                    \n\n                    // Pattern based emissivity -- It doesn't always have to be object based.\n                    emissive = mix(emissive, dCol*2., 1. - smoothstep(0., .01, d3.x + .02));\n                    \n                    // Random blinking.\n                    float rnd = hash21(d3.yz + .43);\n                    rnd = smoothstep(.9, .97, sin(rnd*6.2831 + iTime)*.5 + .5);\n                    \n                    // Ramping up the emissivity in tune with the blinking lights.\n                    if(sgn>.5) emissive = mix(emissive/128., emissive, rnd);\n                    else emissive = emissive/128.;\n\n                    // Turn off the wall lights.\n                    //emissive *= 0.;\n                  \n                }\n               \n                \n                // Tweaking the color and emissive color values a bit.\n                oCol = mix(oCol, oCol.xzy, clamp(sp.y - 1., 0., 1.));  \n                emissive = mix(emissive, emissive.xzy, clamp(sp.y - 1., 0., 1.)); \n                emissive = clamp(emissive*vec3(1, .7, .6), 0., 20.);\n\n                //emissive = emissive.zyx; \n                // Applying some fog, if necessary. You don't actually see this, but\n                // I want it there for completeness.\n                emissive = mix(vec3(0), emissive, 1./(1. + fogD*fogD*.02));\n\n\n\n\n                \n                // I definitely like the more natural way in which colors are applied\n                // when rendering this way. We only add surface color when it's been\n                // hit by a ray that has visited a light source at some point.\n                sCol += emissive*through;\n                // Applying this bounce's color to future bounces. For instance, if we\n                // hit a pink emitter then hit another surface later, that surface will\n                // incorporate a bit of pink into it.\n                through *= oCol;\n \n\n                vec3 ref = reflect(rd, sn); // Purely reflected vector.\n                vec3 rrd = cosDir(0., sn); // Random half hemisphere vector.\n\n                // Mimicking surface inconsistancies with fuzzy reflections.\n                // Rougher surfaces have a greater chance of randomly reflecting at any direction\n                // and smoother surfaces are more likely to purely reflect.\n                float rChance = step(rough, hash21(uv + vec2(i*277, j*113) + fract(iTime*.977 + .137)));\n                rd = (mix(rrd, ref, rChance));\n\n\n                sp += sn*1e-6;\n                //rd = ref; // Pure reflection override. Not as effective at all.\n\n            } \n            \n            \n             if(aCol.x>1e5) break; // Attempting to reduce compile time. \n        }\n        \n\n        // Tone mapping can be helpful in bringing the extremely high values\n        // down to an acceptable range, but I didn't find it necessary here.\n        //sCol = Uncharted2Tonemap(vec4(sCol, 1)).xyz; \n        \n        // Accumulate the sample color.\n        aCol += sCol;\n        \n        if(sCol.x>1e5) break; // Attempting to reduce compile time.\n        \n        \n    }\n    \n    // Average color over all samples.\n    aCol /= float(sampNum);\n    \n   \n    /////\n    \n\n    \n    // Mix the previous frames in with no camera reprojection.\n    // It's OK, but full temporal blur will be experienced.\n    vec4 preCol = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    float blend = (iFrame < 2) ? 1. : 1./blendNum; \n    fragColor = mix(preCol, vec4(clamp(aCol, 0., 1.), 1), blend);\n    \n    // No reprojection or temporal blur, for comparisson.\n    //fragColor = vec4(max(aCol, 0.), 1);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}