{
    "Shader": {
        "info": {
            "date": "1639178399",
            "description": "Is designed to run off any input array of colors and palletize the image, limiting the colors to the colors within the array. Click down to transition to palettized colors.",
            "flags": 32,
            "hasliked": 0,
            "id": "ft3XDM",
            "likes": 1,
            "name": "Custom Runtime Palettes",
            "published": 3,
            "tags": [
                "palette"
            ],
            "usePreview": 0,
            "username": "mthompsen",
            "viewed": 431
        },
        "renderpass": [
            {
                "code": "/*\nFinally, actual screen output.\n*/\n\n//Blur stuff, might be used at a later date\nfloat normpdf(in float x, in float sigma)\n{\n\treturn 0.39894*exp(-0.5*x*x/(sigma*sigma))/sigma;\n}\n\nfloat lookup(vec2 p, float dx, float dy, float d)\n{\n    vec2 uv = (p.xy + vec2(dx * d, dy * d)) / iResolution.xy;\n    vec4 col = texture(iChannel1, uv.xy);\n\t\n\t// return as luma\n    return 0.2126*col.r + 0.7152*col.g + 0.0722*col.b;\n}\n//Edge detection, maybe combine this to help find pixel transitions?\nfloat getEdge(vec2 p, float d) {\n    // simple sobel edge detection\n    float gx = 0.0;\n    gx += -1.0 * lookup(p, -1.0, -1.0, d);\n    gx += -2.0 * lookup(p, -1.0,  0.0, d);\n    gx += -1.0 * lookup(p, -1.0,  1.0, d);\n    gx +=  1.0 * lookup(p,  1.0, -1.0, d);\n    gx +=  2.0 * lookup(p,  1.0,  0.0, d);\n    gx +=  1.0 * lookup(p,  1.0,  1.0, d);\n    \n    float gy = 0.0;\n    gy += -1.0 * lookup(p, -1.0, -1.0, d);\n    gy += -2.0 * lookup(p,  0.0, -1.0, d);\n    gy += -1.0 * lookup(p,  1.0, -1.0, d);\n    gy +=  1.0 * lookup(p, -1.0,  1.0, d);\n    gy +=  2.0 * lookup(p,  0.0,  1.0, d);\n    gy +=  1.0 * lookup(p,  1.0,  1.0, d);\n    \n\t// hack: use g^2 to conceal noise in the video\n    return gx*gx + gy*gy;\n}\n\n//Gaussian Blurring\nvec3 gaussBlur( sampler2D tex, vec2 uv, float lod, float sigma)\n{\n    float rounds = sigma * 2.;\n    float invTwoSigmaSqr = 1. / (2. * sigma * sigma);\n    vec2 d = vec2(exp2(lod)/iChannelResolution[0].xy);\n    vec4 col = textureLod(tex, uv, lod);\n    \n    for (float i = 1.; i < rounds; ++i) {\n        col += (\n        textureLod(tex, uv + d * i, lod) +\n        textureLod(tex, uv - d * i, lod)\n        ) * exp(- i * i * invTwoSigmaSqr);\n    }\n    \n    return col.rgb/col.a;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    vec3 col;\n    //Unneccessary Currently\n    //float edge = getEdge(fragCoord.xy, 1.2);\n    \n    if (iMouse.z > 0.0) {\n        col = texture(iChannel1, uv).rgb; //gaussBlur(iChannel1, uv, 1., 4.*max(edge-0.2, 0.0)); //My attempt to blur around the edges.\n    } else {\n        col = texture(iChannel0, uv).rgb;\n    }\n    \n    // Output to screen\n    fragColor = vec4(col,1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "precision highp float;\nprecision highp int;\n\nconst float EPSILON = 1e-10;\n\nconst float eps = 216.f/24389.f;\nconst float kap = 24389.f/27.f;\nconst vec3  d65_2deg = vec3(0.95047,1.00000,1.08883);\nconst mat3 rgb2xyz_mat = \n    mat3(0.4124564,0.3575761,0.1804375,\n         0.2126729,0.7151522,0.0721750,\n         0.0193339,0.1191920,0.9503041);\nconst mat3 xyz2rgb_mat =\n\tmat3( 3.2404542, -1.5371385, -0.4985314,\n\t\t -0.9692660,  1.8760108,  0.0415560,\n\t      0.0556434, -0.2040259,  1.0572252);\n          \n\n//controls palette array size\nconst float iter = 10.;\nconst int numColors = int(iter*iter*iter);\nconst float oneOver = 1./iter;\n\n//testing for color space conversions as RGB differences don't match the eyes that well\n#define convert false\n#define method 0\n\nvec3 HUEtoRGB(in float hue)\n{\n    // Hue [0..1] to RGB [0..1]\n    // See http://www.chilliant.com/rgb2hsv.html\n    vec3 rgb = abs(hue * 6. - vec3(3, 2, 4)) * vec3(1, -1, -1) + vec3(-1, 2, 2);\n    return clamp(rgb, 0., 1.);\n}\n\nvec3 RGBtoHCV(in vec3 rgb)\n{\n    // RGB [0..1] to Hue-Chroma-Value [0..1]\n    // Based on work by Sam Hocevar and Emil Persson\n    vec4 p = (rgb.g < rgb.b) ? vec4(rgb.bg, -1., 2. / 3.) : vec4(rgb.gb, 0., -1. / 3.);\n    vec4 q = (rgb.r < p.x) ? vec4(p.xyw, rgb.r) : vec4(rgb.r, p.yzx);\n    float c = q.x - min(q.w, q.y);\n    float h = abs((q.w - q.y) / (6. * c + EPSILON) + q.z);\n    return vec3(h, c, q.x);\n}\n\nvec3 HSVtoRGB(in vec3 hsv)\n{\n    // Hue-Saturation-Value [0..1] to RGB [0..1]\n    vec3 rgb = HUEtoRGB(hsv.x);\n    return ((rgb - 1.) * hsv.y + 1.) * hsv.z;\n}\n\nvec3 HSLtoRGB(in vec3 hsl)\n{\n    // Hue-Saturation-Lightness [0..1] to RGB [0..1]\n    vec3 rgb = HUEtoRGB(hsl.x);\n    float c = (1. - abs(2. * hsl.z - 1.)) * hsl.y;\n    return (rgb - 0.5) * c + hsl.z;\n}\n\nvec3 RGBtoHSV(in vec3 rgb)\n{\n    // RGB [0..1] to Hue-Saturation-Value [0..1]\n    vec3 hcv = RGBtoHCV(rgb);\n    float s = hcv.y / (hcv.z + EPSILON);\n    return vec3(hcv.x, s, hcv.z);\n}\n\nvec3 RGBtoHSL(in vec3 rgb)\n{\n    // RGB [0..1] to Hue-Saturation-Lightness [0..1]\n    vec3 hcv = RGBtoHCV(rgb);\n    float z = hcv.z - hcv.y * 0.5;\n    float s = hcv.y / (1. - abs(z * 2. - 1.) + EPSILON);\n    return vec3(hcv.x, s, z);\n}\n\nfloat compand(float f){\n    return pow(f,2.2f);//>0.04045? pow(((f+0.055f)/1.055f),2.4f): f/12.92f;\n}\nfloat invcompand(float f){\n    return pow(f,1.f/2.2f);\n}\n\n\nvec3 rgb2xyz(vec3 rgb){\n\trgb.r = compand(rgb.r);\n\trgb.g = compand(rgb.g);\n\trgb.b = compand(rgb.b);\n    return rgb*rgb2xyz_mat;\n}\nvec3 xyz2rgb(vec3 xyz){\n    xyz *= xyz2rgb_mat;\n\txyz.x = invcompand(xyz.x);\n\txyz.y = invcompand(xyz.y);\n\txyz.z = invcompand(xyz.z);\n    return xyz;\n}\n\nvec3 xyz2lab(vec3 xyz){\n    vec3 f;\n    f.x = xyz.x>eps? pow(xyz.x,1.f/3.f) : (kap*xyz.x+16.f)/116.f;\n    f.y = xyz.y>eps? pow(xyz.y,1.f/3.f) : (kap*xyz.y+16.f)/116.f;\n    f.z = xyz.z>eps? pow(xyz.z,1.f/3.f) : (kap*xyz.z+16.f)/116.f;\n    return vec3(116.f* f.y-16.f,\n                500.f*(f.x-f.y),\n                200.f*(f.y-f.z))/vec3(100)/d65_2deg;\n}\n\nvec3 lab2xyz(vec3 lab){\n    lab *= 100.f;\n    lab *= d65_2deg;\n    float fy = (lab.x+16.f)/116.f;\n    float fx = lab.y/500.f + fy;\n    float fz = fy - (lab.z/200.f);\n    float fx3 = pow(fx,3.f);\n    float fz3 = pow(fz,3.f);\n    return vec3(\n    \tfx3>eps? fx3: (116.f*fx-16.f)/kap,\n        lab.x > (kap*eps)? pow((lab.x+16.f)/116.f,3.f): lab.x/kap,\n        fz3>eps? fz3: (116.f*fz-16.f)/kap);\n}\n\n#define PI 3.1415926535897932384626433832795\n#define EULER 2.7182818284590452353602874713527\n\n\n/*\n * Structures\n */\n\n// Parameters for transfer characteristics (gamma curves)\nstruct transfer {\n\t// Exponent used to linearize the signal\n\tfloat power;\n\n\t// Offset from 0.0 for the exponential curve\n\tfloat off;\n\n\t// Slope of linear segment near 0\n\tfloat slope;\n\n\t// Values below this are divided by slope during linearization\n\tfloat cutoffToLinear;\n\n\t// Values below this are multiplied by slope during gamma correction\n\tfloat cutoffToGamma;\n};\n\n// Parameters for a colorspace\nstruct rgb_space {\n\t// Chromaticity coordinates (xyz) for Red, Green, and Blue primaries\n\tmat3 primaries;\n\n\t// Chromaticity coordinates (xyz) for white point\n\tvec3 white;\n\n\t// Linearization and gamma correction parameters\n\ttransfer trc;\n};\n\n\n/*\n * Preprocessor 'functions' that help build colorspaces as constants\n */\n\n// Turns 6 chromaticity coordinates into a 3x3 matrix\n#define Primaries(r1, r2, g1, g2, b1, b2)\\\n\tmat3(\\\n\t\tr1, r2, 1.0 - r1 - r2,\\\n\t\tg1, g2, 1.0 - g1 - g2,\\\n\t\tb1, b2, 1.0 - b1 - b2)\n\n// Creates a whitepoint's xyz chromaticity coordinates from the given xy coordinates\n#define white(x, y)\\\n\tvec3(x, y, (1.0 - x - y))\n\n#define Bright(w)\\\n\t((w)/w.y)\n\n// Creates a scaling matrix using a vec3 to set the xyz scalars\n#define diag(v)\\\n\tmat3(\\\n\t\t(v).x, 0.0, 0.0,\\\n\t\t0.0, (v).y, 0.0,\\\n\t\t0.0, 0.0, (v).z)\n\n// Creates a conversion matrix that turns RGB colors into XYZ colors\n#define rgbToXyz(space)\\\n\tspace.primaries*diag((inverse(space.primaries)*Bright(space.white)))\n\n// Creates a conversion matrix that turns XYZ colors into RGB colors\n#define xyzToRgb(space)\\\n\tinverse(rgbToXyz(space))\n\n// Creates a conversion matrix converts linear RGB colors from one colorspace to another\n#define conversionMatrix(f, t)\\\n\txyzToRgb(t)*rgbToXyz(f)\n\n\nconst mat3 CIECAM02 = mat3(\n\t0.7328, -0.7036, 0.003,\n\t0.4296, 1.6975, 0.0136,\n\t-0.1624, 0.0061, 0.9834\n);\n\nconst mat3 HUNT = mat3(\n\t0.38971, -0.22981, 0,\n\t0.68898, 1.1834, 0,\n\t-0.07868, 0.04641, 1\n);\n\nconst mat3 CIECAM97_1 = mat3(\n\t0.8951, -0.7502, 0.0389,\n\t0.2664, 1.7135, -0.0685,\n\t-0.1614, 0.0367, 1.0296\n);\n\nconst mat3 CIECAM97_2 = mat3(\n\t0.8562, -0.836, 0.0357,\n\t0.3372, 1.8327, -0.0469,\n\t-0.1934, 0.0033, 1.0112\n);\n\n\n/*\n * Chromaticities for RGB primaries\n */\n\n// Identity RGB\nconst mat3 primariesIdentity = mat3(1.0);\n\n// CIE 1931 RGB\nconst mat3 primariesCie = Primaries(\n\t0.72329, 0.27671,\n\t0.28557, 0.71045,\n\t0.15235, 0.02\n);\n\n// Original 1953 NTSC primaries\nconst mat3 primariesNtsc = Primaries(\n\t0.67, 0.33,\n\t0.21, 0.71,\n\t0.14, 0.08\n);\n\n// Never-popular and antiquated 'HDTV' primaries based mostly on 1953 NTSC\nconst mat3 primaries240m = Primaries(\n\t0.67, 0.33,\n\t0.21, 0.71,\n\t0.15, 0.06\n);\n\n// European Broadcasting Union primaries for SDTV and Rec. 601 (625 lines)\nconst mat3 primariesEbu = Primaries(\n\t0.64, 0.33,\n\t0.29, 0.6,\n\t0.15, 0.06\n);\n\n// P22 Phosphor primaries (allegedly; only found one source)\n// Used by older versions of SMPTE-C, before specific chromaticities were given\nconst mat3 primariesP22 = Primaries(\n\t0.61, 0.342,\n\t0.298, 0.588,\n\t0.151, 0.064\n);\n\n// Modern day SMPTE-C primaries, used in modern NTSC and Rec. 601 (525 lines)\nconst mat3 primariesSmpteC = Primaries(\n\t0.63, 0.34,\n\t0.31, 0.595,\n\t0.155, 0.07\n);\n\n// Alleged primaries for old Sony TVs with a very blue whitepoint\nconst mat3 primariesSony = Primaries(\n\t0.625, 0.34,\n\t0.28, 0.595,\n\t0.155, 0.07\n);\n\n// Rec. 709 (HDTV) and sRGB primaries\nconst mat3 primaries709 = Primaries(\n\t0.64, 0.33,\n\t0.3, 0.6,\n\t0.15, 0.06\n);\n\n// Rec. 709 (HDTV) and sRGB primaries\nconst mat3 primariesAdobe = Primaries(\n\t0.64, 0.33,\n\t0.21, 0.71,\n\t0.15, 0.06\n);\n\n// DCI-P3 primaries\nconst mat3 primariesDciP3 = Primaries(\n\t0.68, 0.32,\n\t0.265, 0.69,\n\t0.15, 0.06\n);\n\n// Rec. 2020 UHDTV primaries\nconst mat3 primaries2020 = Primaries(\n\t0.708, 0.292,\n\t0.17, 0.797,\n\t0.131, 0.046\n);\n\n// If the HUNT XYZ->LMS matrix were expressed instead as\n// chromaticity coordinates, these would be them\nconst mat3 primariesHunt = Primaries(\n\t0.8374, 0.1626,\n\t2.3, -1.3,\n\t0.168, 0.0\n);\n\n// If the CIECAM97_1 XYZ->LMS matrix were expressed instead as\n// chromaticity coordinates, these would be them\nconst mat3 primariesCiecam971 = Primaries(\n\t0.7, 0.306,\n\t-0.357, 1.26,\n\t0.136, 0.042\n);\n\n// If the CIECAM97_2 XYZ->LMS matrix were expressed instead as\n// chromaticity coordinates, these would be them\nconst mat3 primariesCiecam972 = Primaries(\n\t0.693, 0.316,\n\t-0.56, 1.472,\n\t0.15, 0.067\n);\n\n// If the CIECAM02 XYZ->LMS matrix were expressed instead as\n// chromaticity coordinates, these would be them\nconst mat3 primariesCiecam02 = Primaries(\n\t0.711, 0.295,\n\t-1.476, 2.506,\n\t0.144, 0.057\n);\n\n// LMS primaries as chromaticity coordinates, computed from\n// http://www.cvrl.org/ciepr8dp.htm, and\n// http://www.cvrl.org/database/text/cienewxyz/cie2012xyz2.htm\n/*const mat3 primariesLms = Primaries(\n\t0.73840145, 0.26159855,\n\t1.32671635, -0.32671635,\n\t0.15861916, 0.0\n);*/\n\n// Same as above, but in fractional form\nconst mat3 primariesLms = Primaries(\n\t194735469.0/263725741.0, 68990272.0/263725741.0,\n\t141445123.0/106612934.0, -34832189.0/106612934.0,\n\t36476327.0/229961670.0, 0.0\n);\n\n\n/*\n * Chromaticities for white points\n */\n\n// Standard Illuminant C. White point for the original 1953 NTSC color system\nconst vec3 whiteC = white(0.310063, 0.316158);\n\n// Standard illuminant E (also known as the 'equal energy' white point)\nconst vec3 whiteE = vec3(1.0);\n\n// Alleged whitepoint to use with the P22 phosphors (D65 might be more proper)\nconst vec3 whiteP22 = white(0.313, 0.329);\n\n// Standard illuminant D65. Note that there are more digits here than specified\n// in either sRGB or Rec 709, so in some cases results may differ from other\n// software. Color temperature is roughly 6504 K (originally 6500K, but complex\n// science stuff made them realize that was innaccurate)\nconst vec3 whiteD65 = white(0.312713, 0.329016);\n\n// Standard illuminant D65 according to sRGB, Rec. 709, and other display standards\nconst vec3 whiteD65S = white(0.3127, 0.3290);\n\n// Standard illuminant D50. Just included for the sake of including it. Content\n// for Rec. 709 and sRGB is recommended to be produced using a D50 whitepoint.\n// For the same reason as D65, the color temperature is 5003 K instead of 5000 K\nconst vec3 whiteD50 = white(0.34567, 0.35850);\n\n// Standard illuminant D50 according to ICC standards (they specify a hex value\n// for the 16-bit integer representation, as well as a specific way to decode it,\n// so I did some math to figure out exactly the values they expect)\n\n// Floating point representation of ICC D50\nconst vec3 whiteD50I = white(3214.0/9297.0, 10000.0/27891.0);\n\n// White point for DCI-P3 Theater\nconst vec3 whiteTheater = white(0.314, 0.351);\n\n// Very blue white point for old Sony televisions. Color temperature of 9300 K.\n// Use with the 'primariesSony' RGB primaries defined above\nconst vec3 whiteSony = white(0.283, 0.298);\n\n\n/*\n * Gamma curve parameters\n */\n\n// Linear gamma\nconst transfer gam10 = transfer(1.0, 0.0, 1.0, 0.0, 0.0);\n\n// Gamma of 2.2; not linear near 0. Was defined abstractly to be used by early\n// NTSC systems, before SMPTE 170M was modified to specify a more exact curve\nconst transfer gam22 = transfer(2.2, 0.0, 1.0, 0.0, 0.0);\n\n// Gamma of 2.4; not linear near 0. Seems a popular choice among some people\n// online, so I included it. I don't think any standard uses this\nconst transfer gam24 = transfer(2.4, 0.0, 1.0, 0.0, 0.0);\n\n// Gamma of 2.5; not linear near 0. Approximately what old Sony TVs used\nconst transfer gam25 = transfer(2.5, 0.0, 1.0, 0.0, 0.0);\n\n// Gamma of 2.8; not linear near 0. Loosely defined gamma for European SDTV\nconst transfer gam28 = transfer(2.8, 0.0, 1.0, 0.0, 0.0);\n\n// Modern SMPTE 170M, as well as Rec. 601, Rec. 709, and a rough approximation\n// for Rec. 2020 content as well. Do not use with Rec. 2020 if you work with\n// high bit depths!\nconst transfer gam170m = transfer(1.0/0.45, 0.099, 4.5, 0.0812, 0.018);\n\n// Gamma for sRGB. This is the only difference between sRGB and Rec. 709\nconst transfer gamSrgb = transfer(2.4, 0.055, 12.92, 0.04045, 0.0031308);\n\n// Gamma for the CIE L*a*b* Lightness scale\nconst transfer gamLab = transfer(3.0, 0.16, 243.89/27.0, 0.08, 216.0/24389.0);\n\n\n/*\n * RGB Colorspaces\n */\n\n// CIE 1931 RGB\nconst rgb_space Cie1931 = rgb_space(primariesCie, whiteE, gam10);\n\n// Identity RGB\nconst rgb_space Identity = rgb_space(primariesIdentity, whiteE, gam10);\n\n// Original 1953 NTSC\nconst rgb_space Ntsc = rgb_space(primariesNtsc, whiteC, gam22);\n\n// Mostly unused and early HDTV standard (SMPTE 240M)\nconst rgb_space Smpte240m = rgb_space(primaries240m, whiteD65S, gam22);\n\n// European Broadcasting Union SDTV\nconst rgb_space Ebu = rgb_space(primariesEbu, whiteD65S, gam28);\n\n// Original, imprecise colorspace for NTSC after 1987 (probably incorrect)\nconst rgb_space SmpteC = rgb_space(primariesP22, whiteD65S, gam22);\n\n// Modern SMPTE \"C\" colorimetry\nconst rgb_space Smpte170m = rgb_space(primariesSmpteC, whiteD65S, gam170m);\n\n// Old Sony displays using high temperature white point\nconst rgb_space Sony = rgb_space(primariesSony, whiteSony, gam25);\n\n// Rec. 709 (HDTV)\nconst rgb_space Rec709 = rgb_space(primaries709, whiteD65S, gam170m);\n\n// sRGB (mostly the same as Rec. 709, but different gamma)\nconst rgb_space Srgb = rgb_space(primaries709, whiteD65S, gamSrgb);\n\n// Adobe RGB monitors\nconst rgb_space AdobeRgb = rgb_space(primariesAdobe, whiteD65S, gam22);\n\n// DCI-P3 D65\nconst rgb_space DciP3D65 = rgb_space(primariesDciP3, whiteD65S, gam170m);\n\n// DCI-P3 D65\nconst rgb_space DciP3Theater = rgb_space(primariesDciP3, whiteTheater, gam170m);\n\n// Rec. 2020\nconst rgb_space Rec2020 = rgb_space(primaries2020, whiteD65S, gam170m);\n\n// Hunt primaries, balanced against equal energy white point\nconst rgb_space HuntRgb = rgb_space(primariesHunt, whiteE, gam10);\n\n// CIE CAM 1997 primaries v1, balanced against equal energy white point\nconst rgb_space Ciecam971Rgb = rgb_space(primariesCiecam971, whiteE, gam10);\n\n// CIE CAM 1997 primaries v2, balanced against equal energy white point\nconst rgb_space Ciecam972Rgb = rgb_space(primariesCiecam972, whiteE, gam10);\n\n// CIE CAM 2002 primaries, balanced against equal energy white point\nconst rgb_space Ciecam02Rgb = rgb_space(primariesCiecam02, whiteE, gam10);\n\n// Lms primaries, balanced against equal energy white point\nconst rgb_space LmsRgb = rgb_space(primariesLms, whiteE, gam10);\n\n\n/**********************************************************\n *                                                        *\n *  Change these to adjust various conversion parameters  *\n *                                                        *\n **********************************************************/\n\n// Display colorspace\nconst rgb_space disp = rgb_space(primaries709, whiteD65S, gamSrgb);\n\n// Color Appearance Model (or 'reference') white point\nconst vec3 whiteCam = whiteD50I;\n\n// camMat is an easy way to set the transformation matrix, but both\n// toCam and frCam are what should be used, as they're adapted to the\n// color appearance model white point\nconst mat3 camMat = CIECAM97_1;\nconst mat3 toCam = inverse(diag(camMat*Bright(whiteCam)))*camMat;\nconst mat3 frCam = inverse(camMat)*diag(camMat*Bright(whiteCam));\n\n// Modify XYZ↔RGB matrices to perform whitepoint adaptation using a\n// wrong Von Kries transformation matrix (CIECAM97_1 has nonlinearities\n// in the 'S' cone that is not accounted for in ICC profiles)\nconst mat3 toRgb = xyzToRgb(disp)*frCam*diag((toCam*Bright(disp.white))/(toCam*Bright(whiteCam)))*toCam;\nconst mat3 toXyz = frCam*diag((toCam*Bright(whiteCam))/(toCam*Bright(disp.white)))*toCam*rgbToXyz(disp);\n\n// This might be easier to understand (← shows matrix multiplication):\n// toRgb = XYZtoRGB←LMStoXYZ←diag(whiteDispInLMS/whiteCamInLMS)←XYZtoLMS\n// toXyz = LMStoXYZ←diag(whiteCamInLMS/whiteDispInLMS)←XYZtoLMS←RGBtoXYZ\n\n\n/*\n * Conversion Functions\n */\n\nvec4 gamutScale(vec4 color, float luma)\n{\n\tfloat low = min(color.r, min(color.g, min(color.b, 0.0)));\n\tfloat high = max(color.r, max(color.g, max(color.b, 1.0)));\n\n\tfloat lowScale = low/(low - luma);\n\tfloat highScale = max((high - 1.0)/(high - luma), 0.0);\n\tfloat scale = max(lowScale, highScale);\n\tcolor.rgb += scale*(luma - color.rgb);\n\n\treturn color;\n}\n\n// Converts display RGB colors to a linear light scale\nvec4 toLinear(vec4 color, const transfer trc)\n{\n\tbvec4 cutoff = lessThan(color, vec4(trc.cutoffToLinear));\n\tvec4 higher = pow((color + trc.off)/(1.0 + trc.off), vec4(trc.power));\n\tvec4 lower = color/trc.slope;\n\n\tcolor = mix(higher, lower, cutoff);\n\n\treturn color;\n}\n\n// Gamma-corrects RGB colors to be sent to a display\nvec4 toGamma(vec4 color, const transfer trc)\n{\n\tbvec4 cutoff = lessThan(color, vec4(trc.cutoffToGamma));\n\tvec4 higher = (1.0 + trc.off)*pow(color, vec4(1.0/trc.power)) - trc.off;\n\tvec4 lower = color*trc.slope;\n\n\tcolor = mix(higher, lower, cutoff);\n\n\treturn color;\n}\nvec3 lab2rgb(vec3 col) {\n    vec4 color = vec4(col, 1.0);\n    // Convert to XYZ\n\tcolor.y = (color.y + 16.0)/116.0;\n\tcolor.xz = color.y + color.xz/vec2(500, -200);\n\tcolor.xyz = (116.0*color.xyz - 16.0)/100.0;\n\tcolor = toLinear(color, gamLab);\n\tcolor.xyz *= Bright(whiteCam);\n\n\t// Convert to RGB\n\tfloat luma = color.y;\n\tcolor.rgb = toRgb*color.xyz;\n\tcolor = gamutScale(color, luma);\n\tcolor = toGamma(color, disp.trc);\n    if (method == 1) {\n        return color.rgb;\n    } else {\n        return xyz2rgb(lab2xyz(col));\n    }\n}\nvec3 rgb2lab(vec3 col) {\n    vec4 color = vec4(col, 1.0);\n    // Convert to XYZ\n\tcolor = toLinear(color, disp.trc);\n\tcolor.xyz = toXyz*color.rgb;\n\n\t// Convert to L*a*b*\n\t// L* is held in .y (to match XYZ luminosity); a*b* is held in .xz\n\tcolor.xyz /= Bright(whiteCam);\n\tcolor = toGamma(color, gamLab);\n\tcolor.xyz = (color.xyz*100.0 + 16.0)/116.0;\n\tcolor.xz = (color.xz - color.y)*vec2(500, -200);\n\tcolor.y = color.y*116.0 - 16.0;\n    vec3 _col = color.yzx;\n    if (method == 1) {\n        return _col.rgb;\n    } else {\n        return xyz2lab(rgb2xyz(col));\n    }\n}\n\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "/*\nIn this buffer we do the heavy lifting of converting the image to the palette colors.\nDesigned to be used with still images, this makes certain that it is only run when needed instead of each frame.\nThat way, we can save on GPU time without compromising the intended purpose.\n*/\n//Blur stuff, might be used at a later date\nfloat normpdf(in float x, in float sigma)\n{\n\treturn 0.39894*exp(-0.5*x*x/(sigma*sigma))/sigma;\n}\n\nfloat lookup(vec2 p, float dx, float dy, float d)\n{\n    vec2 uv = (p.xy + vec2(dx * d, dy * d)) / iResolution.xy;\n    vec4 col = texture(iChannel1, uv.xy);\n\t\n\t// return as luma\n    return 0.2126*col.r + 0.7152*col.g + 0.0722*col.b;\n}\n#define useArray false\n//Edge detection, maybe combine this to help find pixel transitions?\nfloat getEdge(vec2 p, float d) {\n    // simple sobel edge detection\n    float gx = 0.0;\n    gx += -1.0 * lookup(p, -1.0, -1.0, d);\n    gx += -2.0 * lookup(p, -1.0,  0.0, d);\n    gx += -1.0 * lookup(p, -1.0,  1.0, d);\n    gx +=  1.0 * lookup(p,  1.0, -1.0, d);\n    gx +=  2.0 * lookup(p,  1.0,  0.0, d);\n    gx +=  1.0 * lookup(p,  1.0,  1.0, d);\n    \n    float gy = 0.0;\n    gy += -1.0 * lookup(p, -1.0, -1.0, d);\n    gy += -2.0 * lookup(p,  0.0, -1.0, d);\n    gy += -1.0 * lookup(p,  1.0, -1.0, d);\n    gy +=  1.0 * lookup(p, -1.0,  1.0, d);\n    gy +=  2.0 * lookup(p,  0.0,  1.0, d);\n    gy +=  1.0 * lookup(p,  1.0,  1.0, d);\n    \n\t// hack: use g^2 to conceal noise in the video\n    return gx*gx + gy*gy;\n}\n\n//Gaussian Blurring\nvec3 gaussBlur( sampler2D tex, vec2 uv, float lod, float sigma)\n{\n    float rounds = sigma * 2.;\n    float invTwoSigmaSqr = 1. / (2. * sigma * sigma);\n    vec2 d = vec2(exp2(lod)/iChannelResolution[0].xy);\n    vec4 col = textureLod(tex, uv, lod);\n    \n    for (float i = 1.; i < rounds; ++i) {\n        col += (\n        textureLod(tex, uv + d * i, lod) +\n        textureLod(tex, uv - d * i, lod)\n        ) * exp(- i * i * invTwoSigmaSqr);\n    }\n    \n    return col.rgb/col.a;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    int index = 0;\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    //Get original color variables\n    vec3 col = texture(iChannel0, uv).rgb;\n    vec3 ocol = col;\n    vec3 newCol;\n    \n    //Sample pixel for storing data [not working currently]\n    vec4 samplePix = texture(iChannel1, vec2(1.0));\n    if (iFrame < 3) {\n        //For sample pixel, not working currently though\n        /*if (fragCoord.x >= iResolution.x-1.5 && fragCoord.y >= iResolution.y-1.5) {\n            newCol = vec3(1.0);\n        } else {*/\n            if (convert) {\n                col = RGBtoHSV(col);\n            }\n            float minDist = 10000.0;\n            float dist = 0.0;\n            vec3 colRedef;\n            newCol = col;\n            if (useArray) {\n                for (int i = 0; i < numColors; i++) {\n                    int indexA = i;\n                    float j = mod(float(i), 100.0);\n                    float k = round(float(i)/100.0);\n                    colRedef = texture(iChannel1, vec2(float(i)/iChannelResolution[1].x, 0.0)).rgb;\n                    dist = distance(col, colRedef);\n                    if (dist < minDist) {\n                        minDist = dist;\n                        newCol = colRedef;\n                    }\n                }\n            } else {\n                //Define outside for loop, per AMD: https://www.amd.com/system/files/TechDocs/25112.PDF\n                float i,j,k;\n                for (i = 0.0; i <= 1.0; i += oneOver) {\n                    for (k = 0.0; k <= 1.0; k += oneOver) {\n                        for (j = 0.0; j <= 1.0; j += oneOver) {\n                            //Get the new color\n                            colRedef = vec3(i, j, k);\n                            //Compare with old color\n                            dist = distance(col, colRedef);\n                            //if less than old record holder then we have a winner (until the new record is broken)\n                            if (dist < minDist) {\n                                //was testing blurring distances. No significant impact until too extreme using this implementation.\n                                /*for (float d = 0.; d < 360.; d += 45.) {\n                                    float _d = (d/180.0)*3.1415982;\n                                    float dx = cos(d)/iResolution.x;\n                                    float dy = sin(d)/iResolution.y;\n                                    vec3 ncol = texture(iChannel0, uv+vec2(dx, dy)*2.).rgb;\n                                    dist += distance(ncol, colRedef)/3.0;\n                                }\n                                if (dist < minDist) {*/\n                                    //Award them their titles.\n                                    minDist = dist;\n                                    newCol = colRedef;\n                                //}\n                            }\n                        }\n                    } \n                }\n            }\n            if (convert) {\n                newCol = HSVtoRGB(newCol);\n            }\n        //}\n    } else {\n        //If not first frame just skip over it, no need to do the work again.\n        newCol = texture(iChannel1, uv).rgb;\n    }\n    // Output color\n    fragColor = vec4((newCol), 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "/*\nThis shader just holds whatever image we want to operate on. Useful for changing the image quicker.\n*/\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord.xy/iResolution.xy;\n    fragColor = texture(iChannel0, uv);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "texture",
                        "id": 5,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}