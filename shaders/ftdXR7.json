{
    "Shader": {
        "info": {
            "date": "1640019801",
            "description": "Inspired by https://graphics.cs.illinois.edu/wp-content/uploads/2019/09/paper1013-main.pdf\nPolygonal shapes only, uses basic box kernel with texture space axis aligned max screen space derivative kernel shape",
            "flags": 0,
            "hasliked": 0,
            "id": "ftdXR7",
            "likes": 8,
            "name": "Analytical AA - Polygon VG ",
            "published": 3,
            "tags": [
                "procedural",
                "antialiasing",
                "vector",
                "aa",
                "analytical",
                "texturing",
                "vg"
            ],
            "usePreview": 0,
            "username": "sopyer",
            "viewed": 338
        },
        "renderpass": [
            {
                "code": "// Inspired by https://graphics.cs.illinois.edu/wp-content/uploads/2019/09/paper1013-main.pdf(Real-Time Analytic Antialiased Text for 3-D Environments)\n// Polygonal shapes only, uses basic box kernel with texture space axis aligned max screen space derivative kernel shape.\n\n\n// The MIT License\n// Copyright Â© 2019 Mykhailo Parfeniuk\n// Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\nfloat saturate(float x)\n{\n    return clamp(x, 0.0, 1.0);\n}\n\nvec2 saturate(vec2 x)\n{\n    return clamp(x, vec2(0.0), vec2(1.0));\n}\n\nvec2 rcp(vec2 v)\n{\n\treturn vec2(1.0f) / v;\n}\n\nfloat IntegrateSegment(vec2 P0, vec2 P1, vec2 XBounds, vec2 YBounds)\n{\n\tvec2 D = P1 - P0;\n\tvec2 invD = rcp(D);\n\n\tP0.y -= YBounds.x; \n\tYBounds = vec2(0.0f, YBounds.y - YBounds.x);\n\n\tvec2 tv = saturate((XBounds - P0.xx) * invD.xx);\n\tvec2 th = saturate((YBounds - P0.yy) * invD.yy);\n\n\tfloat tv_min = min(tv.x, tv.y);\n\tfloat tv_max = max(tv.x, tv.y);\n\n\tfloat th_min = min(th.x, th.y);\n\tfloat th_max = max(th.x, th.y);\n\n#if 1 // Handle Nan\n#if 0 // Return second argument in case of NaN\n\ttv_min = max(tv_min, 0.0f);\n\ttv_max = min(tv_max, 1.0f);\n\tth_min = max(th_min, 0.0f);\n\tth_max = min(th_max, 1.0f);\n#else\n\ttv_min = max(0.0f, tv_min);\n\ttv_max = min(1.0f, tv_max);\n\tth_min = max(0.0f, th_min);\n\tth_max = min(1.0f, th_max);\n#endif\n#endif\n\n\tfloat tmin = max(tv_min, th_min);\n\tfloat tmax = min(tv_max, th_max);\n\n\tfloat t_p1 = min(tmin, tmax);\n\tfloat t_p2 = max(tmin, tmax);\n\n\tvec2 p0 = clamp(P0 + tv_min * D, vec2(XBounds.x, YBounds.x), vec2(XBounds.y, YBounds.y));\n\tvec2 p1 = clamp(P0 + t_p1 * D, vec2(XBounds.x, YBounds.x), vec2(XBounds.y, YBounds.y));\n\tvec2 p2 = clamp(P0 + t_p2 * D, vec2(XBounds.x, YBounds.x), vec2(XBounds.y, YBounds.y));\n\tvec2 p3 = clamp(P0 + tv_max * D, vec2(XBounds.x, YBounds.x), vec2(XBounds.y, YBounds.y));\n\n\treturn (p3.x - p2.x) * p3.y + 0.5f * (p2.x - p1.x) * (p2.y + p1.y) + (p1.x - p0.x) * p0.y;\n}\n\n\n\nvec3 bg = vec3(0.1, 0.5, 0.4);\nvec3 grey = vec3(0.1);\nvec3 white = vec3(1);\nvec3 black = vec3(0);\nvec3 red = vec3(1, 0, 0);\nvec3 blue = vec3(0, 0, 1);\nvec3 yellow = vec3(1, 1, 0);\nvec3 magenta = vec3(1, 0, 1);\n\n\n\n// --- AA Box filtered version ---\n\nfloat triangle(in vec2 xBounds, in vec2 yBounds)\n{\n    return IntegrateSegment(vec2(5, -5), vec2(25, -5), xBounds, yBounds)\n                  + IntegrateSegment(vec2(25, -5), vec2(5, -25), xBounds, yBounds)\n                  + IntegrateSegment(vec2(5, -25), vec2(5, -5), xBounds, yBounds);\n}\n\nfloat quad(in vec2 xBounds, in vec2 yBounds)\n{\n    return abs(IntegrateSegment(vec2(-25, -5), vec2(-5, -15), xBounds, yBounds)\n                  + IntegrateSegment(vec2(-5, -15), vec2(-25, -25), xBounds, yBounds)\n                  + IntegrateSegment(vec2(-25, -25), vec2(-15, -15), xBounds, yBounds)\n                  + IntegrateSegment(vec2(-15, -15), vec2(-25, -5), xBounds, yBounds));\n}\n\n\nfloat romb(in vec2 xBounds, in vec2 yBounds)\n{\n    return abs(IntegrateSegment(vec2(5, 15), vec2(15, 25), xBounds, yBounds)\n                  + IntegrateSegment(vec2(15, 25), vec2(25, 15), xBounds, yBounds)\n                  + IntegrateSegment(vec2(25, 15), vec2(15, 5), xBounds, yBounds)\n                  + IntegrateSegment(vec2(15, 5), vec2(5, 15), xBounds, yBounds));\n}\n\nfloat fivegon(in vec2 xBounds, in vec2 yBounds)\n{\n    return IntegrateSegment(vec2(-5, 5), vec2(-20, 5), xBounds, yBounds)\n                  + IntegrateSegment(vec2(-20, 5), vec2(-25, 20), xBounds, yBounds)\n                  + IntegrateSegment(vec2(-25, 20), vec2(-20, 25), xBounds, yBounds)\n                  + IntegrateSegment(vec2(-20,25), vec2(-5, 20), xBounds, yBounds);\n                  + IntegrateSegment(vec2(-5, 20), vec2(-5, 5), xBounds, yBounds);\n}\n\nfloat rect(vec2 pmin, vec2 pmax, float w, in vec2 xBounds, in vec2 yBounds)\n{\n    float result = 0.0;\n\n    result += IntegrateSegment(vec2(pmin.x-w, pmin.y-w), vec2(pmin.x-w, pmax.y+w), xBounds, yBounds);\n    result += IntegrateSegment(vec2(pmin.x+w, pmax.y-w), vec2(pmin.x+w, pmin.y+w), xBounds, yBounds);\n\n    result += IntegrateSegment(vec2(pmin.x-w, pmax.y+w), vec2(pmax.x+w, pmax.y+w), xBounds, yBounds);\n    result += IntegrateSegment(vec2(pmax.x-w, pmax.y-w), vec2(pmin.x+w, pmax.y-w), xBounds, yBounds);\n\n    result += IntegrateSegment(vec2(pmax.x+w, pmax.y+w), vec2(pmax.x+w, pmin.y-w), xBounds, yBounds);\n    result += IntegrateSegment(vec2(pmax.x-w, pmin.y+w), vec2(pmax.x-w, pmax.y-w), xBounds, yBounds);\n\n    result += IntegrateSegment(vec2(pmax.x+w, pmin.y-w), vec2(pmin.x-w, pmin.y-w), xBounds, yBounds);\n    result += IntegrateSegment(vec2(pmin.x+w, pmin.y+w), vec2(pmax.x-w, pmin.y+w), xBounds, yBounds);\n    \n    return result;\n}\n\nvec3 aaBoxFilteredTexture( in vec2 p, in vec2 ddx, in vec2 ddy )\n{\n    vec3 color;\n    vec2 max_dd = max(ddx, ddy);\n    vec2 xBounds = p.xx + vec2(-0.5, 0.5) * max_dd.xx;\n    vec2 yBounds = p.yy + vec2(-0.5, 0.5) * max_dd.yy;\n    float kernelNorm = 1.0 / (max_dd.x * max_dd.y); \n    \n    // background\n    color = bg;\n    color = mix(color, white, saturate(kernelNorm*rect(vec2(-35), vec2(35), 0.15, xBounds, yBounds)));\n    color = mix(color, red, saturate(kernelNorm*romb(xBounds, yBounds)));\n    color = mix(color, blue, saturate(kernelNorm*triangle(xBounds, yBounds)));\n    color = mix(color, magenta, saturate(kernelNorm*quad(xBounds, yBounds)));\n    color = mix(color, yellow, saturate(kernelNorm*fivegon(xBounds, yBounds)));\n\n    return color;\n}\n\n// Helpers\n\nvec2 toUV( in vec3 pos )\n{\n\treturn pos.xz;\n}\n\n\nvoid calcCamera( out vec3 ro, out vec3 ta )\n{\n\tfloat an = 0.2*iTime+2.0;//0.1*sin(3.0*iTime);\n\tro = vec3( 6.0*cos(an), 200.0*abs(0.5+0.5*sin(2.0*an))+1.05, 6.0*sin(an) );\n    ta = vec3( 0.0, 1.0, 0.0 );\n}\n\nvoid calcRayForPixel( in vec2 pix, out vec3 resRo, out vec3 resRd )\n{\n\tvec2 p = (-iResolution.xy + 2.0*pix) / iResolution.y;\n\t\n     // camera movement\t\n\tvec3 ro, ta;\n\tcalcCamera( ro, ta );\n    // camera matrix\n    vec3 ww = normalize( ta - ro );\n    vec3 uu = normalize( cross(ww,vec3(0.0,1.0,0.0) ) );\n    vec3 vv = normalize( cross(uu,ww));\n\t// create view ray\n\tvec3 rd = normalize( p.x*uu + p.y*vv + 2.0*ww );\n\t\n\tresRo = ro;\n\tresRd = rd;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 p = (-iResolution.xy + 2.0*fragCoord) / iResolution.y;\n\t\n\tvec3 ro, rd, ddx_ro, ddx_rd, ddy_ro, ddy_rd;\n\tcalcRayForPixel( fragCoord + vec2(0.0,0.0), ro, rd );\n\tcalcRayForPixel( fragCoord + vec2(1.0,0.0), ddx_ro, ddx_rd );\n\tcalcRayForPixel( fragCoord + vec2(0.0,1.0), ddy_ro, ddy_rd );\n\t\t\n    \n\tvec3 col = vec3(0.9);\n    \n    // intersect plane\n\tfloat t = (0.01-ro.y)/rd.y;\n\tif( t>0.0 )\n\t{\n\t\tvec3 nor = vec3(0.0,1.0,0.0); \n\t\tvec3 pos = ro + t*rd;\n        \n#if 1\n\t\t// -----------------------------------------------------------------------\n        // compute ray differentials by intersecting the tangent plane to the  \n        // surface.\t\t\n\t\t// -----------------------------------------------------------------------\n\n\t\t// computer ray differentials\n\t\tvec3 ddx_pos = ddx_ro - ddx_rd*dot(ddx_ro-pos,nor)/dot(ddx_rd,nor);\n\t\tvec3 ddy_pos = ddy_ro - ddy_rd*dot(ddy_ro-pos,nor)/dot(ddy_rd,nor);\n\n\t\t// calc texture sampling footprint\t\t\n\t\tvec2     uv = toUV(     pos );\n\t\tvec2 ddx_uv = toUV( ddx_pos ) - uv;\n\t\tvec2 ddy_uv = toUV( ddy_pos ) - uv;\n#else\n\t\t// -----------------------------------------------------------------------\n        // Because we are in the GPU, we do have access to differentials directly\n        // This wouldn't be the case in a regular raytrace.\n\t\t// It wouldn't work as well in shaders doing interleaved calculations in\n\t\t// pixels (such as some of the 3D/stereo shaders here in Shadertoy)\n\t\t// -----------------------------------------------------------------------\n\t\tvec2 uvw = toUV( pos );\n\n\t\t// calc texture sampling footprint\t\t\n\t\tvec2 ddx_uvw = dFdx( uvw ); \n        vec2 ddy_uvw = dFdy( uvw ); \n#endif\n\n        // Texture\n        col = vec3(1.0)*aaBoxFilteredTexture( uv, abs(ddx_uv), abs(ddy_uv) );\n\t}\n\t\n    // \"gamma correction\"\t\n\tcol = pow( col, vec3(0.4545) );\n\tfragColor = vec4( col, 1.0 );\n}",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}