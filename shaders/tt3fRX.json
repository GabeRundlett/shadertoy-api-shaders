{
    "Shader": {
        "info": {
            "date": "1613238917",
            "description": "Chain of Exponential Moving Average Infinite Impulse Response filters applied temporally to clean a noisy input. A chain of filters is used to achieve a steeper low-pass filtering slope. Variance Clipping is used to fight the inherent temporal ghosting.",
            "flags": 32,
            "hasliked": 0,
            "id": "tt3fRX",
            "likes": 12,
            "name": "Temporal EMA IIR Denoising",
            "published": 3,
            "tags": [
                "noise",
                "filter",
                "denoise",
                "iir",
                "temporal",
                "varianceclipping",
                "ema"
            ],
            "usePreview": 0,
            "username": "spawner64",
            "viewed": 941
        },
        "renderpass": [
            {
                "code": "// Temporal EMA IIR Denoising\n//\n// EMA IIR?\n//\n// Exponential Moving Average (EMA) Infinite Impulse Response (IIR) filter:\n// - Poor man's low-pass filter.\n// - A fancy name for the well-known \"damping\" filter.\n// - Not possesing the best frequency filtering (not steep, not well behaved).\n// - Ideally would use a Butterworth filter instead, but requires 2 additional buffers just for the first order.\n//\n// More about EMA IIR: https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\n//\n// Goal:\n// - Removing noise from a noisy input.\n//\n// Contraints:\n// - The noise must be pattern-free (the noise from stochastic processes is good).\n//\n// Strategy:\n// - Take the input signal and apply a temporal low-pass filter (in our case, the trivial EMA IIR filter).\n// - Simply applying a temporal filter does remove some noise, but also causes temporal artifacts like ghosting.\n// - Apply Variance Clipping to reject the samples that should not contribute to current sample.\n// - This entire process is used in many temmporal anti-aliasing solutions, but in our case we apply it without\n//   the luxury of knowing the motion vectors of last frame. Knowing the motion vectors is valuable because they\n//   can be used to reproject the history buffer and achieve sharper results.\n//\n// Use more EMA IIR VC filters in a chain to improve the frequency response of the EMA IIR. In our case we use 3\n// filters, which is comparable in frequency response roll-off with a first order Butterworth filter.\n//\n// NOTE: Although it's true that the process produces a result that lost some sharpness compared with the input\n// signal, beware what adding noise to a signal increases its perceived sharpness (left column seems sharper than\n// the original signal (right column)).\n//\n// Feel free to play with different values in the Common section to achieve different results.\n\n// ------------------------------------------------------------------------- //\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 col = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    if (normalizedSpaceUV.x <= V_SPLIT_A) {\n        fragColor = vec4(col, 1.0);\n        return;\n    }\n\n    if (normalizedSpaceUV.x > V_SPLIT_B) {\n        fragColor = vec4(col, 1.0);\n        return;\n    }\n\n    fragColor = vec4(col, 1.0);\n\n    fragColor = renderVSplitLine(fragColor, SPLIT_LINE_COLOR, 2.0, screenSpaceUV, V_SPLIT_A * iResolution.x);\n    fragColor = renderVSplitLine(fragColor, SPLIT_LINE_COLOR, 2.0, screenSpaceUV, V_SPLIT_B * iResolution.x);\n}\n\n// ------------------------------------------------------------------------- //",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// ------------------------------------------------------------------------- //\n\n// CONFIG\n\n#define NOISE_INTENSITY                         (0.2)        // 0.0 - no noise, 1.0 - 0.5 radius noise \n#define EMA_IIR_INVERSE_CUTOFF_FREQUENCY        (0.852)      // 0.0 - 0.999\n#define VARIANCE_CLIPPING_COLOR_BOX_SIGMA       (0.975)      // 0.5 - 1.0\n#define APPLY_VARIANCE_CLIPPING_FIRST           (__ON__)\n#define SPLIT_LINE_COLOR                        (vec3(0))\n#define SPLIT_LINE_THICKNESS                    (2.0)        // in pixels\n\n// ------------------------------------------------------------------------- //\n\n#define SAMPLE_RGBA(sampler, coord) (texture((sampler), (coord)))\n#define SAMPLE_RGB(sampler, coord) (SAMPLE_RGBA((sampler), (coord)).rgb)\n\n// ------------------------------------------------------------------------- //\n\n#define __OFF__ (0)\n#define __ON__  (1)\n\n// ------------------------------------------------------------------------- //\n\n#define V_SPLIT_A (0.333)\n#define V_SPLIT_B (0.666)\n\n// ------------------------------------------------------------------------- //\n\n// https://www.shadertoy.com/view/4djSRW\nvec3 hash33(vec3 p3) {\n\tp3 = fract(p3 * vec3(0.1031, 0.1030, 0.0973));\n    p3 += dot(p3, p3.yxz + 33.33);\n    return fract((p3.xxy + p3.yxx) * p3.zyx);\n}\n\n// ------------------------------------------------------------------------- //\n\n// https://www.shadertoy.com/view/4dSBDt\n\nvec3 RGBToYCoCg(vec3 RGB) {\n    float cTerm = 0.5 * 256.0 / 255.0;\n\tfloat Y  = dot(RGB, vec3( 1, 2,  1)) * 0.25;\n\tfloat Co = dot(RGB, vec3( 2, 0, -2)) * 0.25 + cTerm;\n\tfloat Cg = dot(RGB, vec3(-1, 2, -1)) * 0.25 + cTerm;\n\treturn vec3(Y, Co, Cg);\n}\n\nvec3 YCoCgToRGB(vec3 YCoCg) {\n\tfloat cTerm = 0.5 * 256.0 / 255.0;\n\tfloat Y  = YCoCg.x;\n\tfloat Co = YCoCg.y - cTerm;\n\tfloat Cg = YCoCg.z - cTerm;\n\tfloat R  = Y + Co - Cg;\n\tfloat G  = Y + Cg;\n\tfloat B  = Y - Co - Cg;\n\treturn vec3(R, G, B);\n}\n\n// ------------------------------------------------------------------------- //\n\n// based on https://www.shadertoy.com/view/4dSBDt\nvoid getVarianceClippingBounds(vec3 color, sampler2D colorSampler, ivec2 screenSpaceUV, float colorBoxSigma, out vec3 colorMin, out vec3 colorMax) {\n    vec3 colorAvg = color;\n    vec3 colorVar = color * color;\n\n    // Marco Salvi's Implementation (by Chris Wyman)\n    // unrolled loop version\n    \n    vec3 fetch = vec3(0);\n\n    // unwinded the for loop\n    {\n        // top\n        {\n            // left / top\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2(-1, -1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // center / top\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 0, -1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // right / top\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 1, -1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n        }\n\n        // center\n        {\n            // left / center\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2(-1,  0), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            \n            // center / center is intentionally skipped\n            \n\n            // right / center\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 1,  0), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n        }\n\n        // bottom\n        {\n            // left / bottom\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2(-1,  1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // center / bottom\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 0,  1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // right / bottom\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 1,  1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n        }\n    }\n\n    colorAvg *= 0.111111111;\n    colorVar *= 0.111111111;\n\n    vec3 sigma = sqrt(max(vec3(0.0), colorVar - colorAvg * colorAvg));\n\tcolorMin = colorAvg - colorBoxSigma * sigma;\n\tcolorMax = colorAvg + colorBoxSigma * sigma;\n}\n\n// ------------------------------------------------------------------------- //\n\nvec4 renderVSplitLine(vec4 fragColor, vec3 lineColor, float lineThickness, vec2 screenSpaceUV, float splitScreenSpaceX) {\n    if (abs(screenSpaceUV.x - splitScreenSpaceX) < lineThickness) {\n        fragColor.rgb = lineColor;\n\t}\n\n    return fragColor;\n}\n\n// ------------------------------------------------------------------------- //",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// ------------------------------------------------------------------------- //\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 col = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    if (normalizedSpaceUV.x > V_SPLIT_B) {\n        fragColor = vec4(col, 1.0);\n        return;\n    }\n\n    vec3 noise = hash33(vec3(screenSpaceUV, iTime * 13.74232341));\n    noise *= 2.0;\n    noise -= 1.0;\n    noise *= NOISE_INTENSITY;\n    col += noise;\n\n    fragColor = vec4(col, 1.0);\n}\n\n// ------------------------------------------------------------------------- //",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "video",
                        "id": 36,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/35c87bcb8d7af24c54d41122dadb619dd920646a0bd0e477e7bdc6d12876df17.webm"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// ------------------------------------------------------------------------- //\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 new = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    if (normalizedSpaceUV.x <= V_SPLIT_A) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    if (normalizedSpaceUV.x > V_SPLIT_B) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    new = RGBToYCoCg(new);\n\n    vec3 colorMin = vec3(0);\n\tvec3 colorMax = vec3(0);\n    getVarianceClippingBounds(new, iChannel0, ivec2(screenSpaceUV), VARIANCE_CLIPPING_COLOR_BOX_SIGMA, colorMin, colorMax);\n\n    vec3 history = SAMPLE_RGB(iChannel1, normalizedSpaceUV);\n    history = RGBToYCoCg(history);\n\n    vec3 filtered = vec3(0);\n#if APPLY_VARIANCE_CLIPPING_FIRST\n    // apply Variance Clipping before applying EMA IIR filtering\n    history = clamp(history, colorMin, colorMax);\n\n    // apply EMA IIR filtering after Variance Clipping\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n#else\n    // apply EMA IIR filtering before Variance Clipping\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n\n    // apply Variance Clipping after applying EMA IIR filtering\n    filtered = clamp(filtered, colorMin, colorMax);\n#endif\n    filtered = YCoCgToRGB(filtered);\n\n    fragColor = vec4(filtered, 1.0);\n}\n\n// ------------------------------------------------------------------------- //",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// ------------------------------------------------------------------------- //\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 new = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    if (normalizedSpaceUV.x <= V_SPLIT_A) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    if (normalizedSpaceUV.x > V_SPLIT_B) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    new = RGBToYCoCg(new);\n\n    vec3 colorMin = vec3(0);\n\tvec3 colorMax = vec3(0);\n    getVarianceClippingBounds(new, iChannel0, ivec2(screenSpaceUV), VARIANCE_CLIPPING_COLOR_BOX_SIGMA, colorMin, colorMax);\n\n    vec3 history = SAMPLE_RGB(iChannel1, normalizedSpaceUV);\n    history = RGBToYCoCg(history);\n\n    vec3 filtered = vec3(0);\n#if APPLY_VARIANCE_CLIPPING_FIRST\n    // apply Variance Clipping before applying EMA IIR filtering\n    history = clamp(history, colorMin, colorMax);\n\n    // apply EMA IIR filtering after Variance Clipping\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n#else\n    // apply EMA IIR filtering before Variance Clipping\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n\n    // apply Variance Clipping after applying EMA IIR filtering\n    filtered = clamp(filtered, colorMin, colorMax);\n#endif\n    filtered = YCoCgToRGB(filtered);\n\n    fragColor = vec4(filtered, 1.0);\n}\n\n// ------------------------------------------------------------------------- //",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// ------------------------------------------------------------------------- //\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 new = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    if (normalizedSpaceUV.x <= V_SPLIT_A) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    if (normalizedSpaceUV.x > V_SPLIT_B) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    new = RGBToYCoCg(new);\n\n    vec3 colorMin = vec3(0);\n\tvec3 colorMax = vec3(0);\n    getVarianceClippingBounds(new, iChannel0, ivec2(screenSpaceUV), VARIANCE_CLIPPING_COLOR_BOX_SIGMA, colorMin, colorMax);\n\n    vec3 history = SAMPLE_RGB(iChannel1, normalizedSpaceUV);\n    history = RGBToYCoCg(history);\n\n    vec3 filtered = vec3(0);\n#if APPLY_VARIANCE_CLIPPING_FIRST\n    // apply Variance Clipping before applying EMA IIR filtering\n    history = clamp(history, colorMin, colorMax);\n\n    // apply EMA IIR filtering after Variance Clipping\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n#else\n    // apply EMA IIR filtering before Variance Clipping\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n\n    // apply Variance Clipping after applying EMA IIR filtering\n    filtered = clamp(filtered, colorMin, colorMax);\n#endif\n    filtered = YCoCgToRGB(filtered);\n\n    fragColor = vec4(filtered, 1.0);\n}\n\n// ------------------------------------------------------------------------- //",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Buffer D",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 260
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}