{
    "Shader": {
        "info": {
            "date": "1672555551",
            "description": "Happy 2023 New Year!\n\nEgg: change ichannel3 to nearest",
            "flags": 48,
            "hasliked": 0,
            "id": "DllGWX",
            "likes": 8,
            "name": "Happy 2023 New Year!",
            "published": 3,
            "tags": [
                "3d",
                "interactive",
                "sdf",
                "camera",
                "pathtracing",
                "ibl",
                "pbr",
                "2023"
            ],
            "usePreview": 0,
            "username": "shaofun",
            "viewed": 346
        },
        "renderpass": [
            {
                "code": "// Fork of \"RayTracing PBR 2023 rot\" by shaofun. https://shadertoy.com/view/mtX3Wj\n// 2023-01-01 06:44:00\n\n// Fork of \"RT SDF Bloom Test\" by shaofun. https://shadertoy.com/view/mllGW4\n// 2022-12-23 11:49:13\n\n// from https://www.shadertoy.com/view/MssczX\n\nvec2 rot(vec2 p, float a) {\n    a=radians(a);\n    return cos(a)*p + sin(a)*vec2(p.y, -p.x);\n}\nvec2 saturate(vec2 p) { return clamp(p,0.,1.); }\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    const float n = 24.;\n    const float a1 = -1.;\n    const float a2 = -5.;\n    vec2 uv = fragCoord/iResolution.xy;\n    vec3 color = vec3(0);\n    vec2 colorShift = vec2(2,1)/iResolution.xy;\n    vec2 uv1 = uv+colorShift;\n    vec2 uv2 = uv;\n    vec2 uv3 = uv-colorShift;\n    vec2 axis1 = rot(vec2(0,1.105/iResolution.y),-15.);\n    vec2 axis2 = rot(vec2(0,0.953/iResolution.y),+65.);\n    for(float delta = 0.; delta< n;delta++){\n        float scale = .0625*.0625*(1.-.9875*delta/n);\n        vec2 d1r = delta*rot(axis1,-a1);\n        vec2 d1g = delta*axis1;\n        vec2 d1b = delta*rot(axis1,+a1);\n        vec4 texR1 = texture(iChannel0, saturate(uv1+d1r));\n        vec4 texR2 = texture(iChannel0, saturate(uv1-d1r));\n        vec4 texG1 = texture(iChannel0, saturate(uv2+d1g));\n        vec4 texG2 = texture(iChannel0, saturate(uv2-d1g));\n        vec4 texB1 = texture(iChannel0, saturate(uv3+d1b));\n        vec4 texB2 = texture(iChannel0, saturate(uv3-d1b));\n        vec3 aberr1 = vec3(dot(vec4(10,4,2,0),texR1+texR2),\n                           dot(vec4(3,10,3,0),texG1+texG2),\n                           dot(vec4(2,4,10,0),texB1+texB2));\n        vec3 col1 = aberr1*max(aberr1.r,max(aberr1.g,aberr1.b));\n        vec2 d2r = delta*rot(axis2,+a2);\n        vec2 d2g = delta*axis2;\n        vec2 d2b = delta*rot(axis2,-a2);\n        vec4 texR3 = texture(iChannel0, saturate(uv1+d2r));\n        vec4 texR4 = texture(iChannel0, saturate(uv1-d2r));\n        vec4 texG3 = texture(iChannel0, saturate(uv2+d2g));\n        vec4 texG4 = texture(iChannel0, saturate(uv2-d2g));\n        vec4 texB3 = texture(iChannel0, saturate(uv3+d2b));\n        vec4 texB4 = texture(iChannel0, saturate(uv3-d2b));\n        vec3 aberr2 = vec3(dot(vec4(10,4,2,0),texR3+texR4),\n                           dot(vec4(3,10,3,0),texG3+texG4),\n                           dot(vec4(2,4,10,0),texB3+texB4));\n        vec3 col2 = aberr2*max(aberr2.r,max(aberr2.g,aberr2.b));\n        vec3 col = pow(scale*max(col1,col2)*3.7,vec3(5.2));\n        color+=col;\n    }\n    fragColor = vec4(mix(texture(iChannel0,uv).rgb,\n                         color,\n                         smoothstep(.01,.2,min(uv.x,uv.y))*smoothstep(-.99,-.8,-max(uv.x,uv.y))),1);\n                         \n    vec4 res = texture(iChannel1,uv);\n    fragColor = max(vec4(0),sqrt(10.5*fragColor)*.001025)+vec4(res.rgb/res.a,1.0);;\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// Modified by HK-SHAO - 2022\n\n// Upgraded from genis sole - 2016\n// License Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\n\n#define store(P, V) if (all(equal(ivec2(fragCoord), P))) fragColor = V\n#define key(K)  texelFetch(iChannel0, ivec2(K, 0), 0).x\n#define load(P) texelFetch(iChannel1, ivec2(P), 0)\n\n// Keyboard constants definition\nconst int KEY_W     = 87;\nconst int KEY_A     = 65;\nconst int KEY_S     = 83;\nconst int KEY_D     = 68;\nconst int KEY_E     = 69;\nconst int KEY_Q     = 81;\nconst int KEY_SHIFT = 16;\nconst int KEY_SP    = 32;\n\nvec3 KeyboardInput() {\n\tvec3 i = vec3(key(KEY_D) - key(KEY_A), \n                  key(KEY_E) - key(KEY_Q),\n                  key(KEY_S) - key(KEY_W));\n    \n    float n = abs(abs(i.x) - abs(i.y));\n    return i * (n + (1.0 - n)*inversesqrt(2.0));\n}\n\nvec3 CameraDirInput(vec2 m) {\n    return CameraRotation(m) * KeyboardInput();\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {   \n    if (any(greaterThan(ivec2(fragCoord), MEMORY_BOUNDARY))) discard;\n    \n    fragColor = load(fragCoord);\n    \n    if (iFrame == 0) {\n        store(POSITION, vec4(2.5, 8.2, 24.0, 0.0));\n        store(ROTATION, vec4(0.0,PI/15.1,0.0,0.0));\n        \n        store(TARGET,   vec4(2.5, 6.0, 24.0, 0.0));\n        store(TMOUSE,   vec4(0.0,PI/15.1,0.0,0.0));\n        store(PMOUSE,   vec4(0.0,PI/15.1,0.0,0.0));\n        \n        return;\n    }\n\n    vec2 resolution  = load(RESOLUTION).xy;\n    \n    vec3 position    = load(POSITION).xyz;\n    vec2 rotation    = load(ROTATION).xy;\n\n    vec3 target      = load(TARGET).xyz;\n    vec3 tm          = load(TMOUSE).xyz;\n    vec2 pm          = load(PMOUSE).xy;\n    \n    float dt = clamp(iTimeDelta, 0.0, 0.1);\n    \n    const float rt_acc = 16.0;\n    const float mv_acc = 5.0;\n    float velocity =  5.0 + 15.0 * key(KEY_SHIFT);\n    \n    rotation += (tm.xy - rotation) * dt * rt_acc;\n    target   += CameraDirInput(rotation) * dt * velocity;\n    position += (target - position) * dt * mv_acc;\n    \n    bvec4 moving = bvec4(\n        length(tm.xy - rotation) * iResolution.x > 1.0,\n        length(target - position) * iResolution.x > 1.0,\n        any(notEqual(resolution, iResolution.xy)),\n        key(KEY_SP) > 0.0\n    );\n    \n    store(TARGET,     vec4(target, 0.0));\n    store(POSITION,   vec4(position, 0.0));\n    store(ROTATION,   vec4(rotation, 0.0, 0.0));\n    store(RESOLUTION, vec4(iResolution.xy, 0.0, 0.0));\n    store(MOVING,     vec4(any(moving), 0.0, 0.0, 0.0));\n    \n\tif (iMouse.z > 0.0) {\n        vec2 new_tm  = pm + (abs(iMouse.zw) - iMouse.xy) / iResolution.x;\n        \n        float clamp_y = float(new_tm.y > -PI*0.5+0.01 && new_tm.y < PI*0.5-0.01);\n        new_tm.y = mix(tm.y, new_tm.y, clamp_y);\n        \n        store(TMOUSE, vec4(new_tm, 1.0, 0.0));\n\t} else if (tm.z != 0.0) {\n        store(PMOUSE, vec4(tm.xy, 0.0, 0.0));\n    }\n\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Copyright © 2019-2022 HK-SHAO\n// MIT Licensed: https://shao.fun/blog/w/taichi-ray-tracing.html\n\n// 数学常量\nconst float ZERO = 0.0;\nconst float PI   = 3.141592653589;\nconst float TAU  = 2.0 * PI;\n\n// Buffer A Shared\nconst ivec2 MEMORY_BOUNDARY = ivec2(4, 3);\n\nconst ivec2 PMOUSE     = ivec2(0, 0);\nconst ivec2 TARGET     = ivec2(1, 0);\nconst ivec2 TMOUSE     = ivec2(2, 0);\n\nconst ivec2 RESOLUTION = ivec2(0, 1);\nconst ivec2 POSITION   = ivec2(1, 1);\nconst ivec2 ROTATION   = ivec2(2, 1);\n\nconst ivec2 MOVING     = ivec2(0, 2);\n\nmat3 CameraRotation(vec2 m) {\n    m *= mat2(vec2(0, -1), vec2(1, 0));\n    vec2 s = sin(m), c = cos(m);\n    \n    mat3 rotX = mat3(1.0, 0.0, 0.0, 0.0, c.x, s.x, 0.0, -s.x, c.x);\n    mat3 rotY = mat3(c.y, 0.0, -s.y, 0.0, 1.0, 0.0, s.y, 0.0, c.y);\n    \n    return rotY * rotX;\n}\n\n// Update History\n\n// 2022.12.30\n// 1. fix blackened colors caused by incorrect light absorption.\n// 2. that also improved the frame rate.\n// 3. correct cumulative brightness in the alpha channel instead of always being one.\n// 4. which reduces noise.\n// 5. ~~discard pixels that are too dark, it brighten the pixel quality.~~\n\n// 2022.12.26\n// 1. enables metal to be used in IOR.\n// 2. small optimization of performance.\n// 3. simplified reflection operations.\n// 4. use plain black background.\n\n// 2022.12.24\n// 1. fixed camera jamming when looking up and down.\n\n// 2022.12.23\n// 1. fix the blackening of rough transparent material, it improved the frame rate.\n// 2. fix the camera misalignment when full screen.\n// 3. fix the inability to propagate reflected light inside an object.\n// 4. optimize the judgment about self-luminous light source.\n// 5. some formatting optimizations and minor efficiency optimizations.\n// 6. gamma correction for skybox.\n\n// 2022.12.21\n// 1. make the rotation of the view smooth.\n// 2. automatically perform noise reduction when stopping movement.\n// 3. hold down space to force a screen refresh.",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// Copyright © 2019-2022 HK-SHAO\n// MIT Licensed: https://shao.fun/blog/w/taichi-ray-tracing.html\n\n#define load(P) texelFetch(iChannel1, ivec2(P), 0)\n\n// 摄像机参数\nconst float camera_vfov       = 30.0;                 // 摄像机的纵向视野\nconst float camera_focus      = 2.0;                  // 摄像机的对焦距离\nconst float camera_aperture   = 0.000;                // 摄像机的光圈大小\nconst float camera_exposure   = 0.6;                  // 摄像机曝光值\nconst float light_quality     = 128.0;                // 间接光质量\nconst float gamma             = 2.2;                  // 伽马矫正值\n\n// 配置常量\nconst float TMIN         = 0.5;                     // 光开始传播的起始偏移，避免光线自相交\nconst float TMAX         = 200.0;                    // 最大单次光线传播距离 (相当于可见范围)\nconst float PRECISION    = 0.05;                    // 需小于 TMIN，否则光线无法正常离开物体表面\nconst float VISIBILITY   = pow(1.0 / 256.0, gamma);   // 亮度可见度\n\nconst uint  MAX_RAYMARCH = 512U;                      // 最大光线步进次数\nconst uint  MAX_RAYTRACE = 128U;                      // 最大光线追踪次数\n\nconst float ENV_IOR      = 1.000277;                  // 环境的折射率 （空气）\n\n// 枚举形状\nconst int SHAPE_2   = 0;\nconst int SHAPE_0   = 1;\nconst int SHAPE_3   = 2;\n\nfloat seed; // 随机数种子\n\n// 用随机数种子产生归一化的随机数\nfloat rand13(vec3 x) {\n    uvec3 p = floatBitsToUint(x);\n    p = 1103515245U * ((p.xyz >> 1U) ^ (p.yzx));\n    uint h32 = 1103515245U * ((p.x ^ p.z) ^ (p.y >> 3U));\n    uint n = h32 ^ (h32 >> 16U);\n    return float(n) * (1.0 / float(0xffffffffU));\n}\n\nfloat rand11() {\n    uvec2 n = floatBitsToUint(seed++) * uvec2(1597334673U, 3812015801U);\n    uint q = (n.x ^ n.y) * 1597334673U;\n    return float(q) * (1.0 / float(0xffffffffU));\n}\n\nvec2  rand21() {\n    uvec2 n = floatBitsToUint(seed++) * uvec2(1597334673U, 3812015801U);\n    n = (n.x ^ n.y) * uvec2(1597334673U, 3812015801U);\n    return vec2(n) * (1.0 / float(0xffffffffU));\n}\n\n// 物体材质\nstruct material {\n    vec3  albedo;       // 反照率\n    vec3  emission;     // 自发光\n    vec3  normal;       // 切线空间法线\n    float roughness;    // 粗糙度\n    float metallic;     // 金属度\n    float transmission; // 透明度\n    float ior;          // 折射率\n};\n\n// 物体变换\nstruct transform {\n    vec3 position;      // 位置\n    vec3 rotation;      // 旋转\n    vec3 scale;         // 缩放\n};\n\n// SDF 物体\nstruct object {\n    int       shape;    // 形状\n    float     dis;      // 距离物体表面\n    transform trs;      // 变换\n    material  mtl;      // 材质\n};\n\n// 光线\nstruct ray {\n    vec3 origin;        // 光的起点\n    vec3 direction;     // 光的方向\n    vec3 color;         // 光的颜色\n};\n\n// 光子击中的记录\nstruct record {\n    object obj;         // 物体\n    vec3   pos;         // 击中的位置\n    vec3   normal;      // 世界空间法线\n    bool   hit;         // 是否击中\n};\n\n// 摄像机\nstruct camera {\n    vec3  lookfrom;     // 视点位置\n    vec3  lookat;       // 目标位置\n    vec3  vup;          // 向上的方向\n    float vfov;         // 视野\n    float aspect;       // 传感器长宽比\n    float aperture;     // 光圈大小\n    float focus;        // 对焦距离\n};\n\n// from https://www.shadertoy.com/view/XsfGDn\nvec2 bestUV(vec2 uv) {\n    float textureResolution = iChannelResolution[3].x;\n\tuv = uv*textureResolution + 0.5;\n\tvec2 iuv = floor( uv );\n\tvec2 fuv = fract( uv );\n\tuv = iuv + fuv*fuv*(3.0-2.0*fuv); // fuv*fuv*fuv*(fuv*(fuv*6.0-15.0)+10.0);;\n\tuv = (uv - 0.5)/textureResolution;\n    return uv;\n}\n\n// from https://www.shadertoy.com/view/llcXRl\nvec4 SampleFontTex2(vec2 uv)\n{\n    uv = bestUV(uv);\n    // Do some tricks with the UVs to spell out \"TexFont\" in the middle.\n    vec2 fl = floor(uv + 0.5);\n    if (fl.y == 0.0) {\n         if (fl.x == 0.0) fl = vec2(2.0, 12.0);\n         else return vec4(1000000);\n    } else return vec4(1000000);\n    uv = fl + fract(uv+0.5)-0.5;\n\n    // Sample the font texture. Make sure to not use mipmaps.\n    // Add a small amount to the distance field to prevent a strange bug on some gpus. Slightly mysterious. :(\n    return texture(iChannel3, (uv+0.5)*(1.0/16.0), -100.0) + vec4(0.0, 0.0, 0.0, 0.000000001);\n}\n\nvec4 SampleFontTex0(vec2 uv)\n{\n    uv = bestUV(uv);\n    // Do some tricks with the UVs to spell out \"TexFont\" in the middle.\n    vec2 fl = floor(uv + 0.5);\n    if (fl.y == 0.0) {\n         if (fl.x == 0.0) fl = vec2(0.0, 12.0);\n         else return vec4(1);\n    } else return vec4(1);\n    uv = fl + fract(uv+0.5)-0.5;\n\n    // Sample the font texture. Make sure to not use mipmaps.\n    // Add a small amount to the distance field to prevent a strange bug on some gpus. Slightly mysterious. :(\n    return texture(iChannel3, (uv+0.5)*(1.0/16.0), -100.0) + vec4(0.0, 0.0, 0.0, 0.000000001);\n}\n\nvec4 SampleFontTex3(vec2 uv)\n{\n    uv = bestUV(uv);\n    // Do some tricks with the UVs to spell out \"TexFont\" in the middle.\n    vec2 fl = floor(uv + 0.5);\n    if (fl.y == 0.0) {\n         if (fl.x == 0.0) fl = vec2(3.0, 12.0);\n         else return vec4(1000000);\n    } else return vec4(1000000);\n    uv = fl + fract(uv+0.5)-0.5;\n\n    // Sample the font texture. Make sure to not use mipmaps.\n    // Add a small amount to the distance field to prevent a strange bug on some gpus. Slightly mysterious. :(\n    return texture(iChannel3, (uv+0.5)*(1.0/16.0), -100.0) + vec4(0.0, 0.0, 0.0, 0.000000001);\n}\n\nfloat opSmoothIntersection( float d1, float d2, float k ) {\n    float h = clamp( 0.5 - 0.5*(d2-d1)/k, 0.0, 1.0 );\n    return mix( d2, d1, h ) + k*h*(1.0-h);\n}\n\n// SDF 盒子\nfloat sd_box(vec3 p, vec3 b) {\n    vec3 q = abs(p) - b;\n    return length(max(q, 0.0)) + min(max(q.x, max(q.y, q.z)), 0.0) - 0.02;\n}\n\n// This is the distance function that defines all the scene's geometry.\n// The input is a position in space.\n// The output is the distance to the nearest surface and a material index.\nfloat DistanceToObject2(vec3 p)\n{\n\t// Load the font texture's distance field.\n    float letterDistField = (SampleFontTex2(p.xy).w - 0.5+1.0/256.0);\n    float box = sd_box(p, vec3(10, 1, 0.1));\n    float dis = opSmoothIntersection(letterDistField, box, 0.1);\n    return dis;\n}\n\nfloat DistanceToObject0(vec3 p)\n{\n\t// Load the font texture's distance field.\n    float letterDistField = (SampleFontTex0(p.xy).w - 0.5+1.0/256.0);\n    float box = sd_box(p, vec3(10, 1, 0.1));\n    float dis = opSmoothIntersection(letterDistField, box, 0.1);\n    return dis;\n}\n\nfloat DistanceToObject3(vec3 p)\n{\n\t// Load the font texture's distance field.\n    float letterDistField = (SampleFontTex3(p.xy).w - 0.5+1.0/256.0);\n    float box = sd_box(p, vec3(10, 1, 0.1));\n    float dis = opSmoothIntersection(letterDistField, box, 0.1);\n    return dis;\n}\n\n// SDF 球体\nfloat sd_sphere(vec3 p, float s) {\n    return length(p) - s;\n}\n\n// SDF 圆柱\nfloat sd_cylinder(vec3 p, vec2 rh) {\n    vec2 d = abs(vec2(length(p.xz),p.y)) - rh;\n    return min(max(d.x, d.y), 0.0) + length(max(d, 0.0));\n}\n\n// 地图列表\nconst object[] map = object[] (\n    object(SHAPE_2, ZERO,\n        transform(  vec3(-5, 0.0, 0),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(0.5, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.635  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_0, ZERO,\n        transform(  vec3(0, 0.0, 0),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(1.0, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.635  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_2, ZERO,\n        transform(  vec3(5, 0.0, 0),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(0.5, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.500  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_3, ZERO,\n        transform(  vec3(10, 0.0, 0),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(0.5, 0.5, 1.8)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.635  // 折射率 （沥青）\n        )\n    ),\n    \n    object(SHAPE_2, ZERO,\n        transform(  vec3(-5, 0.0, -100),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(0.5, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.635  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_0, ZERO,\n        transform(  vec3(0, 0.0, -100),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(1.0, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.635  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_2, ZERO,\n        transform(  vec3(5, 0.0, -100),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(0.5, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.500  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_2, ZERO,\n        transform(  vec3(10, 0.0, -100),\n                    vec3(0, 0, 0),\n                    vec3(10, 10, 10)\n        ),\n        material(   vec3(0.5, 1.0, 0.5)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    vec3(0, 0, 1), // 切线空间法线\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.500  // 折射率 （沥青）\n        )\n    )\n);\n\n// 光子在射线所在的位置\nvec3 at(ray r, float t) {\n    return r.origin + t * r.direction;\n}\n\n// 单位圆内随机取一点\nvec2 random_in_unit_disk() {\n    vec2 r = rand21() * vec2(1.0, TAU);\n    return sqrt(r.x) * vec2(sin(r.y), cos(r.y));\n}\n\n// 从摄像机获取光线\nray get_ray(camera c, vec2 uv, vec3 color) {\n    // 根据 VFOV 和显示画布长宽比计算传感器长宽\n    float theta = radians(c.vfov);\n    float half_height = tan(theta * 0.5);\n    float half_width = c.aspect * half_height;\n    \n    // 以目标位置到摄像机位置为 Z 轴正方向\n    vec3 z = normalize(c.lookfrom - c.lookat);\n    // 计算出摄像机传感器的 XY 轴正方向\n    vec3 x = normalize(cross(c.vup, z));\n    vec3 y = cross(z, x);\n    \n    vec3 hwfx = half_width  * c.focus * x;\n    vec3 hhfy = half_height * c.focus * y;\n    \n    vec3 lower_left_corner = c.lookfrom - hwfx - hhfy - c.focus * z;\n    \n    vec3 horizontal = 2.0 * hwfx;\n    vec3 vertical   = 2.0 * hhfy;\n    \n    // 模拟光进入镜头光圈\n    float lens_radius = c.aperture * 0.5;\n    vec2 rud = lens_radius * random_in_unit_disk();\n    vec3 offset = x * rud.x + y * rud.y;\n    \n    // 计算光线起点和方向\n    vec3 ro = c.lookfrom + offset;\n    vec3 po = lower_left_corner + uv.x * horizontal\n                                + uv.y * vertical;\n    vec3 rd = normalize(po - ro);\n    \n    return ray(ro, rd, color);\n}\n\n// 从欧拉角计算旋转矩阵\nmat3 angle(vec3 a) {\n    vec3 s = sin(a), c = cos(a);\n    return mat3(vec3( c.z,  s.z,    0),\n                vec3(-s.z,  c.z,    0),\n                vec3(   0,    0,    1)) *\n           mat3(vec3( c.y,    0, -s.y),\n                vec3(   0,    1,    0),\n                vec3( s.y,    0,  c.y)) *\n           mat3(vec3(   1,    0,    0),\n                vec3(   0,  c.x,  s.x),\n                vec3(   0, -s.x,  c.x));\n}\n\n// 计算有向距离 (物体内部距离为负)\nfloat signed_distance(object obj, vec3 pos) {\n    vec3 position = obj.trs.position;\n    vec3 rotation = obj.trs.rotation;\n    vec3 scale    = obj.trs.scale;\n    \n    vec3 p = pos - position;\n    \n    // 会重复的将欧拉角转换成旋转矩阵，实际上只用在第一次计算就行了\n    // 也有可能被编译器优化掉了\n    p *= angle(radians(rotation));\n    \n    switch(obj.shape) {\n        case SHAPE_2:\n            return DistanceToObject2(p/scale.x)*scale.x;\n        case SHAPE_0:\n            return DistanceToObject0(p/scale.x)*scale.x;\n        case SHAPE_3:\n            return DistanceToObject3(p/scale.x)*scale.x;\n        default:\n            return sd_sphere(p, scale.x);\n    }\n}\n\n// 找到最近的物体并计算距离\nobject nearest_object(vec3 p) {\n    object o; o.dis = TMAX;\n    for (int i = 0; i < map.length(); i++) {\n        object oi = map[i];\n        oi.dis = abs(signed_distance(oi, p));\n        if (oi.dis < o.dis) o = oi;\n    }\n    return o;\n}\n\n// 计算物体法线 from https://iquilezles.org/articles/normalsSDF/\nvec3 calc_normal(object obj, vec3 p) {\n    vec2 e = vec2(1, -1) * 0.5773 * 0.0005;\n    return normalize( e.xyy*signed_distance(obj, p + e.xyy) + \n                      e.yyx*signed_distance(obj, p + e.yyx) + \n                      e.yxy*signed_distance(obj, p + e.yxy) + \n                      e.xxx*signed_distance(obj, p + e.xxx) );\n}\n\n// 用世界坐标下的法线计算 TBN 矩阵 from https://doi.org/10.1080/2165347X.2012.689606\nmat3 TBN(vec3 N) {\n    vec3 T, B;\n    \n    if (N.z < -0.99999) {\n        T = vec3(0, -1, 0);\n        B = vec3(-1, 0, 0);\n    } else {\n        float a = 1.0 / (1.0 + N.z);\n        float b = -N.x*N.y*a;\n        \n        T = vec3(1.0 - N.x*N.x*a, b, -N.x);\n        B = vec3(b, 1.0 - N.y*N.y*a, -N.y);\n    }\n    \n    return mat3(T, B, N);\n}\n\n// 使用光线步进 (Ray March) 检测第一个交点\nrecord raycast(ray r) {\n    record rec; float t = TMIN;\n    for(uint i = 0U; i < MAX_RAYMARCH && t < TMAX && !rec.hit; i++) {\n        rec.pos = at(r, t);\n        rec.obj = nearest_object(rec.pos);\n        rec.hit = rec.obj.dis < PRECISION;\n        t      += rec.obj.dis * 0.1;\n    }\n    return rec;\n}\n\n// 采样立方体贴图\nvec4 mix_cube_lod(samplerCube sharp, samplerCube blur, vec3 dir, float lod) {\n    return mix(textureLod(sharp, dir, lod), textureLod(blur, dir, lod), lod);\n}\n\n// 采样天空\nvec3 sky(ray r, float brightness, float lod) {\n    // float t = 0.5 + 0.5 * r.direction.y;\n    // vec3 bottom = vec3(1.0, 1.0, 1.0);\n    // vec3 top = vec3(0.9, 1.5, 3.0);\n    // return mix(bottom, top, t * brightness);\n    vec4 ibl = textureLod(iChannel2, r.direction, lod); // 天空盒 IBL 照明\n    return pow(ibl.rgb * ibl.a * brightness, vec3(gamma)); // gamma 矫正\n}\n\n// 快速计算五次方\nfloat pow5(float x) {\n    float t = x*x; t *= t;\n    return t*x;\n}\n\n// 菲涅尔反射近似值\nfloat fresnel_schlick(float cosine, float F0) {\n    return mix(pow5(abs(1.0 - cosine)), 1.0, F0);\n}\n\n// 用粗糙度计算菲涅尔\nfloat fresnel_schlick(float cosine, float F0, float roughness) {\n    return mix(fresnel_schlick(cosine, F0), F0, roughness);\n}\n\n// 以 n 为法线进行半球采样\nvec3 hemispheric_sampling() {\n    vec2 r = rand21() * vec2(1.0, TAU);\n\n    vec2  v = vec2(cos(r.y), sin(r.y));\n    float z = sqrt(r.x);\n    vec2 xy = sqrt(1.0 - r.x) * v; \n\n    return vec3(xy, z);\n}\n\n// 用粗糙度采样沿向量 n 半球采样\nvec3 hemispheric_sampling(float roughness) {\n    vec2 r = rand21() * vec2(1.0, TAU);\n\n    float shiny = pow5(roughness); // 光感越大高光越锐利\n    \n    vec2  v = vec2(cos(r.y), sin(r.y));\n    float z = sqrt((1.0 - r.x) / (1.0 + (shiny - 1.0) * r.x));\n    vec2 xy = sqrt(abs(1.0 - z*z)) * v;\n    \n    return vec3(xy, z);\n}\n\n// 应用 PBR 材质\nray BSDF(ray r, record rec) {\n    // 材质参数\n    vec3  albedo       = rec.obj.mtl.albedo;\n    float roughness    = rec.obj.mtl.roughness;\n    float metallic     = rec.obj.mtl.metallic;\n    float transmission = rec.obj.mtl.transmission;\n    vec3  normal       = rec.obj.mtl.normal;\n    float ior          = rec.obj.mtl.ior;\n    \n    normal = TBN(rec.normal) * normal; // 将切线空间法线转换到世界空间\n    float outer = -sign(dot(normal, r.direction)); // 光正在从外面穿入物体表面\n    \n    // 光线和物体表面参数\n    vec3 I  =  r.direction;\n    vec3 V  = -r.direction;\n    vec3 N  =  normal *= outer; // 如果处于 SDF 物体内部就反过来\n    vec3 C  =  r.color;\n    vec3 L;\n    \n    N = TBN(N) * hemispheric_sampling(roughness); // 用粗糙度半球采样\n    float NoV   = dot(N, V);\n\n    float eta = outer > 0.0 ? ENV_IOR / ior : ior / ENV_IOR; // 计算折射率之比\n    float k = 1.0 - eta * eta * (1.0 - NoV * NoV); // 小于 0 为全反射\n    float F0  = (eta - 1.0) / (eta + 1.0); F0 *= 3.0*F0; // 让透明材质的反射更明显一些\n    float F   = fresnel_schlick(NoV, F0, roughness); // 菲涅尔\n\n    vec2 rand2 = rand21(); // 取两个随机数\n    if (rand2.y < F + metallic || k < 0.0) {\n            L = I + 2.0 * NoV * N; // 包含镜面反射、菲涅尔反射、全反射\n            // 下面可以提高帧数，但是会导致透明材质发黑，需要优化\n            C *= float(dot(L, normal) > 0.0); // 如果光穿入或穿出表面就直接吸收掉 \n    } else {\n        if (rand2.x < transmission) {\n            L = eta * I - (sqrt(k)- eta * NoV) * N; // 斯涅尔折射\n        } else {\n            L = TBN(normal) * hemispheric_sampling(); // 漫反射\n        }\n    }\n\n\n    C *= albedo;\n\n    // 更新光的方向和颜色\n    r.color     = C;\n    r.direction = L;\n    \n    return r;\n}\n\n// RGB 亮度\nfloat brightness(vec3 rgb) {\n    return dot(rgb, vec3(0.299, 0.587, 0.114));\n}\n\n// 光线追踪\nray raytrace(ray r) {\n    for (uint i = 0U; i < MAX_RAYTRACE; i++) {\n        // 俄罗斯轮盘赌概率，防止光线过分的反复反射\n        float inv_pdf = exp(float(i) / light_quality);\n        float roulette_prob = 1.0 - (1.0 / inv_pdf);\n    \n        // 光线被毙掉就不用继续了\n        if (rand11() < roulette_prob) { // discard;\n            r.color *= roulette_prob;\n            break;\n        }\n        \n        // 能量守恒\n        r.color *= inv_pdf;\n        \n        // 与地图求交\n        record rec = raycast(r);\n        \n        // 没击中物体就肯定击中天空\n        if (!rec.hit) {\n            r.color *= sign(float(i)); // 纯黑色背景\n            r.color *= sky(r, 2.0, 1.0 - 1.0 / (1.0 + 0.1 * float(i)));\n            break;\n        }\n        \n        // 计算法线\n        rec.normal = calc_normal(rec.obj, rec.pos);\n        \n        // 更新光子的位置\n        r.origin = rec.pos;\n        \n        // 应用 PBR 材质更新光线\n        r = BSDF(r, rec);\n        \n        // 处理自发光\n        float intensity = brightness(r.color);\n        r.color        *= rec.obj.mtl.emission;\n        float visible   = brightness(r.color);\n        \n        if (visible > intensity || visible < VISIBILITY) break; // 光太暗碰到光源\n    }\n\n    return r;\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color *= mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color  = a / b;\n\t// Back to color space\n    color *= mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\n// 片段着色器程序入口\nvec4 fragment(vec2 uv, vec2 SCREEN_PIXEL_SIZE) {\n    // 计算摄像机方位和视线\n    vec3  lookfrom  = load(POSITION).xyz;\n    vec2  rotation  = load(ROTATION).xy;\n    vec3  direction = CameraRotation(rotation) * vec3(0, 0, -1);\n    vec3  lookat    = lookfrom + direction;\n    float aspect    = SCREEN_PIXEL_SIZE.y / SCREEN_PIXEL_SIZE.x;;\n    \n    // 初始化摄像机\n    camera cam;\n    cam.lookfrom = lookfrom;\n    cam.lookat   = lookat;\n    cam.aspect   = aspect;\n    cam.vfov     = camera_vfov;\n    cam.vup      = vec3(0, 1, 0);\n    cam.focus    = camera_focus;\n    cam.aperture = camera_aperture;\n    \n    // 用 UV 和时间初始化随机数发生器种子\n    seed = rand13(vec3(uv, iTime*iTimeDelta));\n\n    // 超采样\n    uv += rand21() * SCREEN_PIXEL_SIZE;\n    \n    // 对每个光子经过的表面采样一次\n    ray r = get_ray(cam, uv, vec3(1));\n    \n    // 处理颜色\n    vec3 color = raytrace(r).color;\n\n    // 色调映射\n    color *= camera_exposure;\n    color  = ACESFitted(color);\n    \n    // 伽马矫正\n    color = pow(color, vec3(1.0 / gamma));\n\n    return vec4(color, brightness(r.color));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 SCREEN_PIXEL_SIZE = 1.0 / iResolution.xy;\n    vec2 uv = fragCoord * SCREEN_PIXEL_SIZE;\n    \n    fragColor = fragment(uv, SCREEN_PIXEL_SIZE); // 获取片元颜色\n    \n    if (bool(load(MOVING).x)) return; // 如果正在移动就不积累上一帧\n    \n    fragColor += texture(iChannel0, uv); // 积累帧进行降噪\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 2,
                        "ctype": "cubemap",
                        "id": 22,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "false",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg"
                    },
                    {
                        "channel": 3,
                        "ctype": "texture",
                        "id": 49,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Fork of \"RayTracing PBR with Free Camera\" by shaofun. https://shadertoy.com/view/ddSSWy\n// 2022-12-23 10:44:30\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy;\n    vec4 color = texture(iChannel0, uv);\n    fragColor = vec4(color.rgb/color.a, 1.0);\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}