{
    "Shader": {
        "info": {
            "date": "1650652255",
            "description": "Basic Kleinian group limit set with fully dynamic GI (+ temporal reprojection denoising and some weird hacky thing where I try to accumulate encoded lighting data from neighboring pixels) plus a bunch of very superfluous postprocess effects. ",
            "flags": 32,
            "hasliked": 0,
            "id": "NlsfzM",
            "likes": 12,
            "name": "AI Escape valve",
            "published": 3,
            "tags": [
                "3d",
                "raymarching",
                "fractal",
                "math",
                "gi",
                "global",
                "dof",
                "bokeh",
                "pathtracing",
                "kleinian",
                "montecarlo",
                "apollonian"
            ],
            "usePreview": 0,
            "username": "xenn",
            "viewed": 447
        },
        "renderpass": [
            {
                "code": "\n\n// Fork of \"Kleinian Landscape\" by amoser. https://shadertoy.com/view/WttBRr\n// 2022-04-22 17:47:11\n\n// Final post-processing\n// \n\n// Sample scene color with FXAA, 0-1 range uvs\nvec4 sceneColor(vec2 uv)\n{\n    vec4 outColor = vec4(FXAA(uv, iChannel1, 1.0/iResolution.xy), 1.0);\n    \n    return outColor;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    vec2 uvAspectCorrected = uv - 0.5;\n    uvAspectCorrected = vec2(uvAspectCorrected.x*(iResolution.x/iResolution.y), uvAspectCorrected.y);\n    uvAspectCorrected += 0.5;\n    \n    // Fringe\n\tconst int fringeSamples = 64;\n    float fringeAmount = fringeStrength*saturate(distance(uvAspectCorrected, vec2(0.5))-fringeStart);\n\n    vec4 outColor = vec4(0);\n\n    if(fringeAmount > 0.0)\n    {\n        for(int i = 0; i < fringeSamples; i++)\n        {\n            float fringe = 1.0+(float(i-fringeSamples/2)*fringeAmount)/float(fringeSamples);\n            outColor += vec4(sceneColor(((uv-0.5)*fringe + 0.5)))*HUE(mod(0.85-1.0*float(i)/float(fringeSamples), 1.0));\n        }\n        outColor /= float(fringeSamples)*0.6;\n    }\n    else\n    {\n        outColor = vec4(sceneColor(uv));\n    }\n\n    \n    // Vignette\n    outColor *= pow(saturate(1.25-1.5*distance(uv, vec2(0.5))), 0.9);\n    outColor += 0.001*(hash12(fragCoord+mod(iTime, 512.0)*0.21+0.1*iMouse.xy)-0.5);\n    \n    // Saturation / discolor highlights\n   // outColor = mix(outColor, vec4(1, 1, 0.66, 1)*vec4(dot(outColor.rgb, luma)), 1.0-saturate(1.05-dot(outColor.rgb, luma))); \n    \n    // Saturation / discolor shadows\n   //               outColor = mix(outColor, vec4(0.6, 0.8, 1, 1)*vec4(dot(outColor.rgb, luma)), saturate(0.3-3.0*dot(outColor.rgb, luma))); \n    \n    // Tonemap + color grade\n  // \toutColor = toneMap(outColor, vec3(0.95,0.95,0.85), vec3(1.15, 1.3, 1.3));\n    \n    // Ungraded tonemap\n    outColor = toneMap(outColor, vec3(1), vec3(1));\n    \n    fragColor = pow(outColor, vec4(1.0/gamma));\n    \n    // For debugging depth\n    //fragColor = vec4(1.0-UDEPTH(fragCoord)*maxDepth);\n    // For debugging GI\n\t//fragColor = textureLod(iChannel0, uv, 0.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Image",
                "outputs": [],
                "type": "image"
            },
            {
                "code": "// Path tracing, partly based (unsurprisingly) on iq's implementation\n//\n// Single sample, one bounce, but stores indirect bounces as \"point lights\" for re-use across neighboring pixels (done in Buffer B) so we only compute final direct light here.\n// I have no idea if any of this is a good idea, but it was a fun experiment.\n// Supports specular (GGX) with multiple importancs sampling, and uses a roughness map\n\nvec4 orbitTrap;\n\nfloat sphere(vec3 ray, vec3 dir, vec3 center, float radius)\n{\n\tvec3 rc = ray-center;\n\tfloat c = dot(rc, rc) - (radius*radius);\n\tfloat b = dot(dir, rc);\n\tfloat d = b*b - c;\n\tfloat t = -b - sqrt(abs(d));\n\tfloat st = step(0.0, min(t,d));\n\treturn mix(-1.0, t, st);\n}\n\nfloat intersect(in ray ray, int maxSteps, float bias)\n{\n    float res = -1.0;\n\n    float t = bias;\n    \n    for(int i=1; i<maxSteps+1; i++ )\n    {\n\t\tvec3 samplePoint = ray.origin+ray.direction*t;\n        if (samplePoint.y >= 1.0 || samplePoint.y <= -1.0 )//|| max(abs(samplePoint.x),abs(samplePoint.z)) >= 6.0)\n        {\n            return -1.0;\n        }\n\n        float h = sceneDistanceFunction(samplePoint, orbitTrap);\n        if(h < mix(0.0001, 0.01, saturate(distance(ray.origin, samplePoint)/12.0)/*smoothstep(0.0, 6.0, distance(ray.origin, samplePoint))*/) || t > maxDepth) \n        {\n            break;\n        }\n        //if( h<0.0012 || t>tmax ) break;\n        t +=  h;\n    }\n    \n    if(t<maxDepth) \n    {\n        res = t;\n    }\n    \n    return res;\n}\n\n// TODO this\n/*\nvec3 dropToFloor(in vec3 origin, int maxSteps)\n{\n    float res = -1.0;\n    \n    float t = 0.001;\n    for(int i=1; i<maxSteps+1; i++ )\n    {\n\t\tvec3 samplePoint = origin + vec3(0, -1, 0)*t;\n        if (samplePoint.y >= 1.0 || samplePoint.y <= -1.0 )//|| max(abs(samplePoint.x),abs(samplePoint.z)) >= 6.0)\n        {\n            // No floor found\n            return origin;\n        }\n        float h = sceneDistanceFunction(samplePoint, orbitTrap);\n        if(h < 0.001 || t > maxDepth)\n        {\n            break;\n        }\n        t +=  h;\n    }\n    \n    if(t<maxDepth) \n    {\n        res = t;\n    }\n    \n    return origin + vec3(0, -res, 0);\n}\n*/\n\nfloat shadow(in ray ray, int maxSteps)\n{\n    float res = 0.0;\n\n    float t = 0.001;\n    \n    float k = 8.0;\n    \n    float h = 0.1;\n    \n    for(int i=1; i<maxSteps+1; i++ )\n    {\n        vec3 samplePoint = ray.origin+ray.direction*t;\n        if (samplePoint.y >= 1.0 || samplePoint.y <= -1.0 )//|| max(abs(samplePoint.x),abs(samplePoint.z)) >= 6.0)\n        {\n            return 1.0;\n        }\n        h = sceneDistanceFunction(ray.origin+ray.direction*t, orbitTrap);\n        res = min( res, (k*h)/t );\n        //if( h<0.0015*pow(distance(ray.origin, samplePoint), 1.0) || t>tmax) break;\n        if(h < 0.00009 || t > maxDepth) \n        {\n            break;\n        }\n        t += h;\n    }\n\n    if(t > maxDepth)\n    {\n        res = 1.0;\n    }\n    \n    return res;\n}\n\nfloat softShadow(in ray ray, int maxSteps/*float mint, float k*/)\n{\n    float k = 4.0;\n    float res = 0.0;\n    float t = 0.001;\n\tfloat h = 1.0;\n    \n    for( int i=0; i<int(maxSteps); i++ )\n    {\n        h = sceneDistanceFunction(ray.origin + ray.direction*t, orbitTrap);\n\n        if(res<0.001)\n        {\n            break;\n        }\n        t += h;//clamp( h, 0.01, 0.05 );\n    }\n    return 1.0-saturate(res);\n}\n\nvoid calculateColor(ray cameraRay, float sa, vec2 fragCoord, out vec3 camHitPosition, out float depth, out vec3 camHitNormal, out vec3 baseColor, out vec3 directLight, out vec3 indirectLight, out pointLight bounceLight, vec3 sunDirection, vec3 sunColor)\n{\n    const float epsilon = 0.0001;\n    float seed = mod(iTime, 1024.0)+0.13*iMouse.x+1.25*iMouse.y;\n    \n    vec3 bounceColor = vec3(1);\n    \n    vec3 totalDirect = vec3(0);\n    vec3 totalGi = vec3(0);\n    \n    ray currentRay = cameraRay;\n    \n    // TODO manually unroll bounces to reduce number of ifs?\n    for(int bounce = 0; bounce<2; bounce++)\n    {\n        currentRay.direction = normalize(currentRay.direction);\n        \n       \n        float traced = -1.0;\n        if(bounce == 0)\n        {\n            traced = intersect(currentRay, 128, 0.005);\n        }\n        else\n        {\n            traced = intersect(currentRay, 80, 0.005);\n        }\n        if(traced < 0.0)\n        {\n            if( bounce==0 ) \n            {\n                // No hit, draw BG\n                vec3 bgColor = getSky(currentRay, sunDirection, sunColor);\n                totalDirect = bgColor;\n\n                // Out\n                directLight = bgColor;\n                indirectLight = vec3(0);\n\n                return;\n            }\n            break;\n        }\n\n        vec3 position = currentRay.origin + currentRay.direction*traced;\n        vec3 surfaceNormal = calcNormal(position);\n        \n        vec3 triplanarNormal = surfaceNormal;\n\t\t\n        float emissiveFactor = saturate((1.0 - orbitTrap.z*50.0)*100000.0);\n        \n        vec3 emissiveColor = pow(((sin(position.x*5.0+mod(iTime, 1024.0)/2.0)+1.0)/2.0), 8.0)*1.33*pow(vec3(0.35,1.0,0.55),vec3(2.0))*emissiveFactor + 0.02*vec3(0.35,1.0,0.55)*emissiveFactor;\n\n        vec3 surfaceColor1 = vec3(0.7);\n        vec3 surfaceColor2 = vec3(0.6, 0.5, 0.8);\n\n        vec3 surfaceColor = mix(surfaceColor1, surfaceColor2, saturate((orbitTrap.y*3.5-0.25)*1.0))*(1.0-emissiveFactor) + emissiveFactor*(vec3(0.5,0.8,1.0));\n        \n        #ifdef ROUGHNESS_MAP\n        \tfloat roughness = saturate(pow(triPlanarMapCatRom(iChannel2, 5.0, triplanarNormal, position*7.0, iChannelResolution[2].xy), vec3(2.0)).r*2.0);\n\t\t#else\n        \tconst float roughness = 0.4;\n        #endif\n        \n\t\t// Direct lighting\n        vec3 iColor = vec3(0.0);\n\n        // Direct sun light\n        vec3 currentSunDir = sunDirection;\n        \n        float sunDiffuse = 0.0;\n        float sunSpec = 0.0;\n\n        if(bounce == 0)\n        {\n            sunDiffuse = saturate(dot(currentSunDir, surfaceNormal))*0.9;\n            sunSpec = GGX(surfaceNormal, -currentRay.direction, currentSunDir, roughness, 0.1);\n        }\n        else\n        {\n            sunDiffuse = saturate(dot(currentSunDir, surfaceNormal));\n            sunSpec = 0.0;\n        }\n        float sunShadow = 1.0;\n        if(sunDiffuse > 0.0) \n        {\n            sunShadow = shadow(ray(position + surfaceNormal*epsilon, currentSunDir), 80);\n        }\n\n        iColor += sunColor*sunDiffuse*sunShadow + sunColor*sunSpec*sunShadow;\n        \n        // Carry surface color through next bounce\n        vec3 previousBounceColor = bounceColor;\n        bounceColor *= surfaceColor;\n\n\t\tif(bounce == 0)\n        {\n            totalDirect += bounceColor*iColor + emissiveColor;\n            // Out\n            camHitPosition = position;\n            depth = traced;\n            baseColor = surfaceColor;\n            camHitNormal = surfaceNormal;\n        }\n        else if(bounce == 1)\n        {\n            totalGi += bounceColor*iColor + emissiveColor;\n\n            // Virtual point light from direct lighting of first bounce, accumulated in Buffer B\n            bounceLight.worldPosition = position;\n            bounceLight.normal = surfaceNormal;\n            bounceLight.color = (previousBounceColor*iColor + emissiveColor);\n\n            // TODO texture map\n            \n            float lightDistance = distance(bounceLight.worldPosition, camHitPosition);\n            float NdotL = saturate(dot(normalize(camHitNormal), normalize(bounceLight.worldPosition - camHitPosition)));\n            \t\n            if(NdotL > 0.00001 && length(baseColor) > 0.00001)\n            {\t\n                // Cancel out cosine distribution\n                bounceLight.color /= NdotL;\n                // Cancel out inverse square attenuation \n                bounceLight.color *= lightDistance*lightDistance;\n                // For debugging direct light\n                //bounceLight.color *= 0.0;\n            }\n        }\n\n\t\t// Send bounce ray\n        vec3 reflectDirection = reflect(normalize(currentRay.direction), normalize(surfaceNormal));\n        currentRay.direction = cosineDirection(surfaceNormal, fragCoord, seed);\n\n        currentRay.origin = position;\n    }\n    \n    // Out\n\tdirectLight = totalDirect;\n    indirectLight = totalGi;\n}\n\nmat3 setCamera(in vec3 ro, in vec3 rt, in float cr)\n{\n\tvec3 cw = normalize(rt-ro);\n\tvec3 cp = vec3(sin(cr), cos(cr),0.0);\n\tvec3 cu = normalize( cross(cw,cp) );\n\tvec3 cv = normalize( cross(cu,cw) );\n    return mat3(cu, cv, -cw);\n}\n//Marching parameters\n#define MAXSTEPS 50\n#define HITTHRESHOLD 0.009\n#define FAR 64.\n//AA : change to 1 to turn it off\n#define AA 1\n//IFS iterations : try 2 or 3\n#define NIFS 6\n//scale and translate for the IFS in-loop transformation\n#define SCALE 2.3\n#define TRANSLATE 4.5\n\nmat2x2 rot(float angle)\n{\n    float c = cos(angle);\n    float s = sin(angle);\n    return mat2x2(c, -s,\n\t\t\t\t  s, c);\n}\n\nvec4 sd2d(vec2 p, float o)\n{\n    float time = 0.2*o+0.6*iTime;\n \tfloat s =.5+0.25*cos(iTime/2.);\n    p*= s;\n    float RADIUS =(1.+sin(iTime));\n    int i;\n    vec3 col;  \n    p = p*rot(-0.4*time);// twist\n\n    for ( i = 0; i<NIFS; i++)\n    {        \n        if (p.x<0.) {p.x = -p.x;col.r++;}\n\t\tp = p*rot(0.9*sin(time));\n        if (p.y<0.) {p.y = -p.y;col.g++; }\n        if (p.x-p.y<0.){ p.xy = p.yx;col.b++;}        \n      \tp = p*SCALE-TRANSLATE;\n        p = p*rot(0.3*(iTime));\n    }\n    \n    float d = 0.425*(length(p)-RADIUS) * pow(SCALE, float(-i))/s;\n    col/=float(NIFS);\n    vec3 oc = mix(vec3(0.7,col.g,0.2),vec3(0.2,col.r,0.7), col.b);\n    \n    return vec4(oc,d);\n}\n\nvec4 map (vec3 p)\n{\n\treturn sd2d(p.xz,p.y);\n}\n\nfloat shadow(vec3 ro, vec3 rd)\n{\n    float h = 0.;\n    float k =3.5;//shadowSmooth\n    float res = 1.;\n    float t = 0.2; //bias\n    for (int i = 0; t < 15.; i++) // t < shadowMaxDist\n    {\n        h = map(ro + rd * t).w;\n\t\tres = min(res, k*h / t);\n        if (h < HITTHRESHOLD)\n        {\n           break;\n        }\n        t = t + h;\n    }\n    return clamp(res+0.05,0.,1.);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{ \n    //camera\n    float height = -0.4;\n    float rot=iTime*0.05;\n    float dist= 32.+6.*sin(0.5*iTime);\n    vec3 ro = dist * vec3(cos(rot),height,sin(rot));\n   \tvec3 lookAt = vec3 (0.,0.,0.);\n    vec3 fw = normalize(lookAt-ro);\n    //tilting camera for a \"weirder\" feel when rotating around Y axis\n    vec3 right = normalize(cross(vec3(0.,1.,1.0), fw));\n    vec3 up = normalize(cross (fw, right));\n    right = normalize(cross(up,fw));\n    \n    //light\n    rot+=sin(iTime)*0.2;\n    vec3 lightPos =  dist * vec3(cos(rot),height,sin(rot));\n    \n    //raymarch\n    vec3 pos, closest;\n    float t;\n    float smallest;\n    int i;\n    vec3 sdfCol; \n    vec3 col;\n    \n    for (int x=0; x<AA;x++)\n    for (int y=0; y<AA;y++)\n    {\n        t = 0.; smallest = 500.;\n        vec2 o = vec2(float(x),float(y)) / float(AA) - 0.5;\n        vec2 uv = (fragCoord+o)/iResolution.xy;\n        uv -= 0.5;\n        uv.x *= iResolution.x/iResolution.y; \n        vec3 rd = normalize( fw *0.5 + right * uv.x + up * uv.y);  \n        \n        for ( i=0; i<MAXSTEPS; i++)\n        {\n            pos = ro + rd *t;   \n            vec4 mr = map(pos);\n            float d = mr.w;\n            if (d < smallest) smallest = d; closest = pos; sdfCol = mr.rgb;\n            if (abs(d)<HITTHRESHOLD || t> FAR) {break;}\n            t +=d;\n        }   \n        pos = closest;\n        vec3 c;\n        if (t<FAR)\n        { \n            c = sdfCol; \n            vec3 toLight = normalize(lightPos-pos);\n            float s = shadow(pos,toLight);\n            c*=s; \n          \tc = mix(c, 1.5*c,1.-s);\n        }\n        else \n        {\n            c = vec3(0.);                \n        }     \n        col += c;\n    }\n    col/=float(AA*AA);\n    \n    fragColor = vec4 (col,t);\n//}\n\n//void mainImage( out vec4 fragColor, in vec2 fragCoord )\n//{\n    vec2 jitter = vec2(hash12(vec2(13.1, mod(float(iFrame*4),4096.0))),hash12(vec2(4.1, mod(float(iFrame*3),4096.0))))*AAjitter-(AAjitter/2.0);\n    \n    vec2 jitteredCoord = fragCoord + jitter;\n    vec2 uv = jitteredCoord/iResolution.xy;\n\tvec2 uvAspectCorrected = vec2(uv.x*(iResolution.x/iResolution.y), uv.y);\n    \n    float sa = hash13(vec3(iFrame, fragCoord.x, fragCoord.y));\n    \n    ray cameraRay;\n    \n    float mouseLocation = 0.1;\n    #ifdef ANIMATE_CAMERA\n\t    mouseLocation += iTime/9.0;\n    #endif\n    #ifdef INTERACTIVE\n\t    mouseLocation += 0.002*iMouse.x;\n    #endif\n    \n    vec3 sunDirection = initialSunDirection;\n    vec3 sunColor = initialSunColor;\n    \n    #ifdef ANIMATE_SUN\n\t    sunDirection.yz *= ROT(mod(iTime*0.05, PI*2.0));\n    \tsunDirection.xy *= ROT(sin(mod(iTime*0.025, PI*2.0)));\n    \n    \t// \"moon\"\n    \tif (sunDirection.y <= 0.0)\n        {\n            float colorMix = smoothstep(0.0, -0.2, sunDirection.y);\n            if(sunDirection.y <= -0.2)\n            {\n\t            sunDirection.y += 0.2;\n    \t        sunDirection.y *= -1.0;\n        \t    sunDirection.y -= 0.2;\n            }\n           \tsunColor = mix(sunColor, moonColor, colorMix);\n        }\n\t#endif\n\n\n    // TODO more interesting camera movement\n    // TODO avoid intersections\n    cameraRay.origin = vec3( 2.8*cos(0.1+.33*mouseLocation), 0.5 + 0.15*cos(0.37*mouseLocation), 2.8*cos(0.5+0.35*mouseLocation) );\n    //cameraRay.origin.y = 1.0;\n    //cameraRay.origin = dropToFloor(cameraRay.origin, 7) + vec3(0, 0.02, 0);\n    cameraRay.direction = stereographicPlaneToSphere((vec2(uvAspectCorrected) - 0.5)/1.5);\n    cameraRay.direction.xyz = normalize(cameraRay.direction.xzy);\n    \n    vec3 color = vec3(0.0);\n    \n    // Results from ray tracing to pack up for use in subsequent passes\n    pointLight bounceLight;\n    vec3 baseColor = vec3(0);\n    vec3 camHitPosition;\n    vec3 directLight;\n    vec3 indirectLight;\n    vec3 camHitNormal;\n    float depth;\n    \n\tcalculateColor(cameraRay, sa, fragCoord, camHitPosition, depth, camHitNormal, baseColor, directLight, indirectLight, bounceLight, sunDirection, sunColor);\n    \n    float dither = 0.008*hdrScale*(hash12(fragCoord+mod(iTime, 512.0)*0.21+0.1*iMouse.xy)-0.5);\n    \n    depth /= depthScale;\n    if(depth <= 0.0 || depth > maxDepth)\n    {\n        depth = maxDepth;\n    }\n    \n    directLight += dither;\n    bounceLight.color += dither;\n    \n    directLight /= hdrScale;\n    indirectLight /= hdrScale;\n    bounceLight.color /= hdrScale;\n    bounceLight.worldPosition /= depthScale;\n    \n    // Clamp brightness, preserve color\n    float totalLight = max(max(length(indirectLight), length(directLight)),  length(bounceLight.color));\n    if(totalLight >= 1.0)\n    {\n        directLight /= totalLight;\n        indirectLight /= totalLight;\n        bounceLight.color /= totalLight;\n    }\n    \n    // For debugging\n    //NdotL = saturate(dot(normalize(camHitNormal), normalize(bounceLight.worldPosition*depthScale - camHitPosition)));\n    //virtualPointColor = baseColor*bounceLight.color*NdotL;\n    //indirectLight = virtualPointColor;\n    //bounceLight.color = indirectLight;\n    \n    // For debugging\n    //bounceLight.color = camHitPosition/depthScale;//clamp(bounceLight.worldPosition, 0.0, depthScale);\n    //bounceLight.color = camHitNormal;\n    //bounceLight.color = bounceLight.worldPosition;\n    \n    \n    \n    // Buffer packing layout:\n    // x = vec4(directLight.rgb, baseColor.r)\n    // y = vec4(bounceLight.color.rgb, baseColor.g)\n    // z = vec4(bounceLight.position.xyz, baseColor.b)\n    // w = vec4(normal.xyz, depth)\n    \n    //#ifdef STORE_NORMAL\n        // Tried packing both normal and depth, loses too much precision in depth to be useful for temporal reprojection\n    //    fragColor = vec4(pack(vec4(directLight, baseColor.r)), pack(vec4(bounceLight.color, baseColor.g)), pack(vec4(bounceLight.worldPosition, baseColor.b)), pack(vec4(camHitNormal/2.0 + 0.5, pow((saturate(depth)), 1.0/depthDistributionExponent))));\n    //#else\n   // \tfragColor = vec4(pack(vec4(directLight, baseColor.r)), pack(vec4(bounceLight.color, baseColor.g)), pack(vec4(bounceLight.worldPosition, baseColor.b)), pow((saturate(depth)), 1.0/depthDistributionExponent));\n    //#endif\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 3,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Kleinian Landscape\n//\n// Except where otherwise specified or cited, all work is my own and available under\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n// Constants, helper functions\n// \n\n#define CLAMP_INDIRECT\n#define ANIMATE_CAMERA\n#define ANIMATE_SUN\n#define INTERACTIVE\n#define ROUGHNESS_MAP\n#define INDIRECT_GATHER_CHECK_DIRECTION\n\n\n////////// GENERAL\n\n#define PI 3.1415926536\n\nconst float gamma = 2.2;\n\n// Dynamic range; keep as low as possible since these buffers are packed with very low precision\nconst float hdrScale = 1.0;\nconst float depthScale = 1.0;\nconst float maxDepth = 32.0;\nconst float depthDistributionExponent = 1.0;\n\nconst vec3 luma = vec3(0.299, 0.587, 0.114);\nconst float goldenAngle = 2.4;\n\n#ifdef TEMPORAL_JITTER\n\tconst float AAjitter = 1.0;\n#else\n\tconst float AAjitter = 0.0;\n#endif\n\nfloat saturate(float a)\n{\n    return clamp(a, 0.0, 1.0);\n}\n\n// from Dave Hoskins: https://www.shadertoy.com/view/4djSRW\n// Hash without Sine\n// MIT License...\n/* Copyright (c)2014 David Hoskins.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.*/\n\n//----------------------------------------------------------------------------------------\n//  1 out, 1 in...\nfloat hash11(float p)\n{\n    p = fract(p * .1031);\n    p *= p + 33.33;\n    p *= p + p;\n    return fract(p);\n}\n\n//----------------------------------------------------------------------------------------\n//  1 out, 2 in...\nfloat hash12(vec2 p)\n{\n\tvec3 p3  = fract(vec3(p.xyx) * .1031);\n    p3 += dot(p3, p3.yzx + 33.33);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\n//----------------------------------------------------------------------------------------\n//  1 out, 3 in...\nfloat hash13(vec3 p3)\n{\n\tp3  = fract(p3 * .1031);\n    p3 += dot(p3, p3.yzx + 33.33);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\n\n//----------------------------------------------------------------------------------------\n///  2 out, 2 in...\nvec2 hash22(vec2 p)\n{\n\tvec3 p3 = fract(vec3(p.xyx) * vec3(.1031, .1030, .0973));\n    p3 += dot(p3, p3.yzx+33.33);\n    return fract((p3.xx+p3.yz)*p3.zy);\n\n}\n\n\n\n// from Fabrice Neyret\n#define ROT(a)  mat2( cos(a), -sin(a), sin(a), cos(a) )\n#define HUE(v) ( .6 + .6 * cos( 2.*PI*(v) + vec4(0,-2.*PI/3.,2.*PI/3.,0) ) )\n\n\n\n// Buffer unpacking\n#define UBOUNCE_COLOR(coord) (unpack(texelFetch(iChannel0, ivec2(coord), 0).y))\n#define UBOUNCE_POSITION(coord) (unpack(texelFetch(iChannel0, ivec2(coord), 0).z))\n#define UBOUNCE_LIGHT(coord) (texelFetch(iChannel2, ivec2(coord), 0))\n#define UBOUNCE_LIGHT_BLUR(coord) UBOUNCE_LIGHT(coord)\n\n#define UDIRECT_ILLUMINATION(coord) (unpack(texelFetch(iChannel0, ivec2(coord), 0).x))\n#define UNORMAL(coord) (((unpack(texelFetch(iChannel0, ivec2(coord), 0).w)).xyz - 0.5)*2.0)\n#define UDEPTH(coord) (pow(texelFetch(iChannel0, ivec2(coord), 0).w, depthDistributionExponent))\n\n#define UDEPTH_CHANNEL1(coord) (texelFetch(iChannel1, ivec2(coord), 0).w)\n#define UBASE_COLOR(coord) vec3((unpack(texelFetch(iChannel0, ivec2(coord), 0).x)).w, (unpack(texelFetch(iChannel0, ivec2(coord), 0).y)).w, (unpack(texelFetch(iChannel0, ivec2(coord), 0).z)).w)\n\n// Color packing from cornusammonis: https://www.shadertoy.com/view/Xlfcz8\nuint packSnorm4x8(vec4 x) \n{\n\tx = clamp(x,-1.0, 1.0) * 127.0;\n    uvec4 sig = uvec4(mix(vec4(0), vec4(1), greaterThanEqual(sign(x),vec4(0))));\n    uvec4 mag = uvec4(abs(x));\n    uvec4 r = sig << 7 | mag;\n    return r.x << 24 | r.y << 16 | r.z << 8 | r.w;\n}\nvec4 unpackSnorm4x8(uint x) \n{\n\tuvec4 r = (uvec4(x) >> uvec4(24, 16, 8, 0)) & uvec4(0xFF);\n    uvec4 sig = r >> 7;\n    uvec4 mag = r & uvec4(0x7F);\n    vec4 fsig = mix(vec4(-1), vec4(1), greaterThanEqual(sig,uvec4(1)));\n    vec4 fmag = vec4(mag) / 127.0;\n    return fsig * fmag;\n}\n\n#define unpack(x) unpackSnorm4x8(floatBitsToUint(x))\n#define pack(x) uintBitsToFloat(packSnorm4x8(x))\n\n\n////////// SCENE\n\nstruct pointLight\n{\n    vec3 worldPosition;\n    vec3 normal;\n    vec3 color;\n};\n    \nstruct directionalLight\n{\n    vec3 worldPosition;\n    float angle;\n    vec3 color;\n};\n    \nstruct ray\n{\n    vec3 origin;\n    vec3 direction;\n};\n    \nstruct material\n{\n    vec3 baseColor;\n    float roughness;\n    float metal;\n};\n\nvec3 initialSunDirection = normalize(vec3(-0.2, 0.7, -0.4));\nvec3 initialSunColor = 1.25*vec3(1.0,0.60,0.3);\n// \"Moon\" is just sun reflected and re-colored when it crosses horizon line\nvec3 moonColor = 1.5*vec3(1.0,0.60,0.3)*vec3(0.25, 0.45, 0.75);\nvec3 skyColor = vec3(0);\n\n// Sphere inversion fractal, similar to iq's \"Apollonian\" (https://www.shadertoy.com/view/4ds3zn) but with octogonal symmetry\nfloat map(vec3 p, inout vec4 orbitTrap)\n{\n    const float s = 1.0;//0.97;\n    const float horizontalWrap = sqrt(s*2.0)/2.0;\n    \n\tfloat scale = 1.0;\n\n\torbitTrap = vec4(1000.0); \n    \n    for(int i=0; i<9; i++)\n\t{\n        p.xz /= horizontalWrap;\n        vec3 pOffset = (0.5*p+0.5);\n\n        vec3 pOffsetWrap = 2.0*fract(pOffset);\n        \n        p = -1.0 + pOffsetWrap;\n        p.xz *= horizontalWrap;\n        \n\t\tfloat r2 = dot(p,p);\n\t\t\n        if(i < 2)\n        {\n\t        orbitTrap.z = min(orbitTrap.z, vec4(abs(p),r2).z);\n        }\n        if(i > 2)\n        {\n            orbitTrap.xyw = min(orbitTrap.xyw, vec4(abs(p),r2).xyw);\n        }\n        \n\t\tfloat k = s/r2;\n\t\tp     *= k;\n\t\tscale *= k;\n\t}\n\t\n\tfloat fractal = 0.33*abs(p.y)/scale;\n    return fractal;\n}\n\nfloat sceneDistanceFunction(vec3 p, inout vec4 orbitTrap)\n{\n    return map(p, orbitTrap);\n}\n\nvec3 calcNormal(in vec3 position)\n{\n    vec3 eps = vec3(0.0001,0.0,0.0);\n    vec4 dummyOrbitTrap;\n\n    return normalize( \n        vec3(\n        sceneDistanceFunction(position+eps.xyy, dummyOrbitTrap) - sceneDistanceFunction(position-eps.xyy, dummyOrbitTrap),\n        sceneDistanceFunction(position+eps.yxy, dummyOrbitTrap) - sceneDistanceFunction(position-eps.yxy, dummyOrbitTrap),\n        sceneDistanceFunction(position+eps.yyx, dummyOrbitTrap) - sceneDistanceFunction(position-eps.yyx, dummyOrbitTrap))\n    \t);\n}\n\nvec3 getSky(ray cameraRay, vec3 sunDirection, vec3 sunColor)\n{\n    // TODO could take dot product with some random hemisphere samples to create fake stars\n    vec3 bgColor = vec3(1.0);\n\n    #ifdef WATER\n        if(cameraRay.direction.y < 0.0)\n        {\n            cameraRay.direction *= vec3(1, -1, 1);\n            bgColor *= waterColor;\n        }\n    #endif\n\n    bgColor *= skyColor + saturate((dot(cameraRay.direction, sunDirection)-.9975)*800.0)*sunColor*80.0 + saturate(dot(cameraRay.direction, sunDirection)+0.75)*sunColor*0.015;\n\treturn bgColor;\n}\n\n\n////////// PATH TRACING\n    \nconst int unpackedNone = 0;\n\n// TODO flags for applying filters to packed textures\n/*\nconst int unpackedDirect = 1;\nconst int unpackedBounce = 2;\nconst int unpackedDepth = 3;\nconst int unpackedBaseColor = 4;\n*/\n\n// from hornet, who says:\n// note: entirely stolen from https://gist.github.com/TheRealMJP/c83b8c0f46b63f3a88a5986f4fa982b1\n//\n// Samples a texture with Catmull-Rom filtering, using 9 texture fetches instead of 16.\n// See http://vec3.ca/bicubic-filtering-in-fewer-taps/ for more details\nvec4 sampleLevel0(sampler2D sceneTexture, vec2 uv, float mipLevel)\n{\n    return textureLod(sceneTexture, uv, mipLevel);\n}\nvec4 SampleTextureCatmullRom(sampler2D sceneTexture, vec2 uv, vec2 texSize, float mipLevel, int getPacked)\n{\n    vec4 result = vec4(0.0);\n    if(getPacked == unpackedNone)\n    {\n        // We're going to sample a a 4x4 grid of texels surrounding the target UV coordinate. We'll do this by rounding\n        // down the sample location to get the exact center of our \"starting\" texel. The starting texel will be at\n        // location [1, 1] in the grid, where [0, 0] is the top left corner.\n        vec2 samplePos = uv * texSize;\n        vec2 texPos1 = floor(samplePos - 0.5) + 0.5;\n\n        // Compute the fractional offset from our starting texel to our original sample location, which we'll\n        // feed into the Catmull-Rom spline function to get our filter weights.\n        vec2 f = samplePos - texPos1;\n\n        // Compute the Catmull-Rom weights using the fractional offset that we calculated earlier.\n        // These equations are pre-expanded based on our knowledge of where the texels will be located,\n        // which lets us avoid having to evaluate a piece-wise function.\n        vec2 w0 = f * ( -0.5 + f * (1.0 - 0.5*f));\n        vec2 w1 = 1.0 + f * f * (-2.5 + 1.5*f);\n        vec2 w2 = f * ( 0.5 + f * (2.0 - 1.5*f) );\n        vec2 w3 = f * f * (-0.5 + 0.5 * f);\n\n        // Work out weighting factors and sampling offsets that will let us use bilinear filtering to\n        // simultaneously evaluate the middle 2 samples from the 4x4 grid.\n        vec2 w12 = w1 + w2;\n        vec2 offset12 = w2 / w12;\n\n        // Compute the final UV coordinates we'll use for sampling the texture\n        vec2 texPos0 = texPos1 - vec2(1.0);\n        vec2 texPos3 = texPos1 + vec2(2.0);\n        vec2 texPos12 = texPos1 + offset12;\n\n        texPos0 /= texSize;\n        texPos3 /= texSize;\n        texPos12 /= texSize;\n        \n        result += sampleLevel0(sceneTexture, vec2(texPos0.x,  texPos0.y), mipLevel) * w0.x * w0.y;\n        result += sampleLevel0(sceneTexture, vec2(texPos12.x, texPos0.y), mipLevel) * w12.x * w0.y;\n        result += sampleLevel0(sceneTexture, vec2(texPos3.x,  texPos0.y), mipLevel) * w3.x * w0.y;\n\n        result += sampleLevel0(sceneTexture, vec2(texPos0.x,  texPos12.y), mipLevel) * w0.x * w12.y;\n        result += sampleLevel0(sceneTexture, vec2(texPos12.x, texPos12.y), mipLevel) * w12.x * w12.y;\n        result += sampleLevel0(sceneTexture, vec2(texPos3.x,  texPos12.y), mipLevel) * w3.x * w12.y;\n\n        result += sampleLevel0(sceneTexture, vec2(texPos0.x,  texPos3.y), mipLevel) * w0.x * w3.y;\n        result += sampleLevel0(sceneTexture, vec2(texPos12.x, texPos3.y), mipLevel) * w12.x * w3.y;\n        result += sampleLevel0(sceneTexture, vec2(texPos3.x,  texPos3.y), mipLevel) * w3.x * w3.y;\n    }\n    \n    return result;\n}\n\n\nvec3 triPlanarMap(sampler2D inTexture, float contrast, vec3 normal, vec3 position)\n{\n    vec3 xTex = textureLod(inTexture, (position).yz, 0.0).rgb;\n    vec3 yTex = textureLod(inTexture, (position).xz, 0.0).rgb;\n    vec3 zTex = textureLod(inTexture, -(position).xy, 0.0).rgb;\n    vec3 weights = normalize(abs(pow(normal.xyz, vec3(contrast))));\n    \n    return vec3(xTex*weights.x + yTex*weights.y + zTex*weights.z);\n}\n\n// from tux: https://www.shadertoy.com/view/lsj3z3\nvec3 triPlanarMapCatRom(sampler2D inTexture, float contrast, vec3 normal, vec3 position, vec2 texResolution)\n{\n    vec3 signs = sign(normal);\n    \n    vec3 xTex = SampleTextureCatmullRom(inTexture, (position).yz, texResolution, 0.0, 0).rgb;\n    vec3 yTex = SampleTextureCatmullRom(inTexture, (position).xz, texResolution, 0.0, 0).rgb;\n    vec3 zTex = SampleTextureCatmullRom(inTexture, -(position).xy, texResolution, 0.0, 0).rgb;\n    \n    vec3 weights = max(abs(normal) - vec3(0.0, 0.4, 0.0), 0.0);\n    weights /= max(max(weights.x, weights.y), weights.z);\n    float sharpening = 10.0;\n    weights = pow(weights, vec3(sharpening, sharpening, sharpening));\n    weights /= dot(weights, vec3(1.0, 1.0, 1.0));\n  \n    return clamp(vec3(xTex*weights.x + yTex*weights.y + zTex*weights.z), vec3(0), vec3(1));\n}\n    \n\n// from iq\nvec3 cosineDirection(in vec3 nor, vec2 fragCoord, float seed)\n{\n    vec2 randomSeed = (fragCoord * .152 + seed * 1500. + 50.0);\n    vec2 random = hash22(randomSeed);\n    float u = random.x;\n    float v = random.y;\n    \n    // method 2 by pixar:  http://jcgt.org/published/0006/01/01/paper.pdf\n    float ks = (nor.z>=0.0)?1.0:-1.0;     //do not use sign(nor.z), it can produce 0.0\n    float ka = 1.0 / (1.0 + abs(nor.z));\n    float kb = -ks * nor.x * nor.y * ka;\n    vec3 uu = vec3(1.0 - nor.x * nor.x * ka, ks*kb, -ks*nor.x);\n    vec3 vv = vec3(kb, ks - nor.y * nor.y * ka * ks, -nor.y);\n\n    float a = 6.2831853 * v;\n    return sqrt(u)*(cos(a)*uu + sin(a)*vv) + sqrt(1.0-u)*nor;\n}\n\n// from John Hable: https://gist.github.com/Kuranes/3065139b10f2d85074da\nfloat GGX(vec3 N, vec3 V, vec3 L, float roughness, float F0)\n{\n    float alpha = roughness*roughness;\n\n    vec3 H = normalize(V+L);\n\n    float dotNL = saturate(dot(N,L));\n\n    float dotLH = saturate(dot(L,H));\n    float dotNH = saturate(dot(N,H));\n\n    float F, D, vis;\n\n    // D\n    float alphaSqr = alpha*alpha;\n    float denom = dotNH * dotNH *(alphaSqr-1.0) + 1.0;\n    D = alphaSqr/(PI * denom * denom);\n\n    // F\n    float dotLH5 = pow(1.0-dotLH,5.);\n    F = F0 + (1.-F0)*(dotLH5);\n\n    // V\n    float k = alpha/2.;\n    float k2 = k*k;\n    float invK2 = 1.-k2;\n    vis = 1./(dotLH*dotLH*invK2 + k2);\n\n    float specular = dotNL * D * F * vis;\n    return specular;\n}\n\n\n// Camera projection stuff\nvec3 stereographicPlaneToSphere(vec2 cartPointOnPlane) \n{\n    float x2 = cartPointOnPlane.x*cartPointOnPlane.x;\n    float y2 = cartPointOnPlane.y*cartPointOnPlane.y;\n    return vec3(\n        (2.0*cartPointOnPlane.x) / (1.0 + x2 + y2), \n\t    (-1.0 + x2 + y2) / (1.0 + x2 + y2),\n        (2.0*cartPointOnPlane.y) / (1.0 + x2 + y2));\n}\nvec2 stereographicSphereToPlane(vec3 cartPointOnSphere) \n{\n    return vec2(\n        cartPointOnSphere.x / (1.0-cartPointOnSphere.y), \n        cartPointOnSphere.z / (1.0-cartPointOnSphere.y));\n}\nvec2 cameraRayToUv(ray cameraRay, float projectionDist)\n{\n    vec2 uv = vec2(normalize(cameraRay.direction).x, normalize(cameraRay.direction).y);\n    uv *= projectionDist/dot(normalize(cameraRay.direction), vec3(0, 0, projectionDist));\n    return uv;\n}\nray uvToCameraRay(vec2 uv, float projectionDist)\n{\n    ray cameraRay;\n    cameraRay.direction = normalize(vec3(uv.x, uv.y, projectionDist));\n    return cameraRay;\n}\n\n\n////////// POST\n\n// Bloom settings\nconst float bloomIntensity = -0.2;\nconst float bloomRadius = 0.6;\n\n// Fringe/chromatic aberration settings\nconst float fringeStrength = 01.91;\nconst float fringeStart = 0.0;\n\n// Bokeh settings\nconst float bokehScale = 0.75;\nconst float bokehClamp = 0.0125;\nconst float bokehForceSharp = 0.01;\nconst float bokehFringe = 0.6;\nfloat bokehAspectRatio = 1.75;\n\n// FXAA settings\nconst float spanMax = 1.0;\nconst float reduceMult = (1.0/spanMax);\nconst float reduceMin = (1.0/48.0);\nconst float subPixelShift = (1.0/4.0);\n\nvec3 FXAA( vec2 uv2, sampler2D tex, vec2 rcpFrame) \n{\n    vec4 uv = vec4( uv2, uv2 - (rcpFrame * (0.5 + subPixelShift)));\n   \n    float lumaTopLeft = dot(textureLod(tex, uv.zw, 0.0).xyz, luma);\n    float lumaTopRight = dot(textureLod(tex, uv.zw + vec2(1,0)*rcpFrame.xy, 0.0).xyz, luma);\n    float lumaBottomLeft = dot(textureLod(tex, uv.zw + vec2(0,1)*rcpFrame.xy, 0.0).xyz, luma);\n    float lumaBottomRight = dot(textureLod(tex, uv.zw + vec2(1,1)*rcpFrame.xy, 0.0).xyz, luma);\n    float lumaCenter  = dot(textureLod(tex, uv.xy, 0.0).xyz,  luma);\n\n    float lumaMin = min(lumaCenter, min(min(lumaTopLeft, lumaTopRight), min(lumaBottomLeft, lumaBottomRight)));\n    float lumaMax = max(lumaCenter, max(max(lumaTopLeft, lumaTopRight), max(lumaBottomLeft, lumaBottomRight)));\n\n    vec2 direction;\n    direction.x = -((lumaTopLeft + lumaTopRight) - (lumaBottomLeft + lumaBottomRight));\n    direction.y =  ((lumaTopLeft + lumaBottomLeft) - (lumaTopRight + lumaBottomRight));\n\n    float dirReduce = max(\n        (lumaTopLeft + lumaTopRight + lumaBottomLeft + lumaBottomRight) * (0.25 * reduceMult),\n        reduceMin);\n    float rcpDirMin = 1.0/(min(abs(direction.x), abs(direction.y)) + dirReduce);\n    \n    direction = min(vec2( spanMax,  spanMax),\n          max(vec2(-spanMax, -spanMax),\n          direction * rcpDirMin)) * rcpFrame.xy;\n\n    vec3 rgbA = (1.0/2.0) * (\n        textureLod(tex, uv.xy + direction * (1.0/3.0 - 0.5), 0.0).xyz +\n        textureLod(tex, uv.xy + direction * (2.0/3.0 - 0.5), 0.0).xyz);\n    vec3 rgbB = rgbA * (1.0/2.0) + (1.0/4.0) * (\n        textureLod(tex, uv.xy + direction * (0.0/3.0 - 0.5), 0.0).xyz +\n        textureLod(tex, uv.xy + direction * (3.0/3.0 - 0.5), 0.0).xyz);\n    \n    float lumaB = dot(rgbB, luma);\n\n    if((lumaB < lumaMin) || (lumaB > lumaMax)) return rgbA;\n    \n    return rgbB; \n}\n\n// \"Airy disc\" bloom, complete gibberish and not based on anything physical; I just like the way it looks.\nvec4 getBloom(sampler2D sceneTexture, vec2 uv, vec2 resolution, float seed, float aspectRatio)\n{ \n    vec2 randomSeed = (uv*resolution * .152 + seed);\n    float random = hash12(randomSeed)*PI*2.0;\n\n    float stepsCenter = 7.0;\n    float stepsRing = 6.0;\n    float mipLevel = log2(resolution.x)/2.25;\n    vec4 outColor = vec4(0);\n    \n    float bloomSum = 0.0;\n    float weight = 0.0;\n    float totalBloom = 0.0;\n\n    vec2 radius = vec2(bloomRadius);\n    radius.y *= aspectRatio;\n\n    vec2 offsetUv = uv;\n    \n    for(float j = 1.0; j < (stepsCenter + 1.0); j++)\n    {   \n        offsetUv = uv + (radius*pow(j/(stepsCenter + 1.0), 0.75))*vec2(sin(j*goldenAngle+random), cos(j*goldenAngle+random));\n\n        weight = 1.0;\n        \n        vec4 colorFringe = 6.0*vec4(1.0, 0.25, 0.7, 1.0) * HUE(mod((0.2 + 0.3*j/stepsCenter), 1.0));\n        \n        outColor += weight*colorFringe*textureLod(sceneTexture, offsetUv, mipLevel);\n        totalBloom += weight;\n    }\n    \n    radius *= 2.0;\n    \n    for(float j = 2.0; j < (stepsRing + 2.0); j++)\n    {   \n        offsetUv = uv + (radius*pow(j/(stepsRing + 2.0), 0.25))*vec2(sin(j*goldenAngle+random), cos(j*goldenAngle+random));\n\n        weight = 0.5;\n       \n        vec4 colorFringe = 6.0*vec4(1.0, 0.25, 0.7, 1.0) * HUE(mod((0.2 + 0.3*j/stepsRing), 1.0));\n        \n        outColor += weight*colorFringe*textureLod(sceneTexture, offsetUv, mipLevel);\n        totalBloom += weight;\n    }\n    \n    return outColor/totalBloom;\n}\n\nvec4 toneMap(vec4 inputColor, vec3 gamma, vec3 exposure)\n{\n    vec3 gradedColor = vec3(pow(inputColor.r,gamma.r)*exposure.r,pow(inputColor.g,gamma.g)*exposure.g,pow(inputColor.b,gamma.b)*exposure.b);\n    vec4 graded = vec4(1.0-1.0/(gradedColor + vec3(1.0)), inputColor.w);\n    \n    vec3 x = clamp(graded.xyz,0.0001,0.999);\n    \n    // ACES tone mapping approximation from https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\n    const float a = 2.51;\n    const float b = 0.03;\n    const float c = 2.43;\n    const float d = 0.59;\n    const float e = 0.14;\n    return vec4(clamp((x*(a*x+b))/(x*(c*x+d)+e),0.0001,0.999), inputColor.z);\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// Final indirect light \n//\n// Makes use of what we computed in Buffer A.\n// Recalculates screen space normals (they couldn't be stored properly in the buffer packing scheme without precision issues).\n\n// Recalculate world position from depth, texture coordinate for reconstructing normal\n// TODO optimize, or use a simpler camera projection\nvec3 reCalcWorldPosition(vec2 uv)\n{\n    vec2 uvAspectCorrected = vec2(uv.x*(iResolution.x/iResolution.y), uv.y);\n    ray currentRay;\n    \n    // Current frame ray direction, camera ray and direction must match Buffer A\n\n    float mouseLocation = 0.1;\n    #ifdef ANIMATE_CAMERA\n    mouseLocation += iTime/9.0;\n    #endif\n\n    #ifdef INTERACTIVE\n    mouseLocation += 0.002*iMouse.x;\n    #endif\n\n    currentRay.origin = vec3( 2.8*cos(0.1+.33*mouseLocation), 0.5 + 0.15*cos(0.37*mouseLocation), 2.8*cos(0.5+0.35*mouseLocation) );\n    currentRay.direction = stereographicPlaneToSphere((vec2(uvAspectCorrected) - 0.5)/1.5);\n    currentRay.direction.xyz = normalize(currentRay.direction.xzy); \n\n    \n    // Recover world position of current frame intersection point from ray direction\n    float pixelDepthForReprojection = UDEPTH(uv*iResolution.xy)*depthScale;\n    return (currentRay.direction)*pixelDepthForReprojection + currentRay.origin;\n}\n\n// Reconstructs screen space normal for deferred rendering. Bad.\nvec3 reCalcNormalFast(vec2 uv)\n{\n    float offsetPixel = 1.0;\n    \n    vec3 center = reCalcWorldPosition(uv);\n    \n    // Only sample two points, but vary which ones per frame in the hopes that temporal AA will smooth out artifacts\n    if(iFrame % 4 == 0)\n    {\n        vec3 up = reCalcWorldPosition(uv+vec2(0, offsetPixel/iResolution.y));\n        vec3 right = reCalcWorldPosition(uv+vec2(offsetPixel/iResolution.x, 0));\n    \n        return normalize(cross(up-center, center-right));\n    }\n    else if(iFrame % 4 == 1)\n    {\n        vec3 down = reCalcWorldPosition(uv+vec2(0, -offsetPixel/iResolution.y));\n        vec3 left = reCalcWorldPosition(uv+vec2(-offsetPixel/iResolution.x, 0));\n\n        return normalize(cross(center-down, left-center));\n    }\n    else if(iFrame % 4 == 2)\n    {\n        vec3 up = reCalcWorldPosition(uv+vec2(0, offsetPixel/iResolution.y));\n        vec3 left = reCalcWorldPosition(uv+vec2(-offsetPixel/iResolution.x, 0));\n\n        return normalize(cross(up-center, left-center));\n    }\n    else\n    {\n        vec3 down = reCalcWorldPosition(uv+vec2(0, -offsetPixel/iResolution.y));\n        vec3 right = reCalcWorldPosition(uv+vec2(offsetPixel/iResolution.x, 0));\n\n        return normalize(cross(center-down, center-right));\n    }\n}\n\n// Reconstructs normal for deferred rendering using distance function. Slow.\nvec3 reCalcNormalSlow(vec2 uv)\n{\n    float offsetPixel = 1.0;\n    vec3 center = reCalcWorldPosition(uv);\n    return calcNormal(center);\n}\n\n// Get the indirect lighting from a \"virtual point light\" as stored in Buffer A\nvec3 getVirtualLightContribution(vec2 uv, vec2 offsetUv, vec3 baseColor, float roughness, vec3 camHitNormal, vec3 camHitPosition, out float dotProduct, out float brdfRef)\n{\n    // Avoid hotspots from lights nearly touching geometry\n    float minDistance = 0.2;\n    \n    vec3 lightPosition = UBOUNCE_POSITION(offsetUv*iResolution.xy).xyz*depthScale;\n    \n    // Diffuse\n    float diffuse = saturate(dot(normalize(camHitNormal), normalize(lightPosition - camHitPosition)))*0.9;\n    float mouseLocation = 0.1;\n    #ifdef ANIMATE_CAMERA\n    \tmouseLocation += iTime/9.0;\n    #endif\n\n    #ifdef INTERACTIVE\n    \tmouseLocation += 0.002*iMouse.x;\n    #endif\n    vec3 camOrigin = vec3( 2.8*cos(0.1+.33*mouseLocation), 0.5 + 0.15*cos(0.37*mouseLocation), 2.8*cos(0.5+0.35*mouseLocation) );\n    float specular = GGX(normalize(camHitNormal), -normalize(camHitPosition - camOrigin), normalize(lightPosition - camHitPosition), roughness, 0.1);\n    \n    \n    float lightDistance = max(distance(lightPosition, camHitPosition), minDistance);\n    float lightDistance2 = lightDistance*lightDistance;\n    dotProduct = dot(reCalcNormalFast(uv), reCalcNormalFast(offsetUv));\n    \n    brdfRef = diffuse + specular;\n    \n    return ((UBOUNCE_COLOR(offsetUv*iResolution.xy).rgb))/lightDistance2;\n}\n\n// This is where we accumulate the \"point lights\" from neighboring pixels that we stored in Buffer A\n// Requires some ad hoc corrections since this causes us to miss some occlusion/shadows, but since everything is localized to nearby pixels it works pretty OK?\nvec3 accumulateLights(vec2 uv)\n{\n    int steps = 32;\n    vec2 radius = max(vec2(.01), 13.0/iResolution.xy);\n    const float goldenAngle = 2.4;    \n    \n    float depth = UDEPTH(uv*iResolution.xy)*depthScale;\n    vec3 baseColor = UBASE_COLOR(uv*iResolution.xy)/hdrScale;\n    vec3 camHitNormal = reCalcNormalSlow(uv);\n    vec3 camHitPosition = reCalcWorldPosition(uv);\n    \n    vec2 offsetUv = uv;\n    vec3 sum = vec3(0);\n    float totalBlur = 0.0;\n    float weight = 1.0; \n    float dotProduct = 1.0;\n    float brdfRef = 1.0;\n    // Counterproductive to apply pixel jitter to low-discrepency points...\n    //float seed = nrand(uv*iResolution.xy + vec2(mod(iTime*131.5,4096.0), mod(iTime*535.1,4096.0)));\n    float seed = hash11(mod(iTime*33.1, 1024.0));\n    mat2 rot = ROT(mod(seed, 2.0*PI));\n    \n    #ifdef ROUGHNESS_MAP\n    \tfloat roughness = saturate(pow(triPlanarMapCatRom(iChannel2, 5.0, camHitNormal, camHitPosition*7.0, iChannelResolution[2].xy), vec3(2.0)).r*2.0);\n    #else\n    \tconst float roughness = 0.4;\n    #endif\n    \n    // Start with \"correct\" GI contribution (i.e. the path that was actually sent for this pixel)\n    sum += getVirtualLightContribution(uv+0.0, uv, baseColor, roughness, camHitNormal, camHitPosition, dotProduct, brdfRef);\n    sum *= brdfRef;\n    totalBlur += 1.0;\n  \n    for(float i = 0.0; i < float(steps); i++)\n    {       \n        // Rotated Hammersley disc kernel\n        //offsetUv = uv + ((hammersleyDisk(int(i), steps)))*radius*rot;\t\n        // Spiral kernel\n        offsetUv = uv + (radius*pow(((i+1.0)/float(steps)), 0.5))*vec2(sin(mod((i+1.0)*goldenAngle+seed, 2.0*PI)), cos(mod((i+1.0)*goldenAngle+seed, 2.0*PI)));\n\n        dotProduct = 1.0;\n        vec3 sampledIndirect = getVirtualLightContribution(uv, offsetUv, baseColor, roughness, camHitNormal, camHitPosition, dotProduct, brdfRef);\n        float sampledDepth = UDEPTH(floor(offsetUv*iResolution.xy))*depthScale;\n\n        // TODO magic numbers\n        weight = 1.0;\n        \n        // Add hoc occlusion part 1\n        #ifdef INDIRECT_GATHER_CHECK_DIRECTION\n        \tif((dotProduct < 0.7) || distance(depth, sampledDepth) > 0.06 || saturate(sampledDepth-depth) > 0.01)\n        #else\n            if(distance(depth, sampledDepth) > 0.06 || saturate(sampledDepth-depth) > 0.01)\n        #endif\n        {\n            weight = 0.0;\n        }\n        \n        // Ad hoc occlusion part 2\n        float curOcclusion = saturate(200000.0*(depth-sampledDepth-0.03));\n        weight *= saturate(1.0-curOcclusion);\n\n        sum += brdfRef*sampledIndirect*weight;\n        totalBlur += weight;\n    }\n    \n    // Fade into shadow when we don't have good sample coverage\n    sum *= smoothstep(1.0, 2.0, totalBlur);\n    \n    return hdrScale*(baseColor*sum)/totalBlur;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{   \n    vec2 uv = fragCoord/iResolution.xy;\n    \n    vec3 baseColor = UBASE_COLOR(fragCoord)/hdrScale;\n    vec3 indirectLight = accumulateLights(uv);\n    #ifdef CLAMP_INDIRECT\n\t    indirectLight = min(indirectLight, vec3(hdrScale/2.0));\n    #endif\n    float depth = UDEPTH(fragCoord);\n    \n    float currentDepthMin = 100000.0;\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(1,0))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(-1,0))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(0,1))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(0,-1))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(1,1))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(-1,1))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(1,-1))*1.0, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoord+vec2(-1,-1))*1.0, currentDepthMin);\n    \n    fragColor = vec4(indirectLight, pow(currentDepthMin, 1.0/depthDistributionExponent));\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Temporal AA / denoise\n//\n// Lots more terrible ad hoc corrections to reduce ghosting, \"fireflies\" etc.\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{    \n    vec2 uv = fragCoord/iResolution.xy;\n    vec2 uvAspectCorrected = vec2(uv.x*(iResolution.x/iResolution.y), uv.y);\n       \n    vec2 fragCoordDejittered = fragCoord;\n    vec2 uvDejittered = uv;\n    \n    vec3 currentDirect = UDIRECT_ILLUMINATION(fragCoordDejittered).rgb*hdrScale;\n    currentDirect = max(vec3(0), currentDirect);\n    \n    vec3 currentIndirect = vec3(0);\n    \n    currentIndirect = UBOUNCE_LIGHT(fragCoordDejittered).rgb*hdrScale;\n    currentIndirect = max(vec3(0), currentIndirect);\n    currentIndirect = clamp(currentIndirect, vec3(0.0001), vec3(hdrScale));\n       \n    float currentDepth = UDEPTH(fragCoordDejittered)*depthScale;\n    \n    float currentDepthMax = 0.0;\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(1,0))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(-1,0))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(0,1))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(0,-1))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(1,1))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(-1,1))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(1,-1))*depthScale, currentDepthMax);\n    currentDepthMax = max(UDEPTH(fragCoordDejittered+vec2(-1,-1))*depthScale, currentDepthMax);\n\n    float currentDepthMin = 100000.0;\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(1,0))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(-1,0))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(0,1))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(0,-1))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(1,1))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(-1,1))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(1,-1))*depthScale, currentDepthMin);\n    currentDepthMin = min(UDEPTH(fragCoordDejittered+vec2(-1,-1))*depthScale, currentDepthMin);\n    \n    float oldDepthMax = 0.0;\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(1,0)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(-1,0)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(0,1)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(0,-1)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(1,1)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(-1,1)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(1,-1)), oldDepthMax);\n    oldDepthMax = max(UDEPTH_CHANNEL1(fragCoord+vec2(-1,-1)), oldDepthMax);\n\n\n    float oldDepthMin = 100000.0;\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(1,0)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(-1,0)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(0,1)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(0,-1)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(1,1)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(-1,1)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(1,-1)), oldDepthMin);\n    oldDepthMin = min(UDEPTH_CHANNEL1(fragCoord+vec2(-1,-1)), oldDepthMin);\n    \n    ray currentRay;\n    // Current frame ray direction, camera ray and direction must match Buffer A\n    \n    \n    float mouseLocation = 0.1;\n    #ifdef ANIMATE_CAMERA\n\t    mouseLocation += /*0.01*iMouse.x+*/ + iTime/9.0;\n    #endif\n    \n    #ifdef INTERACTIVE\n\t    mouseLocation += 0.002*iMouse.x;\n    #endif\n  \n    currentRay.origin = vec3( 2.8*cos(0.1+.33*mouseLocation), 0.5 + 0.15*cos(0.37*mouseLocation), 2.8*cos(0.5+0.35*mouseLocation) );\n    currentRay.direction = stereographicPlaneToSphere((vec2(uvAspectCorrected) - 0.5)/1.5);\n    currentRay.direction.xyz = normalize(currentRay.direction.xzy); \n\n    // Recover world position of current frame intersection point from ray direction\n    float pixelDepthForReprojection = UDEPTH(uv*iResolution.xy)*depthScale;\n    vec3 currentWorldPosition = normalize(currentRay.direction)*pixelDepthForReprojection*2.0 + currentRay.origin;\n\n    // Previous frame data\n    vec3 prevRayOrigin = texelFetch(iChannel1, ivec2(0), 0).xyz;\n    vec3 prevWorldPosition = currentWorldPosition+(currentRay.origin - prevRayOrigin);\n    vec3 prevRayDirection = prevWorldPosition-prevRayOrigin;\n    float prevPixelDepth = length(prevRayDirection);\n    prevRayDirection = normalize(prevRayDirection);\n    \n    // Find warped UV coords based on world space position of this pixel at previous frame\n    prevRayDirection.xzy = prevRayDirection.xyz;\n    vec2 prevUv = stereographicSphereToPlane(normalize(prevRayDirection))*1.5 + 0.5;\n    prevUv = vec2(prevUv.x/(iResolution.x/iResolution.y), prevUv.y);\n       \n    // Store temporal reprojection parameters\n    if(ivec2(fragCoord) == ivec2(0,0))\n    {\n        // Store latest camera pos for reprojection\n        fragColor.xyz = currentRay.origin;\n        return;\n    }\n    if(ivec2(fragCoord) == ivec2(1,0))\n    {\n        // Copy second-latest camera pos for reprojection\n        fragColor.xyz = texelFetch(iChannel1, ivec2(0,0), 0).xyz;\n        return;\n    }\n    \n    // Sample history color with Catmull-Rom filter\n    // since bilinear results in too much blurring from repeated re-sampling of reprojected history\n    vec3 oldColor = textureLod(iChannel1, prevUv, 0.0).rgb;\n    vec3 oldColorSharp = SampleTextureCatmullRom(iChannel1, prevUv, iChannelResolution[1].xy, 0.0, 0).rgb;\n   \n    // HW filtering is fine for depth\n    float oldDepth = textureLod(iChannel1, prevUv, 0.0).w*depthScale;\n    \n    bool offscreen = false;\n    float mixWeight = 0.0;\n    \n    // Don't read offscreen pixels or region reserved for non-color (camera) data\n    vec2 borderPadding = 1.0*vec2(1.0/(ceil(iResolution.x)), 1.0/(ceil(iResolution.y)));\n    if(prevUv.x <= borderPadding.x || prevUv.y <= borderPadding.y || prevUv.x >= 1.0 - borderPadding.x || prevUv.y >= 1.0 - borderPadding.y ||\n       (floor(prevUv.y*iResolution.y) <= 1.0 && floor(prevUv.x*iResolution.x) <= 10.0))\n    {\n        offscreen = true;\n    }\n\t\n    // TODO dilate motion vector, i.e. take longest in neighborhood?\n    // BUG for some reason this seems to behave differently based on overall distance to camera -- precision issue?\n    mixWeight = max(0.0,(50.0*(sqrt(currentDepth)-sqrt(oldDepth)-0.01)));\n    //mixWeight += saturate(200.0*(currentDepth-oldDepth));\n    mixWeight = (mixWeight + 0.04);\n\n    vec2 biasUv = vec2(0);\n   \t\n    mixWeight = saturate(mixWeight);\n\n    // Don't use Catmull-Rom for newly-unoccluded regions since they are extremely noisy\n    if(mixWeight < 0.1 && !offscreen)\n    {\n        oldColor = oldColorSharp;\n    }\n    \n    if(offscreen)\n    {\n       mixWeight = 1.0;\n    }\n    \n    #ifdef CLAMP_INDIRECT      \n        vec3 blurredGi1 = textureLod(iChannel2, uvDejittered, 1.5).rgb*hdrScale;\n        currentIndirect = min(currentIndirect, blurredGi1 + 0.01);\n        currentIndirect = max(currentIndirect, blurredGi1 - 0.02);\n\n        vec3 blurredGi2 = textureLod(iChannel2, uvDejittered, 2.5).rgb*hdrScale;\n        currentIndirect = min(currentIndirect, blurredGi2 + 0.03);\n        currentIndirect = max(currentIndirect, blurredGi2 - 0.04);\n\n        if(mixWeight > 0.15 || offscreen)\n        {\n            // Blur indirect pixels more when we don't have history data\n            vec3 blurredGi3 = textureLod(iChannel2, uvDejittered, 4.5).rgb*hdrScale;\n            currentIndirect = min(currentIndirect, blurredGi3 + 0.005);\n            currentIndirect = max(currentIndirect, blurredGi3 - 0.04);\n\n            vec3 blurredGi4 = textureLod(iChannel2, uvDejittered, 5.5).rgb*hdrScale;\n            currentIndirect = min(currentIndirect, blurredGi4 + 0.01);\n            currentIndirect = max(currentIndirect, blurredGi4 - 0.08);\n\n            // For debugging. Also happens to look neat.\n            //currentIndirect = vec3(1,0,0);\n        }\n        else\n        {\n            vec3 blurredGi5 = textureLod(iChannel2, uvDejittered, 4.5).rgb*hdrScale;\n            currentIndirect = min(currentIndirect, blurredGi5 + 0.08);\n            currentIndirect = max(currentIndirect, blurredGi5 - 0.1);\n        }\n    #endif\n    \n    //currentDirect += bloomIntensity*getBloom(iChannel1, prevUv, iChannelResolution[0].xy, mod(iTime*139.8 + iMouse.x, 4096.0), bokehAspectRatio*iResolution.x/iResolution.y).rgb;\n       \n    vec3 combinedColor = mix(oldColor, currentDirect + currentIndirect, mixWeight);\n    \n    if(currentDepth >= maxDepth - 0.01)\n    {\n        vec3 sunDirection = initialSunDirection;\n        vec3 sunColor = initialSunColor;\n        #ifdef ANIMATE_SUN\n            sunDirection.yz *= ROT(mod(iTime*0.05, PI*2.0));\n            sunDirection.xy *= ROT(sin(mod(iTime*0.025, PI*2.0)));\n            // \"moon\"\n            if (sunDirection.y <= 0.0)\n            {\n                float colorMix = smoothstep(0.0, -0.2, sunDirection.y);\n                if(sunDirection.y <= -0.2)\n                {\n                    sunDirection.y += 0.2;\n                    sunDirection.y *= -1.0;\n                    sunDirection.y -= 0.2;\n                }\n                sunColor = mix(sunColor, moonColor, colorMix);\n            }\n        #endif\n\n        combinedColor.rgb = getSky(currentRay, sunDirection, sunColor);\n    }\n    \n    combinedColor = clamp(combinedColor, vec3(0.0001), 2.0*vec3(hdrScale));\n\n\n\n    // For debugging\n    //float minMaxVisualize = distance(currentDepthMin, oldDepthMin) + distance(currentDepthMax, oldDepthMax);\n \n    float combinedDepth = currentDepth/depthScale;\n    \n    // For debugging\n    //fragColor = vec4(vec3(minMaxVisualize), combinedDepth);\n    //fragColor = vec4(vec3(mixWeight), combinedDepth);\n    //fragColor = vec4(vec3(biasUv, 0.0), combinedDepth);\n    //fragColor = vec4(vec3(distance(oldDepthMax, oldDepthMin)), combinedDepth);\n    //fragColor = vec4(vec3(distance(currentDepthMax, currentDepthMin)), combinedDepth);\n    //fragColor = vec4(blurGi(uv), combinedDepth);\n    //fragColor = vec4(currentDirect + currentIndirect, combinedDepth);\n    \n    fragColor = vec4(combinedColor, combinedDepth);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Bokeh with fake color fringing + autofocus, anamorphic (including realistic \"swirly\" artifacts near edges)\n//\n// Ended up quite hairy/hacky from to trying to avoid edge/background bleed artifacts, but works pretty well.\n// I originally wanted to do a separable version but didn't have enough buffers left, so it's fairly slow.\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 randomSeed = (fragCoord * .152 + iTime * 1500. + iMouse.x);\n    float random = hash12(randomSeed)*PI*2.0;\n    \n    vec2 uv = fragCoord/iResolution.xy;\n    \n    float depth = textureLod(iChannel0, uv, 0.0).w*depthScale;\n        \n    // Autofocus\n    float focalDepth = texelFetch(iChannel1, ivec2(0), 0).w;\n    float focalDepthNew = min(min(min(textureLod(iChannel0, vec2(0.5, 0.25), 5.5).w*depthScale, textureLod(iChannel0, vec2(0.6, 0.5), 6.5).w*depthScale), textureLod(iChannel0, vec2(0.4, 0.5), 6.5).w*depthScale), textureLod(iChannel0, vec2(0.5, 0.5), 8.0).w*depthScale);\n    focalDepth = mix(focalDepth, focalDepthNew, 0.05);\n    \n    vec2 offsetUv = vec2(0);\n    vec4 foregroundColor = vec4(0);\n    vec4 backgroundColor = vec4(0);\n    vec4 midgroundColor = vec4(0);\n    vec4 midgroundColorNoFringe = vec4(0);\n    vec4 totalColor = vec4(0);\n    \n    const float steps = 32.0;\n    const float stepsSmooth = 24.0;\n    \n    vec2 radiusClamp = vec2(bokehClamp);\n    radiusClamp.y *= iResolution.x/iResolution.y;\n    \n    // Radius of circle of confusion based on depth at current pixel\n    vec2 trueRadius = vec2(bokehScale);\n    trueRadius.y *= iResolution.x/iResolution.y;\n    trueRadius *= 1.0-focalDepth/depth;\n  \n    vec2 erodedRadius = vec2(1);\n    vec2 smoothedRadius = vec2(0);\n    \n    const float additionalDilation = 1.25;\n    const float searchMipLevel = 0.0;\n    \n    // Preprocess, estimate kernel size etc.\n    for(float i = 0.0; i < stepsSmooth; i++)\n    {   \n        vec2 searchRadius = additionalDilation/**vec2(1.0/bokehAspectRatio, 1)*/*(radiusClamp*pow((i)/steps, 0.5));\n        offsetUv = uv + searchRadius*vec2(sin(i*goldenAngle/* + random*/), cos(i*goldenAngle/* + random*/));\n        \n        float depthGathered = textureLod(iChannel0, offsetUv, searchMipLevel).w*depthScale;\n\n        vec2 radiusGathered = vec2(bokehScale);\n        radiusGathered.y *= iResolution.x/iResolution.y;\n        radiusGathered *= 1.0-focalDepth/depthGathered;\n        \n        if(length(radiusGathered) >= length(radiusClamp))\n        {\n            radiusGathered = radiusClamp;\n        }\n        \n        smoothedRadius += abs(radiusGathered);\n        erodedRadius = min(abs(radiusGathered), erodedRadius);\n    }\n    smoothedRadius /= stepsSmooth;\n    \n    // Main blur\n    // Limited radius\n    vec2 radiusBias = vec2(bokehForceSharp);\n    radiusBias.y *= iResolution.x/iResolution.y;\n    vec2 radius = max(vec2(0), smoothedRadius-radiusBias);\n    radius /= (1.0-bokehForceSharp);\n    \n    float totalBlur = 0.0;\n    bool fringeValid = true;\n    \n    // Try to sample from lower-res mips to reduce noise, but don't want to go too low and introduce any visible blockiness\n    float mipLevel = min(max(log2(length(erodedRadius*iResolution.xy/3.0))+0.5, 0.0), max(log2(length(min(smoothedRadius, trueRadius)*iResolution.xy/3.0))-1.5, 0.0));   \n    mipLevel = min(mipLevel, 2.0);\n  \n    vec4 currentColor;\n    vec4 colorFringed;\n    float falloff = 1.0;\n    float vignette = 1.0;\n    if(length(radius) > 1.0/length(iResolution.xy))\n    {\n        for(float i = 0.5; i < steps; i++)\n        {   \n            vec2 offset = (radius*pow(i/steps, 0.5))*vec2(sin(i*goldenAngle + random), cos(i*goldenAngle + random));\n            \n            // \"Swirly\" bokeh\n            offset *= ROT(atan((uv.x-0.5)/(iResolution.y/iResolution.x), uv.y-0.5)-PI);\n            if(offset.y >= radius.y-3.0*(radius.y)*distance(uv, vec2(0.5)))\n            {\n                vignette = saturate(offset.y - (radius.y-3.0*(radius.y)*distance(uv, vec2(0.5))));\n                vignette = saturate(1.0 - 0.8*vignette/radius.y);\n                vignette = saturate(0.0001 + vignette);\n                offset.y /= 1.0+saturate(1.0-vignette)/2.0;\n                \n            }\n            offset *= ROT(-atan((uv.x-0.5)/(iResolution.y/iResolution.x), uv.y-0.5)+PI);\n\n            offset *= vec2(1.0/bokehAspectRatio, 1);\n            \n            offsetUv = uv + offset;\n\n            falloff = ((i+1.0)/steps);\n\n            // Using dilated depth to reduce bleed\n            float depthGathered = textureLod(iChannel2, offsetUv, 0.0).w*depthScale;\n\n            vec2 radiusGathered = vec2(bokehScale);\n            radiusGathered.y *= iResolution.x/iResolution.y;\n            radiusGathered *= 1.0-focalDepth/depthGathered;\n            radiusGathered *= vec2(1.0/bokehAspectRatio, 1);\n          \n            float distanceFromCenter = distance(offsetUv, uv);\n\n            if((depthGathered > depth && length(trueRadius) < bokehScale/6.0 /*&& length(radiusGathered) > length(trueRadius)*/))\n            {\n                float factor = smoothstep(bokehScale/80.0, bokehScale/6.0, length(trueRadius));\n                offsetUv = mix(uv, offsetUv, factor);\n            }\n            float curMipLevel = mipLevel;\n            currentColor = textureLod(iChannel0, offsetUv, mipLevel);\n            colorFringed = currentColor * 12.1*vec4(1.0, 0.16, 0.3, 1.0) * HUE(mod((0.2 + 0.3*float(i)/float(steps-1.0)), 1.0)) * falloff;\n            totalBlur += 1.0*vignette;\n\n            // Is the sample we gathered at a depth such that it would actually be scattered onto the current pixel?\n            if((length(radiusGathered) < distanceFromCenter*0.66))\n            {\n                fringeValid = false;\n                currentColor = vec4(0,0,0,1);\n                colorFringed = vec4(0,0,0,1);\n                totalBlur -= 1.0*vignette;\n            }\n             \n            midgroundColor += mix(currentColor, colorFringed, bokehFringe)*vignette;\n            midgroundColorNoFringe += currentColor*vignette;\n        }\n        // If we rejected some samples, the color fringe would become biased\n        if(!fringeValid)\n        {\n            midgroundColor = midgroundColorNoFringe;\n        }\n        else\n        {\n            midgroundColor = mix(midgroundColorNoFringe, midgroundColor, smoothstep(0.0, 4.0/length(iResolution.xy), length(radius)));\n        }\n        if(totalBlur > 0.0)\n        {\n\t        midgroundColor /= totalBlur;\n        }\n        else\n        {\n            midgroundColor = textureLod(iChannel0, uv, 0.0);\n        }\n    }\n    else\n    {\n        midgroundColor = textureLod(iChannel0, uv, 0.0);\n        // For debugging\n        //midgroundColor = vec4(1,0,0,1)*textureLod(iChannel0, uv, 0.0)*steps;\n    }\n    \n    totalColor += midgroundColor;\n    \n    // Bloom\n    totalColor += bloomIntensity*getBloom(iChannel0, uv, iChannelResolution[0].xy, mod(iTime*13.8 + iMouse.x, 1024.0), bokehAspectRatio*iResolution.x/iResolution.y);\n    \n    // Auto exposure\n    float exposure = texelFetch(iChannel1, ivec2(1, 0), 0).w;\n    float exposureNew = length(textureLod(iChannel0, vec2(0.5, 0.5), 8.0).rgb)*3.0 + 0.5;\n    exposure = mix(exposure, exposureNew, 0.05);  \n    exposure = max(exposure, 0.0) + 0.001;\n    totalColor /= exposure;\n\n    float outAlpha = 0.0;\n    \n    if(ivec2(fragCoord) == ivec2(0,0))\n    {\n        // Store focal depth\n        fragColor.w = focalDepth;\n        return;\n    }\n    if(ivec2(fragCoord) == ivec2(1,0))\n    {\n        // Store exposure\n        fragColor.w = exposure;\n        return;\n    }\n    \n    fragColor = vec4(totalColor.rgb, fragColor.w);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer D",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 260
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}