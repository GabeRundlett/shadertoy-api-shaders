{
    "Shader": {
        "info": {
            "date": "1711794340",
            "description": "ESDF to move, arrows or mouse to rotate. Yup, cuts a lot of fancy things out. ",
            "flags": 48,
            "hasliked": 0,
            "id": "DtsXzB",
            "likes": 10,
            "name": "60FPS Clouds on iGPU #3",
            "published": 3,
            "tags": [
                "game",
                "interactive",
                "clouds",
                "flycam"
            ],
            "usePreview": 0,
            "username": "sdfgeoff",
            "viewed": 133
        },
        "renderpass": [
            {
                "code": "/*\nI had a computer game idea that involved using the sky as terrain. Of course,\nthis involves simulating large cloud-scapes - and I want it to run on my\nlaptop. So....\n\nThis is an attempt to make volumetric clouds run at interactive framerates\non an intel GPU. Of course, this doesn't leave much horse-power\nso a lot of fancy things have to be cut out. Still with some properly\ndesigned textures (to prevent artifacting - the cloud map should be a SDF)\nit should be possible to build a stylized game.\n\nDropping the resolution to half of the framebuffer makes a big difference \nin performance - enough to actually do some lighitng in volumetrics.\n\nI'm pretty happy with how the cloud map sampling works: each channel defines a\ndifferent altitude of cloud. This means that you have artistic control over\nthe clouds and where they all are.\n\nThis version has a physically based lighting model imulating simple\nabsorbtion/scatter\n\n//// Open Questions\n\n - Any other advice for performance? If someone wants to dig through my \n   shader code, I'd love some code review. Any advice for profiling shaders?\n\n\n//// Raymarcher notes\nRaymarcher does big steps through empty space and small steps through clouds.\nWhen it hits a cloud it back-tracks. This means that the smallest cloud \nthickness must be bigger than the big step - which is not the case with the texture\nI'm using. This is why there are some artifacts.\nThe raymarcher early aborts on full opacity and on draw distance.\n\n//// Inspiration:\nHorizon Zero Dawn put out some good presentations on this.\n\n\n\n//// License:\nWTFPL - use as you will.\n\n\n*/\n\n#define BUFFER_HUD iChannel1\n#define BUFFER_CLOUDS iChannel0\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\n    fragColor = textureLod(BUFFER_CLOUDS, fragCoord / iResolution.xy * 0.5, 1.0);\n\n\n    // HUD\n    vec4 hud = texture(BUFFER_HUD, fragCoord / iResolution.xy);\n    fragColor = mix(fragColor, hud, hud.a);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "const ivec2 ADDR_AUTO_FLY = ivec2(0,5);\nconst ivec2 ADDR_CAMERA_POSITION = ivec2(0,0);\nconst ivec2 ADDR_CAMERA_ORIENTATION = ivec2(0,1);\nconst ivec2 ADDR_CAMERA_ANG_VELOCITY = ivec2(0,2);\nconst ivec2 ADDR_CAMERA_LIN_VELOCITY = ivec2(0,3);\nconst ivec2 ADDR_MOUSE_DELTA_STATE = ivec2(0,4);\n\n\nconst float LENS = 0.5;\nconst float PHYSICS_RADIUS = 0.05;\n\n//#define PHYSICS\n\n\n\n\nfloat physics_sdf(vec3 position) {\n    // Return zero when colliding\n#ifdef PHYSICS\n    return map(position);\n#else\n    return 10.0;\n#endif\n}\n\nvec3 physics_normal(vec3 position) {\n    // Return direction vector pointing towards free space\n#ifdef PHYSICS\n    return calc_normal(position);\n#else\n    return vec3(1.0, 0.0, 0.0);\n#endif\n}\n\n\n\n// Fetch a single pixe from a buffer\nvec4 read_data(sampler2D buffer, ivec2 address){\n    return texelFetch(buffer, address, 0);\n}\n\n\n// Create a quaternion from axis-angle notation\nvec4 quat_from_axis_angle(vec3 axis, float angle) {\n    float factor = sin(angle) / 2.0;\n    float w = cos(angle) / 2.0;\n    return normalize(vec4(axis*factor, w));\n}\n\n// Convert a quaternion into a transformation matrix\nmat4 quat_to_transform(vec4 quat, vec3 translation) {\n    vec4 q = quat;\n    vec4 q2 = quat * quat;\n    \n \treturn mat4(\n        1.0 - 2.0*(q2.y + q2.z), 2.0*(q.x*q.y - q.z*q.w), 2.0*(q.x*q.z + q.y*q.w), 0.0,\n    \t2.0*(q.x*q.y + q.z*q.w), 1.0 - 2.0*(q2.x + q2.z), 2.0*(q.y*q.z - q.x*q.w), 0.0,\n    \t2.0*(q.x*q.z - q.y*q.w), 2.0*(q.y*q.z + q.x*q.w),1.0 - 2.0*(q2.x + q2.y), 0.0,\n        translation, 0.0\n    );\n}\n\n// Multiply two quaternions\nvec4 quat_mul(vec4 a, vec4 b) {\n \treturn vec4(\n        a.w * b.x + a.x * b.w + a.y * b.z - a.z * b.y,\n        a.w * b.y - a.x * b.z + a.y * b.w + a.z * b.x,\n        a.w * b.z + a.x * b.y - a.y * b.x + a.z * b.w,\n        a.w * b.w - a.x * b.x - a.y * b.y - a.z * b.z\n    );   \n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// STATE: manages moving the camera\n\n#define BUFFER_STATE iChannel0\n#define BUFFER_KEYBOARD iChannel1\n\nconst vec3 START_POSITION = vec3(12.041,29.324,-0.991);\nconst vec4 START_QUATERNION = vec4(0., 0.707, 0.707, 0);\n\nconst vec2 MOUSE_SENSITIVITY = vec2(-0.2, 0.2);\n\n// Flight dynamics\nconst float LIN_ACCELERATION = 50.0;\nconst float LIN_DRAG = 5.0;\nconst float ANG_ACCELERATION = 10.0;\nconst float ANG_DRAG = 10.0;\n\n\n// What keys to use for controls\nconst int KEY_LEFT = 83;\nconst int KEY_UP   = 84;\nconst int KEY_RIGHT = 70;\nconst int KEY_DOWN = 71;\nconst int KEY_FORWARD = 69;\nconst int KEY_BACKWARD = 68;\n\nconst int KEY_TILT_UP = 38;\nconst int KEY_TILT_DOWN = 40;\nconst int KEY_PAN_LEFT = 37;\nconst int KEY_PAN_RIGHT = 39;\nconst int KEY_ROLL_LEFT = 87;\nconst int KEY_ROLL_RIGHT = 82;\n\n\n// Return the state of a key\nfloat get_key(int key_code) {\n    return texelFetch(BUFFER_KEYBOARD, ivec2(key_code,0), 0).x;\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 address = ivec2(fragCoord);\n    \n    if (address == ADDR_CAMERA_POSITION) {\n        // Move the camera based on keypress\n    \tvec4 camera_position = read_data(BUFFER_STATE, ADDR_CAMERA_POSITION);\n        \n        if (iTime < 0.1) {\n            camera_position = vec4(START_POSITION, 0.0);\n        }\n        if (read_data(BUFFER_STATE, ADDR_AUTO_FLY).x < 0.1) {\n            camera_position = vec4(camera_position.xy, START_POSITION.z, 0.0);\n        }\n\n        \n        float distance_field = physics_sdf(camera_position.xyz);\n        float penetration_distance = -(distance_field - PHYSICS_RADIUS);\n        \n        if (penetration_distance > 0.0) {\n            vec3 normal = physics_normal(camera_position.xyz);\n            camera_position.xyz += normal * penetration_distance;\n        }\n        \n        \n        vec3 translation = read_data(BUFFER_STATE, ADDR_CAMERA_LIN_VELOCITY).xyz;\n        \n        // Convert to local coordinate system\n        mat4 orientation = quat_to_transform(\n            read_data(BUFFER_STATE, ADDR_CAMERA_ORIENTATION),\n            vec3(0.0)\n        );\n        translation = (orientation * vec4(translation, 0.0)).xyz;\n        translation *= iTimeDelta;\n        \n        camera_position.xyz += translation;\n        fragColor = camera_position;\n        return;\n    }\n    \n    \n    if (address == ADDR_CAMERA_ORIENTATION) {\n        // Rotate the camera based on keypress\n        vec4 camera_orientation = read_data(BUFFER_STATE, ADDR_CAMERA_ORIENTATION);\n        \n        if (iTime < 0.1) {\n            camera_orientation = START_QUATERNION;\n        }\n        \n        vec4 velocity = read_data(BUFFER_STATE, ADDR_CAMERA_ANG_VELOCITY);\n        velocity *= iTimeDelta;\n        \n        \n        \n        vec4 pan = quat_from_axis_angle(vec3(0.0, 1.0, 0.0), velocity.x);\n        vec4 tilt = quat_from_axis_angle(vec3(1.0, 0.0, 0.0), velocity.y);\n        vec4 roll = quat_from_axis_angle(vec3(0.0, 0.0, 1.0), velocity.z);\n        \n        \n        camera_orientation = quat_mul(pan, camera_orientation); \n        camera_orientation = quat_mul(tilt, camera_orientation); \n        camera_orientation = quat_mul(roll, camera_orientation); \n        \n        fragColor = camera_orientation;\n        return;\n    }\n    if (address == ADDR_CAMERA_ANG_VELOCITY) {\n        vec4 velocity = read_data(BUFFER_STATE, ADDR_CAMERA_ANG_VELOCITY);\n        vec4 mouse_delta_data = read_data(BUFFER_STATE, ADDR_MOUSE_DELTA_STATE);\n        vec2 mouse_delta = iMouse.xy - mouse_delta_data.xy;\n        \n        vec3 acceleration = vec3(\n            get_key(KEY_PAN_LEFT) - get_key(KEY_PAN_RIGHT),\n            get_key(KEY_TILT_UP) - get_key(KEY_TILT_DOWN),\n            get_key(KEY_ROLL_RIGHT) - get_key(KEY_ROLL_LEFT)\n        );\n        if (mouse_delta_data.z > 0.0) {\n            acceleration.xy += mouse_delta * MOUSE_SENSITIVITY;\n        }\n        if (read_data(BUFFER_STATE, ADDR_AUTO_FLY).x < 0.1) {\n            acceleration.x = sin(iTime * 0.5) * 0.2;\n            acceleration.z = -cos(iTime * 0.5) * 0.05;\n            acceleration.y = 0.0165;\n        }\n        acceleration *= ANG_ACCELERATION;\n        velocity.xyz += acceleration * iTimeDelta;\n        \n        vec4 drag = velocity * ANG_DRAG;\n        velocity -= drag * iTimeDelta;\n        \n        fragColor = velocity;\n        return;\n    }\n    if (address == ADDR_CAMERA_LIN_VELOCITY) {\n        vec4 velocity = read_data(BUFFER_STATE, ADDR_CAMERA_LIN_VELOCITY);\n        \n        vec3 acceleration = vec3(\n            get_key(KEY_RIGHT) - get_key(KEY_LEFT),\n            get_key(KEY_UP) - get_key(KEY_DOWN),\n            get_key(KEY_FORWARD) - get_key(KEY_BACKWARD)\n        ) * LIN_ACCELERATION;\n        \n        if (read_data(BUFFER_STATE, ADDR_AUTO_FLY).x < 0.1) {\n            acceleration.z = LIN_ACCELERATION;\n        }\n        \n        velocity.xyz += acceleration * iTimeDelta;\n        \n\n        \n        vec4 drag = velocity * LIN_DRAG;\n        velocity -= drag * iTimeDelta;\n        \n        fragColor = velocity;\n        return;\n    }\n    if (address == ADDR_MOUSE_DELTA_STATE) {\n        fragColor = iMouse;\n    }\n    if (address == ADDR_AUTO_FLY) {\n        if (iTime < 0.1) {\n            fragColor = vec4(0);\n        }\n        fragColor = read_data(BUFFER_STATE, ADDR_AUTO_FLY) + (\n            get_key(KEY_RIGHT) + get_key(KEY_LEFT) +\n            get_key(KEY_UP) + get_key(KEY_DOWN) +\n            get_key(KEY_FORWARD) + get_key(KEY_BACKWARD) +\n            get_key(KEY_PAN_LEFT) + get_key(KEY_PAN_RIGHT) + \n            get_key(KEY_TILT_UP) + get_key(KEY_TILT_DOWN) +\n            get_key(KEY_ROLL_RIGHT) + get_key(KEY_ROLL_LEFT)\n        );\n    }\n}\n\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// HUD: Draws the heads up display\n\n#define BUFFER_STATE iChannel0\n#define BUFFER_FONT iChannel1\n\nconst vec3 HUD_COLOR = vec3(1.0, 0.6, 0.0);\nconst float HUD_LINE_SIZE = 0.005;\nconst float HUD_BORDER_OFFSET = 0.08;\n\n\nvec4 hud(vec2 uv) {\n    vec4 cam_ang_velocity = read_data(BUFFER_STATE, ADDR_CAMERA_ANG_VELOCITY);\n\n    float aspect = iResolution.x / iResolution.y;\n    float borders = step(0.0, HUD_LINE_SIZE - abs((aspect - HUD_BORDER_OFFSET) - abs(uv.x)));\n    borders += step(0.0, HUD_LINE_SIZE - abs(1.0 - HUD_BORDER_OFFSET - abs(uv.y)));\n    \n    float reticle = step(abs(0.03 - length(uv + cam_ang_velocity.xy * vec2(0.2, -0.2))), HUD_LINE_SIZE);\n    \n    float hud = borders + reticle;\n    \n    hud = clamp(hud, 0.0, 0.5);\n    \n    return vec4(HUD_COLOR,hud);\n}\n\n\n\nvec4 sampleIntChar(int number, vec2 coords) {\n    return texture(BUFFER_FONT, (coords + vec2(float(number), -4.0)) / 16.0);\n}\n\n\nfloat drawInt(int number, vec2 coords, int digits) {\n    vec2 arr = coords * vec2(digits, 1.0);\n    int digitId = digits - int(ceil(arr.x));\n    float digitBase = (pow(10.0, float(digitId)));\n    number = int(floor(float(number) / digitBase)) % 10;\n    \n    float sdf = sampleIntChar(number, fract(arr)).x;\n    float edge = smoothstep(0.1, 0.9, sdf);\n    \n    return sdf;\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 raw_uv = fragCoord/iResolution.xy;\n    vec2 uv = raw_uv;\n    uv = (uv - 0.5) * 2.0;\n    uv.x *= iResolution.x / iResolution.y;\n    \n    \n    \n    fragColor = hud(uv);\n    \n    if (uv.y < -1.0 + HUD_BORDER_OFFSET) {\n        // There is almost certainly a more effecient way to do this\n        vec2 textuv = raw_uv * vec2(1.0/4.2, 1.0) / HUD_BORDER_OFFSET * 2.0;\n        float texBuff = 0.0;\n        vec4 camera_position = read_data(BUFFER_STATE, ADDR_CAMERA_POSITION);\n        textuv.x -= HUD_BORDER_OFFSET * 3.0;\n        texBuff += drawInt(int(abs(camera_position.x * 10.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        texBuff += drawInt(int(abs(camera_position.y * 10.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        texBuff += drawInt(int(abs(camera_position.z * 10.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        texBuff += drawInt(int(abs(iFrameRate * 1000.0)), clamp(textuv, 0.0, 1.0), 7); \n        textuv.x -= HUD_BORDER_OFFSET * 15.0;\n        \n        fragColor = mix(fragColor, texBuff * vec4(HUD_COLOR, 1.0), texBuff);\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 49,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Renders clouds at half-resolution\n\n#define BUFFER_STATE iChannel0\n#define BUFFER_HUD iChannel1\n\n#define BUFFER_VOLUME_NOISE iChannel2\n#define BUFFER_CLOUD_COVER iChannel3\n\n\n\n// Raymarcher Parameters\nconst int MAX_STEPS = 128;\nconst float DRAW_DISTANCE = 150.0;\nconst float INSIDE_STEP_SIZE = 1.0;\nconst float OUTSIDE_STEP_SIZE = 4.0;\nconst int STEP_OUTSIDE_RATIO = int(ceil(INSIDE_STEP_SIZE / OUTSIDE_STEP_SIZE));\n\n// Cloud Material Parameters\nconst float CLOUD_DENSITY_SCALE = 0.5;\n\nconst float kb = 1.0; // Backscattering\nconst float kbp = 30.0; // Backscattering falloff\n\nconst float ks = 0.8; // Onmidirectional Scattering\nconst float kt = 1.0; // Transmission Scattering\nconst float ktp = 2.0; // Transmission falloff\n\nconst float BASE_TRANSMISSION = 0.95; // Light that doesn't get scattered at all\n\n\n// Lighting Parameters\nconst vec3 LIGHT_DIRECTION = normalize(vec3(0,1.0,0.5));\nconst vec3 SUN_LIGHT = vec3(0.99, 0.97, 0.96);\nconst vec3 AMBIENT_LIGHT = vec3(0.52,0.80,0.92);\nconst float AMBIENT_INTENSITY = 0.2; // How \"strong\" is the ambient light\nconst float SUN_INTENSITY = 1.2; // How \"strong\" is the sun\n\n// Cloud Shape Parameters\nconst float CLOUD_MAP_EXTENT = 400.0;\nconst vec4 CLOUD_LAYER_HEIGHTS = vec4(-15.0, 2.0, 20.0, 300.0);\nconst float CLOUD_LAYER_THICKNESS = 6.0; // If this is bigger than the distance between the gap between CLOUD_LAYER_HEIGHTS then the clouds can overlap\nconst float CLOUD_UNDERHANG = 2.0; // How much the cloud layer extends below the layer height\nconst float CLOUD_NOISE_SCALE = 0.02;\nconst vec3 CLOUD_NOISE_SPEED = vec3(0.02, 0.0, 0.0);\nconst int CLOUD_NOISE_OCTAVES = 1;\nconst vec4 CLOUD_DENSITY_MAP_OFFSET = vec4(0.4, 0.1, 0.0, 0.0);\n\n\nconst float E = 2.718;\n\n\nfloat hash14(vec4 p4)\n{\n\tp4 = fract(p4  * vec4(.1031, .1030, .0973, .1099));\n    p4 += dot(p4, p4.wzxy+33.33);\n    return fract((p4.x + p4.y) * (p4.z + p4.w));\n}\n\n\nfloat beerPowder(float material_amount) {\n    return exp(-material_amount) - exp(-material_amount * material_amount);\n}\n\nfloat beer(float material_amount) {\n    return exp(-material_amount);\n}\n\n\nvec3 renderSky(vec3 direction) {\n    float elevation = 1.0 - dot(direction, vec3(0,0,1));\n    float centered = 1.0 - abs(1.0 - elevation);\n    float sun_direction = dot(direction, LIGHT_DIRECTION);\n\n    vec3 atmosphere_color = mix(AMBIENT_LIGHT, SUN_LIGHT, sun_direction * 0.5);\n    \n    vec3 base = mix(pow(AMBIENT_LIGHT, vec3(4.0)), atmosphere_color, pow(clamp(elevation, 0.0, 1.0), 0.5));\n    float haze = pow(centered + 0.02, 4.0) * (sun_direction * 0.2 + 0.8);\n    \n    vec3 sky = mix(base, SUN_LIGHT, clamp(haze, 0.0, 1.0));\n    \n    float sun = pow(max((sun_direction - 29.0/30.0) * 30.0 - 0.05, 0.0), 6.0);\n    \n    return sky + sun;\n}\n\n\n\n\nfloat sampleCloudMapShape(vec3 point) {\n    vec4 map_sample = (textureLod(BUFFER_CLOUD_COVER, point.rg / CLOUD_MAP_EXTENT, 0.0) - 0.5 + CLOUD_DENSITY_MAP_OFFSET) * 2.0;\n\n    vec4 layer_density = map_sample;\n    vec4 layer_centerline = CLOUD_LAYER_HEIGHTS + (CLOUD_LAYER_THICKNESS - CLOUD_UNDERHANG) * layer_density;\n    vec4 layer_thickness = max(CLOUD_LAYER_THICKNESS * layer_density, 0.0);\n    vec4 distance_to_centerline = abs(point.z - layer_centerline);\n    vec4 distance_to_surface = distance_to_centerline - layer_thickness;\n    vec4 distance_to_layer = distance_to_surface;\n\n    float distance_to_cloud = min(min(min(distance_to_layer.x, distance_to_layer.y), distance_to_layer.z), distance_to_layer.w);\n\n    float density = -distance_to_cloud;\n    return density * CLOUD_DENSITY_SCALE;\n}\n\n\nfloat addNoiseToDensity(vec3 point, float density, int octaves) {\n    for (int j = 0; j < octaves; j++) {\n        float level = float(j) + 1.0;\n        float l2 = level * level;\n        float scale = CLOUD_NOISE_SCALE * level;\n        vec3 position_offset = iTime * CLOUD_NOISE_SPEED * l2;\n        vec4 small_noise_tex = textureLod(BUFFER_VOLUME_NOISE, point * scale + position_offset, 0.0);\n        density -= pow(small_noise_tex.r, 2.0) * 4.0  * CLOUD_DENSITY_SCALE;\n    }\n    return density;\n}\n\n\n\n\n\nfloat computeDensityTowardsSun(vec3 current_position, float density_here) {\n    float density_sunwards = max(density_here, 0.0);\n    density_sunwards += max(0.0, sampleCloudMapShape(current_position + LIGHT_DIRECTION * 1.0)) * 1.0;\n    density_sunwards += max(0.0, sampleCloudMapShape(current_position + LIGHT_DIRECTION * 4.0)) * 4.0;\n    \n    return density_sunwards;\n}\n\n\nvec3 transmission(vec3 light,float material_amount) {\n    return beer(material_amount * (1.0 - BASE_TRANSMISSION)) * light;\n}\n\nvec3 lightScattering(vec3 light, float angle, float material_amount) {\n    // Compute the color/intensity of the light scattering in a particular direction\n    // Angle ranges from 1.0 (transmission/forward scattering) to -1.0 (back scattering)  \n    \n\n    \n    angle = (angle + 1.0) * 0.5; // Angle between 0 and 1\n  \n  \n    float ratio = 0.0;\n    ratio += kb * pow(1.0 - angle, kbp);\n    ratio += kt * pow(angle, ktp);\n    ratio = ratio * (1.0 - ks) + ks;\n    \n    \n    /*float ratio = 0.0;\n    ratio = (1.0 - smoothstep(0.0, 0.5,(1.0 - angle) * ktp)) * kt;\n    ratio += (1.0 - smoothstep(0.0, 0.5, (angle) * kbp)) * kb;\n    \n    ratio = ratio * (1.0 - ks) + ks;*/\n    light = light * ratio * (1.0 - BASE_TRANSMISSION);\n    \n    // Transmit....\n    return light;\n}\n\n\nvec4 renderScene(vec3 start_point, vec3 direction) {\n    vec4 accumulation = vec4(0.0, 0.0, 0.0, 0.0);\n    \n    float dist_from_camera = 0.0;\n    int steps_outside_cloud = 0;\n    \n    float noise = hash14(vec4(direction * 1000.0, iTime * 10.0));\n    \n    vec3 sky = renderSky(direction);\n    \n    \n    float materialTowardsCamera = 0.0;\n        \n    \n    for (int i=0; i<MAX_STEPS; i+=1) {\n        vec3 current_position = start_point + (dist_from_camera + noise * INSIDE_STEP_SIZE) * direction;\n        \n        float cloud_map = sampleCloudMapShape(current_position);\n        \n        if (cloud_map > 0.0) {\n            if (steps_outside_cloud != 0) {\n                // First step into the cloud;\n                steps_outside_cloud = 0;\n                dist_from_camera = dist_from_camera - OUTSIDE_STEP_SIZE + INSIDE_STEP_SIZE;\n                continue;\n            }\n            steps_outside_cloud = 0;\n            \n        } else {\n            steps_outside_cloud += 1;\n        }\n        \n        float step_size = OUTSIDE_STEP_SIZE;\n        \n        if (steps_outside_cloud <= STEP_OUTSIDE_RATIO && cloud_map > 0.0) {  \n            step_size = INSIDE_STEP_SIZE;\n            \n            float density_here = cloud_map;\n\n            // We only need to sample the detailed cloud texture if\n            // we are close and can see it in lots of detail.\n            if (dist_from_camera < DRAW_DISTANCE / 2.0) {\n                // If we are already mostly opaque, there's no point sampling extra-detail.\n                //vec4 small_noise_tex = textureLod(BUFFER_VOLUME_NOISE, current_position * 0.05 + vec3(0,iTime * 0.02,0), 0.0);\n                //density -= pow(small_noise_tex.r, 3.0) * 3.0;\n                density_here = addNoiseToDensity(current_position, density_here, CLOUD_NOISE_OCTAVES);\n            }\n            \n            density_here = smoothstep(0.0, 0.1, density_here);\n            \n            density_here = max(density_here, 0.0);\n            float material_here = density_here * step_size;\n            materialTowardsCamera += material_here;\n            \n            float materialTowardsSun = computeDensityTowardsSun(current_position, density_here);\n            \n            vec3 lightFromSunAtParticle = transmission(\n                SUN_LIGHT * SUN_INTENSITY,\n                materialTowardsSun\n            );\n                        \n            float angleToSun = dot(direction, LIGHT_DIRECTION);\n\n            vec3 lightAtParticle = lightFromSunAtParticle;\n            vec3 lightScatteringTowardsCamera = lightScattering(\n                lightAtParticle * material_here,\n                angleToSun,\n                materialTowardsCamera\n            );\n            vec3 lightReachingCamera = transmission(\n                lightScatteringTowardsCamera,\n                materialTowardsCamera\n            );\n            accumulation.rgb += lightReachingCamera;\n        }\n        \n\n        dist_from_camera += step_size;\n        \n        if (dist_from_camera > DRAW_DISTANCE) {\n            break;\n        }\n    }\n    \n\n    accumulation.rgb += beer(materialTowardsCamera * (1.0 - BASE_TRANSMISSION)) * sky;\n    \n    return accumulation;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    \n    // Ignore my coordinate transform mess here\n    vec2 raw_uv = fragCoord/iResolution.xy;\n    vec2 uv = raw_uv;\n    uv = (uv - 0.5) * 2.0;\n    \n    if (uv.x > 0. || uv.y > 0.) {\n        fragColor = vec4(0);\n        return;\n    }\n    uv = (uv + 0.5) * 2.0;\n    \n    uv.x *= iResolution.x / iResolution.y;\n    \n\n\n    // Render our geometry\n    mat4 camera_transform = quat_to_transform(\n        read_data(BUFFER_STATE, ADDR_CAMERA_ORIENTATION),\n        read_data(BUFFER_STATE, ADDR_CAMERA_POSITION).xyz\n    );\n    vec3 start_point = camera_transform[3].xyz;\n    vec3 direction = vec3(uv * LENS, 1.0);\n    direction = normalize((camera_transform * vec4(direction, 0.0)).xyz);\n    \n\n    fragColor = renderScene(start_point, direction);\n\n    // HUD\n    //vec4 hud = texture(BUFFER_HUD, fragCoord / iResolution.xy);\n    //fragColor = mix(fragColor, hud, hud.a);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 2,
                        "ctype": "volume",
                        "id": 39,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/27012b4eadd0c3ce12498b867058e4f717ce79e10a99568cca461682d84a4b04.bin"
                    },
                    {
                        "channel": 3,
                        "ctype": "texture",
                        "id": 48,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/8979352a182bde7c3c651ba2b2f4e0615de819585cc37b7175bcefbca15a6683.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}