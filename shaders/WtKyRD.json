{
    "Shader": {
        "info": {
            "date": "1610925538",
            "description": "LoicVDB helped me get the path tracing to use color properly. The Julia set is colored with an Orbit Trap. The Common tab has settings an functions with helpful descriptions.",
            "flags": 32,
            "hasliked": 0,
            "id": "WtKyRD",
            "likes": 15,
            "name": "Volumetric Path-Tracing Julia 4D",
            "published": 3,
            "tags": [
                "fractal",
                "julia",
                "volumetric",
                "pathtrace",
                "trace",
                "path"
            ],
            "usePreview": 0,
            "username": "Zi7ar21",
            "viewed": 708
        },
        "renderpass": [
            {
                "code": "// ^^^ Switch Between Common, Buffer A, Buffer B, and Image! ^^^\n// Common is for settings and some functions\n// Buffer A is for rendering\n// Buffer B is for exporting a 32-Bit Floating Point OpenEXR Image\n// using the button at the bottom of the editor\n// This is for drawing the shader on the left (or above if you are in portrait mode XD)\n\n// Volumetric Path Tracing Julia 4D by Zi7ar21 --- January 17th, 2020\n// If you found this anywhere except ShaderToy, the original and possibly updated version can be found at:\n// https://www.shadertoy.com/view/WtKyRD\n// Updated January 17th, 2020 16:15 Mountain Time\n// Made with help from LoicVDB (https://www.shadertoy.com/user/loicvdb)\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// ^^^ Switch Between Common, Buffer A, Buffer B, and Image! ^^^\n// This is for settings and some functions.\n\n// Adjustable settings (Feel free to change these!)\n\n// Maximum Path-Tracing Steps, more results in slower possible speed but very few paths will bounce\n// enough to end up taking so long.\n#define maxsteps 8192\n\n// Path Tracing Step Size, more results in faster speed but a less accurate volume and a lower possible density.\n#define stepsize 0.01\n\n// Volume Density, more results in a denser volume but values set too high require smaller steps.\n#define volumedensity 50.0\n\n// Scene Size, if a path is this far from the scene it will stop.\n#define scenesize 4.0\n\n// Starting Path Distance, a larger value results in saving steps but you can't render volumes\n// close to the camera. Make sure this is less than the closest point to your object from the camera.\n#define startingdistance 2.0\n\n// Position of the Camera.\n#define cameraposition vec3(0.0, 0.0, -4.0)\n\n// Camera's Field of View, a larger value results in a wider Field of View.\n#define camerafov 1.0\n\n// Size of the Camera's Aperture, a laerger value results in a shallower Depth of Field.\n#define aperturesize 0.05\n\n// Camera Focal Plane, volumes this far are in focus.\n#define focaldistance 4.0\n\n// Constants (Things like Pi for trigonometry, I mean you could change these, but there is no point.)\n#define pi 3.141592653589793\n#define twopi 3.141592653589793*2.0\n\n// High-Quality Random Numbers from Michael0884, proper demo: https://www.shadertoy.com/view/wltcRS\nuint ns;\n#define INIT_RNG ns = 185730U*uint(iFrame)+uint(fragCoord.x + fragCoord.y*iResolution.x);\nvoid pcg(){\n    uint state = ns*747796405u+2891336453u;\n    uint word = ((state >> ((state >> 28u)+4u))^state)*277803737u;\n    ns = (word >> 22u)^word;\n}\n\nfloat rand(){pcg(); return float(ns)/float(0xffffffffu);}\nvec2 rand2(){return vec2(rand(), rand());}\nvec3 rand3(){return vec3(rand(), rand(), rand());}\nvec4 rand4(){return vec4(rand(), rand(), rand(), rand());}\n\n// Normalized Random, also from Michael0884 https://www.shadertoy.com/view/WttyWX\n/*float ErfInv(float x){\n   float lnx = log((1.0-x)*(1.0+x));\n   float tt1 = 4.3308+0.5*lnx;\n   float tt2 = 6.8027*lnx;\n   return(sign(x)*sqrt(-tt1+sqrt(tt1*tt1-tt2)));\n}*/\n\n//float nrand(){return ErfInv(rand()*2.0-1.0);}\nvec2 nrand2(float sigma, vec2 mean){vec2 Z = rand2(); return mean+sigma*sqrt(-2.0*log(Z.x))*vec2(cos(twopi*Z.y),sin(twopi*Z.y));}\nvec3 nrand3(float sigma, vec3 mean){vec4 Z = rand4(); return mean+sigma*sqrt(-2.0*log(Z.xxy))*vec3(cos(twopi*Z.z), sin(twopi*Z.z), cos(twopi*Z.w));}\n//vec4 nrand4(float sigma, vec4 mean){vec4 Z = rand4(); return mean+sigma*sqrt(-2.0*log(Z.xxyy))*vec4(cos(twopi*Z.z), sin(twopi*Z.z), cos(twopi*Z.w), sin(twopi*Z.w));}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// ^^^ Switch Between Common, Buffer A, Buffer B, and Image! ^^^\n// This is for rendering.\n\n// 4D Julia set Distance Estimator (With an Orbit Trap)\nvec4 qsqr(vec4 a){return vec4(a.x*a.x-a.y*a.y-a.z*a.z-a.w*a.w, 2.0*a.x*a.y, 2.0*a.x*a.z, 2.0*a.x*a.w);}\nvec4 distanceestimator(vec3 pos){\n\tvec4 z = vec4(pos, 0.0);\n    float md2 = 1.0;\n    float mz2 = dot(z, z);\n    vec4 orbitTrap = vec4(1.0);\n    for(int i = 0; i < 8; i++){\n        md2 *= 4.0*mz2;\n        z = qsqr(z)+vec4(-0.5, 0.35, 0.5, 0.0);\n        //z = qsqr(z)+vec4(-0.5, 0.5, 0.25, 0.0);\n        orbitTrap = min(abs(z), orbitTrap);\n        mz2 = dot(z,z);\n        if(mz2 > 4.0) break;}\n    float sdf = 0.25*sqrt(mz2/md2)*log(mz2);\n    return vec4(orbitTrap.rgb, sdf);}\n\n// 3D Volumetric Density Function\nvec4 densityfunction(vec3 pathposition){\n    float density = 0.0;\n    vec4 distanceestimation = distanceestimator(pathposition);\n    if(distanceestimation.w < 0.0){density = volumedensity;}\n    return vec4(distanceestimation.rgb, density);\n}\n\n/*// Light Collision Checker\nbool light(vec3 pathposition){\n    if(distance(pathposition, vec3(0.0, 2.0, 0.0))-0.5 < 0.0){return true;}\n    else{return false;}\n}*/\n\n// Path-Tracing\nvec3 pathtrace(vec3 pathdirection, vec3 inputcameraposition){\n    vec4 density;\n    float absorbance;\n    vec3 attenuation = vec3(1.0);\n    float distancetravelled;\n    vec3 pathposition = inputcameraposition+(pathdirection*startingdistance)+(pathdirection*stepsize*2.0*(rand()-0.5));\n    for(int i = 0; i < maxsteps; i++){\n        density = densityfunction(pathposition);\n        absorbance = exp(-density.w*stepsize);\n        if(absorbance < rand()){attenuation *= clamp(density.rgb*32.0, vec3(0.0), vec3(1.0)); pathdirection = normalize(nrand3(1.0, vec3(0.0)));}\n        pathposition += pathdirection*stepsize;\n        distancetravelled += stepsize;\n        if(distance(pathposition, vec3(0.0)) > scenesize || distancetravelled > 128.0){break;}\n        //if(light(pathposition)){return vec3(2.0)*attenuation;}\n    }\n    return texture(iChannel1, pathdirection).rgb*attenuation;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    vec4 oldFragColor = vec4(0.0);\n    if(iFrame != 0) oldFragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    fragColor = oldFragColor;\n    INIT_RNG;\n    vec2 uv = ((fragCoord+nrand2(0.5, vec2(0.0)))-0.5*iResolution.xy)/iResolution.x;\n    mat3 rotationmatrix = mat3(1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0);\n    vec3 aperture = vec3(nrand2(aperturesize, vec2(0.0)), 0.0);\n    vec3 pathdirection = normalize(vec3(camerafov*uv, 1.0)-aperture/focaldistance);\n    vec3 pathposition = aperture;\n    pathdirection *= rotationmatrix;\n    pathposition *= rotationmatrix;\n    pathposition += cameraposition;\n    vec3 pathtraced = pathtrace(pathdirection, pathposition);\n    fragColor += vec4(pathtraced, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "cubemap",
                        "id": 26,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "false",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/94284d43be78f00eb6b298e6d78656a1b34e2b91b34940d02f1ca8b22310e8a0.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// ^^^ Switch Between Common, Buffer A, Buffer B, and Image! ^^^\n// This is for exporting a 32-Bit Floating Point OpenEXR Image\n// using the button at the bottom of the editor.\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    vec4 texel = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    vec3 color = (texel.a == 0.0 ? vec3(0.0) : texel.rgb/texel.a);\n    fragColor = vec4(pow(color, vec3(1.0/2.2)), 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}