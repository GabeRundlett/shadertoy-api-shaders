{
    "Shader": {
        "info": {
            "date": "1583862160",
            "description": "on my GeForce GTX 760, + on ints is a lot costlier than + on floats",
            "flags": 0,
            "hasliked": 0,
            "id": "3lVSDt",
            "likes": 2,
            "name": "benching int+ vs float+",
            "published": 3,
            "tags": [
                "glsl",
                "bench"
            ],
            "usePreview": 0,
            "username": "FabriceNeyret2",
            "viewed": 364
        },
        "renderpass": [
            {
                "code": "#define Z  min(0,iFrame)\n\nvoid mainImage( out vec4 O, vec2 U )\n{\n    float s=0.; int n=0;\n    for(int i=Z,j=Z+Z; i<100000; i++) { // on GeForce GTX 760 linux 640x360\n        s += float(i) + float(j);       // 7.5 fps \n      //s += float(i+j);                // 4.3 fps\n    }\n    O = vec4(s)+vec4(n);\n}",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}