{
    "Shader": {
        "info": {
            "date": "1650633318",
            "description": "A cell by cell traversal of a packed asymmetric rectangle grid texture.",
            "flags": 32,
            "hasliked": 0,
            "id": "7lsBR8",
            "likes": 57,
            "name": "Asymmetric Texture Raycasting",
            "published": 3,
            "tags": [
                "procedural",
                "grid",
                "raycast",
                "dof",
                "rectangle",
                "traversal",
                "packed",
                "asymmetric"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 1238
        },
        "renderpass": [
            {
                "code": "/*\n\n    Asymmetric Texture Raycasting\n    -----------------------------\n    \n    See \"Buffer A\" for an explanation.\n    \n*/\n\n\n// Just a very basic depth of field routine -- I find a lot of it is\n// common sense. Basically, you store the scene distance from the camera \n// in the fourth channel, then use it to determine how blurry you want\n// your image to be at that particular distance.\n//\n// For instance, in this case, I want pixels that are 8 units away from \n// the camera to be in focus (not blurred) and for things to get more \n// blurry as you move away from that point -- aptly named the focal point \n// for non camera people. :)\n//\n// I based this on old code of mine, but adopted things that I found in \n// IQ and Nesvi7's examples, which you can find here:\n//\n// Ladybug - IQ\n// https://www.shadertoy.com/view/4tByz3\n//\n// Cube surface II - Nesvi7\n// https://www.shadertoy.com/view/Mty3DV\n//\nvec3 DpthFld(sampler2D iCh, vec2 uv){\n\t\n    // Focal point and circle of confusion.\n    const float focD = 8., coc = 6.;\n    // Linear distance from either side of the focal point.\n    float l = abs(focD - texture(iCh, uv).w)*2.;\n    // Using it to calculate the DOF.\n    vec2 dof = clamp((l - coc)/(1.*coc), 0., 2.)/vec2(800, 450); \n    \n    // Combine samples. Samples with a larger DOF value are taken further \n    // away from the original point, and as such appear blurrier.\n    vec3 acc = vec3(0);\n\n    for(int i = 0; i<25; i++){\n        // Accumulate samples.\n        acc += texture(iCh, uv + (vec2(i/5, i%5) - 2.)*dof).xyz;\n    }\n\n    // Return the new variably blurred value.\n    return acc /= 25.;\n    // Visual debug representation of DOF value.\n    //return vec3(length(dof)*450./2.5);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n     \n    \n    // Apply some depth of field, then present to the screen.\n    vec3 col = DpthFld(iChannel0, fragCoord/iResolution.xy);\n    //vec3 col = texture(iChannel0, fragCoord/iResolution.xy).xyz;\n    \n    // Rough gamma correction.\n\tfragColor = vec4(sqrt(max(col, 0.)), 1);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "\n// If you want things to wrap, you need a wrapping scale.  Wrapping is not much \n// different to regular mapping. You just need to put \"p = mod(p, gSc)\" in the hash \n// function for anything that's procedurally generated with random numbers. If you're \n// using a repeat texture, then that'll have to wrap too.\nvec3 gSc = vec3(16);\n\n// Maximum frames to perform the precalculation.\nint maxFrames = 1;\n\n   \n#define cubemapRes vec2(1024)\n\n\n/* \n// Reading into one of the cube faces, according to the face ID. To save on cycles,\n// I'd hardcode the face you're after into all but the least costly of situations.\n// This particular function is used just once for an update in the \"CubeA\" tab.\n//\n// The four cube sides - Left, back, right, front.\n// NEGATIVE_X, POSITIVE_Z, POSITIVE_X, NEGATIVE_Z\n// vec3(-.5, uv.yx), vec3(uv, .5), vec3(.5, uv.y, -uv.x), vec3(-uv.x, uv.y, -.5).\n//\n// Bottom and top.\n// NEGATIVE_Y, POSITIVE_Y\n// vec3(uv.x, -.5, uv.y), vec3(uv.x, .5, -uv.y).\nvec4 tx(samplerCube iCh, vec2 p, int id){    \n\n    vec4 rTx;\n    \n    vec2 uv = fract(p) - .5;\n    // It's important to snap to the pixel centers. The people complaining about\n    // seam line problems are probably not doing this.\n    //p = (floor(p*cubemapRes) + .5)/cubemapRes; \n    \n    vec3[6] fcP = vec3[6](vec3(-.5, uv.yx), vec3(.5, uv.y, -uv.x), vec3(uv.x, -.5, uv.y),\n                          vec3(uv.x, .5, -uv.y), vec3(-uv.x, uv.y, -.5), vec3(uv, .5));\n \n    \n    return texture(iCh, fcP[id]);\n}\n*/\n\n// Wrapping cube face conversion.\nvec2 convert(in vec2 p){ return fract((floor(p*cubemapRes) + .5)/cubemapRes) - .5; }\n\n// Cube face conversion with no wrapping.\n//vec2 convert2(in vec2 p){ return ((floor(p*cubemapRes) + .5)/cubemapRes); }\n\n// Cube face conversion with no wrapping.\nvec4 convert2(in vec4 p){ return ((floor(p*cubemapRes.xyxy) + .5)/cubemapRes.xyxy); }\n\n\nvec4 tx0(samplerCube iCh, vec2 p){\n    vec2 uv = convert(p);\n    return texture(iCh, vec3(-.5, uv.yx));\n \n}\n/*\nvec4 tx1(samplerCube iCh, vec2 p){\n\n    vec2 uv = convert(p);\n    return texture(iCh, vec3(.5, uv.y, -uv.x));\n}\n*/\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n// IQ's signed box formula.\nfloat sBoxS(in vec2 p, in vec2 b, in float sf){\n\n  vec2 d = abs(p) - b + sf;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - sf;\n} \n\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){  \n    p = mod(p, gSc.xy);\n    return fract(sin(dot(p, vec2(27.609, 57.583)))*43758.5453); \n}\n\n// IQ's vec2 to vec2 hash.\nvec2 hash22(vec2 p){\n    p = mod(p, gSc.xy);\n    return fract(sin(vec2(dot(p, vec2(12.783, 78.137)), dot(p, vec2(41.581, 57.263))))\n                          *vec2(43758.5453, 23421.6361));\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "\n// Dave Hoskins's vec2 to float hash -- Modified for this particular example.\n// You can find the details here:\n//\n// Hash without Sine - Dave_Hoskins\n// https://www.shadertoy.com/view/4djSRW\nfloat hash21B(vec2 p){ \n   \n    \n    p = mod(p, gSc.xy);\n    //return texture(iChannel1, p/gSc.xy).x;\n    //return fract(sin(dot(p, vec2(27.609, 57.583)))*43758.5453); \n    //return (fract(sin(dot(p, vec2(27.619, 57.583)))*43758.5453) - .5)*.85; \n    //return hash21(p);\n    \n    //  2 in, 1 out. \n\tvec3 p3  = fract(vec3(p.xyx)*.1031);\n    p3 += dot(p3, p3.yzx + 43.523);\n    return (fract((p3.x + p3.y) * p3.z) - .5)*.85;\n\n}\n\n// The asymmetric block pattern.\n//\n// By the way, you could take a simple line-drawing and partitioning approach to greatly\n// minimize the instruction count, and if 2D bump mapping effects, etc, are all you're\n// after, it might be worth doing. However, if you wish to raymarch this, or do other\n// interesting things, the four rectangles, and corresponding IDs, are a necessary evil.\nvec4 pattern(vec2 p, vec2 sc){\n\n    //p = conv(p);\n\n    vec2 p0 = p;\n\n    vec2 ip = floor(p*sc) + .5; // Grid ID.\n    p -= ip/sc; // Local coordinates.\n    \n    vec3 e = vec3(-1, 0, 1); // Helper vector.\n    \n\n    float h11 = hash21B(ip); // Original cell.\n    \n    float h10 = hash21B(ip + e.xy); // Left.\n    float h01 = hash21B(ip + e.yz); // Top.\n    float h12 = hash21B(ip + e.zy); // Right.\n    float h21 = hash21B(ip + e.yx); // Bottom.\n    \n    float h00 = hash21B(ip + e.xz); // Top left.\n    float h02 = hash21B(ip + e.zz); // Top right.\n    float h22 = hash21B(ip + e.zx); // Bottom right.\n    float h20 = hash21B(ip + e.xx); // Bottom left.\n      \n     \n    vec2[4] ctr;\n    vec2[4] l;\n    \n    \n    // The code looks fiddly, but it's based on a simple idea.\n    // A while ago, I noticed that if you ran vertical and \n    // horizontal lines on alternate checkered tiles, you could\n    // render perpendicular lines on either side at random\n    // positions and everything would line up to form rectangles.\n    // The following is just an implementation of that.\n    \n    // If you uncomment the SHOW_GRID define you'll see that \n    // each cell consists of either a vertical line flanked on\n    // either side by horizontal lines at random Y-positions, or \n    // a horizontal line flanked on either side by vertical\n    // lines at random X-positions.\n    \n    // Implementing the aforementioned is simple enough. However, \n    // lines are great, but cell boundaries -- in order to\n    // render things like blocks would be the thing we'd be more \n    // interested in rendering, so that requires a little more\n    // work.   \t\n    \n    \n    \n    \n    if(mod((ip.x + ip.y), 2.)<.5){ // Horizontal cell.\n\n        // Partition the cell with a randomly positioned horizontal \n        // line and two joining randomly positioned vertical lines\n        // then determine the cell dimensions and cell center of\n        // all four resultant rectangular blocks.\n        \n        // Four block dimensions (X: Width, Y: Height).\n        l[0] = vec2(h01 - h10, h00 - h11) + 1.;\n        l[1] = vec2(-h01 + h12, h02 - h11) + 1.;\n        l[2] = vec2(-h21 + h12, -h22 + h11) + 1.;\n        l[3] = vec2(h21 - h10, -h20 + h11) + 1.;\n        \n        // Four block centers.\n        ctr[0] = vec2(h01, h11) + l[0]*vec2(-.5, .5);\n        ctr[1] = vec2(h01, h11) + l[1]*vec2(.5, .5);\n        ctr[2] = vec2(h21, h11) + l[2]*vec2(.5, -.5);\n        ctr[3] = vec2(h21, h11) + l[3]*vec2(-.5, -.5); \n\n    }\n    else { // Vertical cell.\n\n        // Partition the cell with a randomly positioned vertical \n        // line and two joining randomly positioned horizontal lines\n        // then determine the cell dimensions and cell center.\n        \n        // Four block dimensions (X: Width, Y: Height).\n        l[0] = vec2(-h00 + h11, h01 - h10) + 1.;\n        l[1] = vec2(h02 - h11, h01 - h12) + 1.;\n        l[2] = vec2(h22 - h11, -h21 + h12) + 1.;\n        l[3] = vec2(-h20 + h11, -h21 + h10) + 1.;\n        \n        // Four block centers.\n        ctr[0] = vec2(h11, h10) + l[0]*vec2(-.5, .5);\n        ctr[1] = vec2(h11, h12) + l[1]*vec2(.5, .5);\n        ctr[2] = vec2(h11, h12) + l[2]*vec2(.5, -.5);\n        ctr[3] = vec2(h11, h10) + l[3]*vec2(-.5, -.5); \n        \n\n    }\n                                                                             \n\n    // Debugging: Show the squares with a set single dimension.\n    //l[0] = l[1] = l[2] = l[3] = vec2(.7); // Overlapping: vec2(1.5); \n    \n    // Scaling down the block dimensions.\n    //l[0] /= sc; l[1] /= sc; l[2] /= sc; l[3] /= sc;\n    \n    \n    \n    // Determine the minimum block using the standard method.\n    float d = 1e5;\n    vec2 tileID = vec2(0);\n    //vec2 ctri = vec2(0);\n    vec2 li = vec2(0);\n    vec2 svP;\n     \n  \n    vec3 col;\n    for(int i = 0; i<4; i++){\n    \t \n         vec2 ap = abs(p - ctr[i]/sc) - l[i]/sc/2.;\n         float bx = max(ap.x, ap.y);\n    \t//float bx = sBoxS(p - ctr[i]/sc, l[i]/sc/2., 0.);\n        \n        if(bx<d) {\n            d = bx;\n            tileID = (ip + ctr[i]);\n            //ctri = ctr[i];\n            li = l[i];\n            svP = p - ctr[i]/sc;\n            \n            float rnd = hash21(tileID);\n            \n            col = .5 + .5*cos(6.2831*rnd + vec3(0, 1, 2));\n        }\n        \n    }\n    \n    \n    // Return the distance value of the closed rectangular block\n    // and it's cell center, which doubles as a unique ID. In this\n    // case, though, we're returning the the tile center and \n    // and tile dimensions.\n    //return vec4(svP, li);//li/s\n    return vec4(tileID/sc, li/sc);//vec4(tileID/sc, li/sc);\n//return vec4(d, col);//li/s\n}\n\n\n\nvec4 funcFace0(vec3 q3){\n\n\n    // Coordinates.\n    vec2 p = (q3.xy); \n    vec4 p4 = pattern(p, gSc.xy);\n    \n    return p4;\n\n\n}\n\n\n\n// Cube mapping - Adapted from one of Fizzer's routines. \nint CubeFaceCoords(vec3 p){\n\n    // Elegant cubic space stepping trick, as seen in many voxel related examples.\n    vec3 f = abs(p); f = step(f.zxy, f)*step(f.yzx, f); \n    \n    ivec3 idF = ivec3(p.x<.0? 0 : 1, p.y<.0? 2 : 3, p.z<0.? 4 : 5);\n    \n    return f.x>.5? idF.x : f.y>.5? idF.y : idF.z; \n}\n\n\n\nvoid mainCubemap(out vec4 fragColor, in vec2 fragCoord, in vec3 rayOri, in vec3 rayDir){\n    \n    \n    // UV coordinates.\n    //\n    // For whatever reason (which I'd love expained), the Y coordinates flip each\n    // frame if I don't negate the coordinates here -- I'm assuming this is internal, \n    // a VFlip thing, or there's something I'm missing. If there are experts out there, \n    // any feedback would be welcome. :)\n    vec2 uv = fract(fragCoord/iResolution.y*vec2(1, -1));\n    \n    // Adapting one of Fizzer's old cube mapping routines to obtain the cube face ID \n    // from the ray direction vector.\n    int faceID = CubeFaceCoords(rayDir);\n    \n    // We're only using one cube map face, so don't calculate any others...\n    // or give the annoying compiler a chance to calculate others.\n    if(faceID > 0) return;\n  \n  \n    // Pixel storage.\n    vec4 col = vec4(0);\n    \n    \n    \n    // Precalculation flag: GPUs are annoying. Sometimes, they'll will calculate\n    // both the \"if\" and \"else\" statements every time. The \"if\" part here is extremely\n    // expensive, so we don't want that. The solution is to not have an \"if-else\"\n    // statement at all.\n    int preCalc = 0;\n    \n\n    // Initial conditions -- Performed upon initiation.\n    //if(abs(tx(iChannel0, uv, 5).w - iResolution.y)>.001){\n    //if(iFrame<1){\n    //\n    // Great hack, by IQ, to ensure that this loads either on the first frame, or in the\n    // event that the texture hasn't loaded (this happens a lot), wait, then do it...\n    // Well kind of. Either way, it works. It's quite clever, which means that it's something \n    // I never would have considered. :)\n    if(textureSize(iChannel0, 0).x<2 || iFrame<maxFrames){\n        \n \n        \n        //if(iFrame>=maxFrames) return;\n        \n        \n        // Fill the first cube face with a custom 3D function.\n        if(faceID==0){\n            \n            //vec3 p = convert2DTo3D(uv);      \n            vec3 p = vec3(uv, 0);      \n            \n            col = funcFace0(p);\n            //col = mix(col, 1.-funcFace0(p*2.), 1./16.);\n            \n            preCalc = 1;\n           \n        }\n\n        /*\n        // Last channel on the last face: Used to store the current \n        // resolution to ensure loading... Yeah, it's wasteful and it\n        // slows things down, but until there's a reliable initiation\n        // variable, I guess it'll have to do. :)\n        if(faceID==5){\n            \n            col.w = iResolution.y;\n        }\n        */\n\n        \n    }\n    \n    \n    if(preCalc == 0 && faceID == 0){\n\n       col = tx0(iChannel0, uv);\n       //col = texture(iChannel0, vec3(-.5, uv.yx - .5));\n       //col = tx(iChannel0, uv, faceID);\n    }\n    \n    \n    // Update the cubemap faces.\n    fragColor = col;\n    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    }
                ],
                "name": "Cube A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 41
                    }
                ],
                "type": "cubemap"
            },
            {
                "code": "/*\n\n    Asymmetric Texture Raycasting\n    -----------------------------\n    \n    This is a cell by cell traversal of a packed asymmetric rectangle grid\n    texture. I've been wanting to put up a ray traversal example that \n    people may not have seen before. I'm pretty sure there are no packed\n    rectangle grid traversals on Shadertoy, and I don't recall seeing a \n    texture traversal either, but there might be a couple lurking around.\n    \n    Traversing a packed rectangle algorithm created in realtime is not the \n    easist thing to do, but it's definitely doable, and it's accurate. \n    Unfortunately, the process is not quite fast enough... Not yet anyway. \n    Reading from a precalculated buffer texture is subject to resolution \n    constraints, but is way faster, so is the lesser of the two evils. \n    Getting pixels to play nice wasn't fun (it never is), but it's done now, \n    so hopefully the next time won't be as frustrating. :)\n    \n    In theory, traversing a texture grid is pretty easy: Read into the\n    texture and read out the precalculated central grid object position\n    ID and object dimensions (width and height for rectangles), then use\n    them to traverse to the next cell position -- Raytracing to rectangle\n    edges isn't rocket science. However, calculations have to be perfect,\n    and pixel resolution contraints don't always allow for that, so various\n    fudges are necessary.\n    \n    Anyway, the purpose of this was just to show that it could be done. I \n    kind of cobbled this together from my other examples, so I wouldn't pay \n    too much attention to it. I'd like to put together a static path\n    traced version later.\n    \n    \n    Related examples:\n    \n    // The packed texture pattern itself was based on an\n    // idea I came up with a while back.\n    Asymmetric Blocks - Shane\n    https://www.shadertoy.com/view/Ws3GRs\n    \n    // For anyone completely new to cell by cell traversal, here's an\n    // unlisted simplified 2D rectangle traversal example that should \n    // be much easier to understand.\n    Minimal Line Traversal - Shane\n    https://www.shadertoy.com/view/sdfBDM\n    \n    \n*/\n\n// Far plane. Ironically, this one is quite close. :)\n#define FAR 25.\n\n\n // Ray origin, ray direction, point on the line, normal. \nfloat rayLine(vec2 ro, vec2 rd, vec2 p, vec2 n){\n   \n   // This is trimmed down, and can be trimmed down more. Note that \n   // \"1./dot(rd, n)\" can be precalculated outside the loop. However,\n   // this isn't a GPU intensive example, so it doesn't matter here.\n   return dot(p - ro, n)/dot(rd, n);\n\n}\n\nvec2 getUV(vec2 p){\n\n    //p /= 2.;\n \n    // Cube map texture coordinate conversion.\n    p *= cubemapRes;\n    vec2 ip = floor(p); //p -= ip;\n    return fract((ip + .5)/cubemapRes) - .5;\n    \n}\n\n// The path is a 2D sinusoid that varies over time, which depends upon the \n// frequencies and amplitudes.\nvec2 path(in float z){ \n    //return vec2(0);\n    return vec2((cos(z*.36/8.) - sin(z*.2/8.)*1.2)*6., sin(z*.12));\n} \n\n\nfloat h(vec2 p){\n\n    // Only one texture read.\n    vec3 tx = texture(iChannel0, p/iChannelResolution[0].xy).xyz;  tx *= tx;///iChannelResolution[0].xy\n    // Greyscale height. Using \"tx.x\" would work, too.\n\tfloat f = dot(tx, vec3(.299, .587, .114));\n    float f2 = f;//min(f, .5);\n    \n    //f = sin(f*6.2831 + iTime)*.5 + .5;\n    // Using the camera path to carve out a channel for the camera to glide through.\n    vec2 pth = path(p.y);\n    float pX = abs(p.x - pth.x); // The channel.\n    f *= min(pX*pX/24., 1.);\n    \n    // Overall height.\n    return f*8. + f2*.5 + pth.y;\n\n}\n\n// Rectangle scale: This was hacked in at the last minute and is a little\n// fickle. Sizes one to about 8 are OK. Lower numbers mean smaller rectangles,\n// which require more traversal steps in the \"raycast\" function.\nconst vec2 txSc = vec2(6);\n\n// Grid cell function.\nvec4 gridID(vec2 p){\n\n    // Same size squares, for comparison. \n    //return vec4(floor(p/txSc) + .5, txSc);\n\n    // Texture multiple ID.\n    vec2 p0 = (floor(p/txSc)*txSc.xy);\n\n    // Texture grid information -- Cube map faces are annoying to read into.\n    vec2 uv = getUV(p/txSc);\n    \n    // Read the texture face information.\n    vec4 hm2 = texture(iChannel3, vec3(-.5, uv.yx)); \n    // Converting to exact pixel positions for wrapping purposes.\n    hm2 = convert2(hm2)*txSc.xyxy;\n\n    // Return the central position and dimension of the nearest rectangle.\n    return vec4((p0 + hm2.xy), hm2.zw);\n\n}\n\n\n\n\n// Sign function without the zero, which can cause problems for some routines.\nvec3 sign2(in vec3 p){ return vec3(p.x<0.? -1 : 1, p.y<0.? -1 : 1,  p.z<0.? -1 : 1); }\n//vec2 sign2(in vec2 p){ return vec2(p.x<0.? -1 : 1, p.y<0.? -1 : 1); }\n\nvec4 raycast(vec3 ro, vec3 rd){\n   \n    // Result.\n    vec4 res = vec4(FAR, 0, 0, 0);\n    \n    // Unit direction sign.\n    vec3 srd = sign2(rd);\n    \n    // Rectangle normals: Any two will do. By the way, there's nothing\n    // stopping you from declaring all four normals for all surrounding\n    // walls, but since you know only two will be in front of the\n    // direction ray at any given time, it makes sense to only choose\n    // two.\n    //\n    // Declare two normals. Any side by side ones will do.\n    vec2 n1 = vec2(-1, 0), n2 = vec2(0, -1); // Right and top edges.\n    \n    // If the cell wall is behind the ray (or the ray is facing the opposing cell\n    // wall, if you prefer), use the normal index from the back cell wall. This \n    // trick is possible because of the rectangle symmetry. As an aside, for \n    // anyone who doesn't know, dotting the direction ray with the face normal \n    // is something you do in software engines for back face culling.\n    n1 = dot(rd.xz, n1)<0.? -n1 : n1;\n    n2 = dot(rd.xz, n2)<0.? -n2 : n2;\n    \n    // Initiate the ray position at the ray origin.\n    vec3 pos = ro;\n    \n    // Obtain the coordinates of the cell that the current ray position \n    // is contained in -- I've arranged for the cell coordinates to \n    // represent the cell center to make things easier.\n    //vec2 ip = gridID(pos.xz);\n    \n    float t1 = 1e8, t2 = 1e8, tT = 1e8;\n    \n    int hit = 0;\n    \n    vec4 gID = gridID(pos.xz);\n    vec2 ip;// = gID.xy;\n    \n    \n    // Iterate through 24 cells -- Obviously, if the cells were smaller,\n    // you'd need more to cover the distance.\n    for(int i = 0; i<120; i++){ \n\n         \n        ip = gID.xy;\n        float ma = h(ip);\n        \n        // At this point, we haven't advanced the ray to the back of the cell boundary,\n        // so we're at one of the front cell face positions. Therefore, check to see if \n        // we're under the pylon height. If so, we've hit a face, so mark the face as hit, \n        // then break.\n        if(pos.y<ma){\n            // Hit a side.\n            hit = 1;\n            break; \n        \n        } \n        \n        // Ray intersection from the currect cell position to each of the \n        // visible cell walls. Normals face inward.\n        // You pass in the current position, the unit direction ray, a known \n        // point on the cell wall (any will do) and the cell wall's normal.\n        t1 = rayLine(pos.xz, rd.xz, (ip + n1*gID.zw*.5), -n1);\n        t2 = rayLine(pos.xz, rd.xz, (ip + n2*gID.zw*.5), -n2);\n        \n        // Determine the closest edge then record the closest distance and\n        // asign its normal index.\n        vec3 tn = t1<t2? vec3(t1, n1) : vec3(t2, n2);\n        \n        // Top face distance.\n        tT = (ma - pos.y)/rd.y;\n        tT = tT<0. ? 1e8 : tT;\n        \n        \n        // We've now advanced to one of the back faces of the cell. Check to see whether\n        // we're still under the pylon height, and if so, we've hit the top face --  \n        // I always have to think about this, but the logic is that we haven't hit a front\n        // cell face and we're still under the height, so we've hit the top. Anyway, mark \n        // the top face as hit, advance the distance in the Y direction to the top face, \n        // then break.\n        if(tT<tn.x){\n            \n            //dist += tT;\n            pos += rd*tT; \n            hit = 2;\n            break;\n             \n        }      \n         \n    \n        // If this cell's ID matches the ID of the backgound cell, \n        // flag it as hit in order to color it, or whatever.\n        //if(length(cell - ip)<.001){ hit = 1; break; }\n        \n        // Advance the cell index position by the indices of the \n        // cell wall normal that you hit. \n        //ip += tn.yz;\n        // Advance the ray position by the distance to the next cell wall.\n        pos += rd*tn.x;\n        \n        // Textures have fixed size, so increasing the scale effects stepping from\n        // one grid cell to the next. Hence, the \"txSc\" variable.\n        gID = gridID(pos.xz + (srd.xz/1024.)*txSc);// + (srd.xz/1024.)*txSc\n         \n    \n    }\n    \n    float fID = tT<t1 && tT<t2? 0. : t1<t2? 1. : 2.;\n    if(fID == 1.){ fID = dot(rd.xz, vec2(-1, 0))<0.? -fID : fID; }\n    else if(fID == 2.){ fID = dot(rd.xz, vec2(0, -1))<0.? -fID : fID; }\n    \n    res.x = length(pos - ro);\n    if(hit == 0) res.x = FAR;\n    \n    return vec4(res.x, fID, ip);\n    \n}\n\n// mat3 rotation... I did this in a hurry, but I think it's right. :)\n// I have a much better one than this somewhere. \nmat3 rot(vec3 ang){\n    \n    vec3 c = cos(ang), s = sin(ang);\n\n    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,\n                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,\n                c.y*s.z, -s.y, c.y*c.z);    \n}\n\n// Standard normal function.\nvec3 nr(float fID, vec3 rd) {\n\t\n    vec3 n = fID == 0.? vec3(0, 1, 0) : abs(fID) == 1.? vec3(1, 0, 0) : vec3(0, 0, 1);\n    n *= fID<-.001? -1. : 1.; \n\treturn n;\n}\n\n// Very lame sky with sun-like object. Basically, this was a quick hack to emulate\n// the \"Forest Blurred\" cube map... It needs work. :)\nvec3 getSky(vec3 rd, vec3 ld){\n\n    float lgt = max(dot(rd, ld), 0.);\n    vec3 sky = mix(vec3(.1, .05, .04), vec3(.95, .97, 1)*3., clamp((rd.y + .5),0., 1.))/1.5;\n    sky = mix(sky, vec3(8), pow(lgt, 8.));\n    return min(sky*vec3(1, 1.1, 1.3), 1.);\n}\n\n// Block face pattern field.\nvec3 df(vec2 p){\n    \n    // Asymetric grid pattern.\n    const float sc = 1.5;\n    p /= sc;\n    \n    // Texture multiple.\n    vec2 p0 = floor(p);\n    // Read into the texture (from the cube map face).\n    vec2 uv = getUV(p);\n    vec4 hm2 = texture(iChannel3, vec3(-.5, uv.yx));\n    hm2 = convert2(hm2);\n    // Rectangle distance. \n    vec2 q = abs((uv + .5) - hm2.xy) - hm2.zw/2.;\n    float d = max(q.x, q.y); \n    // Rectangle distance and central ID.\n    return vec3(d, p0 + hm2.xy);\n    \n}\n\nvoid mainImage(out vec4 c, vec2 u){\n\n\n    // Screen coordinates: The coordinates are already in one to one ratio form, so \n    // a simple translation and scaling is all that is necessary in this setting.\n    u = (u - iResolution.xy*.5)/iResolution.y;\n    \n    // Ray origin.\n    vec3 o = vec3(0, 1.5, iTime*1.5);\n    \n    \n    // \"Look At\" position.\n    vec3 lk = o + vec3(0, -.35, 1.);//vec3(0, -.25, iTime);  \n \n    \n\t// Sending the camera and \"look at\" vectors along the path. The \"path\" function is \n\t// synchronized with the distance function.\n    o.xy += path(o.z);\n\tlk.xy += path(lk.z);\n \n\n    // Using the above to produce the unit ray-direction vector.\n    float FOV = .75; // FOV - Field of view.\n\n    vec3 fwd = normalize(lk - o);    \n    vec3 rgt = normalize(vec3(fwd.z, 0., -fwd.x)); \n    // \"right\" and \"forward\" are perpendicular, due to the dot product being zero. Therefore, I'm \n    // assuming no normalization is necessary? The only reason I ask is that lots of people do \n    // normalize, so perhaps I'm overlooking something?\n    vec3 up = cross(fwd, rgt); \n    \n    // Camera.\n    mat3 mCam = mat3(rgt, up, fwd);\n    \n    // Camera movement. Rotation, swivle, etc.\n    mCam *= rot(vec3(-path(o.z).x/64., 0, 0)); // Camera roll.\n    //mCam *= rot(vec3(0, 0, iTime/4.)); // Camera pitch.\n    \n    // Unit direction ray.\n    vec3 r = mCam*normalize(vec3(u, 1./FOV));\n \n    // Directional light.\n    vec3 l = normalize(vec3(.2, .7, .8)); \n\n    // Raycasting\n    vec4 res = raycast(o, r);\n    \n    float t = res.x, d;\n    float fID = res.y;\n    vec2 id = res.zw;\n    \n    t = min(t, FAR); // Clipping to the far distance, which helps avoid artifacts.\n    \n    // Scene color, initialized to zero.\n    c = vec4(0);\n    \n    // If we've hit an object, light it up.\n    if(t<FAR){\n    \n        vec3 p = o + r*t, n = nr(fID, r);\n\n        l -= p; // Light to surface vector. Ie: Light direction vector.\n        d = max(length(l), 0.001); // Light to surface distance.\n        l /= d; // Normalizing the light direction vector.\n        \n        l = normalize(vec3(.7, .8, 1));\n        \n        // Diffuse.\n        float dif = max(dot(l, n), 0.);\n        \n        float sh = 1.;\n        if(dif>0.){\n           vec4 resSh = raycast(p + n*.002, l);\n           \n           if(resSh.x<FAR - 1e-3) sh = 0.; //\n           //if(resSh.x<d - 1e-3) sh = 0.; // Point light.\n           \n        }\n\n        \n        // Scene object color.\n        //\n        // Coloring half the grid objects.\n        float rnd = fract(sin(dot(id, vec2(157, 113)))*43758.5453);\n        //float rnd2 = fract(sin(dot(id + .5, vec2(157, 113)))*43758.5453);\n    \n  \n        // Rectangle ID to texure color.\n        vec3 txC = texture(iChannel1, id/gSc.xy*txSc).xyz; txC *= txC;\n\n         \n        // UV coordinates for each face.\n        vec2 uv = fID == 0.? p.xz : abs(fID) == 1.? p.zy : p.xy;\n        \n        // Texture pattern layers.\n        vec3 tx = texture(iChannel1, rot2(3.14159/3.*1.)*uv/2.).xyz; tx *= tx;\n        vec3 tx2 = texture(iChannel1, rot2(-3.14159/6.*1.)*uv/1. + .5).xyz; tx2 *= tx2;\n        vec3 tx3 = texture(iChannel1, rot2(-3.14159/12.*1.)*uv*2. + 1.).xyz; tx3 *= tx3;\n        // Mixing the layers.\n        tx = mix(tx, tx2, .35);\n        tx = mix(tx, tx3, .35);\n        float gr = dot(tx, vec3(.299, .587, .114));\n        \n        // Applying the texture color and pattern.\n        c.xyz = txC;\n        c.xyz *= (.75 + gr*1.5);\n         \n        \n        // IQ's rim lighting snippet: For anyone not familiar, he's using \n        // the Fresnel factor for some sillouette lighting.\n        float rim = pow(clamp(1. + dot(r, n), 0., 1.), 5.);\n        \n         \n        // Specular reflection. \n        float spe = pow(clamp(dot(l, reflect(r, n)), 0., 1.), 8.);\n        \n        // Grid rectangle central position and dimension.\n        // Note the desperate step hack to ensure we hit the correct cell -- Seems to work.\n        vec4 gID = gridID(p.xz + sign2(r).xz/1024.*txSc);\n       \n        // Lamest AO ever, and not accurate at all. I'll sort it out later.\n        vec2 p2 = (p.xz - gID.xy);\n        float h0 = h(gID.xy);\n        vec4 h4 = vec4(h((gID.xy + vec2(-1, 0))*gID.zw), h((gID.xy + vec2(1, 0))*gID.zw), \n                       h((gID.xy + vec2(0, -1))*gID.zw), h((gID.xy + vec2(0, 1))*gID.zw));\n                       \n        vec4 h4mh0 = h4 - h0;\n        float ao = 1.;\n        float minEdge = min(gID.z, gID.w)/4.;\n        float edge = gID.w/4.;//min(s.x, s.y)/4.;\n        float edge2 = gID.z/4.;//max(s.x, s.y)/4.;\n        \n         \n        float aoSh = .25;\n        if(n.y>.5){\n            if(p2.y>minEdge && h4mh0.w>0.) ao = min(ao, 1. - smoothstep(0., 1., (p2.y - edge)/edge)*aoSh);\n            if(p2.y<-minEdge && h4mh0.z>0.) ao = min(ao, 1. - smoothstep(0., 1., (-p2.y - edge)/edge)*aoSh);\n            if(p2.x<-minEdge && h4mh0.x>0.) ao = min(ao, 1. - smoothstep(0., 1., (-p2.x - edge2)/edge2)*aoSh);\n            if(p2.x>minEdge && h4mh0.y>0.) ao = min(ao, 1. - smoothstep(0., 1., (p2.x - edge2)/edge2)*aoSh);\n        }\n        else {\n            \n            vec4 mEdge4 = vec4(minEdge) - (h4 - h0)/2.;\n            vec4 hp = p.y - h4 - mEdge4;\n             \n            \n            if(n.z<-.5 && hp.z<0.) ao = min(ao, 1. - smoothstep(0., 1., -(hp.z)/(mEdge4.z))*aoSh);\n            if(n.z>.5  && hp.w<0.) ao = min(ao, 1. - smoothstep(0., 1., -(hp.w)/(mEdge4.w))*aoSh);\n            if(n.x<-.5 && hp.x<0.) ao = min(ao, 1. - smoothstep(0., 1., -(hp.x)/(mEdge4.x))*aoSh);\n            if(n.x>.5 && hp.y<0.) ao = min(ao, 1. - smoothstep(0., 1., -(hp.y)/(mEdge4.y))*aoSh);\n             \n        }\n        ao = max(ao, 0.);\n        \n        \n        // Side wall shading. Also a hack, but it's effective.\n        vec2 pth = path(p.z);\n        ao *= pow(clamp((p.y - pth.y + .001)/(h0 - pth.y + .001), 0., 1.), 1.);\n        \n        // Side wall debugging.\n        //if(abs(n.y)<.5) c.xyz *= vec3(2, 1, 1);\n        \n        \n        // Local coordinates.\n        vec2 lc = p.xz - gID.xy;\n        // Domain.\n        vec2 ap = abs(lc) - gID.zw/2.;\n        \n        // Face edges.\n        float fEdge = max(ap.x, ap.y);\n        fEdge = abs(fEdge);\n        fEdge = max(fEdge, -(p.y - h0)) - .01;\n        // Side edges.\n        float sEdge = min(ap.x, ap.y);\n        sEdge = max(-sEdge, (p.y - h0)) - .01;\n        // Combining.\n        fEdge = min(fEdge, sEdge);\n        \n        \n        // Applying the finer pattern to the box faces... This  definitely needs\n        // a tidy up.\n        vec3 d3 = df(uv);\n        vec3 sC = c.xyz; // Old color.\n        vec3 txC2 = texture(iChannel1, hash22(d3.yz + .1)).xyz; txC2 *= txC2;\n        //if(fID == 0.){ // Top of the box only.\n        vec3 smC = txC2;\n        smC *= (.75 + gr*1.5);\n        smC = mix(sC, smC, .5);\n        c.xyz = mix(c.xyz/8., smC, 1. - smoothstep(0., txSc.x*.001*(1. + res.x*res.x*.001), d3.x + .007));\n        //}\n\n   \n        \n        // Applying diffuse lighting, ambient lighting, etc.\n        vec3 cCol = (dif*sh + vec3(1, .8, .5)*spe*sh + vec3(.3, .5, 1)*rim*4. + .25)*ao;\n        c.xyz = c.xyz*cCol;\n        sC = sC*cCol;\n        \n        \n        // Applying the edges. I've hacked a lot of this in after the fact, so will need\n        // to reorder, etc.\n        vec3 svC = c.xyz;\n        float grr = dot(c.xyz, vec3(.299, .587, .114));\n        c.xyz = mix(c.xyz/(.5 + grr*grr), vec3(1), .03/(.5 + grr*grr)); // Lightening.\n        float grrC = dot(sC, vec3(.299, .587, .114));\n        sC = mix(sC/(.5 + grrC*grrC), vec3(1), .03/(.5 + grrC*grrC)); // // Lightening.\n        \n        // Edge rendering.\n        const float ew = .05;\n        c.xyz = mix(c.xyz + .0, mix(sC, vec3(1), .1), \n                    (1. - smoothstep(0., .001*(1. + res.x*res.x*.05), fEdge - ew)));\n        c.xyz = mix(c.xyz, vec3(0), (1. - smoothstep(0., .001*(1. + res.x*res.x*.05), fEdge))*.6);\n        c.xyz = mix(c.xyz, mix(sC, vec3(0), .6),\n                    (1. - smoothstep(0., .001*(1. + res.x*res.x*.05), abs(fEdge - ew) - .01/2.)));\n     \n       \n        \n        // Reflection: Not a proper reflective color pass, but it works well\n        // enough here. If we hit something, render nothing, otherwise, render\n        vec3 ref = reflect(r, n);\n        vec4 resRef = raycast(p + n*.002, ref);\n        vec3 refTx = getSky(ref, l);\n        if(resRef.x<FAR - 1e-3) refTx *= 0.; // Point light.\n        \n        // Fresnel reflection of sorts. This has been poached from one of IQ's examples.\n        float fr = mix(.03, .25, pow(max(0., 1. + dot(r, n)), 3.));\n        c.xyz = mix(c.xyz, min(refTx, 1.)*3., fr);\n        \n        \n        \n        // Debug.\n        //c.xyz = vec3((dif + .5))*ao;\n        \n        \n        \n    }\n    \n    // Applying some distance fog.\n    vec4 fCol = vec4(getSky(r, l), 1);\n    c = mix(clamp(c, 0., 1.), fCol, smoothstep(.2, .8, t/FAR));\n    \n\n    /*\n    // Just the height texture on its own, for anyone interested.\n    vec2 u2 = u + iTime/8.;\n    vec3 d3 = df(u2);\n    float rnd = hash21(d3.yz/32. + .05);\n    //float rnd = hash21(hm2.zw)*.5 + .5;\n    vec3 rCol = .5 + .5*cos(6.2831*rnd*8. + vec3(0, 1, 2)*1.5);\n    c.xyz = mix(vec3(0), rCol, 1. - smoothstep(0., 1./iResolution.y, d3.x));\n    // Equal to the focal point to avoid blurriness from the DOF pass.\n    // Alternatively, you could turn DOF off.\n    t = 8.; \n    */\n    \n    // Temporal blurring. Not used here.\n    //vec4 bTx = texture(iChannel2, u0/iResolution.xy);\n    //c = mix(bTx, vec4(max(c.xyz, 0.), t), 1./2.);\n    \n    // Backbuffer value. The camera to hit point distance is there for DOF calculations.\n    if(iFrame < maxFrames) c = vec4(1);\n    c = vec4(max(c.xyz, 0.), t);\n    \n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 9,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/bd6464771e47eed832c5eb2cd85cdc0bfc697786b903bfd30f890f9d4fc36657.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "texture",
                        "id": 30,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png"
                    },
                    {
                        "channel": 3,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}