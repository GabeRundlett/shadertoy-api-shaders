{
    "Shader": {
        "info": {
            "date": "1611254046",
            "description": "uniformly sampling a Bbox, dispatching the sampling budget according to faces apparent size (next: blue noise?)\nMethod assuming the apparent Bbox is small ( i.e. doesn't account for perspective to select and weight the 3 faces ).\n\nMouse controls rotation.",
            "flags": 0,
            "hasliked": 0,
            "id": "WtKyRy",
            "likes": 4,
            "name": "sampling Bbox src - no perspecti",
            "published": 3,
            "tags": [
                "sampling",
                "mm"
            ],
            "usePreview": 0,
            "username": "FabriceNeyret2",
            "viewed": 309
        },
        "renderpass": [
            {
                "code": "#define N           300.                  // target number of samples\n\n#define PI          3.14159265359\n#define rot(a)      mat2( cos( a + vec4(0,-PI/2.,PI/2.,0) ) )\n#define rot3(V,a,b) V.xz *= rot(a), V.yz *= rot(b)\n#define hash2(p)    fract(sin( (p) * vec2(12.9898, 78.233)) * 43758.5453)\n#define R           iResolution.xy\n\nstruct Bbox {                             // object bounding box:\n    vec3 position, edgeX, edgeY, edgeZ;   // position (corner), local frame ( with size)\n};\n\nvec3 CameraPos = vec3(0,0,-30),\n     CameraDir = vec3(0,0,1);\nfloat fov = 10.;                          // high value â†’ low perspective\n\n// uniformly sample a face with n samples\nfloat sampl(vec2 U, vec3 position, vec3 edgeU, vec3 edgeV, float n) {\n    float v = 0.;\n    for (float i=0.; i < n+.5; i++ ) {\n        vec2 r = hash2(i);                // should use better hash, + seed !\n        vec3 surfacePos = position + edgeU * r.x + edgeV * r.y,\n             P = surfacePos - CameraPos;\n        v += smoothstep(3./R.y,0.,length(fov*P.xy/P.z - U) ); // demo task: perspective-draw samples\n    }\n    return v;\n}\n\nvoid mainImage( out vec4 O, vec2 u )\n{\n    vec2 U = ( 2.*u - R ) / R.y,\n         M = length(iMouse.xy) < 15. ? cos( .1*iTime + vec2(1,.372))\n                                     : 2.*iMouse.xy/R - 1.;\n    O -= O;\n    \n    float a = -PI*M.x, b = -PI*M.y;       // setup bbox from rotation angles a,b\n    Bbox bbox = Bbox( vec3(0), vec3(3,0,0), vec3(0,2,0), vec3(0,0,1) );\n    rot3(bbox.edgeX,a,b);\n    rot3(bbox.edgeY,a,b);\n    rot3(bbox.edgeZ,a,b);\n\n    vec3 dir = normalize(bbox.position - CameraPos);\n    bbox.position -= ( bbox.edgeX+bbox.edgeY+bbox.edgeZ ) /2.; // from center to corner\n\n    float s1 = dot( cross(bbox.edgeX,bbox.edgeY), dir ), // apparent surface of each side\n          s2 = dot( cross(bbox.edgeY,bbox.edgeZ), dir ),\n          s3 = dot( cross(bbox.edgeZ,bbox.edgeX), dir ),\n          sT = abs(s1) + abs(s2) + abs(s3);              // total bbox footprint on screen (parallel projection)\n    vec3  d1 = s1 > 0. ? vec3(0) : bbox.edgeZ,           // for each face pair, offset to the visible face\n          d2 = s2 > 0. ? vec3(0) : bbox.edgeX, \n          d3 = s3 > 0. ? vec3(0) : bbox.edgeY; \n          \n    O.r += sampl(U, bbox.position+d1, bbox.edgeX, bbox.edgeY, N*abs(s1)/sT ); // sample faces at prorata of visibility\n    O.g += sampl(U, bbox.position+d2, bbox.edgeY, bbox.edgeZ, N*abs(s2)/sT );\n    O.b += sampl(U, bbox.position+d3, bbox.edgeZ, bbox.edgeX, N*abs(s3)/sT );\n   \n}",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}