{
    "Shader": {
        "info": {
            "date": "1654695877",
            "description": "Using a pseudo path tracing technique to produce a simple realtime scene lit up with multiple emitters.",
            "flags": 32,
            "hasliked": 0,
            "id": "ssycDR",
            "likes": 135,
            "name": "Pseudo Realtime Path Tracing",
            "published": 3,
            "tags": [
                "global",
                "illumination",
                "tracing",
                "realtime",
                "path",
                "quad",
                "faux",
                "emissive"
            ],
            "usePreview": 1,
            "username": "Shane",
            "viewed": 3878
        },
        "renderpass": [
            {
                "code": "/*\n\n    Pseudo Realtime Path Tracing\n    ----------------------------\n    \n    See \"Buffer A\" for an explanation.\n    \n*/\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    // The other buffer has a maximum Y-resolution of 540 set, which \n    // means any pixels outside that are not rendered. On a 1980x1080\n    // fullscreen resolution, this means roughly a quarter of the pixels\n    // are rendered, which is a huge saving. Of course, this also means\n    // that the scene needs to be upscaled, which will make things less\n    // crisp, but you can't have everything. :)\n    //\n    // By the way, this tip came from Shadertoy user, Spalmer, who has\n    // a heap of interesting work for anyone interested:\n    // https://www.shadertoy.com/user/spalmer\n    //\n    float maxRes = 540.;\n    vec2 uv = fragCoord/iResolution.xy;\n    // If the resolution exceeds the maximum, upscale.\n    if(iResolution.y>maxRes) uv = (uv - .5)*maxRes/iResolution.y + .5;\n    \n    // Retrieving the stored color.\n    vec4 col = texture(iChannel0, uv);\n    \n    // I should probably tone map here, but the lighting isn't exactly\n    // realistic, plus I like the contrast here.\n\n    // Rough gamma correction and screen presentation.\n    fragColor = pow(col, vec4(1./2.2));\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\n\n    Pseudo Realtime Path Tracing\n    ----------------------------\n    \n    Using a pseudo path tracing technique to produce a simple realtime scene \n    lit up with multiple emitters. Basically, this was an excuse to play \n    around with pretty colors. :)\n    \n    At this stage, I'm sure most have seen those cool looking faux realtime \n    path traced examples at demo competitions and on Shadertoy. All of them\n    use a simple trick, which I'm sure has been around for ages, but I first\n    saw it in Shadertoy user W23's \"Path Racer\" example.\n    \n    Path tracing involves multiple bounces with random surface reflections \n    based on surface properties. The results are great -- fuzzy reflections,\n    soft lighting, shadows, etc, but require a heap of random samples to look\n    right. Regular purely reflected multiple bounce examples require just the \n    one sample, but look too sharp and unnatural.\n    \n    This particular example uses random surface reflections, but restricts the\n    randomness to a fairly narrow cone-like domain around the purely reflected\n    ray. That way, you're still getting the fuzzy shadows, lights, etc from\n    the surrounding scene. However, due to the narrowness of the random spread\n    around the rays, fewer samples are required for things to converge.\n    \n    The resultant lighting is not entirely realistic, but it looks nice. The \n    weird bounce angles can also be mitigated by using small tiles with \n    variable roughness values. Because of the narrow beams used, smaller \n    roughness values tend to look better, which is fine by me, because it \n    makes everything look more sparkly. :)\n    \n    Geometrically speaking, the scene is about as basic as it gets. The tiling \n    was made up on the spot and contains random emitters, which act as multiple \n    light sources. The multi-emitter color bleeding effect would be near \n    impossible to emulate using cheaper Blinn-Phong methods. By the way, I \n    settled on the \"Organic 2\" texture, but it works with others. I almost went\n    with the \"Stars\" texture, which gives things a slight planetarium feel.\n    \n    \n    \n    Other examples:\n    \n    // A lot of the realtime path tracing demos out there\n    // are based on elements from this example.\n    past racer by jetlag - w23\n    https://www.shadertoy.com/view/Wts3W7\n\n    // Simple, but georgeous lighting and colors.\n\tCorridor Travel - NuSan\n    https://www.shadertoy.com/view/3sXyRN\n\n*/\n\n\n// Sample number and blend number: The trick is to find a balance between the\n// two, or use a faster computer. :)\n\n// Number of samples: My computer can handle more. If yours is struggling, you \n// can lower this. Naturally, sample number is proportional to noise quality.\n#define sampNum 16\n\n// The blended samples per frame: Higher numbers give the impression of more\n// samples, which boosts quality. However, there's a price to pay, and that's \n// ghosting effects. Larger numbers will result in noticeable ghosting.\n#define blendNum 4.\n\n\n\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){  return fract(sin(dot(p, vec2(27.619, 57.583)))*43758.5453); }\n\n\n\n// Random seed.\nvec2 seed = vec2(.13, .27);\n\n// Vec2 to vec2 hash function.\nvec2 hash22() {\n    \n    seed = fract(seed + vec2(.7123, .6247));\n     \n    return fract(sin(vec2(dot(seed.xy, vec2(12.989, 78.233)), dot(seed.xy, vec2(41.898, 57.263))))\n                      *vec2(43758.5453, 23421.6361));\n}\n\n/*\n// Vec2 to vec3 hash function.\nvec3 hash23(){\n    \n    seed = fract(seed + vec2(.7123, .6247));\n     \n    return fract(sin(vec3(dot(seed.xy, vec2(12.989, 78.233)), dot(seed.xy, vec2(39.687, 78.233)),\n                          dot(seed.xy, vec2(41.898, 57.263))))*vec3(43758.5453, 23421.6361, 28234.8477));\n}\n*/\n\n// IQ's box routine.\nfloat sBox(in vec2 p, in vec2 b, float r){\n\n  vec2 d = abs(p) - b + r;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - r;\n}\n\n\n\n \n// A nice random hemispherical routine taken out of one of IQ's examples.\n// The routine itself was written by Fizzer.\nvec3 cosDir( in float seed, in vec3 n){\n\n    vec2 rnd = hash22();\n    float u = rnd.x;\n    float v = rnd.y;\n    \n    // Method 1 and 2 first generate a frame of reference to use with an arbitrary\n    // distribution, cosine in this case. Method 3 (invented by fizzer) specializes \n    // the whole math to the cosine distribution and simplfies the result to a more \n    // compact version that does not depend on a full frame of reference.\n\n    // Method by fizzer: http://www.amietia.com/lambertnotangent.html\n    float a = 6.2831853*v;\n    u = 2.*u - 1.;\n    return normalize(n + vec3(sqrt(1. - u*u)*vec2(cos(a), sin(a)), u));\n    \n}\n\n\n\n// Sphere normal.\nvec3 sphereNorm(vec3 p, float id, vec4 sph){\n   \n    return (p - sph.xyz)/sph.w; \n    \n}\n \n// Hitting a number of walls from the inside: You could simply raytrace four\n// planes, but this is a little more concise. I was too lazy to write my own\n// routine, so quickly adapted a working one (sadly, not many of those around) \n// from one of PublicIntI's examples. At some stage, I'll get in amongst it and \n// rewrite one, or find one of my older routines. Alternatively, if someone\n// knows of a concise reliable function or sees a way to tidy the following up, \n// feel free to let me know. :)\n//\n// crystal exhibit(pathtraced) - public_int_i \n// https://www.shadertoy.com/view/wljSRz\n//\n// Ray-box intersection: The function takes in the ray origin (offset if needed),\n// the unit direction ray and the box dimensions, then returns the distance and \n// normal.\n//\nvec4 boxIntersect(vec3 ro, vec3 rd, vec3 dim) {\n\n    const float maxT = 1e8;\n \n    vec3 minD = (ro + dim)/rd, maxD = (ro - dim)/rd;\n\tminD = -(minD - step(vec3(-1e-6), minD)*(minD + maxT));\n\tmaxD = -(maxD - step(vec3(-1e-6), maxD)*(maxD + maxT));\n\tminD = min(minD, maxD);\n    \n    // Result: Distance and normal.\n    vec4 res = vec4(maxT, 0, 0, 0);\n\n    // Performing some ray-plane intersections, modified to handle\n    // two planes at once. I'd imagine you could cleverly combine this\n    // into just one test, but I'm not clever, so I'll leave that to \n    // someone else. :D\n     \n    // We don't need the left and right walls for this example.\n    //if (minD.x<maxT){\n        //vec2 pd = abs(ro.zy + rd.zy*minD.x) - dim.zy;\n        //if (max(pd.x, pd.y) < 0.) res = vec4(minD.x, -sign(rd.x), 0, 0);\n    //}\n    \n    // Top and bottom surfaces, or ceiling and floor, if you prefer.\n    if (minD.y<maxT){\n        vec2 pd = abs(ro.xz + rd.xz*minD.y) - dim.xz;\n        if (max(pd.x, pd.y) < 0.) res = vec4(minD.y, 0., -sign(rd.y), 0.);\n    }\n    \n    // Front and back walls.\n    if (minD.z<maxT){\n        vec2 pd = abs(ro.xy + rd.xy*minD.z) - dim.xy;\n        if (max(pd.x, pd.y) < 0.) res = vec4(minD.z, 0., 0., -sign(rd.z));\n       \n    }\n    \n    // Return the distance and normal.\n    return res;\n}\n \n \n// Sphere intersection: Pretty standard, and adapted from one\n// of IQ's formulae.\nvec2 sphereIntersect(in vec3 ro, in vec3 rd, in vec4 sph){\n\n    vec3 oc = ro - sph.xyz;\n\tfloat b = dot(oc, rd);\n    if(b > 0.) return vec2(1e8, 0.);\n\tfloat c = dot(oc, oc) - sph.w*sph.w;\n\tfloat h = b*b - c;\n\tif(h<0.) return vec2(1e8, 0.);\n\treturn vec2(-b - sqrt(h), 1.); \n    \n}\n\n\n// Sphere position and radius.\nconst vec4 sph4 = vec4(0, -.32, 1.35, .68);\n\n// Hacking in a normal for the box equation.\nvec3 boxNrm;\n\n// Scene normal logic: Not that exciting for this example. :)\nvec3 getNorm(vec3 p, float id){\n    \n    return (id<.5)? sphereNorm(p, id, sph4) : boxNrm; \n}\n\n\n// Intersection logic for all objects.\nvec3 intersect(vec3 ro, vec3 rd){\n    \n    // Containers for two objects. Usually there'd be more.\n    vec2[2] q;\n    \n    // The sphere.\n    q[0] = sphereIntersect(ro, rd, sph4);//vec2(1e5);//\n    //q[0].x = 1e5;\n \n    // The box tube object, or 4 walls at once, if you prefer. :)\n    vec4 bx = boxIntersect(ro - vec3(0, 1, -.5), rd, vec3(1e8, 2, 3.5));\n    q[1] = vec2(bx.x, 1);\n    boxNrm = bx.yzw; \n   \n    \n    // Returning the object distance, a hit ID (inside surface, etc, and redundant \n    // for this example) and the object ID used for materials and so forth.\n    return q[0].x<q[1].x? vec3(q[0], 0) : vec3(q[1], 1);\n    \n    /*\n    // For more objects, you need to do a little more work.\n    vec3 d = vec3(1e5);\n    \n    for(int i = 0; i<2; i++){\n       if(q[i].x< d.x) d = vec3(q[i], i);\n    }\n        \n    return d;\n    */\n    \n}\n\n// The wall and floor pattern, which is just something quick and effective.\n// It's an offset row square grid pattern with some random subdivision.\nvec3 distField(vec2 p){\n    \n    // Scale.\n    vec2 sc = vec2(1)/5.;//vec2(6./5., 4./5.)/5.;\n    \n    // Edge width.\n    const float ew = .0125;\n    \n    vec2 q = p;\n    // Partitioning into cells and providing the local cell ID\n    // and local coordinates.\n    //p.x += floor(hash21(floor(p.yy/sc.yy))*1.9999)/2.*sc.x;\n    // Offset alternate rows.\n    if(mod(floor(p.y/sc.y), 2.)<.5) p.x += sc.x/2.;\n    // Cell ID and local coordinates.\n    vec2 ip = floor(p/sc);\n    p -= (ip + .5)*sc;\n    \n    // Random subdivision.\n    if(hash21(ip + .1/sc)<.5){\n        sc /= 2.;\n        p = q;\n        ip = floor(p/sc);\n        p -= (ip + .5)*sc;\n         \n        /*\n        // Extra subdivision.\n        if(hash21(ip + .1/sc)<.666){\n            sc /= 2.;\n            p = q;\n            ip = floor(p/sc);\n            p -= (ip + .5)*sc;\n             \n        }*/\n    }     \n    \n    // Rounded square.\n    float sh = sBox(p, sc/2. - ew, .15*sc.x);//1.5*sc.x*sc.x\n    //float sh = length(p) - sc.x/2. + ew;\n \n    // Producing a rounded circle.\n    float d = sh; \n    \n    // Putting a hole in it just to break things up.\n    //d = max(d, -(length(p) - .2*sc.x));\n    \n    // Rings.\n    //d = abs(d + .125*sc.x) - .125*sc.x;\n    \n    // Returning the distance and local cell ID. Note that the \n    // distance has been rescaled by the scaling factor.\n    return vec3(d, ip*sc);\n}\n\n// IQ's signed square formula with some roundness thrown in. \nfloat sBoxS(in vec2 p, in vec2 b, in float rf){\n  \n  vec2 d = abs(p) - b + rf;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - rf;\n    \n}\n\n\n// mat3 rotation... I did this in a hurry, but I think it's right. :)\n// I have a much better version of this that I'll have to find.\nmat3 rot(vec3 ang){\n    \n    vec3 c = cos(ang), s = sin(ang);\n\n    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,\n                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,\n                c.y*s.z, -s.y, c.y*c.z);\n    \n}\n\n \n \nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    \n    // Setting a maximum resolution, then upscaling. I picked up this tip when\n    // looking at one of Spalmer's examples, here:\n    // https://www.shadertoy.com/view/sdKXD3\n    float maxRes = 540.;\n    float iRes = min(iResolution.y, maxRes);\n    //ivec2 iR = ivec2(fragCoord);\n    //if(iR.y > 0 || iR.x>3){\n    fragColor = vec4(0, 0, 0, 1);\n    vec2 uv2 = abs(fragCoord - iResolution.xy*.5) - iRes/2.*vec2(iResolution.x/iResolution.y, 1.);\n    if(any(greaterThan(uv2, vec2(0)))) return;  // if(uv2.x>0. || uv2.y>0.) return;\n    //} \n    \n    float sf = 1./iResolution.y;\n        \n    // Screen pixel coordinates.\n    vec2 seed0 = fract(iTime/vec2(111.13, 57.61))*vec2(-.143, .457);\n    vec2 uv0 = (fragCoord - iResolution.xy*.5)/iRes;\n    \n  \n    float FOV = 1.; // FOV - Field of view.\n    vec3 ro = vec3(0, .25, -2);\n    // \"Look At\" position.\n    vec3 lk = ro + vec3(0, -.01, .25);\n    vec3 fwd = normalize(lk - ro);\n    vec3 rgt = normalize(vec3(fwd.z, 0., -fwd.x )); \n    // \"right\" and \"forward\" are perpendicular, due to the dot product being zero. Therefore, I'm \n    // assuming no normalization is necessary? The only reason I ask is that lots of people do \n    // normalize, so perhaps I'm overlooking something?\n    vec3 up = cross(fwd, rgt); \n    \n    // Camera.\n    mat3 mCam = mat3(rgt, up, fwd);\n    mCam *= rot(vec3(0, .05, 0)); \n    mCam *= rot(vec3(0, 0, -sin(iTime/6.)*.125)); \n    \n    // Accumulative color.\n    vec3 aCol = vec3(0);\n    \n    \n    for(int j = min(0, iFrame); j<sampNum; j++){\n        \n        // Seed value and jitter.\n        seed = uv0 + seed0 + vec2(j*57, j*27)/1321.;\n        vec2 jit = hash22()*2. - 1.;\n        \n        // Jittered UV coordinate.\n        vec2 uv = uv0 - jit/iResolution.y;\n\n        // Using the above to produce the unit ray-direction vector.\n        vec3 rd = mCam*normalize(vec3(uv, 1./FOV));\n\n        // Camera position. Initially set to the ray origin.\n        vec3 cam = ro;\n        // Surface postion. Also initially set to the ray origin.\n        vec3 sp = ro;\n\n        vec3 col = vec3(0);\n        \n        // Emissive, throughput and sample colors.\n        vec3 emissive = vec3(0);\n        vec3 through = vec3(1);\n        vec3 sCol = vec3(0);\n        \n        // Fog.\n        float fogD = 1e8;\n       \n        \n        // Just four bounces. More looks better, but the extra randomess\n        // requires more samples. For static scenes, that's not a problem,\n        // but this is a realtime one.\n        for(int i = min(0, iFrame); i<4; i++){\n\n            \n            vec3 scene = intersect(sp, rd); // Scene intersection.\n\n            float t = scene.x; // Scene distance.\n            float retVal = scene.y; // Redundant here, but used when refraction is involved.\n            float id = scene.z;// Object ID.\n            \n            // Set the fog distance on the first pass.\n            if(i==0) fogD = t;\n\n            sp += rd*t; // Advance the ray position.\n\n  \n            if(t<1e8){\n\n                \n                vec3 sn = getNorm(sp, id); // Normal.\n\n                vec3 oCol = vec3(0), emissive = vec3(0); // Object color, and emissivity.\n\n                emissive = vec3(0);\n                float rough = 0.;\n\n               \n                if(id<.5) { \n                   \n                    // Placing an offset subdivided grid pattern on the sphere,\n                    // then randomly lighting up random cells.\n \n                    // Texture coordinates.\n                    vec3 txP = sp - sph4.xyz;\n                    // Rotation.\n                    txP.xy *= rot2(-3.14159/12.);\n                    txP.xz *= rot2(-iTime/4.);\n                    \n                    // Using spherical coordinates to put some latitudinal squares\n                    // around the longitudinal direction... Not much different to the\n                    // way you'd put a square grid on a plane, but with spherical\n                    // coordinates.\n                    \n                    float aNum = 32.; // Scale.\n                    \n                    // Spherical longitudinal and latitudinal angles.\n                    vec2 sphA = vec2(atan(txP.z, txP.x), atan(length(txP.xz), txP.y))/6.2831;\n                    vec2 sphID = (floor(sphA*aNum) + .5)/aNum;\n                    \n                    // Offsetting alternate rows just for fun.\n                    if(mod(sphID.y*aNum - .5, 2.)<.5){\n                        \n                        sphA.x = fract(sphA.x + .5/aNum);\n                        // The above is the same as:\n                        //txP.xz *= rot2(3.14159/aNum);\n                        //sphA.x = atan(txP.z, txP.x)/6.2831;\n                        //sphID.x = (floor(sphA.x*aNum) + .5)/aNum;\n                        sphID.x = (floor(sphA.x*aNum) + .5)/aNum;\n                    }\n                    \n                    // Original scale and latitudinal dimension.\n                    float aNum0 = aNum, y0 = sphID.y;\n                    \n                    // Local X and Y square grid coordinates.\n                    vec2 sph = mod(sphA, 1./aNum) - .5/aNum;\n                  \n                    // Random subdivision.\n                    if(hash21(sphID + .3)<.5 && abs(y0 - .25)<4./aNum/2.){\n                        aNum *= 2.;\n                        sph = mod(sphA, 1./aNum) - .5/aNum;\n                        sphID = (floor(sphA*aNum) + .5)/aNum;\n                    } \n                    \n                    \n                    // Rounded square.\n                    float d = sBoxS(sph, vec2(.5/aNum) - .0025, .15/aNum);\n                    // Distance field isoline boundary.\n                    d = smoothstep(0., sf, d);\n\n                    \n                    // Render the pattern onto the sphere.\n                    oCol = mix(vec3(1), vec3(.1), d);\n                    \n                    // Emissivity.\n                    // Using a texture to color the emissive lights.\n                    vec3 tx = texture(iChannel1, sphID + iTime/128.).xyz; tx *= tx;\n                    // Fade out emissivity higher up the walls.\n                    float st = clamp(sp.y/1.25 - 1., 0., 1.);\n                    float rnd = smoothstep(st, 1., dot(tx, vec3(.299, .587, .114)));\n              \n        \n                    // Emissivity.\n                    emissive = vec3(0);\n                    // Color a limited set of bands around the equator.\n                    //if(abs(b0 - .25)<6./aNum0/2.) { emissive = oCol*(rnd*.99 + .01)*2.;  }\n                    if(abs(y0 - .25)<4./aNum0/2.) { emissive = oCol*tx*tx*rnd*16.;  }\n                    emissive = mix(emissive, vec3(0), d);\n                    emissive = mix(emissive, emissive.zyx, clamp((sp.y + .5)*3., 0., 1.));\n                    \n                    \n                    // Roughness.\n                    rough = hash21(vec2(sphID.x*aNum, sphID.y) + .23)*.5; //(clamp(.5 - d3.x/.2, 0., 1.))*\n                \n               }\n               else {\n\n                   \n                    // Producing a wall and floor pattern, coloring it, and using\n                    // parts to act as emitters.\n                    \n                    // Back wall or not.\n                    float sgn = (abs(sn.z)>.5)? 1. : -1.;\n                    \n                    // UV coordinates for the walls and floors.\n                    vec2 uv = sgn>.5? sp.xy : abs(sn.x)>.5? sp.yz : sp.xz;\n\n                    // Distance field pattern:\n                    // Returns the distance field and cell ID.\n                    vec3 d3 = distField(uv);\n                    // Distance field isoline boundary.\n                    d3.x = smoothstep(0., sf, d3.x);\n \n                    // Render the pattern on the walls, ceiling and floor.\n                    oCol = mix(vec3(1), vec3(.1), d3.x);\n                    \n                    // Emissivity.\n                    // Using a texture to color the emissive lights.\n                    vec3 tx = texture(iChannel1, d3.yz/16. - vec2(-1, 2)*iTime/64.).xyz; tx *= tx;\n                    // Fade out emissivity higher up the walls.\n                    float st = clamp(d3.z/1.25 - 1., 0., 1.);\n                    float rnd = smoothstep(st, 1., dot(tx, vec3(.299, .587, .114)));\n                    if(sgn<.5) rnd = 0.; // No lights on the floor or ceiling.\n                    //if(sn.z>.5) rnd = 0.;\n                    // Pattern based emissivity -- It doesn't always have to be object based.\n                    emissive = mix(oCol*tx*tx*rnd*16., vec3(0), d3.x);\n                    emissive = mix(emissive, emissive.zyx, clamp(sp.y, 0., 1.));\n                    \n                    // Roughness.\n                    rough = hash21(d3.yz + .1)*.5; //(clamp(.5 - d3.x/.2, 0., 1.))*\n \n                  \n                }\n                \n                \n                // I definitely like the more natural way in which colors are applied\n                // when rendering this way. We only add surface color when it's been\n                // hit by a ray that has visited a light source at some point.\n                sCol += emissive*through;\n                // Applying this bounce's color to future bounces. For instance, if we\n                // hit a pink emitter then hit another surface later, that surface will\n                // incorporate a bit of pink into it.\n                through *= oCol;\n\n\n                vec3 ref = reflect(rd, sn); // Purely reflected vector.\n                vec3 rrd = cosDir(0., sn); // Random half hemisphere vector.\n                //vec3 rrd = normalize(hash23() - .5); // Less evenly distributed.\n\n\n                // Mimicking surface inconsistancies with fuzzy reflections.\n                // Rougher surfaces have a greater chance of randomly reflecting at any direction\n                // and smoother surfaces are more likely to purely reflect.\n                //float rChance = step(rough, hash21(uv + vec2(i*277, j*113) + fract(iTime*.977 + .137)));\n                //rd = (mix(rrd, ref, rChance));\n                //rd = normalize(mix(ref, rrd, rough));\n                rd = normalize(ref + rrd*rough);\n                if(dot(rd, sn)<0.) rd = -rd; // Not sure this line really matters.\n\n\n                sp += sn*1e-5;\n                //rd = ref; // Pure reflection override. Not as effective at all.\n\n            } \n            \n            \n             if(aCol.x>1e5) break; // Attempting to reduce compile time. \n        }\n        \n        // Applying some fog, if necessary. You don't actually see this, but\n        // I want it there for completeness.\n        sCol = mix(vec3(0), sCol, 1./(1. + fogD*fogD*.02));\n\n        \n        // Accumulate the sample color.\n        aCol += sCol;\n        \n        if(sCol.x>1e5) break; // Attempting to reduce compile time.\n        \n        \n    }\n    \n    // Average color over all samples.\n    aCol /= float(sampNum);\n    \n   \n    /////\n    \n\n    \n    // Mix the previous frames in with no camera reprojection.\n    // It's OK, but full temporal blur will be experienced.\n    vec4 preCol = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    float blend = (iFrame < 2) ? 1. : 1./blendNum; \n    fragColor = mix(preCol, vec4(clamp(aCol, 0., 1.), 1), blend);\n    \n    // No reprojection or temporal blur, for comparisson.\n    //fragColor = vec4(max(aCol, 0.), 1);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 10,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/92d7758c402f0927011ca8d0a7e40251439fba3a1dac26f5b8b62026323501aa.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}