{
    "Shader": {
        "info": {
            "date": "1603777042",
            "description": "Spectral ray tracing.",
            "flags": 0,
            "hasliked": 0,
            "id": "3sKcRd",
            "likes": 27,
            "name": "Spectral",
            "published": 3,
            "tags": [
                "raytracing",
                "spectral"
            ],
            "usePreview": 0,
            "username": "Pidhorskyi",
            "viewed": 784
        },
        "renderpass": [
            {
                "code": "/*\nStanislav Pidhorskyi 2020\n\nThis one is inspired by the book by Peter Shirley \"Ray Tracing: The Rest of Your Life\".\n\n\nI implemented a spectral path tracer, where each ray has a random wavelength. Surprisingly, it's not much noisier than conventional RGB path tracing.\nWavelength is sampled uniformly from 400.0nm to 700.0nm, but of course, it would be better to utilize importance sampling here and sample more those wavelengths that contribute to the RGB color more.\n\nSpecter can be converted to the color values by computing dot products with color matching functions. \nI used CIE color-matching functions that I took from John Walker website: https://www.fourmilab.ch/documents/specrend/\nThese functions are tabulated and correspond to the CIE tristimulus values X, Y, and Z.\nThe lookup table would not be too large, but it seems to be a significant source of slowdown, so I decided to approximate them with Gaussians.\nBut before with dive into the approximation, it worth noting that white color does not have a uniform specter.\nIn order to get sources of white light, we need to use a specific specter, like Illuminant D65.\nI took the values for D65 from here: https://www.waveformlighting.com/tech/calculate-illuminant-d-spd-and-cie-1931-xy-from-color-temperature/\nI computed the point-wise product of D65 specter and CIE color-matching functions so that we could pretend that now the white color has a uniform specter.\nThe result functions I approximated with Gaussians and a mixture of two Gaussians for the Red color:\n\n\nRed:    \t8233.31 * f(l | mu=593.95, sigma=34.00) + 1891.26 * f(l | mu=448.89, sigma=18.785),\nGreen:      10522.64 * f(l | 555.38, 40.80),\nBlue:       111254.78 * f(l | mu=452.98, sigma=21.57)\n\nwhere f(l) = 1/(sigma sqrt(2 * pi)) * exp(-1/2 * ((l - mu) / sigma)^2)\n\nCode for computing the coefficients can be found here: https://gist.github.com/podgorskiy/99c283773f7cee8e71386aa8ef622fdf\n\nRepresented in this way, it would be actually not hard to compute a CDF and perform importance sampling, but I did not do it. I just used uniform sampling for wavelengths.\n\nTo compute the XYZ values given a specter, we need to compute the integral of the point-wise product of the specter with the color matching functions. \nThe integral is computed in the Monte Carlo way by sampling wavelength at random and then accumulating the XYZ values. The averaged XYZ value is then converted to RGB\n\nIn order to actually appreciate the spectral path tracing, we need to make the refraction index to be a function of the wavelength. Otherwise, the output of the spectral raytracer won't differ from the conventional one.\n\nI use the Sellmeier equation https://en.wikipedia.org/wiki/Sellmeier_equation. The material of the prism is Flint glass, parameters I found here: https://refractiveindex.info/?shelf=glass&book=SCHOTT-F&page=F2.\n\nTo sample from the cubemap, we need to do an inverse operation, go from RGB values to a specter. Sure, that's an ill-posed problem, but we could approach it with some basis of orthogonal functions and Non-negative least squares (NNLS), but that would be too costly. Instead, I used a very naive way and assumed that the CIE color-matching functions are orthogonal (which are not) and used just a dot product. \nBecause of such a naive assumption, colors are off.\n\nAnd finally, I wrote the code for a ray-prism intersection because I could not find one.\n\n----------------------------------------\n\nReuses some code from https://www.shadertoy.com/view/lssBD7 that implements Peter Shirley's \"Ray Tracing in One Weekend\" pathtracer.\n\nPost-processing from Inigo Quilezh's `Happy Jumping` ttps://www.shadertoy.com/view/3lsSzf\n\n\n*/\n\n#define PI \t\t\t3.1415926535\n#define MAXFLOAT\t99999.99\n\n#define MAXDEPTH \t8\n#define NUMSAMPLES \t64\n\n\n// Do not unroll.\n#define DNU(X)  min(int(iResolution.x) << 12, X)\n\nconst mat3 XYZ_2_RGB = (mat3(\n     3.2404542,-0.9692660, 0.0556434,\n    -1.5371385, 1.8760108,-0.2040259,\n    -0.4985314, 0.0415560, 1.0572252\n));\n\nconst mat3 RGB_2_XYZ = (mat3(\n    0.4124564, 0.2126729, 0.0193339,\n    0.3575761, 0.7151522, 0.1191920,\n    0.1804375, 0.0721750, 0.9503041\n));\n\nuint seedA = 0x9c127997U;\nuint seedB = 0x140b75b2U;\n\nuint urand()\n{\n\tuint x = seedA;\n\tuint y = seedB;\n\tseedA = y;\n\tx ^= x << 23;\n\tseedB = x ^ y ^ (x >> 17) ^ (y >> 26);\n    uint n = seedB + y;\n\treturn n * (n * n * 15731U + 789221U) + 1376312589U;\n}\n\nfloat rand1()\n{\n \treturn uintBitsToFloat( (urand()>>9U) | 0x3f800000U ) - 1.0;\n}\n\nvec2 rand2()\n{\n \tfloat a = uintBitsToFloat( (urand()>>9U) | 0x3f800000U ) - 1.0;\n \tfloat b = uintBitsToFloat( (urand()>>9U) | 0x3f800000U ) - 1.0;\n    return vec2(a, b);\n}\n\n\nfloat rand(float a, float b)\n{\n \treturn rand1() * (b - a) + a;\n}\n\n// Random unit vector, uniformly distributed on a sphere\nvec3 random_unit_vector()\n{\n    float a = rand(0.0, 2. * PI);\n    float z = rand(-1.0, 1.0);\n    float r = sqrt(1.0 - z*z);\n    return vec3(r * cos(a), r * sin(a), z);\n}\n\n// Random, uniformely distributed point on unit disk\nvec2 random_in_unit_disk()\n{\n    vec2 uv = rand2();\n    float theta = 6.283185 * uv.x;\n    return sqrt(uv.y) * vec2(cos(theta), sin(theta));\n}\n\nvec3 random_cosine_direction(in vec3 normal)\n{\n    return normalize(normal + random_unit_vector());\n}\n\nfloat gaussian(float x, float mu, float sigma)\n{\n    return 1.0 / (sigma * sqrt(2.0 * PI)) * exp(-(x-mu)*(x-mu)/(2.*sigma*sigma));\n}\n\n\n// The CIE color matching functions were taken from  https://www.fourmilab.ch/documents/specrend\n// The tabulated functions then were approximated with gaussians (for G and B) and with a mixture of two gaussiuns (R).\nvec3 wavelength2XYZ(float l)\n{\n\treturn vec3(\n    \t8233.31 * gaussian(l, 593.95, 34.00) + 1891.26 * gaussian(l, 448.89, 18.785),\n        10522.64 * gaussian(l, 555.38, 40.80),\n        11254.78 * gaussian(l, 452.98, 21.57)\n    );\n}\n\n\n// Very very crude convertion from XYZ color to spectrum. It is wrong in many ways, but I don't know a faster way to do it.\n// The assumption is that the three color matching functions are orthogonal, but they are not.\nfloat XYZ2WavelengthApprox(float l, vec3 color)\n{\n    return dot(wavelength2XYZ(l), color) / 100.0;\n}\n\nfloat glass_crown_n(float l)\n{\n    l /= 1000.0;\n    float l2 = l * l;\n\tvec3 k = vec3(1.03961212, 0.231792344, 1.01046945) * l2 /\n        (l2 - vec3(0.0060007, 0.020018, 103.560));\n\treturn 1.0 * (sqrt(1. + dot(k, vec3(1.0))) - 1.52) + 1.52;\n}\n\n\nfloat glass_flint_n(float l)\n{\n    l /= 1000.0;\n    float l2 = l * l;\n\tvec3 k = vec3(1.34533359, 0.209073176, 0.937357162) * l2 /\n        (l2 - vec3(0.00997743871, 0.0470450767, 111.886764));\n\treturn sqrt(1. + dot(k, vec3(1.0)));\n}\n\nstruct Ray\n{\n    vec3 origin;\n    vec3 direction;\n    float wave_length;\n};\n\nstruct Material\n{\n    int   materialType;\n    vec3  albedo;\n    float fuzz;\n    float refractionIndex;\n};\n\nstruct IntersectInfo\n{\n    vec2 t;\n    vec3  p;\n    vec3  normal;\n    Material mat;\n};\n\nstruct Transform\n{\n\tmat3 rotation;\n    vec3 position;\n    vec3 scale;\n};\n\nstruct Object\n{\n    Transform transform;\n    Material mat;\n};\n\nvec3 InvertseTransformPosition(Transform tr, vec3 p)\n{\n    return (tr.rotation * (p - tr.position)) / tr.scale;\n}\n\nvec3 DirectTransformPosition(Transform tr, vec3 p)\n{\n    return (p * tr.scale) * tr.rotation + tr.position;\n}\n\nvec3 InvertseTransformDirection(Transform tr, vec3 d)\n{\n    return normalize((tr.rotation * d) / tr.scale);\n}\n\nvec3 DirectTransformDirection(Transform tr, vec3 d)\n{\n    return normalize((d * tr.scale) * tr.rotation);\n}\n\nIntersectInfo Box(Object box, Ray ray, vec2 t)\n{\n    Transform tr = box.transform;\n    IntersectInfo rec;\n    rec.t.x = MAXFLOAT;\n    vec3 o = InvertseTransformPosition(tr, ray.origin);\n    vec3 d = InvertseTransformDirection(tr, ray.direction);\n    vec3 m = 1.0 / d;\n    vec3 k = abs(m);\n    vec3 a = -m * o -k;\n    vec3 b = a + k * 2.0;\n    float near = max(max(a.x, a.y), a.z);\n    float far = min(min(b.x, b.y), b.z);\n    if (near > far)\n    {\n\t\treturn rec;\n    }\n\n    vec3 localPosFar = o + far * d;\n    vec3 localPosNear = o + near * d;\n    vec3 posFar = DirectTransformPosition(tr, localPosFar);\n    vec3 posNear = DirectTransformPosition(tr, localPosNear);\n\n    float dmax = dot(posFar - ray.origin, ray.direction);\n    float dmin = dot(posNear - ray.origin, ray.direction);\n\n    if (dmin < t.y && dmin > t.x)\n    {\n       rec.t = vec2(dmin, dmax);\n       rec.p                = posNear;\n       vec3 f = step(0.999, abs(localPosNear));\n       rec.normal = normalize(localPosNear * f * tr.rotation);\n       rec.mat = box.mat;\n    }\n\telse\n    if (dmax < t.y && dmax > t.x)\n    {\n       rec.t = vec2(dmax, MAXFLOAT);\n       rec.p                = posFar;\n       vec3 f = step(0.999, abs(localPosFar));\n       rec.normal = normalize(localPosFar * f * tr.rotation);\n       rec.mat = box.mat;\n    }\n    return rec;\n}\n\n\nIntersectInfo Prism(Object box, Ray ray, vec2 t)\n{\n    Transform tr = box.transform;\n    IntersectInfo rec;\n    rec.t.x = MAXFLOAT;\n    vec3 o = InvertseTransformPosition(tr, ray.origin);\n    vec3 d = InvertseTransformDirection(tr, ray.direction);\n    vec3 m = 1.0 / d;\n    vec3 k = abs(m);\n    vec3 a = -m * o -k;\n    vec3 b = a + k * 2.0;\n    float near = max(max(a.x, a.y), a.z);\n    float far = min(min(b.x, b.y), b.z);\n    if (near > far)\n    {\n\t\treturn rec;\n    }\n\n    vec3 pn1 = normalize(vec3(2.0, 1.0, 0.0));\n    vec3 pn2 = pn1;\n    pn2.x = -pn2.x;\n    float pm1 = -1.0 / dot(pn1, d);\n    float pm2 = -1.0 / dot(pn2, d);\n    float p1 = dot(o, pn1) * pm1 - pn1.y * pm1;\n    float p2 = dot(o, pn2) * pm2 - pn2.y * pm2;\n    float pb = o.y * m.y + m.y;\n\n    if (pm1 > 0.0)\n     \tnear = max(near, p1);\n    else\n      \tfar = min(far, p1);\n    if (pm2 > 0.0)\n      \tnear = max(near, p2);\n    else\n      \tfar = min(far, p2);\n\n    if (near > far)\n    {\n\t\treturn rec;\n    }\n\n    vec3 localPosFar = o + far * d;\n    vec3 localPosNear = o + near * d;\n    vec3 posFar = DirectTransformPosition(tr, localPosFar);\n    vec3 posNear = DirectTransformPosition(tr, localPosNear);\n\n    float dmax = dot(posFar - ray.origin, ray.direction);\n    float dmin = dot(posNear - ray.origin, ray.direction);\n\n    if (dmin < t.y && dmin > t.x)\n    {\n       rec.t = vec2(dmin, dmax);\n       rec.p                = posNear;\n       vec3 f = step(0.9999, abs(localPosNear));\n       rec.normal = normalize(sign(localPosNear) * f);\n       if (all( lessThan(f, vec3(1.0))))\n       {\n           rec.normal = mix(pn1, pn2, bvec3(localPosNear.x < 0.0));\n       }\n       rec.normal *= tr.rotation;\n       rec.mat = box.mat;\n    }\n\telse\n    if (dmax < t.y && dmax > t.x)\n    {\n       rec.t = vec2(dmax, MAXFLOAT);\n       rec.p                = posFar;\n       vec3 f = step(0.9999, abs(localPosFar));\n       rec.normal = normalize(localPosFar * f);\n       if (all( lessThan(f, vec3(1.0))))\n       {\n           rec.normal = mix(pn1, pn2, bvec3(localPosFar.x < 0.0));\n       }\n       rec.normal *= tr.rotation;\n       rec.mat = box.mat;\n    }\n    return rec;\n}\n\n\n\nIntersectInfo Sphere(Object sphere, Ray ray, vec2 t)\n{\n    Transform tr = sphere.transform;\n    IntersectInfo rec;\n    rec.t.x = MAXFLOAT;\n    vec3 o = InvertseTransformPosition(tr, ray.origin);\n    vec3 d = InvertseTransformDirection(tr, ray.direction);\n    float a = dot(d, d);\n    float b = 2.0 * dot(d, o);\n    float c = dot(o, o) - 1.0;\n\n    float discriminant = b * b - 4.0 * a * c;\n\n    if (discriminant < 0.0f)\n    {\n    \treturn rec;\n    }\n\n    float D = sqrt(discriminant);\n    vec2 temp = vec2(D - b, -D - b) / 2.0 / a;\n\n    vec3 localPosMax = o + temp.x * d;\n    vec3 localPosMin = o + temp.y * d;\n    vec3 posMax = DirectTransformPosition(tr, localPosMax);\n    vec3 posMin = DirectTransformPosition(tr, localPosMin);\n\n    float dmax = dot(posMax - ray.origin, ray.direction);\n    float dmin = dot(posMin - ray.origin, ray.direction);\n\n    if (dmin < t.y && dmin > t.x)\n    {\n       rec.t                = vec2(dmin, dmax);\n       rec.p                = posMin;\n       rec.normal           = normalize(localPosMin * tr.scale * tr.rotation);\n       rec.mat = sphere.mat;\n    }\n\telse\n    if (dmax < t.y && dmax > t.x)\n    {\n       rec.t                = vec2(dmax, MAXFLOAT);\n       rec.p                = posMax;\n       rec.normal           = normalize(localPosMax * tr.scale * tr.rotation);\n       rec.mat = sphere.mat;\n    }\n    return rec;\n}\n\n// Schlick's approximation for approximating the contribution of the Fresnel factor\n// in the specular reflection of light from a non-conducting surface between two media\n//\n// Theta is the angle between the direction from which the incident light is coming and\n// the normal of the interface between the two media\nfloat schlick(float cos_theta, float n2)\n{\n    const float n1 = 1.0f;  // refraction index for air\n\n    float r0s = (n1 - n2) / (n1 + n2);\n    float r0 = r0s * r0s;\n\n    return r0 + (1.0f - r0) * pow((1.0f - cos_theta), 5.0f);\n}\n\nbool refractVec(vec3 v, vec3 n, float ni_over_nt, out vec3 refracted)\n{\n    vec3 uv = normalize(v);\n    float dt = dot(uv, n);\n    float discriminant = 1.0 - ni_over_nt * ni_over_nt * (1.0f - dt * dt);\n    refracted = ni_over_nt*(uv - n * dt) - n * sqrt(discriminant);\n    return discriminant > 0.0f;\n}\n\nvec3 reflectVec(vec3 v, vec3 n)\n{\n     return v - 2.0f * dot(v, n) * n;\n}\n\n\nstruct Camera\n{\n    float apertureRadius;\n    vec3 origin;\n    mat3 cam;\n    mat3 k_inv;\n    float focusDist;\n};\n\n\nvoid Camera_init(out Camera camera, vec3 lookfrom, vec3 lookat, vec3 vup, float vfov, float aspect, float aperture, float focusDist)\n{\n    camera.apertureRadius = aperture;\n    camera.focusDist = focusDist;\n\n    float theta = vfov * PI / 180.0;\n    float halfHeight = tan(theta / 2.0);\n    float halfWidth = aspect * halfHeight;\n\n    camera.origin = lookfrom;\n\n    vec3 z = normalize(lookfrom - lookat);\n    vec3 x = normalize(cross(vup, z));\n    vec3 y = normalize(cross(z, x));\n\n    camera.cam = mat3(x, y, z);\n    camera.k_inv = mat3(vec3(halfWidth, 0, 0), vec3(0, halfHeight, 0), vec3(0.0, 0.0, -1.));\n}\n\n\nRay Camera_getRay(Camera camera, vec2 uv)\n{\n    vec3 rd = camera.apertureRadius * vec3(random_in_unit_disk(), 0.0);\n\n    Ray ray;\n    vec2 pixel = 1.0/iResolution.xy;\n\tuv += pixel * (rand2() - 0.5);\n    uv = 2.0 * uv - 1.0;\n\n    ray.origin = camera.origin;\n    ray.direction = camera.cam * (normalize(camera.k_inv * vec3(uv, 1.0)));\n\n    return ray;\n}\n\n#define LAMBERT    0\n#define METAL      1\n#define DIELECTRIC 2\n#define LIGHT 3\n\nbool Material_bsdf(IntersectInfo rec, Ray wo, out Ray wi, out float attenuation, out float emission)\n{\n    int materialType = rec.mat.materialType;\n\n    if(materialType == LAMBERT)\n    {\n        wi.origin = rec.p;\n        wi.direction = random_cosine_direction(rec.normal);\n        attenuation = rec.mat.albedo.x;\n        return true;\n    }\n    else if(materialType == LIGHT)\n    {\n        emission = 1.0;\n        return false;\n    }\n    else\n    if(materialType == METAL)\n    {\n        vec3 reflected = reflect(normalize(wo.direction), rec.normal);\n\n        wi.origin = rec.p;\n        wi.direction = reflected + rec.mat.fuzz * random_cosine_direction(rec.normal);\n\n        attenuation = rec.mat.albedo.x;\n\n        return (dot(wi.direction, rec.normal) > 0.0f);\n    }\n    else\n    if(materialType == DIELECTRIC)\n    {\n        vec3 outward_normal;\n        vec3 reflected = reflect(wo.direction, rec.normal);\n\n        float ni_over_nt;\n\n        attenuation = 1.0f;\n        vec3 refracted;\n        float reflect_prob;\n        float cosine;\n\n        float rafractionIndex = glass_flint_n(wo.wave_length);\n\n        if (dot(wo.direction, rec.normal) > 0.0f)\n        {\n            outward_normal = -rec.normal;\n            ni_over_nt = rafractionIndex;\n\n            cosine = dot(wo.direction, rec.normal) / length(wo.direction);\n            cosine = sqrt(1.0f - rafractionIndex * rafractionIndex * (1.0f - cosine * cosine));\n        }\n        else\n        {\n            outward_normal = rec.normal;\n            ni_over_nt = 1.0f / rafractionIndex;\n            cosine = -dot(wo.direction, rec.normal) / length(wo.direction);\n        }\n        if (refractVec(wo.direction, outward_normal, ni_over_nt, refracted))\n            reflect_prob = schlick(cosine, rafractionIndex);\n        else\n            reflect_prob = 1.0f;\n\n        if (rand1() < reflect_prob)\n        {\n            wi.origin = rec.p;\n            wi.direction = reflected;\n        }\n        else\n        {\n            wi.origin = rec.p;\n            wi.direction = refracted;\n        }\n\n        return true;\n    }\n\n    return false;\n}\n\nObject prism = Object(\n    \tTransform(mat3(1.0), vec3(0.0, 2.0, 0.0), vec3(2.0, 2.0, 2.0)),\n    \tMaterial(2, vec3( 0.193093, 0.510542, 0.613362), 0.200000, 1.500000));\n\nObject table = Object(\n    \tTransform(mat3(1.0), vec3(-4.5, -2.1, 0.0), vec3(5.5, 0.1, 5.0)),\n    \tMaterial(0, vec3( 0.500000, 0.500000, 0.500000), 1.000000, 1.500000));\n\nObject prop1 = Object(\n    \tTransform(mat3(1.0), vec3(0.0, -1.001, -1.9), vec3(1.0, 1.0, 0.1)),\n    \tMaterial(0, vec3( 0.500000, 0.500000, 0.500000), 1.000000, 1.500000));\n\nObject prop2 = Object(\n    \tTransform(mat3(1.0), vec3(0.0, -1.001, 1.9), vec3(1.0, 1.0, 0.1)),\n    \tMaterial(0, vec3( 0.500000, 0.500000, 0.500000), 1.000000, 1.500000));\n\nObject light = Object(\n    \tTransform(mat3(1.0), vec3(-9.0, -1.0, 0.0), vec3(1.0, 1.0, 1.0)),\n    \tMaterial(3, vec3( 0.500000, 0.500000, 0.500000), 1.000000, 1.500000));\n\nObject wall = Object(\n    \tTransform(mat3(1.0), vec3(10.0, 0.0, 0.0), vec3(0.1, 10.0, 10.0)),\n    \tMaterial(0, vec3( 0.500000, 0.500000, 0.500000), 1.000000, 1.500000));\n\nIntersectInfo Add(IntersectInfo a, IntersectInfo b)\n{\n\tif (a.t.x < b.t.x) return a; else return b;\n}\n\nbool intersectScene(Ray ray, vec2 t, out IntersectInfo rec)\n{\n    IntersectInfo hit;\n    hit.t.x = MAXFLOAT;\n\n\thit = Add(hit,  Box(table, ray, t));\n\thit = Add(hit,  Box(prop1, ray, t));\n\thit = Add(hit,  Box(prop2, ray, t));\n\thit = Add(hit,  Box(light, ray, t));\n\thit = Add(hit, Prism(prism, ray, t));\n\n    rec = hit;\n\treturn hit.t.x != MAXFLOAT;\n}\n\nfloat skyColor(Ray ray)\n{\n\tvec3 sky = texture(iChannel0, normalize(ray.direction)).rgb;\n    sky = RGB_2_XYZ * pow(sky, vec3(2.2));\n    return XYZ2WavelengthApprox(ray.wave_length, sky);\n}\n\n\nfloat radiance(Ray ray)\n{\n    IntersectInfo rec;\n    Material mat;\n    float intensity = 1.0;\n\n    for(int i = 0; i < DNU(MAXDEPTH); i++)\n    {\n        if (intersectScene(ray, vec2(0.001, MAXFLOAT), rec))\n        {\n            Ray wi;\n            float attenuation;\n            float emission;\n\n            bool wasScattered = Material_bsdf(rec, ray, wi, attenuation, emission);\n\n            ray.origin = wi.origin;\n            ray.direction = wi.direction;\n\n            if (wasScattered && intensity > 0.01)\n                intensity *= attenuation;\n            else\n            {\n                return intensity * emission;\n            }\n        }\n        else\n        {\n            return intensity * skyColor(ray);\n        }\n    }\n\n    return 0.0;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 mo = iMouse.xy/iResolution.xy;\n\n    uvec2 p = uvec2(fragCoord);\n\tseedA = p.x + 1920U*p.y + (1920U*1080U)*uint(iFrame);\n\tseedB = p.y + 1920U*p.x + (1920U*1080U)*uint(iFrame);\n\n    //vec3 lookfrom = vec3(13.0, 2.0, 3.0);\n    const vec3 lookat = vec3(0.0, 1.5, 0.0);\n    float aperture = 1.0;\n\n    if (iMouse.z + iMouse.w < 1.0)\n    {\n        vec2 mo1 = vec2(0.59, 0.53);\n        vec2 mo2 = vec2(0.5, 0.415);\n        vec2 mo3 = vec2(0.5, 0.895);\n        vec2 mo4 = vec2(0.4, 0.4);\n        vec2 mo5 = vec2(0.1, 0.5);\n        mo = mo1;\n        float time = iTime - 25.0 * floor(iTime / 25.0);\n        mo = mix(mo, mo2, smoothstep(1.0, 4.0, time));\n        mo = mix(mo, mo3, smoothstep(5.0, 10.0, time));\n        mo = mix(mo, mo4, smoothstep(12.0, 15.0, time));\n        mo = mix(mo, mo5, smoothstep(15.0, 20.0, time));\n        mo = mix(mo, mo1, smoothstep(20.0, 25.0, time));\n    }\n\t// camera\n    float theta = 6.283*(0.5 * mo.y - 0.5);\n    vec3 ro = vec3(cos(6.283*mo.x) * sin(theta),\n                   cos(theta),\n                   sin(6.283*mo.x) * sin(theta));\n  \tro *= 35.0;\n    float distToFocus = length(lookat - ro);\n\n    Camera camera;\n    Camera_init(camera, ro, lookat, vec3(0.0f, 1.0f, 0.0f), 20.0f, float(iResolution.x) / float(iResolution.y), aperture, distToFocus);\n\n    vec3 col = vec3(0.0, 0.0, 0.0);\n\n    vec2 uv = fragCoord / vec2(iResolution);\n\n    IntersectInfo rec;\n    for (int s = 0; s < DNU(NUMSAMPLES); s++)\n    {\n        Ray r = Camera_getRay(camera, uv);\n        r.wave_length = rand(400.0, 700.0);\n\n        float intensity = radiance(r);\n\n        // vec3 color = cie_colour_match[r.wave_length] * D65[r.wave_length];\n        vec3 color = wavelength2XYZ(r.wave_length);\n\n        col += color * intensity;\n    }\n    col = XYZ_2_RGB * col;\n    col /= float(NUMSAMPLES);\n    col /= 40.0;\n\tcol = clamp(col, vec3(0.0), vec3(1.0));\n\n    // compress\n    col = 1.35*col/(1.0+col);\n\n    // gamma\n    col = pow( col, vec3(0.4545) );\n\n    //// s-surve\n    col = clamp(col,0.0,1.0);\n    col = col*col*(3.0-2.0*col);\n\n    // output\n    fragColor = vec4( col, 1.0 );\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 24,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "false",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/488bd40303a2e2b9a71987e48c66ef41f5e937174bf316d3ed0e86410784b919.jpg"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}