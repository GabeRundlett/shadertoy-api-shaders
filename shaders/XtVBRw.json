{
    "Shader": {
        "info": {
            "date": "1542173054",
            "description": "Uses SoundCloud input. Try hitting play/stop if it doesn't start. Might not work on some systems.\nUse mouse to adjust the vertical position.\n\nProject: https://gitlab.com/8vit-research/shadertoytv/commit/19a0922\nOriginal video: https://youtu.be/8Ow5OhwrWCQ",
            "flags": 96,
            "hasliked": 0,
            "id": "XtVBRw",
            "likes": 5,
            "name": "shadertoytv: Best Friends Untilâ€¦",
            "published": 3,
            "tags": [
                "audio",
                "soundcloud"
            ],
            "usePreview": 0,
            "username": "8vit",
            "viewed": 534
        },
        "renderpass": [
            {
                "code": "//! # Image\n//!\n//! Bell and whistle.\n//!\n//!  - **iChannel0**: Buffer D\n//!  - **iChannel1**: Noise texture\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    // Zoom\n    uv += (uv - 0.5) * 0.1;\n    \n    // 4:3 screen\n    uv.x += (uv.x - 0.5) * ((16.0 / 9.0) / (4.0 / 3.0) - 1.0);\n    \n    // Distortion\n    uv += (uv - 0.5) * (pow(length(uv - 0.5), 2.0) - 0.25) * 0.3;\n    vec2 uv2 = uv;\n    uv += normalize(uv - 0.5) * pow(max(length(uv - 0.5) - 0.68, 0.0), 2.0) * 30.0;\n    \n    // Main image\n    vec2 mainUV = uv;\n    fragColor.xyz = texture(iChannel0, uv).xyz;\n    \n    // Convert to linear\n    fragColor.xyz = pow(fragColor.xyz, vec3(2.0));\n    \n    // Add noise\n    float n1 = texture(iChannel1, vec2(iTime, 0.1)).x;\n    float n2 = texture(iChannel1, vec2(iTime, 0.2)).x;\n    float n3 = texture(iChannel1, vec2(iTime, 0.3)).x;\n    fragColor.xyz += texture(iChannel1, uv + vec2(n1, n2)).x * 0.03;\n    \n    if (max(abs(uv.x - 0.5), abs(uv.y - 0.5)) > 0.48) {\n        // Render a border.\n        float borderMix = min(1.0,\n            (max(abs(uv.x - 0.5), abs(uv.y - 0.5)) - 0.48) * 300.0);\n        fragColor.xyz = mix(fragColor.xyz, \n            vec3(0.006, 0.012, 0.006), borderMix);\n    }\n    \n    if (max(abs(uv.x - 0.5), abs(uv.y - 0.5)) > 0.5) {\n        // Render another border.\n        float borderMix = min(1.0,\n            (max(abs(uv.x - 0.5), abs(uv.y - 0.5)) - 0.5) * 300.0);\n        \n        // Reflection\n        float refl = 1.0 - exp2((0.5 - max(abs(uv2.x - 0.5), abs(uv2.y - 0.5)))\n                                * 6.0);\n        refl = refl * 0.3 + 0.02;\n        \n        // Outside the border\n        refl *= clamp(1.0 - (max(abs(uv2.x - 0.5), abs(uv2.y - 0.5)) - 0.6) * 100.0, 0.0, 1.0);\n        \n        float roughness = max(abs(uv2.x - 0.5), abs(uv2.y - 0.5)) - 0.5;\n        roughness = (1.0 - exp2(-roughness * 100.0)) * 0.5;\n        \n        vec2 reflOrigin = mix(clamp(uv2, 0.0, 1.0),\n             normalize(uv2 - 0.5) + 0.5, roughness * 0.5);\n        reflOrigin -= (reflOrigin - 0.5) * 0.2;\n        \n        vec4 sum = vec4(0.0);\n        vec2 tangent = normalize(uv.yx - 0.5) * vec2(1.0, -1.0);\n        float jitter = texture(iChannel1, uv + vec2(n2, n3)).x - 0.5;\n        for (float i = -0.5 + jitter / 4.0; i <= 0.5; i += 1.0 / 32.0) {\n        \tsum += vec4(textureLod(iChannel0, reflOrigin + i * tangent * roughness, 0.0).xyz, 1.0)\n                * exp2(-i * i * 100.0);\n        }\n        \n        fragColor.xyz = mix(fragColor.xyz, sum.xyz / sum.w * refl, borderMix);\n    }\t\n    \n    // Gamma correction\n    fragColor.xyz = pow(fragColor.xyz, vec3(0.7));\n\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 30,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "//! # Buffer A\n//!\n//! This shader produces scanlines from an input audio signal\n//! preprocessed by Buf C.\n//!\n//!  - **iChannel1**: Buffer A\n//!  - **iChannel2**: Buffer C\n\n// Read Buf C\nvec4 data(float i) {\n    return texture(iChannel2, vec2(\n        mod(i, iResolution.x) + 0.5, floor(i / iResolution.x) + 0.5\n    ) / iResolution.xy);\n}\n\n// `i` must be an integer in range `[0, NUM_AVAILABLE_FREQ_BINS - 1]`\nfloat readBin(float i) {\n    return data(i + 513.0 + 256.0).x;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    float chunkIndex = round(iTime * 44100.0 / CHUNK_NUM_SAMPLES);\n    \n    // The position within a frame.\n    float subchunkIndex = mod(chunkIndex, NUM_CHUNKS_PER_FRAME);\n    \n    // The scanline number that the current audio input represents.\n    float audioLine = subchunkIndex * NUM_LUMA_LINES_PER_CHUNK;\n    \n    // The scanline number of the current pixel.\n    float lumaRenderLine = floor(fragCoord.y);\n    \n    float renderX = floor(fragCoord.x);\n    \n    fragColor = texture(iChannel1, uv);\n    \n    if (renderX > FRAME_WIDTH || lumaRenderLine < audioLine || lumaRenderLine >= audioLine + NUM_LUMA_LINES_PER_CHUNK) {\n        return;\n    }\n    \n    float sublumaRenderLine = lumaRenderLine - audioLine;\n    float subchromaRenderLine = floor(sublumaRenderLine / CHROMA_SUBSMAPLE_Y);\n    \n    float yBin = renderX + sublumaRenderLine * FRAME_WIDTH;\n\n    float uBin = NUM_LUMA_FREQ_BINS +\n        floor((renderX + subchromaRenderLine * FRAME_WIDTH) / CHROMA_SUBSMAPLE_X);\n    float vBin = NUM_LUMA_FREQ_BINS + NUM_CHROMA_FREQ_BINS +\n        floor((renderX + subchromaRenderLine * FRAME_WIDTH) / CHROMA_SUBSMAPLE_X);\n\n    fragColor.x = readBin(yBin);\n    fragColor.y = readBin(uBin);\n    fragColor.z = readBin(vBin);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "//! # Buffer B\n//!\n//! This ahader analyses the Buffer A's output and adjusts the input range.\n//!\n//!  - **iChannel0**: Buffer A\n//!  - **iChannel1**: Buffer B\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    fragColor = texture(iChannel1, uv);\n                         \n    if (floor(fragCoord) != vec2(0.0, 0.0)) {\n     \treturn;   \n    }\n    \n    float minVal = 4.0;\n    float maxVal = -4.0;\n    \n    for (float x = 0.0; x < FRAME_WIDTH; x += 1.0) {\n        for (float y = 0.0; y < FRAME_HEIGHT; y += 1.0) {\n         \tvec4 x = textureLod(iChannel0, vec2(x + 0.5, y + 0.5) / iResolution.xy, 0.0);\n            \n            minVal = min(min(minVal, x.x), min(x.y, x.z));\n            maxVal = max(max(maxVal, x.x), max(x.y, x.z));\n        }\n    }\n    \n    fragColor.x += (minVal - fragColor.x) * (minVal < fragColor.x ? 0.1 : 0.03);\n    fragColor.y += (maxVal - fragColor.y) * (maxVal > fragColor.y ? 0.1 : 0.03);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "//! # Buffer C\n//!\n//! The shader preprocesses the audio input to improve the reproduction quality.\n//!\n//!  - **iChannel0**: Audio input\n//!  - **iChannel1**: Buffer C\n\n// The sampling rate of the input to `AnalyserNode`.\n// Try `44100.0` and `48000.0` if the image is not displayed\n// correctly. `0.0` means auto detection.\nconst float SYSTEM_SAMPLE_RATE = 0.0;\n\nfloat sampleRate = SYSTEM_SAMPLE_RATE;\n\nvec4 lastData(float i) {\n    return texture(iChannel1, vec2(\n        mod(i, iResolution.x) + 0.5, floor(i / iResolution.x) + 0.5\n    ) / iResolution.xy);\n}\n\nfloat readFFT(float i) {\n    float scale = 44100.0 / sampleRate;\n    return texture(iChannel0, vec2((i + 0.5) / 512.0 * scale, 0.25)).x;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragCoord = floor(fragCoord);\n    float i = fragCoord.x + fragCoord.y * iResolution.x;\n    \n    if (i > 2000.0) {\n     \treturn;   \n    }\n    \n    fragColor = lastData(i);\n    \n    float lastSampleTime = lastData(0.0).x;\n    if (iTime < lastSampleTime + CHUNK_NUM_SAMPLES / 44100.0) {\n        return;   \n    }\n    \n    if (sampleRate == 0.0) {\n     \t// Auto-detect sampling rate\n        float sum = 0.0;\n        for (float i = 500.0; i < 512.0; i += 4.0) {\n         \tsum += pow(readFFT(i), 2.0);   \n        }\n        \n        // If the system sampling rate is 48000, the frequency\n        // spectrum is scaled and we will see inactive bands near\n        // the end of visible spectrum\n        if (pow(sum / 12.0, 0.5) < 0.01) {\n            sampleRate = 48000.0;\n        } else {\n            sampleRate = 44100.0;\n        }\n    }\n    \n    // Sample a new chunk\n    if (i == 0.0) {\n        fragColor.x = iTime;\n    } else if (i < 513.0) {\n        fragColor.x = readFFT(i - 1.0);\n    } else if (i < 1025.0) {\n        float hpf = 8.0; // adjustable parameter - changes the strength of HPF\n        fragColor.x = readFFT(i - 1.0) * (1.0 + hpf) - lastData(i - 512.0).x * hpf;\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer02.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "musicstream",
                        "id": 16642,
                        "published": 0,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "https://soundcloud.com/user-327432232/shadertoytv"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "//! # Buffer D\n//!\n//! Produces a RGB image suitable for presentation based on Buffer A.\n//! This also displays a status text on the image.\n//!\n//!  - **iChannel0**: Buffer A\n//!  - **iChannel1**: Buffer B\n//!  - **iChannel2**: Font texture\n\n// SoundCloud is weird\nconst bool INVERT = true;\n\nvec3 decodePalYuv(vec3 yuv)\n{\n    // https://www.shadertoy.com/view/lt3SWj\n    return vec3(\n        dot(yuv, vec3(1., 0., 1.13983)),\n        dot(yuv, vec3(1., -0.39465, -0.58060)),\n        dot(yuv, vec3(1., 2.03211, 0.))\n    );\n}\n\n// https://www.shadertoy.com/view/ltcXzs\n // --- access to the image of ascii code c\nvec4 char(vec2 p, int C) {\n    if (p.x<0.|| p.x>1. || p.y<0.|| p.y>1.) return vec4(0,0,0,1e5);\n  //return texture   ( iChannel0, p/16. + fract( vec2(C, 15-C/16) / 16. ) );\n  //return textureLod( iChannel0, p/16. + fract( vec2(C, 15-C/16) / 16. ) , \n  //                   log2(length(fwidth(p/16.*iResolution.xy))) );\n    return textureGrad( iChannel2, p/16. + fract( vec2(C, 15-C/16) / 16. ) , \n                       dFdx(p/16.),dFdy(p/16.) );\n    // possible variants: (but better separated in an upper function) \n    //     - inout pos and include pos.x -= .5 + linefeed mechanism\n    //     - flag for bold and italic \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    uv.y = 1.0 - uv.y;\n    \n    // 16:9 letter box in a 4:3 monitor\n    uv.y += (uv.y - 0.5) * ((16.0 / 9.0) / (4.0 / 3.0) - 1.0);\n    if (abs(uv.y - 0.5) > 0.5) {\n        fragColor = vec4(0.06, 0.12, 0.06, 0.0);\n     \treturn;   \n    }\n    \n    uv.y = fract(uv.y + iMouse.y / iResolution.y);\n    \n    uv *= vec2(FRAME_WIDTH, FRAME_HEIGHT) / iResolution.xy;\n\n    // Decode buffer (Buf A)\n    vec3 t = texture(iChannel0, uv).xyz;\n    \n    if (false) {\n        // Remove stripe artifact\n        t += texture(iChannel0, uv + vec2(0.0, 1.0 / iResolution.y)).xyz;\n        t *= 0.5;\n    }\n    \n    // Normalize/rescale\n    vec4 analysis = texture(iChannel1, vec2(0.0, 0.0)); // (Buf B)\n    analysis.xy += vec2(-0.0001, 0.0001); // supress NaN/inf\n    t.xyz = (t.xyz - analysis.x) / (analysis.y - analysis.x);\n    if (INVERT) {\n    \tt = 1.0 - t;\n    }\n    t = clamp(t, 0.0, 1.0);\n    \n    t.yz = (t.yz - 0.5) / 2.0;\n    \n    // Color adjustment\n    t.yz *= 1.2;\n\n    fragColor.xyz = decodePalYuv(t.xyz);\n    \n    // OSD - Display \"NO INPUT\" if \"Buffer A\" is generating\n    // a uniform output (indicating a problem with audio feeding)\n    if (analysis.y < analysis.x + 0.3) {\n        vec2 U = fragCoord/iResolution.xy * vec2(10.0, 10.0) - vec2(2.75, 4.25);\n        fragColor.y += char(U,64+14   ).x; U.x-=.5;\n        fragColor.y += char(U,64+15   ).x; U.x-=.5;\n        U.x-=.5;\n        fragColor.y += char(U,64+ 9   ).x; U.x-=.5;\n        fragColor.y += char(U,64+14   ).x; U.x-=.5;\n        fragColor.y += char(U,64+16   ).x; U.x-=.5;\n        fragColor.y += char(U,64+21   ).x; U.x-=.5;\n        fragColor.y += char(U,64+20   ).x; U.x-=.5;\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 2,
                        "ctype": "texture",
                        "id": 49,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer D",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 260
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "\n// From `shadertoytv/src/encoder.rs`\nconst float FRAME_WIDTH = 96.0;\nconst float FRAME_HEIGHT = 64.0;\n\nconst float CHUNK_NUM_SAMPLES = 2048.0;\nconst float NUM_AVAILABLE_FREQ_BINS = CHUNK_NUM_SAMPLES / 8.0;\n\nconst float NUM_LUMA_FREQ_BINS = 192.0;\nconst float NUM_CHROMA_FREQ_BINS = (NUM_AVAILABLE_FREQ_BINS - NUM_LUMA_FREQ_BINS) / 2.0;\n\nconst float NUM_LUMA_LINES_PER_CHUNK = NUM_LUMA_FREQ_BINS / FRAME_WIDTH;\n\nconst float CHROMA_SUBSMAPLE_Y = 2.0;\nconst float NUM_CHROMA_LINES_PER_CHUNK = NUM_LUMA_LINES_PER_CHUNK / CHROMA_SUBSMAPLE_Y;\nconst float CHROMA_SUBSMAPLE_X = FRAME_WIDTH / (NUM_CHROMA_FREQ_BINS / NUM_CHROMA_LINES_PER_CHUNK);\n\nconst float NUM_CHUNKS_PER_FRAME = FRAME_HEIGHT / NUM_LUMA_LINES_PER_CHUNK;\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}