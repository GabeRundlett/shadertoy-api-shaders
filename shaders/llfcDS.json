{
    "Shader": {
        "info": {
            "date": "1506218358",
            "description": "arrows move.\n\na light source at the camera pivot is fun!\nkick to change scene texture (kick lower part for first person). (should be intuitive?)\ndrag to rotate camera\nmake many small drags to keep the blending within a small range.",
            "flags": 48,
            "hasliked": 0,
            "id": "llfcDS",
            "likes": 4,
            "name": "shadow differential forest",
            "published": 3,
            "tags": [
                "collision",
                "checkerboard",
                "forest",
                "debug",
                "curvature",
                "differential",
                "calculus",
                "dynamiceps",
                "ckecker"
            ],
            "usePreview": 0,
            "username": "ollj",
            "viewed": 1152
        },
        "renderpass": [
            {
                "code": "\nvoid mainImage( out vec4 o, in vec2 u ){\n o=texelFetch(iChannel0,ivec2(u),0);\n// if(abs(length(u-iResolution.xy*.5)-10.)-1.) \n o=mix(vec4(1)-o,o,smoothstep(0.,4.,abs(length(u-iResolution.xy*.5)-10.)));\n}\n\n\n\n/*\nTo improve soft shadow sampling \n (all soft shadows are sampling points along a ray of light) \nThe basic idea is to use a function to push ANY sample points along a ray \n closer into screen space. we can also test if a ray is even close to screen space.\n\nThis is not implemented here. its a concept asking for pointers or ridicule.\n Like, any good reason to not do it.\nFirst asking if the idea is just bad, \n if you intentionally did not do it, or have a better function.\n\n---------\n\nWhen you do calculate soft shadows within a distance function gradient, \n you sample multiple points along a ray in a loop.\nThe ray goes from a light source to a point near a surface. \n you basically lerp with weights.\n\nYour soft shadow function sphere tracks along the ray and keeps lowest brightness, \n the smallest radius, of multiple samples.\n The spreading of these samples is somewhat arbitiary.\n Sphere tracking is a simple choice, \n  but that easily has many samples not inside screen space\n  ,assuming the source of your shadow or the light source in not in the camera frame\n  ,thse samples are likely wasted calculations.\nbetter sample spread has all samples close to screen space.\n\nMy idea is not implemented anywhere. \nIt is to use the first antiderivative of cauchy distribution \n to push sample points more into screen space.\n\n\n[[---\n\nstarting with linear interpolation. \n i have seen lerp-soft-shadows done many times, \n it is slighly faster, has one less multiplication per iteration.\nlerp shadows are just fine for simple predictable small scale camera movements.\nbut not good enough for a larger set with free camera movement \n and collision detection physics.\n\n#define MaxDistance 9999.\nvec3 posLightSource=vec3(0);\nvec3 posSurface=vec3(-3);\nfloat maxIter=64.; \nfloat accumulator=MaxDistance;\nfor (float i=0,i<maxIter;i++){\n vec3 p=mix(posLightSource,posSurface,i/maxIter);\n accumulator min(accumulator,getDistancetoSurfaceOfGradientAtPoint(p));\n}\n\n---]]\n\nAbove code samples 64 points from posLightSource till posSurface;\nI skip your spheretracking implementation, its good and very well known.\n it spreads sample points, depending on the previous spheretracking result.\n\nBut what if only a few sample points are even close to screen space? \n They are likely wasted samples\n ,unless the shadow there is large enough reach screen space, unlikely! \nLarge shadows are likely just very diffuse, can be spread out more, neglible.\n\nWe can use the cauchy distribution first andiderivative\n (cauchy cummulative distribution functon) to push sample points into screen space:\nIt is far from optimal, but its a decent simple start.\n\nhttps://en.wikipedia.org/wiki/Cauchy_distribution\n\nvec3 cahcyDistributionCumulativeDistributionFunction(\n vec3 x,\n vec3 locationParameter,\n vec3 scaleParameter){\n  return 1./pi*atan((x-locationParameter,)/scaleParameter)+.5\n;}\n\nAngle between any 2 rays is a cakewalk acos();\nA small (close to 0 angle between gamera ray and shadow ray makes the bell curve wider. \n A larger [scaleParameter]?\nA 90deg angle between camera and ray shadoe makes the bell curve thinner. \n A smaller [scaleParameter]?\n\nCalculating a point on one ray \n  that is closest to another ray in 3d is like 4 dotproducts.\nWith that we have the point on a ray, from light source to surface\n ,that is closest to the center of the camera view!\n This point feets into [locationParameter]\n ,which sets the \"half width maximum\" of this bell-shaped curve \n (we do its CDF==first antiderivative cauchy distribution here!)\n \nso, all in all, its;\n\n[---\n\n#define MaxDistance 9999.\nvec3 posLightSource=vec3(0);\nvec3 posSurface=vec3(-3);\nfloat maxIter=64.; \nfloat accumulator=MaxDistance;\nfor (float i=0,i<maxIter;i++){\n\n//todo, implement these 2 common library functions; see \"second life wiki gerometry\"\n float scaleParameter=getClosestPointOnLightRayToRayFromCameraToCameraForwardDirection();\n float locationParameter=getsmallestUnsignedAngleBetween2Rays(rayditectionA,rayDirectionB);\n\n vec3 p=mix(\n       posLightSource,\n       posSurface,\n       cahcyDistributionCumulativeDistributionFunction(x,locationParameter,scaleParameter));\n accumulator min(accumulator,getDistancetoSurfaceOfGradientAtPoint(p));\n}\n\noh damn it need the inverse of the CDF, doesnt it?\nyeah thats why i asked, i am not good at inverting a function.\nespecially not probabalistic ones, their inverses tend to be trickier.\n\nwww.math.wm.edu/~leemis/chart/UDR/PDFs/StandardcauchyI.pdf\n\n---}\n\n*/\n\n\n\n//abve part is younger than below part\n//might want to read below part first, for temporal continuity.\n\n\n\n\n\n\n\n\n\n\n/*\nopen question, regarding better smooth shadow sampling\n\nHow about applying [cauchy distribution] to the sampling points of soft shadows.\nInstead of sampling soft shadows by marching along a ray, \n or by samling linearly or by appllying some hermite interpolation,\n we increase the density of samples for soft shadows near the camera's central ray.\n\nwe have 2 rays (lines)\n[line 1]==[camera line] \n         Is the camera ray trouigh the center of the vamera view, looking straight forward.\n         Is the same for all fragments of a frame\n[line 2]==[shadow line] \n         Goes from a soft-shadow casting light source to a point on (or near) a surface.\n         Is diffferent for fragments of the same frame.\n\n//return the point on [line 1] that is closest to [line 2]\n//O1 Line 1 Origin\n//D1 Line 1 Direction \n//O2 Line 2 Origin\n//D2 Line 2 Direction\n//2 lines defined by [O]rigins and [d]irections \n//(i assume normalized directions before testing non-normalized)\nvec3 gLLnX(vec3 O1,vec3 D1,vec3 O2,vec3 D2){\n    vec3 nO1 = vec3( dot(O1,D1), dot(O1,D2), 0);\n    vec3 nO2 = vec3( dot(O2,D1), dot(O2,D2), 0);\n    vec3 nD1 = vec3( dot(D1,D1), dot(O1,D2), 0);\n    vec3 nD2 = vec3( dot(O2,D1), dot(O2,D2), 0);\n    float t = ( nD2.x*nD1.y - nD1.x*nD2.y );\n    t = ( nD2.y*(nO1.x-nO2.x) - nD2.x*(nO1.y-nO2.y) ) / t;\n    return O1+D1*t;}//from [second life wiki geometric] library page\n\nwe calculate the [point] on the [shadow line] that is closest to the [camera line].\nwe calculate the distance between that [point] and the [light source]\nWe feed that distance into [the inverse] \n of a [cauchy distribution]s [first antiderivative]\nhttps://en.wikipedia.org/wiki/Cauchy_distribution\nor something like that.\n\nThere may be a simpler faster special functions \n that similarly attract linearly spread points to one point along a line. \nyou may just use something like \n\nx=1/(x-a)/(x-a)\n\ncauchy distribution is just a nice normal-distribution-like curve, \n useful for [spectroscopy], because it has offset and width as parameters.\n\nwe also want a higher density of sampling points for soft shadows near the surface\n to get the correct result for \"lit\" or \"dark\" near the horizon.\n\nThis method could pull shadow sampling points close to locally small objects.\n*/",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "\n\n//raymarch iterations, most likely cause of compiler crash (or bad performace)\n#define iterMarch 62.\n//soft shadow iterations, quality of shadows (is sample count, not spread, not softness)\n#define iterShadow 7.\n//maximum recursions of iterations with shadows in them\n#define iterMaxReflectionsWithShadows 1.\n//above values are hard limits to loops within loops, these can crash a parser.\n\n//maximum iteratiosn of reflections (within refllections...) \n// generally more constrained by Dept_of_Field or view distance than by iterMaxReflections\n#define iterMaxReflections 999.\n//cubed view distance, gets scaled by resolution, lazy simple constrain.\n#define zFarE 1000000.\n//heuristic Epsilon-factor for everything, efficient constrain, especially for blur/fog.\n#define eps .0001\n//number of shadow castig light sources; 0,1,2\n#define LightSources 2\n\n//Distort gradient over distances for better convergence and more LOD scaling.\n//Epsilon increases by log([squared distance to camera] / [last step length])\n//Allows for much smaller close up [eps]. Allows for wider range of [iterShadow]\n//Allows for more understepping, larger lipschitz constants, less C1 continuity.\n// https://www.shadertoy.com/results?query=DynamicEps\n#define DynamicEps\n\n//.rgb ratio of athmospheric scattering, like an atmospheres blackbody radiation.\n#define shadowColor    vec3(.1,.2,.4)\n\n//distance between camera and pivot point that the camera rotates around\n//#define distCam2Pivot 2.\n//above is simple, below is \"weird\" because it blends between 1st and 3rd person.\n#define distCam2Pivot -5.*(1.-iMouse.y)/iResolution.y\n\n//add checkerboard overlay of nornals and curvature (2 gradient derivatives)\n// to to visualize 3d space and to debug the df()\n//0=disable 256=100% , gets scaled by m.y,iMouse.y,\n#define debugCheckerCalculus 256\n\n//mouse.y sets amplitude of floor (initially a bit too confusing, also large lipschitz)\n//#define mouseSetsFloorAmpAndTime\n\n/*\ndrag to rotate camera\nklick to blend\niMouse.x mixes between; \n rainbow-textured world position (0th derivative) && checkerboard tiling of;\n    normal (1st derivative) && curvature(2nd derivative)\niMouse.y mixes between;\n Oclusion of a light source at [eye\n*/\n\n//a silly thing\n// the gradient of the sinusoidial floor is too differnetly scaled from the rest.\n//this messs up surface normal calculations.\n//temp fix is to only calculate very blurry surface normals.\n\n/* Tiny Movement Collision\nparent1: 4 BuffABCD         : https://www.shadertoy.com/view/XtXyW4\nparent2: 2 BuffAB           : https://www.shadertoy.com/view/4tfcRf  \nparent3: abje feature crunch: https://www.shadertoy.com/view/4dSBzW \nparent4: ollj 1 BuffA       : https://www.shadertoy.com/view/lllcRl\nself   : ollj               : https://www.shadertoy.com/view/llfcDS\n\nFamily history shows how someone unintntionally proves a new concept. \n and 2 others extract that and remove all the less novel parts.\n/\nKnown issues (super simplifications):\n Distance field is a messy gradient mix of euclidean trees and .y waveforms.\n Distance field is (partially) (lipschitz-)discontinuous (linear .y waveforms)\n  Intentionally! Good colision detection amnd occlusion still works with bad continuity!\n  This shader is designed as debugger.\n  Without known errors, without being knowably out of bounds, there is nothing to debug!\n I accidentally made this 4 dimensional\n  Here the distance field has .w=0 (ignores 4th domain), it is up to you to change that:\n  https://www.youtube.com/watch?v=vZp0ETdD37E\n There is no Jump() towards +.y\n Falling() towards -.y is linear over time, should be quadratic gravity.\n Rotation got simplifid so much in parent1, it got \"partially broken\":\n  Euler rotation order seems very wrong here, but is not too noticable.\n  Uses euler rotation, should not use Euler rotation.\n\nTo do (not included yet);\n Calculate hard shadows, that are shrunk down by shadowSoftness\n  If(that is fast enough) it may be a nice alternative to softShadows\n   I must review a [general hard analytic shadow] method for this one. \n CrepuscularRays (godRays)\n  An infinite forest of infinite height surrounds its sun and blocks most of its rays.\n   This needs a different setting.  \n Offset rotating camera that never collides with a wall \n  and that never has a wall between camerapos and camera target, by re-Using softshadow()\n  https://www.shadertoy.com/view/4dSBzW\n Include libraries\n  use libraries to make a better distance field.\n  AutomaticDifferentiation()\n   https://www.shadertoy.com/results?query=automatic+differentiation\n   https://www.shadertoy.com/results?query=derivative+arithmetic\n  noise()\n   better with first AutomaticDifferentiation() and fract() scaling?\n  kelvinToRgb() blackBodyColor\n  nonVR2VR()  \n   https://www.shadertoy.com/view/XtfcRX\n  compose() \n   https://www.shadertoy.com/view/4tscRf\n   https://www.shadertoy.com/results?query=composi\n Bounding volume stuff\n  https://www.shadertoy.com/results?query=boundi\n  https://www.shadertoy.com/results?query=lighthouse  (see comments)\n reflect()\n  https://www.shadertoy.com/view/4td3Dj\n scatter() glass() TraceVolume()\n  https://www.shadertoy.com/results?query=glass\n  https://www.shadertoy.com/results?query=transpar\n  https://www.shadertoy.com/results?query=xRay\n  https://www.shadertoy.com/results?query=cloud\n hdr() high dynamic range\n General4d()\n  https://www.shadertoy.com/results?query=polychora\n  https://www.shadertoy.com/results?query=hyper\n  https://www.shadertoy.com/results?query=fibration\n  https://www.shadertoy.com/results?query=tag%3D4d\n  https://www.shadertoy.com/results?query=stereograp\n  https://www.shadertoy.com/results?query=s4\n  https://www.youtube.com/results?search_query=introduction+4d+space   (4d intro)\n  https://www.youtube.com/watch?v=LOVzytir7bM                          (4d exhibition)\n  https://www.youtube.com/results?search_query=hypercube+stereographic (4d youtube)\n Game4d() \n  https://www.youtube.com/watch?v=Tzyws5ZkSYg                          (4d Tetris)\n  https://www.youtube.com/watch?v=8IUnqm8j4BE                          (4d Snake)\n  https://www.youtube.com/user/MiegakureGame/videos                    (4d Rpg)\n hyperbolic()   stuff\n  https://www.youtube.com/results?q=hyperrogue&sp=CAJQFA%253D%253D  (hyperbolic Rogue)\n  https://www.youtube.com/watch?v=ztsi0CLxmjw                       (hyperbolic VR)\n  https://www.youtube.com/watch?v=MTfviv_aZYI                       (hyperbolic VR)\n  https://www.youtube.com/watch?v=F7yLL5fJxT4            (boolean && hyperbolic VR)\n Add in-world buttons and sliders that buffer gradients.\n  Make a 3d UI, and then Hide the 3d ui along a 4th domain\n  ,so it does not obstruct your field of view too much AND is in-world\n dynamicScaling()\n  https://www.youtube.com/watch?v=6NsI6XgzSn8\n relativity()\n  https://www.shadertoy.com/view/ldBSDt\n  http://gamelab.mit.edu/games/a-slower-speed-of-light/\n Vehicles\n  http://wiki.secondlife.com/wiki/Linden_Vehicle_Tutorial\n  Wallwalker()\n   ollj.turboherz.de/walking-on-walls-with-a-saddle-on\n   https://www.google.com/search?q=Wall+walker+second+life\n*/\n\n\n/* df(p) Sets a distance_field gradient; \nif(    df(p)  == 0. ){ [p] is  on  a surface.}\nif(    df(p)  < eps ){ [p] touches a surface.} //[eps] is a bit like \"air pressure\"\nif(abs(df(p)) < eps ){ [p] is near a surface.} //can also be below it\n https://iquilezles.org/articles/distfunctions\n mercury.sexy/hg_sdf/\nShould return distance of [p] to an implicit surface or at least an upper boudndary:\n https://en.wikipedia.org/wiki/Gradient\n https://en.wikipedia.org/wiki/Contour_line\n https://en.wikipedia.org/wiki/Upper_and_lower_bounds\n https://en.wikipedia.org/wiki/Signed_distance_function\n https://iquilezles.org/www/index.htm\nShould be continuous, its first derivative should be continuous (over all domains)\n https://en.wikipedia.org/wiki/Continuity\n https://en.wikipedia.org/wiki/Lipschitz_continuity\n*/\n\n\n//planar zoom.\n#define ViewZoom 3.\n//sub-pixel blur\n#define fsaa 14./min(iResolution.x,iResolution.y)\n//View Frame\n#define fra(u) (u-.5*iResolution.xy)*ViewZoom/iResolution.y\n/* End__.Parameters\n   Start.Lib.Frame.7\n*/\n\n//index starts at 0!\n#define v0 float\n#define v1 vec2\n#define v2 vec3\n#define v3 vec4\n#define u5(a) (a*.5+.5)\n#define u2(a) (a*2.-1.)\nv0 suv(v3 a){return dot(v3(1),a);}v0 suv(v2 a){return dot(v2(1),a);}\nv0 suv(v1 a){return a.x+a.y;}//sum of vector\nv0 mav(v1 a){return max(a.y,a.x);}\nv0 mav(v2 a){return max(a.z,mav(a.xy));}\nv0 mav(v3 a){return max(mav(a.zw),mav(a.xy));}\n//max of vector\n#define miv(a) -mav(-a)\n//triangle wave //euclidean grid\n#define tri(a) a=abs(u2(fract(a)))\n#define grid(a) mav(tri(a))\n//clamp().special clamp.general; //clamp().pseudo.inverse\n#define sat(a) clamp(a,0.,1.)\nv0 sat2(v0 a,v1 m){a=.5*(sign(a)+m.x)*a+m.y;a=(sign(2.-a)+1.)*(a-2.)+2.;return a*.5;}\n//stretch; mirror_centric, most common, atomic\n#define stretch(u,m) .5*(sign(u)*m-u)*((sign(abs(u)-m))+1.)\n//stretchMinus; positive values do not change; stretchPlus; negatives do not change.\n#define stretchM(u,m) stretch((u*2.+m),m)*.5\n#define stretchP(u,m) stretch((u*2.-m),m)*.5\n#define dd(a) dot(a,a)\n//perpendicular ==90deg rotation, relevant for distance to line\nv1 perp(v1 a){return v1(-a.y,a.x);}\n//return [perpendicular dot product], relevant for distance to line\nv0 dotp(v1 a,v1 b){return dot(perp(a),b);}\n//return distance of [u] from segment, from [a] to [b]\nv0 dSegment(v1 p,v1 a,v1 b){p-=a;b-=a;return length(p-b*sat(dot(p,b)/dd(b)));}\n//---trigonometry, rotations and (distance to) Quadratic functions.\n//(distance to quadratic is a cubic with less than 2 intersections==roots)\n#define cs(a) vec2(cos(a),sin(a))\n//mirror p at half rotated axis == cheap SINGLE 2d rotation.\n#define rs(r) mat2(sin(r+vec4(1,0,0,-1)*asin(1.)))\n//golden ratios are the best factors for hashes because; phi.xy-1.=1/phi.xy\nconst v1 phi=v1(sqrt(5.)*.5)+v1(-.5,.5);\n//a not too work save plotter for quadratic functions.\nv1 evalQuad(v1 t,v1 A,v1 B,v1 C){A=(1.-t)*(A/B+C/A);return A*A;}\n//Solve quadratic equation for roots \nv2 SolveQuad(v2 a){float e=-a.x/3.;v0 p=a.y+a.x*e,t=p*p*p,\n q=-(2.*a.x*a.x-9.*a.y)*e/9.+a.z,d=q*q+4.*t/27.;if(d>.0){v1 x=(v1(1,-1)*sqrt(d)-q)*.5;\n return v2(suv(sign(x)*pow(abs(x),v1(1./3.)))+e);}v1 m=cs(acos(-sqrt(-27./t)*q*.5)/3.)\n  *v1(1,sqrt(3.));return v2(m.x+m.x,-suv(m),m.y-m.x)*sqrt(-p/3.)+e;}\n//return squared distance to line segment\nv0 dLine(v1 a,v1 b,v1 p){a=a-p;b-=p;p=b-a;return dd(a+p*sat(-dot(a,p)/dd(p)));}\n#define ddb(a) (dd(d+(c+b*t.a)*t.a))\n// Find the signed distance from a point to a bezier curve\nv0 dBezier(v1 p,v1 A,v1 B,v1 C){   \n //B=mix(B+v1(1e-4), B, abs(sign(B * 2.0 - A - C)));//colinear CV triviality\n v1 a=B-A,b=A-B*2.+C,c=a*2.,d=A-p;v2 k=v2(3.*dot(a,b),2.*dd(a)+dot(d,b),dot(d,a))/dd(b),\n t=sat(SolveQuad(k));return sqrt(miv(v2(ddb(x),ddb(y),ddb(z))));}\n//---window function curve fittings.y:  https://www.shadertoy.com/view/Xtscz7\n#define bma(b,a,c) (((b)-(a))*(c)+a)\n//float Linear(float x, float a, float b){return  a*(x*(b/a-1.)+1.);}//doesnt look too good.\n#define wLinear(x,a,b) a*(x*(b/a-1.)+1.)\n//float Cosine(float x, float a, float b){return (b-a)*(1.-cos(x*acos(-1.)))*.5 + a;}\n#define wCosine(x,a,b) (bma(b,a,(1.-cos(x*acos(-1.)))*.5)\n//float Smoothstep(0,1,x), without sat(a);\n#define wSs2(x) (x)*(x)*(3.-2.*(x))\n#define wSs(x,a,b) wSs2((x)-(a)/((b)-(a)))//this is not too useful, without sat it sucks\n//bma(b,a,x*x*(3.-2.*x))\n//lower lipschitz == less likely spheretracking overestimation.\n//most general, smoothest most excessive, most zigzag, lowest lipschitz\n#define wHermiteD(x,a,b,e,f) (b+.5*x*(e+b-a+x*(a-b+e+x*3.*(e*3.+f+x*5./3.*(-e*3.-f+x*.4*(e*3.+f))))))\n#define wHermite(x,a,b,c,d) HermiteD(x,a,b,(c-b),(a-d))\n//special case of Hermite(), with a smooth .5 average. medium zigzag\n#define wCatmullRom(x,a,b,c,d) ((((d-a+3.*(b-c))*x+(2.*(a+c+c)-d-5.*b))*x+(c-a))*.5*x+b)\n//efficient and smooth 2nd derivative, least zigzag, highest lipschitz \n#define wCubic(x,a,b,c,d) ((((d-c-a+b)*(x-1.)+a-b)*x+(c-a))*x+b)\n//Cosine() is smoother than Cubic()\n//fast good monochrome distance field visualization.\nv3 rg(v3 c){v3 b=smoothstep(fsaa,-fsaa,c);\n return mix(fract(c*4.),b,.5+(atan(c))/acos(-1.));}\n//---hash\n//hash11 fast mediocre, better for mobile gpu.\nv0 h11(float p){v2 f=fract(v2(p)*.1031);f+=dot(f,f.yzx+19.19);\n return fract((f.x+f.y)*f.z);}\n\n/* End__.Lib.Frame.7\n   Start.Main\n*/\n#define rot(spin) mat2(cos(spin),sin(spin),-sin(spin),cos(spin))\n#define KEY_UP 38\n#define KEY_DOWN 40\n#define KEY_RIGHT 39\n#define KEY_LEFT 37\n#define INDEX_CAM 0\n#define INDEX_MOUSE 1\n#define INDEX_ROT 2\n#define INDEX_LOADED 3\n//this occupies all pixels on the bottom line from A to B\n#define INDEX_DECAL_A 4\n#define INDEX_DECAL_B 14\n#define HALF_PI 1.5\n\n\nfloat df(vec4 p)\n{vec2 p2=mod(p.xz,10.)-5.\n#ifdef mouseSetsFloorAmpAndTime\n;float t=iTime*5.*iMouse.z/iResolution.x\n;float m=iMouse.w/iResolution.y\n#else\n;float t=-iTime\n;float m=cos(t)*.1+.15;\n#endif\n;float floorEgg=(sin(p.x+t)+sin(p.z))*(2.*m+.1);//egg cardridge gloor\n;float flootSplash=cos(length(p.xz)+t);\n;float ground=mix(floorEgg,flootSplash,.5)+p.y;//flpash floor\n;return min(ground,length(p2)-1.0);\n}\n\nfloat df(vec3  p){return df(vec4(p,0));}//a 3d variant of the above. .w flattened to .z\nfloat df(vec2  p){return df(vec3(p,0));}//a 2d variant of the above, .z flattened to .y\nfloat df(float p){return df(vec2(p,0));}//a 1d variant of the above, .y flattened to .x\n\nfloat dfd1(float p,float d){float e=eps*d\n;return normalize(float(df(p+e)-df(p-e)))\n;return sign(float(df(p+e)-df(p-e)));}//normalize gradient over 1 domains==sign()\nvec2 dfd1(vec2 p,float d){vec2 e=vec2(eps*d,0)\n;return normalize(vec2(df(p+e.xy)-df(p-e.xy),//normalize gradient over 2 domains\n                       df(p+e.yx)-df(p-e.yx)));}\nvec3 dfd1(vec3 p,float d){vec2 e=vec2(eps*d,0)\n;return normalize(vec3(df(p+e.xyy)-df(p-e.xyy),//normalize gradient over 3 domains\n                       df(p+e.yxy)-df(p-e.yxy),\n                       df(p+e.yyx)-df(p-e.yyx)));}\n//return normal at p, == first derivative of distance field\nvec4 dfd1(vec4 p,float d){vec2 e=vec2(eps*d,0)\n;return normalize(vec4(df(p+e.xyyy)-df(p-e.xyyy),//normalize gradient over 4 domains\n                       df(p+e.yxyy)-df(p-e.yxyy),\n                       df(p+e.yyxy)-df(p-e.yyxy),\n                       df(p+e.yyyx)-df(p-e.yyyx)));}\n\nvec4 tf(ivec2 u){return texelFetch(iChannel0,u,0);}\nvec4 tf(int x, int y){return texelFetch(iChannel0,ivec2(x,y),0);}\nfloat tf2(int x){return texelFetch(iChannel1,ivec2(x,0),0).x;}\n    \n\n//return n-dimensional checkerboard at position [p] of interval [o]!=.0\n#define checkerBoardN(a) float checkerBoard(a p,a o){return mod(suv(a(lessThan(mod(p,o),o*.5))),2.);}\ncheckerBoardN(vec4)checkerBoardN(vec3)checkerBoardN(vec2)\n                   \n//euler camera rotation\nvec3 rotatecam(vec3 r)\n{vec4 rotation=tf(INDEX_ROT,0);r.yz *= rot(rotation.y);r.xz *= rot(rotation.x);return r;}\n\nvec4 setvariables(int i)\n{bool b=all(equal(tf(INDEX_LOADED,0),vec4(1)))\n;vec4 o\n;if(i==INDEX_CAM\n){if(!b)return vec4(0,10,0,1)\n ;o=texelFetch(iChannel0,ivec2(0),0)\n ;vec3 h=o.xyz//simple idea is that you can bumb head or feet.\n ;vec3 feet=vec3(0,-2,0)//todo, should instead do mstretch;\n ;h.y-=clamp(df(h+feet)-.5,-.1,.1)\n ;vec2 m=vec2(tf2(KEY_RIGHT)-tf2(KEY_LEFT),\n              tf2(KEY_UP   )-tf2(KEY_DOWN))\n ;if(dot(m,m)>0.1) m=normalize(m)*iTimeDelta*3.\n ;m*=rot(tf(INDEX_ROT,0).x)\n ;vec3 c=h+vec3(m,0).xzy//collider\n ;float d=df(c)\n ;if(!(d>0.5)//a collision becomes an offset\n ){vec2 e=vec2(.01,0)\n  ;vec2 n=normalize(vec2(df(c+e.xyy)-d,\n                         df(c+e.yyx)-d))*iTimeDelta*3.\n  ;h.xz+=n;\n }h.xz+=m\n;return vec4(h,o.z);\n}if(i==INDEX_MOUSE)return iMouse/iResolution.xyxy\n;if(i==INDEX_ROT\n){if(!b)return vec4(0)\n ;o=tf(INDEX_ROT,0)\n ;vec4 l=tf(INDEX_MOUSE,0)*iResolution.xyxy//lastiMouse\n ;vec4 d=vec4(0)//mousedelta\n ;if(all(greaterThan(min(l,iMouse),vec4(0))))d=iMouse-l\n ;o.x += d.x*0.02\n ;return vec4(o.x,clamp(o.y+d.y*0.01,-HALF_PI,HALF_PI),o.zw);\n}/*if(i==INDEX_LOADED)*/\n return vec4(1);}\n\n//iterations of soft shadows (is avtually rather static)\n#define iterSS 164.\n\n//on shadow:\n//all shaddows are multi-sampling occlusions\n//sample points are arbitiarly linear spread (from light source to surface)\n//moving sample points by hermite spline makes sense\n//the trick to best sampling is do;\n// \"cauchyDistribution(dot(camerPos,ShadowRayDirection))\"\n//calculate a dotproduct to project the camera position onto the shadow-ray\n// To get the point on the shadow ray that is closest to the camera.\n//Ssample points should have a higher density around that area\n// I think Cauchy.Distribution is good for this.\n\n//sample weights are arbitiary, the weights make the shadow smooth.\n//the weighting is the tricky part. i use a lot of smoothstep for this=\n\n\n//return ambientOcclusion at point=[p] normal=[n], ...\nfloat AmbientOcclusion (vec3 p,vec3 n,float d,float s){float r=1.;\n  for(int i=0;i<5;++i){if(--s<0.)break;r-=(s*d-(df(p+n*s*d)))/pow(2.,s);}return r;}\n\n//return surface color at point=[o] \n//with ray direction=[d] (can change by reflection)\n//,head_position=[h] (becomes light source position)\n//,[r]=remaining_SHADOW_reflections\n//, accumulative color=[c]\n//,accumulative color=[rr]\n//,reflectionJuice=[sg]\n\n//return softShadow Occlusion at (surface) position [p] for light source s\n//shadow calculation is scaled by [r]\n//good FAST soft , mathematically its hard to describe approximation\nfloat shadow(vec3 s,vec3 p,float r)//lightSource,Position,r=softness\n{float zFar=sqrt(iResolution.y*zFarE)\n//;if(length(s-p)>zFar*.1)return .0//near max distance, all is in perpetual haze.\n//this diminishes contrast at the \"horizon of an infinite forest\".\n;vec3 dir=normalize(s-p)\n;float l=length(p-s)\n;float o=r*l//occlusion accumulator\n;float t=.0// distance traveled\n;float iterShB=.25;\n;float sd=0.;\n;for (float i=.0;i<iterShadow;++i){//i wish i knew WHY this looks good, it just does!\n;sd=df(p+l*dir*smoothstep(-l*.5,l,t))// /sqrt(l)//soft shadow\n;if(sd<-r)return .0;//100% occlusion cases\n//;if(t>zFar*.1)\n   // return step(.5,o);\n//   return smoothstep(.0,1.,o);//far away points are stepped;\n;sd=min(sd,df(p+dir*smoothstep(-(l)*i,i*l,iterShB))/iterShB);//optional,enforce tangential shadow lines\n\t\t//i would like to soften that one!\t\n        //this dies a hardshaddow within softshadow\n        \n        o=min(o,sd/t);\n\t\t//t +=max(l/iterShadow,sd);\n\t\tt +=max(l*iterShB/iterShadow,sd);\n\t\tif (t>l) break;\n\t}\n\to=clamp((o*l + r) / (2.*r), 0., 1.);\n\to=smoothstep(0.,1.,o);//optional hermite interpolation between samples\n\treturn min(1.,o);\n}\n\nvec4 getColor(vec3 o,vec3 d,vec3 h,inout float r,vec4 c,inout float sg)\n{vec3 n=dfd1(o,1e4);//surface normals, gradient first derivative\n;vec3 rr;//accumulated color of THIS iteration.\n;vec3 curvature=dfd1(n,1e4);//surface curvatuve, gradient second derivative\n;vec3 rainbow=sin(o)//diffuse https://www.google.de/search?q=unicorn+puking+rainbows\n//;return vec4(rainbow,1.);//debug axe;\n;vec2 m=iMouse.xy/iResolution.xy;\n//above is diffuse color without ambient effects. below is ambience and reflection code\n;vec3 s=vec3(.0);\n //#if (LightSources>0)\n;if(r>0.//accumulate one more shadow (for a shadow in iterateable reflections)\n){      s=vec3(0,.5,.5)*shadow(h      ,o,.5)//first  shadow of green light, looks red\n #if (LightSources>1)\n ;s=max(s,vec3(1, 0, 0)*shadow(vec3(1),o,.5))//second shadow of red light, looks blue.\n #endif\n //different materials may have diferent reflectiveness\n // that must be done outside of this function!\n     \n //;rr=mix(shadowColor,c.xyz,sat(o.y/7.));\n //;float attenuation=sat(dot(n,normalize(h)));\n //;s=min(s,attenuation)\n //;rr=mix(shadowColor,c.xyz,s)\n //;float AO=AmbientOcclusion(o,n,1.,7.)\n //;rr=mix(shadowColor,c.xyz,AO)\n //;r--\n \n // ;rr=shadowColor*AO;\n; }\n //#endif\n;rainbow=mix(s,rainbow,m.y);\n//;rainbow=mix(rainbow,s,m.y*1.5+.5);//.x also sets \"shadow sharpness\", off scaling is useful\n#if (debugCheckerCalculus>0)\n;float b=checkerBoard(o,vec3(1))//checkerboard for normal and curvature because\n;n=mix(n,curvature,b);//...it makes little sense to mix normal and curvature\n;rr=mix(rainbow,n,m.y*float(debugCheckerCalculus)/256.);//to debug, mix diffuse with \"derivative checkerboard\"\n#else\n;rr=rainbow\n#endif\n   \n//;rr=rainbow//debug axe no shadows\n//beware that mixing different types of disrtances messes up ANY normal\n//and dfd1(df()) has df() mix euclidean (trees) with .y (floor) distances.\n//above are mixed by m.y, below is mixed by m.x\n \n //reflection code:\n;float refl=.4;//reflectiveness of a material, should be set outside of this function at some point\n //if (mtl==GROUND_MTL)refl=.2;\n \n //this one is a tricy bitch:\n //ray is tinted in [c.xyz], and the surface is tintet in [rr]\n //\n rr=mix(rr,c.xyz,sg);\n \n sg=sg*refl;\n //if(sg<0.1)\n {\n     return vec4(rr,1);\n     }//ran out of reflectiveness juice.\n d=d-(n*2.*(dot(d,n))); \n \n//;\n //return vec4(rr,1);\n    return vec4(n,1);\n}\n//a good fast shadow, it needs cauchy distribution modificatiin\n//but without it it is still retty good\n//https://www.shadertoy.com/view/llfcDS\n\n//on shadow:\n//all shaddows are multi-sampling occlusions\n//sample points are arbitiarly linear spread (from light source to surface)\n//moving sample points by hermite spline makes sense\n//the trick to best sampling is do;\n// \"cauchyDistribution(dot(camerPos,ShadowRayDirection))\"\n//calculate a dotproduct to project the camera position onto the shadow-ray\n// To get the point on the shadow ray that is closest to the camera.\n//Ssample points should have a higher density around that area\n// I think Cauchy.Distribution is good for this.\n\n//sample weights are arbitiary, the weights make the shadow smooth.\n//the weighting is the tricky part. i use a lot of smoothstep for this=\n\n\n//return color from raymarching (and tracing) a distance field\n//RayOrigin=[o]\n//RayDirection=[t]\n//HeadPosition=[h] (is camera pivot point, useful for an \"avatar\")\n// for the option to see your own (body feet) or at least its shadow.\n// [h] is independent from the camera, allowing for 3rd person perspectives.\nvec4 render(vec3 o,vec3 t,vec3 h)//rayOrigin,RayTarget,headOffset\n{vec4 c=vec4(0)//color accumulator\n//;vec3 rr=vec3(0)//color accumulator\n;float r=iterMaxReflectionsWithShadows\n;float d=.0\n;float sg=1.;//something on reflections\n;vec3 feet=vec3(0,-2,0)\n;float zFar=sqrt(iResolution.y*zFarE)\n;for(float i=.0;i<iterMarch;i++\n){float a=o.y-h.y-feet.y*.5//avatar vars\n ;a=min(df(o),length(vec3(o.xz-(h.xz+feet.xz),a-clamp(a,-1.,1.)))-.5)//avatar shape\n //;d+=a\n ;o+=t*a//add distance to avatar surface\n ;if(d>zFar)break;\n ;bool bo=0.<log(d*d*eps/a);\n #ifdef DynamicEps\n ;bo=a <        eps  ;\n #endif\n ;if(bo){//if we are close to a surface\n     \n     \n     \n     c=getColor(o,t,h,r,c,sg);\n     \n }\n}//if(d<=zFar)r=getColor(o,t,h,remaining_SHADOW_reflections,r,sg);\n;return c;}\n\n\nvoid mainImage( out vec4 o, in vec2 u)\n{bool b=all(equal(tf(6,0),vec4(1)))\n;if(u.y<1.)o = setvariables(int(u.x))\n;else\n {vec2 uv=(u.xy*2.-iResolution.xy)/iResolution.y\n ;vec3 p=tf(INDEX_CAM,0).xyz\n ;vec3 dir = rotatecam(normalize(vec3(uv,1)))\n ;vec4 posdist=render(p-rotatecam(vec3(0,0,distCam2Pivot))*4.+vec3(0,1,0),dir, p)\n ;p=posdist.xyz;\n //;float dist=posdist.w\n ;o=vec4(u5(sin(p)),1);}\n}\n\n\n/*\n      ^\n      |\n     38\n <--37 39-->\n     40\n      |\n      v\n*/\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}