{
    "Shader": {
        "info": {
            "date": "1653318376",
            "description": "Maps a texture to a plane using any arbitrary 2D vector field to give orientation. Places no constraints/requirements on vector field at all. Downside is lots of blending of samples. Right side naively computes tangent frame directly from vector field.",
            "flags": 0,
            "hasliked": 0,
            "id": "NddcDr",
            "likes": 66,
            "name": "Bracketing",
            "published": 3,
            "tags": [
                "uv",
                "mapping",
                "interpolation"
            ],
            "usePreview": 0,
            "username": "huwb",
            "viewed": 2105
        },
        "renderpass": [
            {
                "code": "// 'Bracketing' technique maps a texture to a plane using any arbitrary 2D vector field to give orientation\n// Copyright Huw Bowles May 2022\n// MIT license\n\n// Explanation: https://twitter.com/hdb1/status/1528761299701841921\n\n// A problem I've had working on water systems is having waves travel in arbitrary directions on a 2D plane, for example to align to\n// shorelines. While one can create a custom UV mapping that tracks a shoreline, this can easily break down if shoreline is non trivial\n// shape (high curvature, concave, small islands very close to shore). What we ideally want is to be able to map a texture onto\n// any arbitrary vector field, for example a vector to nearest coastline position.\n\n// A brute force approach would simply construct a UV coordinate frame directly from the vector field and use this to calculate\n// UVs, which is shown in the right pane). Unfortunately this breaks down badly. The problem is that the UVs vary\n// wildly across pixels and feeding these UVs directly as input to a function like texture sampling creates crazy high frequencies\n// and distortions in the function output.\n\n// Instead of feeding in wild varying UV input into the function, we snap the vector field direction to a set of canonical directions\n// (for example every 15 degrees), evaluate the function at the snapped angle and the other nearby snapped angle, and then\n// blend the outputs of the function based on the angle. So the function does it's thing on stable inputs, and we blend the outputs.\n// To make this snapping obvious, set AngleDelta below to PI/5.0 and inspect the vector field which blends directions using this\n// approach.\n\n// The result tends to be very robust. The vector field I use below from iChannel1 is very bad quality, see the left side of the screen.\n// Click the mouse to apply a circular vector field which is high quality, but exhibits extreme distortion without our bracketing method\n// (again compare with left hand side).\n\n// Blending artifacts are visible, and result is blurred. There are ways to combat this blurring such as histogram. But if the function\n// is animated the blending may not be noticeable at all. This approach has been very effective in the Crest Ocean System.\n\n// The worst remaining issues are where the vector field is divergent - when nearby directions vary strongly such as a sink/source. This\n// can potentially be masked out (enable MaskOutDivergence) or an extra sample can re-add in using a given frame which can work (enable\n// ReplaceDivergence).\n\n// As a final bonus, one can animate the UVs to create a \"flow\" effect as shown here. However this only supports flow which has a fixed\n// global speed rather than varying flow speeds. The flow technique could be applied on top of this.\n\n\n// Defined in Common tab\n//const float PI = 3.141592654;\n\nconst float RightPaneSize = 0.3;\nconst bool ShowVectorField = true;\nconst bool ShowBruteForceMethod = true;\nconst bool ColouriseSamples = false;\n\n// In diverging areas, take one more sample to get \"something\". For waves, blending in this additional sample\n// in the wind direction works well.\nconst bool ReplaceDivergence = true;\nconst bool MaskOutDivergence = false;\n\nconst float UVSpeedTexture = 1.0 / 160.0;\nconst float UVSpeedVectorField = 1.0 / 2000.0;\n\n// Parameter for bracketing - bracket size in radians. Large values create noticeable linear structure,\n// small values prone to simply replicating the issues with the brute force approach. In my use cases it\n// was quick and easy to find a sweet spot.\nconst float AngleDelta = PI / 20.0;\nconst mat2x2 RotateByAngleDelta = mat2x2(cos(AngleDelta), sin(AngleDelta), -sin(AngleDelta), cos(AngleDelta));\n\nvec2 CalculateUV(vec2 vAxis, vec2 position)\n{\n    vec2 uAxis = vec2(-vAxis.y, vAxis.x);\n    vec2 uv = vec2( dot(position, uAxis), dot(position, vAxis) );\n    // Animate\n    uv.y -= iTime * UVSpeedTexture;\n    return uv;\n}\n\n// This should return the normal to the field, which the texture will orient to.\n// This can be a normalized vector, but does not need to be. This shader\n// uses the length of the normal to mask out divergences. This is a mechanism\n// to hint that there is a divergence.\nvec2 Normal(vec2 position)\n{\n    vec2 aspect = vec2( iResolution.x / iResolution.y, 1.0 );\n    \n    if (iMouse.z > 0.0)\n    {\n        vec2 uvMouse = aspect * iMouse.xy / iResolution.xy;\n        return position - uvMouse;\n    }\n    else\n    {\n        // Sample normal from texture 1. This gives a very bad quality vector field, which\n        // helps to demonstrate the robustness of this technique.\n        vec2 posScaled = position / 8.0 + vec2(0.4, 0.5);\n        posScaled -= (iTime+35.0) * vec2(1.0, 1.33) * UVSpeedVectorField;\n        float lodBias = 4.0;\n        float v = textureLod(iChannel1, posScaled, lodBias).x;;\n        vec2 dx_0 = vec2(0.2, 0.0);\n        float v_x = textureLod(iChannel1, posScaled + dx_0.xy, lodBias).x;;\n        float v_y = textureLod(iChannel1, posScaled + dx_0.yx, lodBias).x;;\n        vec2 normal = vec2(v_x, v_y) - v;\n        \n        // If we don't normalize, the grad vector will go to 0 at divergent points.\n        // This term can be used as a mask.\n        if(!MaskOutDivergence && !ReplaceDivergence)\n        {\n            normal = normalize(normal);\n        }\n        return normal;\n    }\n}\n\n// This is whatever 2D function we want to map on the plane, such as sampling a texture\nvec4 Function(vec2 uv)\n{\n    return textureLod(iChannel0, uv, 1.0);\n}\n\n// Vector field direction is used to drive UV coordinate frame, but instead\n// of directly taking the vector directly, take two samples of the texture\n// using coordinate frames at snapped angles, and then blend them based on\n// the angle of the original vector.\nvoid Bracketing(vec2 normal, out vec2 vAxis0, out vec2 vAxis1, out float blendAlpha)\n{\n    // Heading angle of the original vector field direction\n    float angle = atan(normal.y, normal.x) + 2.0*PI;\n\n    // Snap to a first canonical direction by subtracting fractional angle\n    float fractional = mod(angle, AngleDelta);\n    float angle0 = angle - fractional;\n    \n    // Compute one V axis of UV frame. Given angle0 is snapped, this could come from LUT, but would\n    // need testing on target platform to verify that a LUT is faster.\n    vAxis0 = vec2(cos(angle0), sin(angle0));\n\n    // Compute the next V axis by rotating by the snap angle size\n    vAxis1 = RotateByAngleDelta * vAxis0;\n\n    // Blend to get final result, based on how close the vector was to the first snapped angle\n    blendAlpha = fractional / AngleDelta;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 aspect = vec2( iResolution.x / iResolution.y, 1.0 );\n    \n    vec2 uvPixel = aspect * fragCoord / iResolution.xy;\n    \n    // Normal is vector field direction, used to create UV coordinate frame\n    vec2 normal = Normal(uvPixel);\n    \n    // Demo things\n    float tNormalised = fract(iTime / 6.0);\n    bool vectorFieldOn = ShowVectorField && tNormalised > 0.5; // fragCoord.y/iResolution.y<0.3\n    bool bruteForceMethod = ShowBruteForceMethod && fragCoord.x/iResolution.x>(1.0-RightPaneSize);\n    \n    float uvScale = 4.0;\n    // Blur a bit to see vector field easier\n    //float lodBias = vectorFieldOn ? 3.0 : 1.0;\n\n    if (!bruteForceMethod)\n    {\n        ////////////////// Technique for texturing using UVs from vector field starts here! //////////////////\n        \n        vec2 vAxis0, vAxis1;\n        float blendAlpha;\n        Bracketing(normal, vAxis0, vAxis1, blendAlpha);\n        \n        // Compute the function for the two canonical directions\n        vec2 uv0 = uvScale * CalculateUV(vAxis0, uvPixel);\n        vec2 uv1 = uvScale * CalculateUV(vAxis1, uvPixel);\n        \n        // Now sample function/texture\n        vec4 sample0 = Function(uv0);\n        vec4 sample1 = Function(uv1);\n        \n        if (ColouriseSamples)\n        {\n            sample0.xy *= 0.5;\n            sample1.yz *= 0.5;\n        }\n        \n        // Blend to get final result, based on how close the vector was to the first snapped angle\n        fragColor = mix( sample0, sample1, blendAlpha );\n        \n        ////////////////// Technique for texturing using UVs from vector field ends here! //////////////////\n    }\n    else\n    {\n        fragColor = Function(uvScale * CalculateUV(normalize(normal), uvPixel));\n    }\n    \n    // Moar visualisation - colourise background based on vector field\n    if( false )\n    {\n        fragColor = vec4(0.5 + 0.35 * normalize(normal), 0.5, 1.0);\n    }\n    \n    if (!bruteForceMethod)\n    {\n    \n        // Apply patch\n        if (ReplaceDivergence)\n        {\n            float strength = smoothstep(0.0, 0.2, length(normal)*3.0);\n            vec2 arbitraryDirection = -vec2(cos(0.5),sin(0.5));\n            fragColor = mix(Function(uvScale * CalculateUV(arbitraryDirection, uvPixel)), fragColor, strength);\n        }\n        else if (MaskOutDivergence)\n        {\n            fragColor = mix(vec4(0.0, 1.0, 0.0, 1.0), fragColor, smoothstep(0.0, 0.2, length(normal)*3.0)); \n        }\n    }\n    \n\n    if (ShowBruteForceMethod && abs(fragCoord.x/iResolution.x - (1.0 - RightPaneSize)) < 2.0/iResolution.x)\n    {\n        fragColor = vec4(1.0);\n    }\n\n    if( vectorFieldOn )\n    {\n#if 0\n        // Output vector field directly\n        fragColor = max(0.8*fragColor, 0.9*arrow(uvPixel*iResolution.xy/aspect, normal*70.));\n#else\n        // Blend based on bracketing to show what is being used for the UV frame\n        vec2 arrowCenterUV = arrowTileCenterCoord(uvPixel*iResolution.xy/aspect)*aspect/iResolution.xy;\n        vec2 vAxis0, vAxis1;\n        float blendAlpha;\n        vec2 normalForArrow = Normal(arrowCenterUV);\n        Bracketing(normalForArrow, vAxis0, vAxis1, blendAlpha);\n        \n        float arrowVal = mix( arrow(uvPixel*iResolution.xy/aspect, vAxis0*70.), arrow(uvPixel*iResolution.xy/aspect, vAxis1*70.), blendAlpha);\n        \n        // Boost a bit\n        arrowVal = sqrt(arrowVal);\n        \n        if(MaskOutDivergence)\n        {\n            //arrowVal *= smoothstep(0.0, 0.2, length(normalForArrow)*3.0);\n        }\n        fragColor = max(0.8*fragColor, arrowVal);\n#endif\n    }\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "texture",
                        "id": 1,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/10eb4fe0ac8a7dc348a2cc282ca5df1759ab8bf680117e4047728100969e7b43.jpg"
                    },
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 47,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/ad56fba948dfba9ae698198c109e71f118a54d209c0ea50d77ea546abad89c57.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// Shared code\n\nconst float PI = 3.141592654;\n\n// From https://www.shadertoy.com/view/4s23DG\n// Morgan McGuire, @morgan3d, http://casual-effects.com\n\nconst int   ARROW_V_STYLE = 1;\nconst int   ARROW_LINE_STYLE = 2;\n\n// Choose your arrow head style\nconst int   ARROW_STYLE = ARROW_LINE_STYLE;\nconst float ARROW_TILE_SIZE = 32.0;\n\n// How sharp should the arrow head be? Used\nconst float ARROW_HEAD_ANGLE = 45.0 * PI / 180.0;\n\n// Used for ARROW_LINE_STYLE\nconst float ARROW_HEAD_LENGTH = ARROW_TILE_SIZE / 6.0;\nconst float ARROW_SHAFT_THICKNESS = 3.0;\n\t\n\n\n// Computes the center pixel of the tile containing pixel pos\nvec2 arrowTileCenterCoord(vec2 pos) {\n\treturn (floor(pos / ARROW_TILE_SIZE) + 0.5) * ARROW_TILE_SIZE;\n}\n\n\n// v = field sampled at tileCenterCoord(p), scaled by the length\n// desired in pixels for arrows\n// Returns 1.0 where there is an arrow pixel.\nfloat arrow(vec2 p, vec2 v) {\n\t// Make everything relative to the center, which may be fractional\n\tp -= arrowTileCenterCoord(p);\n\t\t\n    float mag_v = length(v), mag_p = length(p);\n\t\n\tif (mag_v > 0.0) {\n\t\t// Non-zero velocity case\n\t\tvec2 dir_p = p / mag_p, dir_v = v / mag_v;\n\t\t\n\t\t// We can't draw arrows larger than the tile radius, so clamp magnitude.\n\t\t// Enforce a minimum length to help see direction\n\t\tmag_v = clamp(mag_v, 5.0, ARROW_TILE_SIZE / 2.0);\n\n\t\t// Arrow tip location\n\t\tv = dir_v * mag_v;\n\t\t\n\t\t// Define a 2D implicit surface so that the arrow is antialiased.\n\t\t// In each line, the left expression defines a shape and the right controls\n\t\t// how quickly it fades in or out.\n\n\t\tfloat dist;\t\t\n\t\tif (ARROW_STYLE == ARROW_LINE_STYLE) {\n\t\t\t// Signed distance from a line segment based on https://www.shadertoy.com/view/ls2GWG by \n\t\t\t// Matthias Reitinger, @mreitinger\n\t\t\t\n\t\t\t// Line arrow style\n\t\t\tdist = \n\t\t\t\tmax(\n\t\t\t\t\t// Shaft\n\t\t\t\t\tARROW_SHAFT_THICKNESS / 4.0 - \n\t\t\t\t\t\tmax(abs(dot(p, vec2(dir_v.y, -dir_v.x))), // Width\n\t\t\t\t\t\t    abs(dot(p, dir_v)) - mag_v + ARROW_HEAD_LENGTH / 2.0), // Length\n\t\t\t\t\t\t\n   \t\t\t         // Arrow head\n\t\t\t\t\t min(0.0, dot(v - p, dir_v) - cos(ARROW_HEAD_ANGLE / 2.0) * length(v - p)) * 2.0 + // Front sides\n\t\t\t\t\t min(0.0, dot(p, dir_v) + ARROW_HEAD_LENGTH - mag_v)); // Back\n\t\t} else {\n\t\t\t// V arrow style\n\t\t\tdist = min(0.0, mag_v - mag_p) * 2.0 + // length\n\t\t\t\t   min(0.0, dot(normalize(v - p), dir_v) - cos(ARROW_HEAD_ANGLE / 2.0)) * 2.0 * length(v - p) + // head sides\n\t\t\t\t   min(0.0, dot(p, dir_v) + 1.0) + // head back\n\t\t\t\t   min(0.0, cos(ARROW_HEAD_ANGLE / 2.0) - dot(normalize(v * 0.33 - p), dir_v)) * mag_v * 0.8; // cutout\n\t\t}\n\t\t\n\t\treturn clamp(1.0 + dist, 0.0, 1.0);\n\t} else {\n\t\t// Center of the pixel is always on the arrow\n\t\treturn max(0.0, 1.2 - mag_p);\n\t}\n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}