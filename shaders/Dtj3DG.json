{
    "Shader": {
        "info": {
            "date": "1674230731",
            "description": "A very simple physics-based ray-tracing renderer.\nWASDQE to move, SHIFT to accelerate, SPACE to refresh.\n\nmore info: https://shao.fun/blog/w/taichi-ray-tracing.html\ngithub: https://github.com/HK-SHAO/RayTracingPBR",
            "flags": 48,
            "hasliked": 0,
            "id": "Dtj3DG",
            "likes": 10,
            "name": "A very simple PBRT",
            "published": 3,
            "tags": [
                "3d",
                "interactive",
                "sdf",
                "camera",
                "pathtracing",
                "ibl",
                "pbr"
            ],
            "usePreview": 0,
            "username": "shaofun",
            "viewed": 964
        },
        "renderpass": [
            {
                "code": "// Fork of \"RayTracing PBR with Free Camera\" by shaofun. https://shadertoy.com/view/ddSSWy\n// 2023-01-16 08:11:26\n\n// Copyright © 2019-2023 HK-SHAO\n// MIT Licensed: https://shao.fun/blog/w/taichi-ray-tracing.html\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(vec3 color) {\n\t// sRGB => XYZ => D65_2_D60 => AP1 => RRT_SAT\n    color *= mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color  = a / b;\n\t// ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color *= mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy;\n    vec4 color = texture(iChannel0, uv);\n    \n    color.rgb = color.rgb / color.a;\n    \n    // 伽马矫正\n    color.rgb *= camera_exposure;\n    color.rgb  = pow(color.rgb, vec3(1.0 / gamma));\n    \n    // 色调映射\n    color.rgb = ACESFitted(color.rgb);\n    \n    fragColor = vec4(color.rgb, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// Modified by HK-SHAO - 2022\n\n// Upgraded from genis sole - 2016\n// License Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International.\n\n#define store(P, V) if (all(equal(ivec2(fragCoord), P))) fragColor = V\n#define key(K)  texelFetch(iChannel0, ivec2(K, 0), 0).x\n#define load(P) texelFetch(iChannel1, ivec2(P), 0)\n\n// Keyboard constants definition\nconst int KEY_W     = 87;\nconst int KEY_A     = 65;\nconst int KEY_S     = 83;\nconst int KEY_D     = 68;\nconst int KEY_E     = 69;\nconst int KEY_Q     = 81;\nconst int KEY_SHIFT = 16;\nconst int KEY_SP    = 32;\n\nvec3 KeyboardInput() {\n\tvec3 i = vec3(key(KEY_D) - key(KEY_A), \n                  key(KEY_E) - key(KEY_Q),\n                  key(KEY_S) - key(KEY_W));\n    \n    float n = abs(abs(i.x) - abs(i.y));\n    return i * (n + (1.0 - n)*inversesqrt(2.0));\n}\n\nvec3 CameraDirInput(vec2 m) {\n    return CameraRotation(m) * KeyboardInput();\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {   \n    if (any(greaterThan(ivec2(fragCoord), MEMORY_BOUNDARY))) discard;\n    \n    fragColor = load(fragCoord);\n    \n    if (iFrame == 0) {\n        store(POSITION, vec4(0.0, 0.2, 4.0, 0.0));\n        store(ROTATION, vec4(0.0));\n        \n        store(TARGET,   vec4(0.0, -0.2, 4.0, 0.0));\n        store(TMOUSE,   vec4(0.0));\n        store(PMOUSE,   vec4(0.0));\n        \n        return;\n    }\n\n    vec2 resolution  = load(RESOLUTION).xy;\n    \n    vec3 position    = load(POSITION).xyz;\n    vec2 rotation    = load(ROTATION).xy;\n\n    vec3 target      = load(TARGET).xyz;\n    vec3 tm          = load(TMOUSE).xyz;\n    vec2 pm          = load(PMOUSE).xy;\n    \n    float dt = clamp(iTimeDelta, 0.0, 0.1);\n    \n    const float rt_acc = 16.0;\n    const float mv_acc = 5.0;\n    float velocity =  5.0 + 15.0 * key(KEY_SHIFT);\n    \n    rotation += (tm.xy - rotation) * dt * rt_acc;\n    target   += CameraDirInput(rotation) * dt * velocity;\n    position += (target - position) * dt * mv_acc;\n    \n    bvec4 moving = bvec4(\n        length(tm.xy - rotation) * iResolution.x > 1.0,\n        length(target - position) * iResolution.x > 1.0,\n        any(notEqual(resolution, iResolution.xy)),\n        key(KEY_SP) > 0.0\n    );\n    \n    store(TARGET,     vec4(target, 0.0));\n    store(POSITION,   vec4(position, 0.0));\n    store(ROTATION,   vec4(rotation, 0.0, 0.0));\n    store(RESOLUTION, vec4(iResolution.xy, 0.0, 0.0));\n    store(MOVING,     vec4(any(moving), 0.0, 0.0, 0.0));\n    \n\tif (iMouse.z > 0.0) {\n        vec2 new_tm  = pm + (abs(iMouse.zw) - iMouse.xy) / iResolution.x;\n        \n        float clamp_y = float(new_tm.y > -PI*0.5+0.01 && new_tm.y < PI*0.5-0.01);\n        new_tm.y = mix(tm.y, new_tm.y, clamp_y);\n        \n        store(TMOUSE, vec4(new_tm, 1.0, 0.0));\n\t} else if (tm.z != 0.0) {\n        store(PMOUSE, vec4(tm.xy, 0.0, 0.0));\n    }\n\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Copyright © 2019-2023 HK-SHAO\n// MIT Licensed: https://shao.fun/blog/w/taichi-ray-tracing.html\n\n// 数学常量\nconst float ZERO = 0.0;\nconst float PI   = 3.141592653589;\nconst float TAU  = 2.0 * PI;\n\nconst mat3 MAT3_NULL = mat3(vec3(0),vec3(0),vec3(0));\n\n// 摄像机参数\nconst float camera_vfov       = 30.0;                 // 摄像机的纵向视野\nconst float camera_focus      = 2.0;                  // 摄像机的对焦距离\nconst float camera_aperture   = 0.002;                // 摄像机的光圈大小\nconst float camera_exposure   = 0.8;                  // 摄像机曝光值\nconst float light_quality     = 128.0;                // 间接光质量\nconst float gamma             = 2.2;                  // 伽马矫正值\n\n// 配置常量\nconst float TMAX         = 2000.0;                    // 最大单次光线传播距离 (相当于可见范围)\nconst float VISIBILITY   = 0.0001;                    // 亮度可见度\n\nconst uint  MAX_RAYMARCH = 512U;                      // 最大光线步进次数\nconst uint  MAX_RAYTRACE = 128U;                      // 最大光线追踪次数\n\nconst float ENV_IOR      = 1.000277;                  // 环境的折射率 （空气）\n\n// 枚举形状\nconst int SHAPE_SPHERE   = 0;\nconst int SHAPE_BOX      = 1;\nconst int SHAPE_CYLINDER = 2;\n\n// SDF 球体\nfloat sd_sphere(vec3 p, float s) {\n    return length(p) - s;\n}\n\n// SDF 盒子\nfloat sd_box(vec3 p, vec3 b) {\n    vec3 q = abs(p) - b;\n    return length(max(q, 0.0)) + min(max(q.x, max(q.y, q.z)), 0.0) - 0.03;\n}\n\n// SDF 圆柱\nfloat sd_cylinder(vec3 p, vec2 rh) {\n    vec2 d = abs(vec2(length(p.xz), p.y)) - rh;\n    return min(max(d.x, d.y), 0.0) + length(max(d, 0.0));\n}\n\nfloat seed; // 随机数种子\n\n// 用随机数种子产生归一化的随机数\nfloat rand13(vec3 x) {\n    uvec3 p = floatBitsToUint(x);\n    p = 1103515245U * ((p.xyz >> 1U) ^ (p.yzx));\n    uint h32 = 1103515245U * ((p.x ^ p.z) ^ (p.y >> 3U));\n    uint n = h32 ^ (h32 >> 16U);\n    return float(n) * (1.0 / float(0xffffffffU));\n}\n\nfloat rand11() {\n    uvec2 n = floatBitsToUint(seed++) * uvec2(1597334673U, 3812015801U);\n    uint q = (n.x ^ n.y) * 1597334673U;\n    return float(q) * (1.0 / float(0xffffffffU));\n}\n\nvec2  rand21() {\n    uvec2 n = floatBitsToUint(seed++) * uvec2(1597334673U, 3812015801U);\n    n = (n.x ^ n.y) * uvec2(1597334673U, 3812015801U);\n    return vec2(n) * (1.0 / float(0xffffffffU));\n}\n\n// Buffer A Shared\nconst ivec2 MEMORY_BOUNDARY = ivec2(4, 3);\n\nconst ivec2 PMOUSE     = ivec2(0, 0);\nconst ivec2 TARGET     = ivec2(1, 0);\nconst ivec2 TMOUSE     = ivec2(2, 0);\n\nconst ivec2 RESOLUTION = ivec2(0, 1);\nconst ivec2 POSITION   = ivec2(1, 1);\nconst ivec2 ROTATION   = ivec2(2, 1);\n\nconst ivec2 MOVING     = ivec2(0, 2);\n\nmat3 CameraRotation(vec2 m) {\n    m *= mat2(vec2(0, -1), vec2(1, 0));\n    vec2 s = sin(m), c = cos(m);\n    \n    mat3 rotX = mat3(1.0, 0.0, 0.0, 0.0, c.x, s.x, 0.0, -s.x, c.x);\n    mat3 rotY = mat3(c.y, 0.0, -s.y, 0.0, 1.0, 0.0, s.y, 0.0, c.y);\n    \n    return rotY * rotX;\n}\n\n// Update History\n\n// 2023.01.27\n// Fix the order of tone mapping.\n\n// 2023.01.26\n// Fixes placing objects inside the glass, but reduces a few frames.\n\n// 2023.01.25\n// Use enhanced sphere tracing to accelerate the intersection. About 10 fps improvement.\n// http://erleuchtet.org/~cupe/permanent/enhanced_sphere_tracing.pdf\n\n// https://www.shadertoy.com/view/ddSSWy before 2023.01.17",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// Copyright © 2019-2023 HK-SHAO\n// MIT Licensed: https://shao.fun/blog/w/taichi-ray-tracing.html\n\n#define load(P) texelFetch(iChannel1, ivec2(P), 0)\n\n// 光线\nstruct ray {\n    vec3 origin;        // 光的起点\n    vec3 direction;     // 光的方向\n    vec3 color;         // 光的颜色\n};\n\n// 物体材质\nstruct material {\n    vec3  albedo;       // 反照率\n    vec3  emission;     // 自发光\n    float roughness;    // 粗糙度\n    float metallic;     // 金属度\n    float transmission; // 透明度\n    float ior;          // 折射率\n};\n\n// 物体变换\nstruct transform {\n    vec3 position;      // 位置\n    vec3 rotation;      // 旋转\n    vec3 scale;         // 缩放\n    mat3 matrix;        // 旋转矩阵\n};\n\n// SDF 物体\nstruct object {\n    int       shape;    // 形状\n    float     dis;      // 距离物体表面\n    transform trs;      // 变换\n    material  mtl;      // 材质\n};\n\n// 光子击中的记录\nstruct record {\n    object obj;         // 物体\n    vec3   pos;         // 击中的位置\n    vec3   normal;      // 世界空间法线\n    bool   hit;         // 是否击中\n};\n\n// 摄像机\nstruct camera {\n    vec3  lookfrom;     // 视点位置\n    vec3  lookat;       // 目标位置\n    vec3  vup;          // 向上的方向\n    float vfov;         // 视野角度\n    float aspect;       // 传感器长宽比\n    float aperture;     // 光圈大小\n    float focus;        // 对焦距离\n};\n\n// 全局变量\nfloat pixradius;\nfloat bias;\n\n// 地图列表\nobject[] map = object[] (\n    object(SHAPE_SPHERE, ZERO,\n        transform(  vec3(0, -100.501, 0),\n                    vec3(0, 0, 0),\n                    vec3(100, 100, 100), MAT3_NULL\n        ),\n        material(   vec3(1.0, 1.0, 1.0)*0.6, // 基础色\n                    vec3(1), // 自发光\n                    0.9, // 粗糙度\n                    0.1, // 金属度\n                    0.0, // 透明度\n                    1.635  // 折射率 （沥青）\n        )\n    ),\n    object(SHAPE_SPHERE, ZERO,\n        transform(  vec3(0, 1, 0),\n                    vec3(0, 0, 0),\n                    vec3(0.5, 0.5, 0.5), MAT3_NULL\n        ),\n        material(   vec3(1.0, 1.0, 1.0), // 基础色\n                    vec3(1.0, 100.0, 1.0), // 自发光\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.000  // 折射率 （真空）\n        )\n    ),\n    object(SHAPE_CYLINDER, ZERO,\n        transform(  vec3(-1.0, -0.2, 0),\n                    vec3(0, 0, 0),\n                    vec3(0.3, 0.3, 0.3), MAT3_NULL\n        ),\n        material(   vec3(1.0, 0.2, 0.2), // 基础色\n                    vec3(1), // 自发光\n                    0.1, // 粗糙度\n                    0.0, // 金属度\n                    0.0, // 透明度\n                    1.460  // 折射率 （塑料）\n        )\n    ),\n    object(SHAPE_SPHERE, ZERO,\n        transform(  vec3(1.0, -0.2, 0),\n                    vec3(0, 0, 0),\n                    vec3(0.3, 0.3, 0.3), MAT3_NULL\n        ),\n        material(   vec3(0.2, 0.2, 1.0), // 基础色\n                    vec3(1), // 自发光\n                    0.2, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    1.100  // 折射率 （铜）\n        )\n    ),\n    object(SHAPE_SPHERE, ZERO,\n        transform(  vec3(0.0, -0.2, 2),\n                    vec3(0, 0, 0),\n                    vec3(0.3, 0.3, 0.3), MAT3_NULL\n        ),\n        material(   vec3(1.0, 1.0, 1.0)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    0.0, // 粗糙度\n                    0.0, // 金属度\n                    1.0, // 透明度\n                    1.500  // 折射率 （玻璃）\n        )\n    ),\n    object(SHAPE_BOX, ZERO,\n        transform(  vec3(0, 0, 5),\n                    vec3(0, 0, 0),\n                    vec3(2, 1, 0.2), MAT3_NULL\n        ),\n        material(   vec3(1.0, 1.0, 0.2)*0.9, // 基础色\n                    vec3(1), // 自发光\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    0.470  // 折射率 （金）\n        )\n    ),\n    object(SHAPE_BOX, ZERO,\n        transform(  vec3(0, 0, -1),\n                    vec3(0, 0, 0),\n                    vec3(2, 1, 0.2), MAT3_NULL\n        ),\n        material(vec3(1.0, 1.0, 1.0)*0.5, // 基础色\n                    vec3(1), // 自发光\n                    0.0, // 粗糙度\n                    1.0, // 金属度\n                    0.0, // 透明度\n                    2.950  // 折射率 （铁）\n        )\n    )\n);\n\n// 光子在射线所在的位置\nvec3 at(ray r, float t) {\n    return r.origin + t * r.direction;\n}\n\n// 单位圆内随机取一点\nvec2 random_in_unit_disk() {\n    vec2 r = rand21() * vec2(1.0, TAU);\n    return sqrt(r.x) * vec2(sin(r.y), cos(r.y));\n}\n\n// 从摄像机获取光线\nray get_ray(camera c, vec2 uv, vec3 color) {\n    // 根据 VFOV 和显示画布长宽比计算传感器长宽\n    float theta = radians(c.vfov);\n    float half_height = tan(theta * 0.5);\n    float half_width = c.aspect * half_height;\n    \n    // 以目标位置到摄像机位置为 Z 轴正方向\n    vec3 z = normalize(c.lookfrom - c.lookat);\n    // 计算出摄像机传感器的 XY 轴正方向\n    vec3 x = normalize(cross(c.vup, z));\n    vec3 y = cross(z, x);\n    \n    // 模拟光进入镜头光圈\n    float lens_radius = c.aperture * 0.5;\n    vec2  rud = lens_radius * random_in_unit_disk();\n    vec3  offset = x * rud.x + y * rud.y;\n    \n    // 计算半高、半宽、左下角位置等\n    vec3 hwfx = half_width  * c.focus * x;\n    vec3 hhfy = half_height * c.focus * y;\n    \n    vec3 lower_left_corner = c.lookfrom - hwfx - hhfy - c.focus * z;\n    \n    vec3 horizontal = 2.0 * hwfx;\n    vec3 vertical   = 2.0 * hhfy;\n    \n    // 计算光线起点和方向\n    vec3 ro = c.lookfrom + offset;\n    vec3 po = lower_left_corner + uv.x * horizontal + uv.y * vertical;\n    vec3 rd = normalize(po - ro);\n    \n    return ray(ro, rd, color);\n}\n\n// 从欧拉角计算旋转矩阵\nmat3 angle(vec3 a) {\n    vec3 s = sin(a), c = cos(a);\n    return mat3(vec3( c.z,  s.z,    0),\n                vec3(-s.z,  c.z,    0),\n                vec3(   0,    0,    1)) *\n           mat3(vec3( c.y,    0, -s.y),\n                vec3(   0,    1,    0),\n                vec3( s.y,    0,  c.y)) *\n           mat3(vec3(   1,    0,    0),\n                vec3(   0,  c.x,  s.x),\n                vec3(   0, -s.x,  c.x));\n}\n\n// 计算有向距离 (物体内部距离为负)\nfloat signed_distance(object obj, vec3 pos) {\n    vec3 position = obj.trs.position;\n    vec3 rotation = obj.trs.rotation;\n    vec3 scale    = obj.trs.scale;\n    mat3 matrix   = obj.trs.matrix;\n    \n    vec3 p = pos - position;\n    p *= matrix;\n    \n    switch(obj.shape) {\n        case SHAPE_SPHERE:\n            return sd_sphere(p, scale.x);\n        case SHAPE_BOX:\n            return sd_box(p, scale);\n        case SHAPE_CYLINDER:\n            return sd_cylinder(p, scale.xy);\n        default:\n            return sd_sphere(p, scale.x);\n    }\n}\n\n// 找到最近的物体并计算距离\nobject nearest_object(vec3 p) {\n    object o = map[0]; o.dis = signed_distance(o, p);\n    for (int i = 1; i < map.length(); i++) {\n        object oi = map[i];\n        oi.dis = signed_distance(oi, p);\n        if (oi.dis < o.dis) o = oi;\n    }\n    return o;\n}\n\n// 计算物体法线 from https://iquilezles.org/articles/normalsSDF/\nvec3 calc_normal(object obj, vec3 p) {\n    vec2 e = vec2(1, -1) * 0.5773 * 0.005;\n    return normalize( e.xyy*signed_distance(obj, p + e.xyy) + \n                      e.yyx*signed_distance(obj, p + e.yyx) + \n                      e.yxy*signed_distance(obj, p + e.yxy) + \n                      e.xxx*signed_distance(obj, p + e.xxx) );\n}\n\n// 光线步进检测第一个交点 from http://erleuchtet.org/~cupe/permanent/enhanced_sphere_tracing.pdf\nrecord raycast(ray r) {\n    record rec; float w = 1.6, t = bias, s = 0.0, d = 0.0;\n    \n    for (uint i = 0U; i < MAX_RAYMARCH && t < TMAX && !rec.hit; i++) {\n        rec.pos = at(r, t);\n        rec.obj = nearest_object(rec.pos);\n\n        float ld = d; d = abs(rec.obj.dis);\n        \n        if (w > 1.0 && ld + d < s) {\n            s -= w * s; t += s; w = 1.0;\n            continue;\n        }\n        \n        rec.hit = d < pixradius * t;\n        \n        t += s = w * d;\n    }\n    return rec;\n}\n\n// 采样天空\nvec3 sky(ray r, float brightness, float lod) {\n    vec3 ibl = textureLod(iChannel2, r.direction, lod).rgb; // 天空盒 IBL 照明\n    return pow(ibl * brightness, vec3(gamma)); // gamma 矫正\n}\n\n// 菲涅尔反射近似值\nfloat fresnel_schlick(float NoI, float F0) {\n    return mix(pow(abs(1.0 + NoI), 5.0), 1.0, F0);\n}\n\n// 用粗糙度计算菲涅尔\nfloat fresnel_schlick(float NoI, float F0, float roughness) {\n    return mix(fresnel_schlick(NoI, F0), F0, roughness);\n}\n\n// 在切线空间半球采样\nvec3 hemispheric_sampling(vec3 nor) {\n    vec2  r = rand21() * vec2(2.0, TAU) - vec2(1, 0);\n    float z = r.x;\n    vec2 xy = sqrt(1.0 - z*z) * vec2(sin(r.y), cos(r.y));\n    \n    return normalize(nor + vec3(xy, z));\n}\n\n// 用粗糙度改变采样方向\nvec3 roughness_sampling(vec3 hemispheric_sample, vec3 nor, float roughness) {\n    float alpha = roughness * roughness;\n    return normalize(mix(nor, hemispheric_sample, alpha));\n}\n\n// 应用 PBR 材质\nray ray_surface_interaction(ray r, record rec) {\n    // 材质参数\n    vec3  albedo       = rec.obj.mtl.albedo;\n    float roughness    = rec.obj.mtl.roughness;\n    float metallic     = rec.obj.mtl.metallic;\n    float transmission = rec.obj.mtl.transmission;\n    float ior          = rec.obj.mtl.ior;\n    \n    vec3 normal = rec.normal;\n    bool outer = dot(normal, r.direction) < 0.0; // 光正在从外面穿入物体表面\n    \n    vec3 I  =  r.direction; // 入射光方向\n    vec3 N  =  normal *= outer ? 1.0 : -1.0; // 如果处于 SDF 物体内部就反过来\n    vec3 C  =  r.color; // 光的颜色\n    vec3 L; // 出射光方向\n    \n    vec3 hemispheric_sample = hemispheric_sampling(normal); // 切线空间的半球采样方向\n    \n    N = roughness_sampling(hemispheric_sample, normal, roughness);\n    float NoI = dot(N, I);\n\n    float eta = outer ? ENV_IOR / ior : ior / ENV_IOR; // 计算折射率之比\n    float k   = 1.0 - eta * eta * (1.0 - NoI * NoI); // 小于 0 为全反射\n    float F0  = (eta - 1.0) / (eta + 1.0); F0 *= 2.0*F0; // 让透明材质的反射更明显一些\n    float F   = fresnel_schlick(NoI, F0, roughness); // 菲涅尔\n\n    vec2 rand2 = rand21(); // 取两个随机数\n    if (rand2.x < F + metallic || k < 0.0) {\n        L = I - 2.0 * NoI * N; // 包含镜面反射、菲涅尔反射、全反射\n        // 下面可以提高帧数，但是会导致透明材质发黑，需要优化\n        C *= float(dot(L, normal) > 0.0); // 如果光穿入或穿出表面就直接吸收掉\n    } else if (rand2.y < transmission) {\n        L = eta * I - (sqrt(k) + eta * NoI) * N; // 斯涅尔折射\n    } else {\n        L = hemispheric_sample; // 漫反射\n    }\n\n    C *= albedo;\n\n    // 更新光的方向和颜色\n    r.color     = C;\n    r.direction = L;\n    r.origin += normal * bias * sign(dot(L, normal)); // 偏移一点\n    \n    return r;\n}\n\n// RGB 亮度\nfloat brightness(vec3 rgb) {\n    return dot(rgb, vec3(0.299, 0.587, 0.114));\n}\n\n// 光线追踪\nray raytrace(ray r) {\n    for (uint i = 0U; i < MAX_RAYTRACE; i++) {\n        // 俄罗斯轮盘赌概率，防止光线过分的反复反射\n        float roulette_prob = 1.0 - float(i / MAX_RAYTRACE);\n    \n        // 光线被毙掉就不用继续了\n        if (rand11() > roulette_prob) {\n            r.color *= 1.0 - roulette_prob;\n            break;\n        }\n        \n        // 与地图求交\n        record rec = raycast(r);\n        \n        // 没击中物体就肯定击中天空\n        if (!rec.hit) {\n            r.color *= sign(float(i)); // 纯黑色背景\n            r.color *= sky(r, 2.0, 1.0 - 1.0 / (1.0 + 0.1 * float(i)));\n            break;\n        }\n        \n        // 计算法线\n        rec.normal = calc_normal(rec.obj, rec.pos);\n        \n        // 更新光子的位置\n        r.origin = rec.pos;\n        \n        // 应用 PBR 材质更新光线\n        r = ray_surface_interaction(r, rec);\n        \n        // 处理自发光\n        float intensity = brightness(r.color);\n        r.color *= rec.obj.mtl.emission;\n        float visible   = brightness(r.color);\n        \n        // 光太暗或者击中光源\n        if (intensity < visible || visible < VISIBILITY) break;\n    }\n\n    return r;\n}\n\n// 片段着色器程序入口\nvec4 fragment(vec2 uv, vec2 SCREEN_PIXEL_SIZE) {\n    // 计算摄像机方位和视线\n    vec3  lookfrom  = load(POSITION).xyz;\n    vec2  rotation  = load(ROTATION).xy;\n    vec3  direction = CameraRotation(rotation) * vec3(0, 0, -1);\n    vec3  lookat    = lookfrom + direction;\n    float aspect    = SCREEN_PIXEL_SIZE.y / SCREEN_PIXEL_SIZE.x;;\n    \n    // 初始化摄像机\n    camera cam;\n    cam.lookfrom = lookfrom;\n    cam.lookat   = lookat;\n    cam.aspect   = aspect;\n    cam.vfov     = camera_vfov;\n    cam.vup      = vec3(0, 1, 0);\n    cam.focus    = camera_focus;\n    cam.aperture = camera_aperture;\n    \n    // 用 UV 和时间初始化随机数发生器种子\n    seed = rand13(vec3(uv, iTime*iTimeDelta));\n\n    // 超采样\n    uv += rand21() * SCREEN_PIXEL_SIZE;\n    \n    // 对每个光子经过的表面采样一次\n    ray r = get_ray(cam, uv, vec3(1));\n    \n    // 处理颜色\n    vec3 color = raytrace(r).color;\n\n    return vec4(color, 1.0);\n}\n\nvoid pre_calculate() {\n    pixradius = 0.5 / max(iResolution.x, iResolution.y);\n    bias = 2.5 * pixradius;\n    \n    for (int i = 0; i < map.length(); i++) {\n        vec3 rotation = map[i].trs.rotation;\n        map[i].trs.matrix = angle(radians(rotation));\n    }\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 SCREEN_PIXEL_SIZE = 1.0 / iResolution.xy;\n    vec2 uv = fragCoord * SCREEN_PIXEL_SIZE;\n    \n    pre_calculate(); // 预计算某些参数\n    fragColor = fragment(uv, SCREEN_PIXEL_SIZE); // 获取片元颜色\n    \n    if (bool(load(MOVING).x)) return; // 如果正在移动就不积累上一帧\n    \n    fragColor += texture(iChannel0, uv); // 积累帧进行降噪\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 2,
                        "ctype": "cubemap",
                        "id": 22,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "false",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}