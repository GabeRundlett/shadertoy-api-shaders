{
    "Shader": {
        "info": {
            "date": "1700509319",
            "description": "Morphing glowing 2d shapes to beat (takes a few beats to initialize).\n\n- use with audio in iChannel0 of Buffer A -",
            "flags": 96,
            "hasliked": 0,
            "id": "mttyDr",
            "likes": 2,
            "name": "Fork: Blue Penta",
            "published": 3,
            "tags": [
                "2d",
                "glow",
                "25d",
                "pentagon"
            ],
            "usePreview": 0,
            "username": "QuantumSuper",
            "viewed": 249
        },
        "renderpass": [
            {
                "code": "// Fork: Blue Penta v0.4.231120 by Quantum Super\n// forked from Blue Pentagon v0.7.231103 by QuantumSuper & Audio Analyser 0.5.230727 by QuantumSuper\n// pseudo-3d animation by morphing glowing 2d shapes to music beat\n// \n// - use with audio in iChannel0 of Buffer A -\n\n\n#define PI 3.14159265359 \nfloat count, bpm, timeFirstBeat, aTime;\n\n\nmat2 rotM(float r){float c = cos(r), s = sin(r); return mat2(c,s,-s,c);} //2D rotation matrix\n\nvec3 tmUnreal( vec3 c){ //tone map, source: https://www.shadertoy.com/view/llXyWr\n    return c / (c + .155) * 1.019;\n}\n\nfloat hash21(vec2 p){ //pseudorandom generator, cf. The Art of Code on youtu.be/rvDo9LvfoVE\n    p = fract(p*vec2(13.81, 741.76));\n    p += dot(p, p+42.23);\n    return fract(p.x*p.y);\n}\n \nfloat sdSegment( vec2 p, vec2 a, vec2 b){ //source: https://iquilezles.org/articles/distfunctions2d/ \n    vec2 pa = p - a, ba = b - a; \n    float h = clamp( dot(pa,ba)/dot(ba,ba), 0., 1.); \n    return length(pa - ba*h);\n}\n\nfloat sdBox( vec2 p, vec2 b){ //source: https://iquilezles.org/articles/distfunctions2d/\n    vec2 d = abs(p) - b; \n    return length(max(d,.0)) + min(max(d.x,d.y),.0);\n}\n\nfloat sdPentagon( vec2 p, float r){ //source: https://iquilezles.org/articles/distfunctions2d/\n    const vec3 k = vec3( .809016994, .587785252, .726542528);\n    p.x = abs(p.x);\n    p -= 2.*min( dot(vec2(-k.x,k.y),p), 0.) * vec2( -k.x, k.y);\n    p -= 2.*min( dot(k.xy,p), 0.) * k.xy;\n    p -= vec2( clamp( p.x, -r*k.z, r*k.z), r);    \n    return length(p) * sign(p.y);\n}\n\nfloat sdOctogon( in vec2 p, in float r ){ //source: https://iquilezles.org/articles/distfunctions2d/\n    const vec3 k = vec3(-.9238795325, .3826834323, .4142135623 );\n    p = abs(p);\n    p -= 2.*min( dot(k.xy,p), 0.) * k.xy;\n    p -= 2.*min( dot(vec2(-k.x,k.y),p), 0.) * vec2(-k.x,k.y);\n    p -= vec2(clamp(p.x, -k.z*r, k.z*r), r);\n    return length(p)*sign(p.y);\n}\n\nfloat glow( float sd, float amp){\n    return clamp( amp / max( amp, sd), .0 ,1.);\n}\n\nfloat myObj(vec2 p, float scale, float speed, float off){\n    float id = mod( (aTime-timeFirstBeat)/(60./bpm*16.), 3.);\n    if (id<1.)\n        return abs(sdPentagon( p/vec2(cos(aTime*speed+off),1.-sin(aTime*speed+off)*p.x/cos(aTime*speed+off)), .85/scale)) + .01;\n    else if (id<2.) \n        return abs(sdBox( p/vec2(cos(aTime*speed+off),1.-sin(aTime*speed+off)*p.x/cos(aTime*speed+off)), vec2(.85/scale))) + .01;\n    else\n        return abs(sdOctogon( p/vec2(cos(aTime*speed+off),1.-sin(aTime*speed+off)*p.x/cos(aTime*speed+off)), 1./scale)) + .01; \n}\n\nvec3 getCol(float id){ //v0.8, color definitions, for pairs\n    vec3 setCol = vec3(0);\n    id = fract(id/8.)*8.;// mod(id,8.);\n         if (id< 1.) setCol = vec3( 23,123,250); //cneon blue\n    else if (id< 2.) setCol = vec3( 30, 29,215); //vw2 blue\n    else if (id< 3.) setCol = vec3(244,  0,204); //vw2 pink\n    else if (id< 4.) setCol = vec3(131, 58,187); //nordic violet\n    else if (id< 5.) setCol = vec3(  0,250,253); //vw2 light blue\n    else if (id< 6.) setCol = vec3( 66,120, 91); //matrix green 2\n    else if (id< 7.) setCol = vec3(252,157,  0); //miami orange\n    else if (id< 8.) setCol = vec3(231, 15, 20); //arena red\n    return setCol/256.;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n\n    // Read compression values from Buffer A\n    vec4 fft, ffts;\n    for (int n=0;n<4;n++) \n        fft[n] = getDat( iChannel0, vec2( 0, n)).a,\n        ffts[n] = getDat( iChannel0, vec2( 0, n+4)).a;\n      \n    // Read analysis results from Buffer C\n    count         = getDat( iChannel2, vec2(0,0)).a; //beat count (0..15)\n    bpm           = getDat( iChannel2, vec2(0,1)).a; //bmp estimate (>90..180)\n    float frameRate     = getDat( iChannel2, vec2(0,2)).a; //frame rate average\n    float isPause       = getDat( iChannel2, vec2(0,3)).a; //is bass less high than average\n    timeFirstBeat = getDat( iChannel2, vec2(0,4)).a; //iTime at sudden bass increase\n    float isBeat        = getDat( iChannel2, vec2(0,5)).a; //is bass high\n    float isFlank       = getDat( iChannel2, vec2(0,6)).a; //is bass just getting high\n    aTime = (iTime-timeFirstBeat)/bpm*60.;\n\n\n    // Central object\n    vec2 uv = (2.*fragCoord-iResolution.xy) / max(iResolution.x, iResolution.y); //long edge -1 to 1, square aspect ratio\n\tvec3 col = vec3(0);\n    float amp;\n    \n    float scale = 1. + .5*sin(iTime/8.) + fft.x*5.; //coordinate system scale\n    float matDiff = .33; //material brightness difference   \n    float speed = .5; //speed factor\n      \n    float off = .01; //rotation offset per slice\n    float num = 32.; //number of 2d slices\n    float totCount = aTime/128.;\n    float colId = floor(fract( totCount)*4.)*2.;\n    vec3 color1 = getCol( colId+0.);\n    vec3 color2 = getCol( colId+1.);\n    float phase = (ceil(totCount)/16.*.7 + .3*ceil(totCount/4.)/4.)*PI*2.;\n    \n    for(float n=0.;n<num;n++){\n        amp = glow( myObj( uv, scale, speed, n*off+phase), .01) //draw\n            * ((uv.x/cos(aTime*speed+n*off+phase)*scale*.5+1.5) * (1.-matDiff) + (cos(aTime*speed+PI/2.+n*off+phase)*.5+.5) * matDiff); //lighting\n        col += clamp(amp,.0,1.) * (color1*(1.-n/num)+color2*n/num)/num * (.5+ffts.xyz) * .8; //color \n        off *= 1.05 - .05*cos(aTime/PI); //iterate rotation offset\n    }\n    col *= mix( abs( cos( .06*iTime*.0 + PI/vec3(.5,2.,4.) + ffts.xyz*PI)), vec3(1), clamp(fft.x-.7,.0,.3)/.3); //color shift    \n\n    \n    // Flying segments\n    float myTime = aTime*2. - .02; //local timer\n    vec4 s1 = vec4(.7,2.3*fft.z,.7,-2.3*fft.z) * (.1+.4*(1.-fft.x)) * .5; //segment coordinates\n    float occ = smoothstep(.3,.0,max(max(col.x,col.y),col.z)); //occlusion factor\n    float numOfSeg = (isPause<1.)? 8. : 4.; //number of segments\n    \n    for (float n=.0;n<numOfSeg;n++)\n        col += glow( sdSegment( uv * rotM(hash21(vec2(ceil(myTime+n/numOfSeg),n/numOfSeg))*2.*PI-aTime) * fract(myTime+n/numOfSeg) * 2.7,  s1.xy,  s1.zw), 3e-4 * (1.+fft.x)) \n            * getCol( colId+fract(floor(n/4.)/2.)*2.+2.) //color\n            * (1.-fract(myTime+n/numOfSeg))*(1.-fract(myTime+n/numOfSeg)) //fade out\n            * (occ - step(fract(myTime+n/numOfSeg),.13*fft.x)*(occ-1.)) //occlusion\n            * ffts[int(fract(n/4.)*4.)] * (1.+2.*fract(n/4.)); //intensity\n\n      \n    // Output finalization    \n    col *= (1.+isFlank);\n    col = tmUnreal(col);\n    \n    // Tools (for full visualization see Audio Analyzer at https://www.shadertoy.com/view/ddBBWw)\n    //col = vec3(step(.0,(fragCoord.y/iResolution.y-.9))) + .7*dot( step(.0,fft-abs(floor(fragCoord.x/iResolution.x*4.-vec4(0,1,2,3)))-fragCoord.y/iResolution.y/.9),vec4(1)) + .3*dot( step(.0,ffts-abs(floor(fragCoord.x/iResolution.x*4.-vec4(0,1,2,3)))-fragCoord.y/iResolution.y/.9),vec4(1)); //compression amplitudes\n    //col *= .2+vec3(step(count/16.,fragCoord.y/iResolution.y)); //visualize count\n    //col += vec3(step( fragCoord.y/iResolution.y, isBeat)); //visualize isBeat  \n    //col += smoothstep(.01,.0,abs(fragCoord.y/iResolution.y-(bpm-90.)/90.)); //bpm line (>90..180)\n    \n    fragColor = vec4( col, 1.);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// BUFFER A (1.0) of Audio Analyser by QuantumSuper FOR Fork: Blue Penta\n// audio spectrum by brightness of frequency by y-axis at time by x-axis (0 now; >0 historic)\n// .r: amplitude \n// .g: waveform\n// .b: average amplitude\n// .a: ( fft, ffts, timestamp, 0..0) variables\n// \n// - use with audio in iChannel0 of Buffer A -\n\n\n#define TRACKDURATIONINFRAMES 3600.\nvec4 fft, ffts; //compressed frequency amplitudes\n\n\nvoid compressFft(){ //v1.2, compress sound in iChannel0 to simplified amplitude estimations by frequency-range\n    fft = vec4(0), ffts = vec4(0);\n\n\t// Sound (assume sound texture with 44.1kHz in 512 texels, cf. https://www.shadertoy.com/view/Xds3Rr)\n    for (int n=0;n<3;n++) fft.x  += texelFetch( iChannel0, ivec2(n,0), 0 ).x; //bass, 0-517Hz, reduced to 0-258Hz\n    for (int n=6;n<8;n++) ffts.x  += texelFetch( iChannel0, ivec2(n,0), 0 ).x; //speech I, 517-689Hz\n    for (int n=8;n<14;n+=2) ffts.y  += texelFetch( iChannel0, ivec2(n,0), 0 ).x; //speech II, 689-1206Hz\n    for (int n=14;n<24;n+=4) ffts.z  += texelFetch( iChannel0, ivec2(n,0), 0 ).x; //speech III, 1206-2067Hz\n    for (int n=24;n<95;n+=10) fft.z  += texelFetch( iChannel0, ivec2(n,0), 0 ).x; //presence, 2067-8183Hz, tenth sample\n    for (int n=95;n<512;n+=100) fft.w  += texelFetch( iChannel0, ivec2(n,0), 0 ).x; //brilliance, 8183-44100Hz, tenth2 sample\n    fft.y = dot(ffts.xyz,vec3(1)); //speech I-III, 517-2067Hz\n    ffts.w = dot(fft.xyzw,vec4(1)); //overall loudness\n    fft /= vec4(3,8,8,5); ffts /= vec4(2,3,3,23); //normalize\n\t\n\t//for (int n=0;n++<4;) fft[n] *= 1. + .3*pow(fft[n],5.); fft = clamp(fft,.0,1.); //limiter? workaround attempt for VirtualDJ [WIP]\n}\n\nfloat estMax(float p){ //estimate changing maximum over time of sound texel by weighted amplitude tracking\n    float curVal = clamp( getDat( iChannel0, vec2(p/iResolution.y*512.,0)).x, .0, 1.); //current amplitude\n    float maxVal = clamp( getDat( iChannel1, vec2(0,p)).z, .0, 1.); //latest max amp\n    \n    if (curVal >= maxVal) maxVal = 0.; //check for new max    \n    \n    if (maxVal != 0.) //avoid uninitialized state & deprecated maxVal\n        curVal *=    1./TRACKDURATIONINFRAMES,\n        maxVal *= 1.-1./TRACKDURATIONINFRAMES;\n  \n    return maxVal+curVal; //returns value between 0 and 1\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n    compressFft(); //initializes fft, ffts\n    fragColor = (fragCoord.x<1.)? vec4( \n        getDat( iChannel0, vec2( fragCoord.y/iResolution.y*512., 0)).x, //.r amplitudes\n        getDat( iChannel0, vec2( fragCoord.y/iResolution.y*512., 1)).x, //.g waveform (does not work in VirtualDJ)\n        estMax( fragCoord.y), //.b average amplitude\n        (fragCoord.y<4.)? fft[int(fragCoord.y)] : //.a compression part 1\n        (fragCoord.y<8.)? ffts[int(fragCoord.y)-4] : //.a compression part 2\n        (fragCoord.y<9.)? iTime : //.a timestamp\n        0.) //.a empty\n        : getDat( iChannel1, fragCoord-vec2(1,0)); //history   \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "musicstream",
                        "id": 35283,
                        "published": 0,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "https://soundcloud.com/blackworksclub/minor-dott-sueno-de-la-noche-2"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// COMMON (0.0) of Audio Analyser by QuantumSuper FOR Fork: Blue Penta\n// \n// - use with audio in iChannel0 of Buffer A -\n\n#define getDat( buf, addr) texelFetch( buf, ivec2(addr), 0)\n#define getDatN( buf, addr) getDat( buf, addr).r / getDat( buf, addr).b",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// BUFFER B (0.1) of Audio Analyser by QuantumSuper FOR Fork: Blue Penta\n// filter of audio spectrum\n// .r: beats (1D)\n// .g: 0\n// .b: 0\n// .a: 0\n// \n// - use with audio in iChannel0 of Buffer A -\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n    \n    if (fragCoord.x < 1.) { //new data\n    \n        vec3 pos = 5. * vec3(0,1,2); //defines spread over frames (max beat width)      \n\n        vec3 amp = vec3(\n            (getDatN( iChannel0, vec2(pos.x,1)) + getDatN( iChannel0, vec2(pos.x,2))),\n            (getDatN( iChannel0, vec2(pos.y,1)) + getDatN( iChannel0, vec2(pos.y,2))),\n            (getDatN( iChannel0, vec2(pos.z,1)) + getDatN( iChannel0, vec2(pos.z,2)))\n            ) * .5; //normalize\n            \n        fragColor = vec4(0);\n        if (amp.y>.92 && amp.x<amp.y && amp.z<amp.y) //super simple max rise detection\n            fragColor.r = 1.;  //beat\n            \n    } else\n        fragColor = getDat( iChannel1, fragCoord-vec2(1,0)); //history \n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// BUFFER C (0.91) of Audio Analyser by QuantumSuper FOR Fork: Blue Penta\n// analyse filtered beats\n// .r: bpm estimation, brightness corresponds to certainty, linear 90-180bpm\n// .g: buffer to find maximum\n// .b: -\n// .a: variables ( count (0..15), bmp estimate (>90..180), frame rate estimate, isPause (fract), timeFirstBeat, beat (bool), flank (bool), 0..0)\n// \n// - use with audio in iChannel0 of Buffer A -\n\n\nfloat isFlank( float shift){ //simple comparison of bool-like data\n    return (getDat( iChannel1, vec2( mod(shift,iResolution.x), 0)).r > getDat( iChannel1, vec2( mod(shift+1.,iResolution.x), 0)).r)? 1. : 0.;\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n         \n    // Set space for search algorithm\n    float isVert = float(iResolution.x < iResolution.y); //vertical screen orientation, bool-like\n    vec2 orient = vec2( 1.-isVert, isVert); //(1,0) horizontal/square; (0,1) vertical\n    vec2 myResolution = bool(isVert)?\n        iResolution.yx : iResolution.xy;\n    vec2 myFragCoord = bool(isVert)?\n        fragCoord.yx : fragCoord.xy; \n    \n    \n    // Estimate average frame rate\n    float estFrameRate = (iFrame < int(iResolution.x))? //buffer not yet fully filled \n        (iFrame < 1)? //initialization\n            30. : //guess frame rate\n            float(iFrame) / (iTime - getDat( iChannel0, vec2( iFrame, 8)).a) : //estimate average frame rate with less accuracy\n        iResolution.x / (iTime - getDat( iChannel0, vec2( iResolution.x-1., 8)).a); //estimate average frame rate\n    \n    \n    // Estimate BPM certainties (comb-like sum)\n    float beat = getDat( iChannel1, vec2(0)).r; //beat ongoing, bool-like\n    float flank = isFlank(0.); //rising flank of beat, bool-like\n    float amp = 0.;\n    \n    if (bool(flank)) //recalculate bpm probability if there is a new beat\n    \n        if (fragCoord.x < 1.){\n        \n            float minStep = estFrameRate / 3.; //assume max 180 bpm (3bps)\n            float stepSize = minStep * (1.+myFragCoord.y/myResolution.y); //assume min >90bpm (>1.5bps)\n            \n            for ( float n=0.; n++ < myResolution.x/stepSize; ) //go through beat history at bpm-rate steps\n                amp += isFlank( n*stepSize); //add found beat flanks\n            amp /= myResolution.x/stepSize; //normalize          \n            \n            float prevAmp = getDat( iChannel2, myFragCoord*orient.yx).r;\n            amp = (amp + prevAmp*359.) / 360.; //weight, assume stable bpm over about 2 minutes at 180bpm (or 4 min at 90bpm)\n            \n        } else \n            amp = getDat( iChannel2, myFragCoord-orient).r; //history     \n    else \n        amp = getDat( iChannel2, fragCoord).r; //copy old data (no new info) \n        \n    fragColor.r = amp;\n\n    \n    // Find BPM estimate (search algorithm)\n    vec2 compPos = (myFragCoord.x < 1.)? //is first line\n        myFragCoord.y + orient.yx : //first neighbour\n        vec2(\n            getDat( iChannel2, myFragCoord - orient).g,\n            getDat( iChannel2, myFragCoord - orient + mod( myFragCoord.x + myFragCoord.y + 1., myResolution.y) * orient.yx ).g ); //next new neighbour\n    \n    amp = (getDat( iChannel2, compPos.x*orient.yx).r < getDat( iChannel2, compPos.y*orient.yx).r)? //compare current compPos-bpm-certainties\n        compPos.y : compPos.x ; //keep only position of higher certainty\n    fragColor.g = amp;  \n    \n    float bpm = (iFrame<1)?\n        127. : //guess\n        180. / (1. + getDat( iChannel2, ceil(iResolution.y*.5)*orient).g / iResolution.y); //most certain beat-rate, range from >90 to 180 bpm\n \n    \n    // Find Beat-offset (watchdog)\n    float isPause = 1. - clamp( getDat( iChannel0, vec2(0,1)).b + getDat( iChannel0, vec2(0,2)).b, .0, 2.)/2.; //inverse average max, bool-like intent but fract usage\n    \n    float timeFirstBeat = (iFrame < 1)? 0. : //initialization\n        (isPause<.05 && getDat( iChannel2, vec2(5,3)).a > .13)? //there was a pause but is no more\n            iTime : //new first beat\n            getDat( iChannel2, vec2(0,4)).a; //old first beat\n    \n    float count = mod( (iTime-timeFirstBeat) / 60.*bpm, 16.); //count to 16 at bpm from first beat\n    \n    \n    // Save variables \n    if (fragCoord.x<1.)\n             if (fragCoord.y<1.) amp = count; //beat count (0..15) float\n        else if (fragCoord.y<2.) amp = bpm; //bmp estimate (>90..180)\n        else if (fragCoord.y<3.) amp = estFrameRate; //frame rate average\n        else if (fragCoord.y<4.) amp = isPause; //is average max-bass low\n        else if (fragCoord.y<5.) amp = timeFirstBeat; //iTime at sudden bass increase\n        else if (fragCoord.y<6.) amp = beat; //is bass high\n        else if (fragCoord.y<7.) amp = flank; //is bass beginning\n        else amp = 0.; //empty\n    else amp = getDat( iChannel2, fragCoord-vec2(1,0)).a; //history\n        \n    fragColor.a = amp;\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}