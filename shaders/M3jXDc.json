{
    "Shader": {
        "info": {
            "date": "1711190850",
            "description": "Renders to a 3d voroni texture to select which lights it needs to sample for each part of the volume.",
            "flags": 32,
            "hasliked": 0,
            "id": "M3jXDc",
            "likes": 9,
            "name": "Hundreds of Volumetric Lights",
            "published": 3,
            "tags": [
                "3d",
                "volume",
                "particles"
            ],
            "usePreview": 0,
            "username": "sdfgeoff",
            "viewed": 231
        },
        "renderpass": [
            {
                "code": "/**\n\nCan I render hundreds of dynamic volumetric lights on an IGPU? I think so!\n\nUse mouse to look around.\n\n#####################################################################\n\nLighting volumetrics can be quite wasteful to render by traditional\nraymarching: you calculate the lighting for the same point in\nspace multiple times.\n\n\nConsider marching a ray and sampling lighting towards a directional\nlight:\n\n< ------*-----*-----*-----*-----*\n         \\     \\     \\     \\    \n          \\     \\     \\     \\    \n(2)        *     *     *     *    \n            \\     \\     \\     \\    \n             \\     \\     \\     \\    \n              *     *     *     *    \n               \\     \\     \\     \\   \n\nThe camera on the left looks out and at various points samples\nthe volume. At each point the light needs to be calculated, so\nit marches volume samples for each of those. \n\nImagine if you took another ray and marched it starting at point\n2 (also marching horizontally). You'd hit the same points\nin the volume, and calculate the same density/scattering information.\nThis gets worse the more lights you have.\n\n\n#####################################################################\n\n\nWhat if we could pre-cache this in a volumetric texture? Then\nwe could avoid evaluating our volume distance field and calculating\nlighting quite so many times.\n\nYou could store other information in the volume. Eg:\n 1. Shadowing from sun light\n 2. Which lights contribute the most to this voxel\n 3. Local Volume density modifiers\n \nThis effectively allows a defferred/clustered renderer for volumes. \n\n\n#####################################################################\n\n\nThis is my second play with this (The first is\nhttps://www.shadertoy.com/view/4XjSWV ), and it implements point 2 above:\nfiguring out which light contributes most to each voxel. This allows sampling\nhundreds of lights/particles in a volume, while still running at 60FPS on low end\nhardware.\n\nSo:\n 1. Buffer A:    Simulation is done in per-particle space and is\n                       O(num_lights)\n 2. BUFFER B:    Picking which light to use is done in voxel-space and is\n                       O(num_lights * num_voxels)\n 3. Image:       Lighting is done in screen space and is\n                       O(screen_size * ray_march_steps)\n\nIt would be nice to remove the `num_lights` term from BUFFER B, but I'm not sure\nhow to do that - any acceleration structure is probably > O(n) to build.\nBut in comparison, the naieve solution is\n     O(screen_size * num_lights * ray_march_steps)\nwhich is even worse. By splitting out the num_lights and ray_march_steps we gain\na lot of performance: 60FPS on my intel laptop. \n\n\n\n#####################################################################\n\n\nThis scene expects the viewport to be at least 640x360 pixels or so.\nSmaller than that and it'll start clipping the volume texture in\nbuffer A. There's probably an intelligent way to pick that texture\nresolution, but for now I'm running with a volume of 64x64x45\n\n\nThe lighting model in this scene is very simple, but it works as a\nproof of concept of how to render this sort of lighting.\n\n\n**/\n\n#define BUFFER_VOLUME_DATA iChannel0\n#define BUFFER_STATE_DATA iChannel2\n#define BUFFER_BACKGROUND iChannel3\n\n\nconst float FOV = 0.5;\nconst vec3 absorbtion = vec3(1.0, 0.9, 0.8);\n\nint num_steps = 50;\nfloat step_size = 0.08;\nfloat max_dist = 3.0;\n\n\n\nvec3 calculate_transmitance(float material_to_pass_through, vec3 input_energy) {\n    // Beer Lambert\n    return input_energy * exp(-material_to_pass_through * absorbtion);\n}\n\n\n\nvec3 Tonemap_ACES(vec3 x) {\n    // Narkowicz 2015, \"ACES Filmic Tone Mapping Curve\"\n    // Copied from https://www.shadertoy.com/view/WdjSW3\n    const float a = 2.51;\n    const float b = 0.03;\n    const float c = 2.43;\n    const float d = 0.59;\n    const float e = 0.14;\n    return (x * (a * x + b)) / (x * (c * x + d) + e);\n}\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    if (all(lessThan(fragCoord, iResolution.xy / 3.0))) {\n        // Volume Texture Preview\n        fragColor = texture(iChannel0, vec2(fragCoord / iResolution.xy)) / float(NUM_LIGHTS);\n        return;\n    }\n    \n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.y - iResolution.xy / iResolution.y / 2.0;\n    uv *= iResolution.x / iResolution.y;\n    vec2 coords = uv * 0.5 + 0.5;\n    \n    vec2 angles = iMouse.xy / iResolution.xy * 3.14 * vec2(2.0, 1.0) + vec2(0.0, -1.5) ;//iTime * 0.2;\n    \n    vec2 s = sin(angles);\n    vec2 c = cos(angles);\n    mat4 camera_pivot_origin = mat4(\n        c.x,0,-s.x,0,\n        0,1,0,0,\n        s.x,0,c.x,0,\n        0,0,0,1\n    ) * mat4(\n        1,0,0,0,\n        0,c.y,-s.y,0,\n        0,s.y,c.y,0,\n        0,0,0,1\n    );\n    \n    vec3 ray_start = (camera_pivot_origin * vec4(0,0,-2,1)).xyz + vec3(0.5);\n    vec3 ray_direction = (camera_pivot_origin * normalize(vec4(uv * FOV, 1.0, 0.0))).xyz;\n    \n    ivec2 noiseCoords = ivec2(mod(fragCoord + iTime * 689.7, vec2(1024)));\n    float noise = texelFetch(iChannel1, noiseCoords, 0).r;\n    ray_start += ray_direction * step_size * noise;\n    \n    // Raymarch the volume;\n    float material_to_camera = 0.0;\n    float density_here = 0.0;\n    float reached_end = 1.0;\n    \n    \n    \n    vec3 from = ray_start;\n    vec3 direction = ray_direction;\n        \n    vec3 color = vec3(0.0);\n    \n    for (int i=0; i<num_steps; i++) {\n        float dist = float(i) * step_size;\n        if (dist > max_dist) {\n            reached_end = 0.0;\n            break;\n        }\n        vec3 position = from + direction * dist;\n        vec4 volumeCacheData = vec4(0);\n      \n      \n        \n        if (any(lessThan(position, vec3(0)))  || any(greaterThan(position, vec3(1)))) {\n            volumeCacheData = vec4(0.0);\n            continue;\n        } else {\n            vec2 coordIn2D = coordToSlice(position);\n            volumeCacheData = texelFetch(BUFFER_VOLUME_DATA, ivec2(coordIn2D), 0);\n        }\n\n        //density_here = step(length(position * 2.0 - 1.0), 0.8) * 3.0 + 1.0;//volumeCacheData.r;\n        density_here = volumeMap(position).r;\n        \n        material_to_camera += density_here * step_size;\n        \n        vec3 light_towards_camera_at_particle = vec3(0.00);\n        \n        for (int l=0; l <= 4; l+=1) {\n            int lightId = int(volumeCacheData[l]);\n            if (lightId == -1) {\n                break;\n            }\n            vec4 lightPositionData = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_POSITION), 0);\n            vec4 lightColorData = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_COLOR), 0);\n            vec3 vecToLight = position - lightPositionData.xyz;\n            vecToLight *= 50.0;\n            float distSquared = dot(vecToLight, vecToLight);\n            \n            vec3 color = lightColorData.rgb;\n            light_towards_camera_at_particle += color * 1.0 / distSquared;// * 1.0 / distSquared;\n        }\n        \n        //vec3 light_towards_camera_at_particle = vec3(density_here * step_size);\n        \n        // vec3 light_towards_camera_at_particle = calculate_lighting(position, density_here, direction) * step_size;\n        vec3 light_reaching_camera = calculate_transmitance(material_to_camera, light_towards_camera_at_particle);\n        \n        color += light_reaching_camera;\n    }\n    \n    vec3 background = textureLod(BUFFER_BACKGROUND, ray_direction, 1.0).rgb * 0.2;\n    color += calculate_transmitance(material_to_camera, background);\n    \n    color = Tonemap_ACES(color);\n    \n    fragColor = vec4(color, material_to_camera);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 3,
                        "ctype": "cubemap",
                        "id": 22,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "false",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 14854,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\nState Buffer\n\nADDR_POSITION:\nRGB - Position\nA - Unused\n\nADDR_COLOR:\nRGB - Color\nA - Unused\n\nADDR_VELOCITY:\nRGB = Velocity\nA - Unused\n\n*/\n\n#define BUFFER_STATE_DATA iChannel0\n\n\n// Copied from https://www.shadertoy.com/view/4djSRW\nvec4 hash42(vec2 p)\n{\n\tvec4 p4 = fract(vec4(p.xyxy) * vec4(.1031, .1030, .0973, .1099));\n    p4 += dot(p4, p4.wzxy+33.33);\n    return fract((p4.xxyz+p4.yzzw)*p4.zywx);\n}\n\n\n\n\n// The first row of pixels contains the light \n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \n    //fragColor = hash42(fragCoord);\n    //return;\n        \n    ivec2 addr = ivec2(fragCoord);\n    int lightId = addr.x;\n    if (lightId >= NUM_LIGHTS) {\n        fragColor = vec4(0);\n        return;\n    }\n    \n    if (addr.y == ADDR_POSITION) {\n        // Position\n        if (iFrame == 0) {\n            fragColor = hash42(fragCoord);\n            return;\n        } else {\n            vec4 oldPosition = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_POSITION), 0);\n            vec4 velocity = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_VELOCITY), 0);\n            //oldData -= vec4(0,0,1,0) * iTimeDelta;\n            vec4 newPosition = oldPosition + velocity * iTimeDelta;\n            //newPosition.xz = mod(newPosition.xz, vec2(1.0));\n            newPosition.y = max(0.0, newPosition.y);\n            fragColor = newPosition;\n            return;\n\n        }\n    } else if (addr.y == ADDR_COLOR) {\n        // Color\n        fragColor = hash42(fragCoord);\n        return;\n    } else if (addr.y == ADDR_VELOCITY) {\n        // Velocity\n        if (iFrame == 0) {\n            vec4 velocity = hash42(fragCoord) * 2.0 - 1.0;\n            fragColor = velocity * 0.2;\n            return;\n        } else {\n            vec4 position = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_POSITION), 0);\n            vec4 oldVelocity = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_VELOCITY), 0);\n            //oldData -= vec4(0,0,1,0) * iTimeDelta;\n            vec4 velocity = oldVelocity;\n\n\n            if (position.y <= 0.0) {\n                velocity.y = abs(velocity.y);\n            }\n            if (position.x <= 0.0) {\n                velocity.x = abs(velocity.x);\n            } else if (position.x >= 1.0) {\n                velocity.x = -abs(velocity.x);\n            }\n            if (position.z <= 0.0) {\n                velocity.z = abs(velocity.z);\n            } else if (position.z >= 1.0) {\n                velocity.z = -abs(velocity.z);\n            }\n            velocity.y -= 0.01;\n            velocity.y *= 0.9999;\n\n            \n            \n            fragColor = velocity;\n            return;\n\n        }\n        return;\n    } else {\n        fragColor = vec4(1);\n        return;\n    }\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "const vec2 SLICE_PIXELS = vec2(64.0);\nconst vec2 SLICES = vec2(9,5);\nconst float SLICE_COUNT = SLICES.x * SLICES.y;\n\n\nconst int NUM_LIGHTS = 256;\n\nconst int ADDR_POSITION = 0;\nconst int ADDR_COLOR = 1;\nconst int ADDR_VELOCITY = 2;\n\n\n// Convert from a 3D position in space into a texture coordinate\n// 3D Coords from 0->1\n// 2D coords are in pixel-space\nvec2 coordToSlice(vec3 coord) {\n    vec2 positionInCell = coord.xy * SLICE_PIXELS;\n    float cellId = coord.z * SLICE_COUNT;\n    float rowId = floor(mod(cellId / SLICES.y, 1.0) * SLICES.y);\n    float colId = floor((cellId - rowId) / SLICES.y);\n    // colId is the position on the horizontal axis: ie X axis\n    vec2 cellOffsets = vec2(colId, rowId) * SLICE_PIXELS;\n    \n    return cellOffsets + positionInCell;\n    \n}\n\n// Convert from a texture coordinate into a 3D position in space\n// 3D Coords from 0->1\n// 2D coords are in pixel-space\nvec3 sliceToCoord(vec2 cell) {\n    vec2 cellIds = cell / SLICE_PIXELS;\n    vec2 positionInCell = mod(cellIds, vec2(1));\n    cellIds = floor(cellIds);\n    if (any(greaterThanEqual(cellIds, SLICES))) {\n        return vec3(-1);\n    }\n    float cellId = cellIds.y + cellIds.x * SLICES.y;\n    \n    return vec3(positionInCell, cellId / SLICE_COUNT);\n}\n\n\n\nvec4 volumeMap(vec3 position) {\n    float shape = step(length(position * 2.0 - 1.0), 1.1);\n    shape = 1.0 - shape;\n    \n    return vec4(shape * 6.0);\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// Volume Caching buffer. This buffer renders 3D space into a 2D texture\n//\n// There are four channels. Each channel contains a lookup to indicate which\n// light should be sampled.\n//\n\n\n#define BUFFER_STATE_DATA iChannel0\n\n\n\nvoid storeLowestFourIds(inout ivec4 fourLowestIds, inout vec4 fourLowestDistances, int newId, float newDistance) {\n    \n    if (newDistance < fourLowestDistances.x) {\n        fourLowestDistances.xyzw = vec4(\n            newDistance, fourLowestDistances.xyz\n        );\n        fourLowestIds.xyzw = ivec4(\n            newId, fourLowestIds.xyz\n        );\n    } else if (newDistance < fourLowestDistances.y) {\n        fourLowestDistances.yzw = vec3(\n            newDistance, fourLowestDistances.yz\n        );\n        fourLowestIds.yzw = ivec3(\n            newId, fourLowestIds.yz\n        );\n    } else if (newDistance < fourLowestDistances.z) {\n        fourLowestDistances.zw = vec2(\n            newDistance, fourLowestDistances.z\n        );\n        fourLowestIds.zw = ivec2(\n            newId, fourLowestIds.z\n        );\n    } else if (newDistance < fourLowestDistances.w) {\n        fourLowestDistances.w = newDistance;\n        fourLowestIds.w = newId;\n    }\n        \n\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    if (any(greaterThanEqual(fragCoord, SLICES * SLICE_PIXELS))) {\n        fragColor = vec4(0,1,1,0);\n        return;\n    }\n    // Find out what 3d position the slice represents;\n    vec3 position = sliceToCoord(fragCoord);\n    \n    // Find the closest lights to this point\n    ivec4 ids = ivec4(-1);\n    vec4 distances = vec4(9999);\n    \n    for (int lightId=0; lightId < NUM_LIGHTS; lightId+=1) {\n        vec4 lightPositionData = texelFetch(BUFFER_STATE_DATA, ivec2(lightId, ADDR_POSITION), 0);\n        vec3 dist = position - lightPositionData.xyz;\n        float d = dot(dist, dist);\n        \n        // Maintain sorted vector of ids/distances\n        storeLowestFourIds(ids, distances, lightId, d);\n        \n    }\n    \n        \n    // Output to screen\n    fragColor = vec4(ids);// volumeMap(position);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}