{
    "Shader": {
        "info": {
            "date": "1654086595",
            "description": "A realtime path traced square prism grid traversal using IQ's temporal reprojection routine to give the appearance of a higher sample count.",
            "flags": 32,
            "hasliked": 0,
            "id": "Nd3yRX",
            "likes": 86,
            "name": "Multisample Raycaster",
            "published": 3,
            "tags": [
                "grid",
                "raycasting",
                "global",
                "illumination",
                "pathtracing",
                "city",
                "multisample",
                "reprojection",
                "emitter"
            ],
            "usePreview": 1,
            "username": "Shane",
            "viewed": 2234
        },
        "renderpass": [
            {
                "code": "/*\n\n    Multisample Raycaster\n    ---------------------\n\n    See \"Buffer A\" for an explanation.\n\n*/\n\n\n// The following is based on John Hable's Uncharted 2 tone mapping, which\n// I feel does a really good job at toning down the high color frequencies\n// whilst leaving the essence of the gamma corrected linear image intact.\n//\n// To arrive at this non-tweakable overly simplified formula, I've plugged\n// in the most basic settings that work with scenes like this, then cut things\n// right back. Anyway, if you want to read about the extended formula, here\n// it is.\n//\n// http://filmicworlds.com/blog/filmic-tonemapping-with-piecewise-power-curves/\n// A nice rounded article to read. \n// https://64.github.io/tonemapping/#uncharted-2\nvec4 uTone(vec4 x){\n    return ((x*(x*.6 + .1) + .004)/(x*(x*.6 + 1.)  + .06) - .0667)*1.933526;    \n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    // The other buffer has a maximum Y-resolution of 540 set, which \n    // means any pixels outside that are not rendered. On a 1980x1080\n    // fullscreen resolution, this means roughly a quarter of the pixels\n    // are rendered, which is a huge saving. Of course, this also means\n    // that the scene needs to be upscaled, which will make things less\n    // crisp, but you can't have everything. :)\n    //\n    // By the way, this tip came from Shadertoy user, spalmer, who has\n    // a heap of interesting work for anyone interested:\n    // https://www.shadertoy.com/user/spalmer\n    //\n    float maxRes = iResolution.y;//540.;\n    vec2 uv = fragCoord/iResolution.xy;\n    // If the resolution exceeds the maximum, upscale.\n    if(iResolution.y>maxRes) uv = (fragCoord/iResolution.xy - .5)*maxRes/iResolution.y + .5;\n    \n    // Retrieving the stored color.\n    vec4 col = texture(iChannel0, uv);\n   \n    // Toning down the high frequency values. A simple Reinhard toner would \n    // get the job done, but I've dropped in a heavily modified and trimmed \n    // down Uncharted 2 tone mapping formula.\n    // mapping functio.\n    col = uTone(col); \n    \n    // Subtle vignette.\n    //col *= pow(16.*uv.x*uv.y*(1. - uv.x)*(1. - uv.y) , 1./32.);\n    \n  \n    // Rough gamma correction and screen presentation.\n    fragColor = pow(max(col, 0.), vec4(1./2.2));\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\n\n    Multisample Raycaster\n    ---------------------\n    \n    This is a realtime path traced cell by cell square grid traversal. The scene \n    is lit entirely by rendered square emitters on the sides of the square prisms\n    and a small portion of atmospheric haze. No Blinn-Phong was harmed during the \n    making of this shader. :D\n    \n    I've been meaning to post one of these for a while. Individually, all the \n    concepts involved are pretty simple. However, tying them all together involves \n    more thinking than I enjoy, so I've been procrastinating on it for a while. :)\n    \n    Since this is realtime path tracing, things aren't going to be perfect on an\n    average system -- and apologies in advance for those with slower systems. A \n    basic static path traced scene normally takes seconds to minutes to produce in \n    a fast application like Blender, but realtime requirements only allow for a \n    fraction of a second per frame, so perfect quality is a big ask.\n    \n    Realtime path traced cell by cell traversals are not common, but they're \n    nothing new, and there's even a few examples on Shadertoy -- By the way, check \n    out 0b5vr's work on here, if you're into this kind of thing. A lot of realtime \n    path traced examples that have been appearing in demo competitions feel like \n    they're based on W23's \"past racer by jetlag\" engine, which is fair enough, as \n    it lends itself well to that kind of thing. This particular example was coded \n    off the top of my head, and uses simple traditional techniques that have been \n    around for ages. The grid traversal code is also standard and the very simple \n    emitter and throughput lighting code is as basic as it gets.\n    \n    As mentioned in other examples, the only genuinely interesting thing is the use \n    of IQ's temporal reprojection code. Under the right circumstances it can give \n    the appearance of a huge sample boost.\n    \n    In regard to scene design, there is none. It's a textured square grid with some \n    tiny colored squares painted on the sides and some dark edging. That's the \n    beauty of path traced light emitters. Once everything's in place, the algorithm \n    does a lot of the aesthetic work for you.\n    \n    \n    \n    Other examples:\n    \n    // A lot of the realtime path tracing demos out there\n    // are based on elements from this example.\n    past racer by jetlag - w23\n    https://www.shadertoy.com/view/Wts3W7\n    \n    // Like everyone else, I really like this example.\n    20210930_CLUB-CAVE-09 - 0b5vr\n    https://www.shadertoy.com/view/ss3SD8\n    \n    // Path tracing a heap of boxes in realtime with the help of camera\n    // reprojection -- It's one of IQ's many understated examples that \n    // does something amazing.\n    Some boxes - iq\n    https://www.shadertoy.com/view/Xd2fzR\n\n\n*/\n\n\n// Unfortunately, if you have a slow machine IQ's temporal reprojection option\n// will usually result in blur. Regular accumulation might work, but you'll \n// probably have to use straight samples (BUFF_ACCUM 0).\n// Buffer accumulation style:\n// 0: No accumulation -- Noisy, sharper picture, but with no blur. \n// 1: Regular accumulation with no reprojection -- A mixture.\n// 2: Temporal reprojection. -- Smoother for faster machines.\n#define BUFF_ACCUM 2\n\n\n// Far plane. I've kept it close.\n#define FAR 25.\n\n\n///////////////\n\n// Random seed value.\nvec2 seed = vec2(.13, .27);\n\n// Basic random function.\nvec3 rnd23() {\n    \n    //seed += vec2(.723, .647);\n    //return texture(iChannel2, seed*43266.1341).xyz;\n    \n    seed = fract(seed + vec2(.723, .647));\n    vec3 p = vec3(dot(seed.xy, vec2(12.989, 78.233)), \n                          dot(seed.xy, vec2(41.898, 57.267)),\n                          dot(seed.xy, vec2(65.746, 83.765)));\n                          \n    return fract(sin(p)*vec3(43758.5453, 23421.6361, 34266.8747));\n    \n}\n\n// Basic random function. Not a lot of thought was put into it. Using one of\n// the more reliable positive integer based ones might be better... Common sense\n// would dictate that integers work faster, but on a GPU, I'm not really sure.\nvec2 hash22() {\n    \n    //seed += vec2(.723, .647);\n    //return texture(iChannel2, seed*43266.1341).xy;\n    \n    seed = fract(seed + vec2(.723, .647));\n    return fract(sin(vec2(dot(seed.xy, vec2(12.989, 78.233)), dot(seed.xy, vec2(41.898, 57.263))))\n                    *vec2(43758.5453, 23421.6361));\n}\n\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){  return fract(sin(dot(p, vec2(27.619, 57.583)))*43758.5453); }\n\nfloat hash31(in vec3 p){ return fract(sin(dot(p, vec3(91.537, 151.761, 72.453)))*435758.5453); }\n\n\n \n// A nice random hemispherical routine taken out of one of IQ's examples.\n// The routine itself was written by Fizzer.\nvec3 cosDir( in float seed, in vec3 n){\n\n    vec2 rnd = hash22();\n    float u = rnd.x;\n    float v = rnd.y;\n    \n    // Method 1 and 2 first generate a frame of reference to use with an arbitrary\n    // distribution, cosine in this case. Method 3 (invented by fizzer) specializes \n    // the whole math to the cosine distribution and simplfies the result to a more \n    // compact version that does not depend on a full frame of reference.\n\n    // Method by fizzer: http://www.amietia.com/lambertnotangent.html\n    float a = 6.2831853*v;\n    u = 2.*u - 1.;\n    return normalize(n + vec3(sqrt(1. - u*u)*vec2(cos(a), sin(a)), u));\n    \n}\n\n////////////////\n\n\n\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n// Rectangle scale. Smaller scales mean smaller squares, thus more of\n// them. Sometimes, people (including myself) will confuse matters\n// and use the inverse number. :)\nvec2 s = vec2(1, 1)/2.; \n\n // Ray origin, ray direction, point on the line, normal. \nfloat rayLine(vec2 ro, vec2 rd, vec2 p, vec2 n){\n   \n   // This it trimmed down, and can be trimmed down more. Note that \n   // \"1./dot(rd, n)\" can be precalculated outside the loop. However,\n   // this isn't a GPU intensive example, so it doesn't matter here.\n   return dot(p - ro, n)/dot(rd, n);\n\n}\n\n// Grid cell function.\nvec2 gridID(vec2 p){\n    // Using the rectangle's center position for the ID. \n    return floor(p/s) + .5;\n\n}\n\n\nfloat h(vec2 p){\n\n    // Only one texture read.\n    vec3 tx = texture(iChannel0, p/iChannelResolution[0].xy*4.).xyz;  tx *= tx;///iChannelResolution[0].xy\n    // Greyscale height. Using \"tx.x\" would work, too.\n\tfloat f = dot(tx, vec3(.299, .587, .114));\n    float f2 = f;\n    \n    //f = sin(f*6.2831 + iTime)*.5 + .5;\n    \n    f *= min(p.x*p.x/16., 1.);\n    \n    return floor((f*12. + f2*4.)*8.)/8.;\n\n}\n \n// A standard square cell by cell traversal. Not optimized enough for path tracing\n// purposes, but it's reasonable quick otherwise.\nvec4 raycast(vec3 ro, vec3 rd){\n   \n    // Initial result.\n    vec4 res = vec4(FAR, 0, 0, 0);\n    \n    // Rectangle normals: Any two will do. By the way, there's nothing\n    // stopping you from declaring all four normals for all surrounding\n    // walls, but since you know only two will be in front of the\n    // direction ray at any given time, it makes sense to only choose\n    // two.\n    //\n    // Declare two normals. Any side by side ones will do.\n    vec2 n1 = vec2(-1, 0), n2 = vec2(0, -1); // Right and top edges.\n    \n    // If the cell wall is behind the ray (or the ray is facing the opposing cell\n    // wall, if you prefer), use the normal index from the back cell wall. This \n    // trick is possible because of the rectangle symmetry. As an aside, for \n    // anyone who doesn't know, dotting the direction ray with the face normal \n    // is something you do in software engines for back face culling.\n    float d1 = dot(rd.xz, n1);\n    float d2 = dot(rd.xz, n2);\n    n1 = d1<0.? -n1 : n1;\n    n2 = d2<0.? -n2 : n2;\n    \n    // Initiate the ray position at the ray origin.\n    vec3 pos = ro;\n    \n    // Obtain the coordinates of the cell that the current ray position \n    // is contained in -- I've arranged for the cell coordinates to \n    // represent the cell center to make things easier.\n    vec2 ip = gridID(pos.xz);\n    \n    float t1 = 1e8, t2 = 1e8, tT = 1e8;\n    \n    int hit = 0;\n    \n    \n    // Iterate through 24 cells -- Obviously, if the cells were smaller,\n    // you'd need more to cover the distance.\n    for(int i = 0; i<64; i++){ \n\n         \n        // Height. \n        float ma = h(ip*s);\n        \n         \n        // At this point, we haven't advanced the ray to the back of the cell boundary,\n        // so we're at one of the front cell face positions. Therefore, check to see if \n        // we're under the pylon height. If so, we've hit a face, so mark the face as hit, \n        // then break.\n        if(pos.y<ma){\n            // Hit a side.\n            hit = 1;\n            break; \n        \n        } \n        \n        // Ray intersection from the currect cell position to each of the \n        // visible cell walls. Normals face inward.\n        // You pass in the current position, the unit direction ray, a known \n        // point on the cell wall (any will do) and the cell wall's normal.\n        t1 = rayLine(pos.xz, rd.xz, (ip + n1*.5)*s, -n1);\n        t2 = rayLine(pos.xz, rd.xz, (ip + n2*.5)*s, -n2);\n        \n        // Determine the closest edge then record the closest distance and\n        // asign its normal index.\n        vec3 tn = t1<t2? vec3(t1, n1) : vec3(t2, n2);\n        \n        // Top face distance.\n        tT = (ma - pos.y)/rd.y;\n        tT = tT<0. ? 1e8 : tT;\n        \n        \n        // We've now advanced to one of the back faces of the cell. Check to see whether\n        // we're still under the pylon height, and if so, we've hit the top face --  \n        // I always have to think about this, but the logic is that we haven't hit a front\n        // cell face and we're still under the height, so we've hit the top. Anyway, mark \n        // the top face as hit, advance the distance in the Y direction to the top face, \n        // then break.\n        if(tT<tn.x){\n            \n            //dist += tT;\n            pos += rd*tT; \n            hit = 2;\n            break;\n             \n        }      \n         \n    \n        // If this cell's ID matches the ID of the backgound cell, \n        // flag it as hit in order to color it, or whatever.\n        //if(length(cell - ip)<.001){ hit = 1; break; }\n        \n        // Advance the cell index position by the indices of the \n        // cell wall normal that you hit. \n        ip += tn.yz;\n        // Advance the ray position by the distance to the next cell wall.\n        pos += rd*tn.x;\n    \n    }\n    \n    float fID = tT<t1 && tT<t2? 0. : t1<t2? 1. : 2.;\n    if(fID == 1.){ fID = d1<0.? -fID : fID; }\n    else if(fID == 2.){ fID = d2<0.? -fID : fID; }\n    \n    res.x = length(pos - ro);\n    if(hit == 0) res.x = FAR;\n    \n    return vec4(res.x, fID, ip);\n    \n}\n\n// Standard normal function.\nvec3 nr(float fID, vec3 rd) {\n\t\n    vec3 n = fID == 0.? vec3(0, 1, 0) : abs(fID) == 1.? vec3(1, 0, 0) : vec3(0, 0, 1);\n    //if(fID == 1.) n = dot(rd.xz, n.xz)<0.? -n : n;\n    //if(fID == 2.) n = dot(rd.xz, n.xz)<0.? -n : n;\n    n *= fID<-.001? -1. : 1.; \n\treturn n;\n}\n\n// mat3 rotation... I did this in a hurry, but I think it's right. :)\n// I have a much better one than this somewhere. \nmat3 rot(vec3 ang){\n    \n    vec3 c = cos(ang), s = sin(ang);\n\n    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,\n                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,\n                c.y*s.z, -s.y, c.y*c.z);    \n}\n\nvoid mainImage(out vec4 fragColor, vec2 fragCoord){\n\n\n\n    #if BUFF_ACCUM == 2\n    // Initial hit point and distance.\n    vec3 resPos = vec3(0);\n    float resT = 0.;\n    #endif\n\n    // Screen pixel coordinates.\n    vec2 uv0 = (fragCoord - iResolution.xy*.5)/iResolution.y;\n    \n\n    // Initializing the seed value. It needs to be different every frame.\n    seed = uv0 + vec2(fract(iTime/113.671)*.123, fract(iTime/57.913)*.14527);\n    \n    // Ray origin.\n    vec3 ro = vec3(-s.x/2., 3.5, iTime*.25); \n    // Setting the camera to the ray origin. The ray origin vector will change\n    // from bounce to bounce, so we'll need a record of the initial camera position.\n    vec3 cam = ro;\n    \n    \n    // Using the above to produce the unit ray-direction vector.\n    float FOV = 1.; // FOV - Field of view.\n    \n    // Lazy identity camera -- No to and from. I might update it later.\n    mat3 mCam = mat3(vec3(1, 0, 0), vec3(0, 1, 0), vec3(0, 0, 1));\n\n \n    mCam *= rot(vec3(0, 0, cos(iTime/8.*.25)/4.)); // Camera yaw.\n    mCam *= rot(vec3(-sin(iTime/4.*.25)/8., 0, 0)); // Camera roll.\n    mCam *= rot(vec3(0, .5, 0)); // Y axis tilt, or pitch.\n    \n/*\n    // Artistic black movie strips. 20% faster elite democoder move. :D\n    if(abs(uv0.y)>.4) { \n        ivec2 q = ivec2(fragCoord);\n        vec4 c = vec4(0, 0, 0, 1); \n    \tif(q.y == 0 && q.x<3){\n    \n    \t// Camera matrix in lower left three pixels, for next frame.\n        if(q.x == 0) c = vec4(mCam[0], -dot(mCam[0], cam));\n        else if(q.x == 1) c = vec4( mCam[1], -dot(mCam[1], cam));\n        else c = vec4( mCam[2], -dot(mCam[2], cam));\n        } \n        fragColor = c;\n        return; \n    }\n*/\n    \n    // Accumulative color and sample number. 8 is all that my computer can \n    // handle. Some computers would be able to handle more and others less.\n    vec3 atot = vec3(0);\n    const int sampNum = 8;\n    \n    for(int j = min(0, iFrame); j<sampNum; j++){\n    \n    \n        //vec2 jit = vec2(hash21(uv0 + seed + vec2(j, j + 1)), \n        //                hash21(uv0 - seed + vec2(j + 5, j + 7))) - .5;\n        \n        vec2 jit = hash22() - .5;\n                        \n        vec2 uv = uv0 + jit/iResolution.y;\n    \n        // Unit direction vector.\n        vec3 rd = mCam*normalize(vec3(uv, 1./FOV)); \n        \n        // Depth of field. I hacked this in as an afterthought... It seems\n        // about right, but I'll have to take a closer look later.\n        float fDist = 6.;\n        vec2 jitDOF = hash22()*2. - 1.;\n        vec3 vDOF = mCam*vec3(jitDOF, 0.)*.035;\n        rd = normalize(rd - vDOF/fDist);\n        ro = cam + vDOF;\n        \n        // Accumulative, and thoughput.\n        vec3 acc = vec3(0);\n        \n        vec3 through = vec3(1);\n\n        // First hit distance. It's used for fog, amongst other things.\n        float t0; \n        \n  \n        for(int i = min(0, iFrame); i<3; i++){\n\n            // Raycasting\n            vec4 res = raycast(ro, rd);\n\n            float t = res.x, d;\n            float fID = res.y;\n            vec2 id = res.zw;\n\n            t = min(t, FAR); // Clipping to the far distance, which helps avoid artifacts.\n\n            if(i == 0) t0 = t; // Recording the first hit distance.\n\n\n            // Hit point.\n            vec3 p = ro + rd*t;\n            \n            #if BUFF_ACCUM == 2\n            if(i==0){\n                // Only save the initial hit point and distance. Ignore other bounces.\n                resPos += p/float(sampNum); // Accumulative position.\n                resT += t/float(sampNum); // Accumulative distance.\n            }\n            #endif\n\n            // If we've hit an object, light it up.\n            if(t<FAR - 1e-6){\n            \n                \n                // Surface normal.\n                vec3 n = nr(fID, rd);\n\n                // Scene object color.\n                //\n                // Texture coordinates, based on a cube mapping routine.\n                vec2 tuv = fID == 0.? p.xz : abs(fID) == 1.? p.zy : p.xy;\n                vec3 tx = texture(iChannel1, tuv/3.).xyz; tx *= tx;\n\n                vec3 oCol = .125 + tx*2.5;\n\n\n                // Edging routine.\n                float h0 = h(id*s); // Square prism height.\n\n                float minEdge = min(s.x, s.y)/4.;\n                float edge = s.y/4.;\n                float edge2 = s.x/4.;\n\n                // Local coordinates.\n                vec2 lc = p.xz - id*s;\n                // Domain.\n                vec2 ap = abs(lc) - s/2.;\n                // Face edges.\n                float fEdge = max(ap.x, ap.y);\n                fEdge = abs(fEdge);\n                fEdge = max(fEdge, -(p.y - h0)) - .015;\n                // Side edges.\n                float sEdge = min(ap.x, ap.y);\n                sEdge = max(-sEdge, (p.y - h0)) - .015;\n                // Combining.\n                fEdge = min(fEdge, sEdge);\n\n                // Smoothing facor... Not even sure if it's needed in a multisample\n                // example, but it's here anyway.\n                float sf = .001*(1. + res.x*res.x*.1);\n                \n                // Edge rendering.\n                oCol = mix(oCol, vec3(0), (1. - smoothstep(0., sf, fEdge))*.85);\n\n                // Window stips.\n                float strip = abs(p.y - h0 + 2./8.) - 1./8.;\n                oCol = mix(oCol, vec3(0), (1. - smoothstep(0., sf, abs(strip) - .02/2.))*.85);\n\n                // Top face markings, for debug purposes.\n                //c.xyz = mix(c.xyz, vec3(0), 1. - smoothstep(0., sf, length(p.xz - id*s) - .05));\n\n                // Windows.\n                vec2 tip = floor(tuv*8.);\n                vec2 tup = abs(tuv - (tip + .5)/8.);\n                float sq = max(tup.x, tup.y) - .5/8.;\n\n                // Surface roughness. Larger values are duller in appearance, and lower\n                // values are more relective.\n                float rough = .9;\n\n                // Substance emissive color. Initialized to zero.\n                vec3 emissive = vec3(0);\n                \n                // If we hit square prism strip, color random windows and set their emission color. \n                if(strip<.0){\n                //if(hash21(id +.1)<.25 && strip<0.){\n                    \n                    // Render random square frames.\n                    oCol = mix(oCol, vec3(0), (1. - smoothstep(0., sf*8., abs(sq) - .01/2.))*.85);\n                \n                    // Random window color.\n                    vec3 eCol = .5 + .45*cos(6.2831*hash21(tip +.17)/5. + vec3(0, 1.4, 2));\n\n                    // Random emissive color.\n                    emissive = oCol*eCol; // Warm hues.\n                    if(hash21(id +.2)<.5) emissive = oCol*eCol.zyx; // Random cool hues.\n                    // Applying some random green.\n                    emissive = mix(emissive, emissive.xzy, floor(hash21(tip +.42)*4.999)/4.*.35);\n                    // Pink. Too much.\n                    //if(hash21(tip +.33)<.1) emissive = oCol*mix(oCol, eCol.xzy, .5);\n\n                    // Randomly turn lights on and off for some visual interest.\n                    float blink = smoothstep(.2, .3, sin(6.2831*hash21(tip + .09) + iTime/4.)*.5 + .5);\n                    emissive *= mix(1., 0., blink);\n                 \n                    // Ramp up the emissive power.\n                    emissive *= 8.; \n                    \n                    // Make the windows less rough, and randomize a bit.\n                    rough = hash21(tip + .21)*.75;\n                }\n                else {\n                    // Subtly Color the pylons outside the strips.\n                    oCol *= (1. + .25*cos(hash21(id + .06)*6.2831/4. + vec3(0, 1, 2)));\n                }\n                 \n                // Applying the edging to the emission value. You don't have to, but it looks better. \n                emissive = mix(emissive, vec3(0), (1. - smoothstep(0., sf, fEdge))*.95);\n\n                // Tapering emission into the distance.\n                //emissive = mix(emissive, vec4(0), smoothstep(.25, .99, t0/FAR));\n\n                // If an emissive sustance has been hit, use it to light the surface.\n                acc += emissive*through;\n                through *= oCol; // Integrate colors from previous surfaces. \n\n                \n                vec3 ref = reflect(rd, n); // Purely reflected vector.\n                vec3 rrd = cosDir(0., n); // Random half hemisphere vector.\n\n                // Mimicking surface inconsistancies with fuzzy reflections.\n                // Rougher surfaces have a greater chance of random reflecting at any direction and\n                // smoother surfaces are more likely to purely reflect.\n                float rChance = step(0., rough - hash21(uv + vec2(i*277, j*113) + fract(iTime*.97 + .137)));\n                rd = (mix(ref, rrd, rChance));\n                // Other variations. Not physically correct, but they have their purposes.\n                //float rChance = rough*hash21(uv + vec2(i*277, j*113) + fract(iTime*.97 + .137));\n                //rd = normalize(ref + rrd*rChance);\n                //rd = normalize(mix(ref, rrd, rough));\n                //rd = normalize(ref + normalize(rnd23() - .5)*rChance);             \n                //rd = normalize(ref + rrd*rough);\n\n                // Bump the ray off of the hit surface to avoid self collision.\n                ro = p + n*.001;\n\n            }\n            else { \n                // If the scene hasn't been hit, add a touch of atmospheric haze, then exit.\n                // Depending what you're after, you could include the throughput also --\n                // Infact, for some situations, I'm pretty sure you need it:\n                //acc += through*vec3(.4, .6, 1)*.05;\n                acc += vec3(.4, .6, 1)*.035;\n                break;\n            }\n\n    \n        }\n       \n        // Very simple sky fog, or whatever. Not really the way you apply atmosphere in a \n        // path tracer, but way, way cheaper. :)\n        vec3 sky = mix(vec3(1, .7, .5), vec3(.4, .6, 1), uv0.y*2.5 - .15)*1.5;//vec4(.6, .75, 1, 0)/.6\n        //sky *= fBm((cam + r*t0)*128.)*2.;\n        acc = mix(acc, sky, smoothstep(.35, .99, t0/FAR));\n        \n        \n        // Add this sample to the running total.\n        atot += acc;\n        \n    }\n    \n    vec3 col = atot/float(sampNum);\n    \n    \n    \n    // This is IQ's temporal reprojection code: It's well written and\n    // it makes sense. I wrote some 2D reprojection code and was not\n    // looking forward to writing the 3D version, and then this \n    // suddenly appeared on Shadertoy. If you're interested in rigid \n    // realtime path traced scenes with slowly moving cameras, this is \n    // much appreciated. :)\n    //\n    #if BUFF_ACCUM == 2\n    //-----------------------------------------------\n\t// Reproject to previous frame and pull history.\n    //-----------------------------------------------\n    \n    float kFocLen = 1./FOV;\n    vec3 pos = resPos;\n    ivec2 q = ivec2(fragCoord);\n    col = clamp(col, 0., 1.);\n\n    // Fetch previous camera matrix from the bottom left three pixels.\n    mat3x4 oldCam = mat3x4(texelFetch(iChannel3, ivec2(0, 0), 0),\n                           texelFetch(iChannel3, ivec2(1, 0), 0),\n                           texelFetch(iChannel3, ivec2(2, 0), 0));\n    // World space point.\n    vec4 wpos = vec4(pos, 1.);\n    // Convert to camera space (note inverse multiply).\n    vec3 cpos = wpos*oldCam;\n    // Convert to NDC space (project).\n    vec2 npos = (kFocLen*2.)*cpos.xy/cpos.z;//*iRes/iResolution.y;\n    // Convert to screen space.\n    vec2 spos = .5 + .5*npos*vec2(iResolution.y/iResolution.x, 1);\n\t// Convert to raster space.\n    vec2 rpos = spos*iResolution.xy;\n\n    // Read color+depth from this point's previous screen location.\n    vec4 ocolt = textureLod(iChannel3, spos, 0.);\n    // If we consider the data contains the history for this point.\n    if(iFrame>0 && resT<FAR && (rpos.y>1.5 ||rpos.x>3.5)){\n    \n        // Blend with history (it's an IIR low pas filter really).\n        col = mix( ocolt.xyz, col, 1./8.);\n    }\n    \n    // Color and depth.\n    fragColor = vec4(col, resT);\n    \n    // Output.\n\tif(q.y == 0 && q.x<3){\n    \n    \t// Camera matrix in lower left three pixels, for next frame.\n        if(q.x == 0) fragColor = vec4(mCam[0], -dot(mCam[0], cam));\n        else if(q.x == 1) fragColor = vec4( mCam[1], -dot(mCam[1], cam));\n        else fragColor = vec4( mCam[2], -dot(mCam[2], cam));\n    } \n    #elif BUFF_ACCUM == 1\n    // Mix the previous frames in with no camera reprojection.\n    // It's OK, but full temporal blur will be experienced.\n    vec4 preCol = texelFetch(iChannel3, ivec2(fragCoord), 0);\n    float blend = (iFrame < 2) ? 1. : 1./4.; \n    fragColor = mix(preCol, vec4(clamp(col, 0., 1.), 1), blend);\n    #else\n    // No reprojection or temporal blur, for comparisson.\n    fragColor = vec4(max(col, 0.), 1);\n    #endif\n    \n\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 3,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/95b90082f799f48677b4f206d856ad572f1d178c676269eac6347631d4447258.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "texture",
                        "id": 46,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/79520a3d3a0f4d3caa440802ef4362e99d54e12b1392973e4ea321840970a88a.jpg"
                    },
                    {
                        "channel": 3,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}