{
    "Shader": {
        "info": {
            "date": "1689081720",
            "description": "Rendering a repeat irregular quad texture pattern to a cube map face, then using it to path trace an extruded asymmetric quad prism grid in realtime.",
            "flags": 32,
            "hasliked": 0,
            "id": "msXfz2",
            "likes": 93,
            "name": "Path Traced Quad Prism Traversal",
            "published": 3,
            "tags": [
                "grid",
                "raycasting",
                "global",
                "illumination",
                "pathtracing",
                "city",
                "multisample",
                "quad",
                "reprojection",
                "emitter"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 1217
        },
        "renderpass": [
            {
                "code": "/*\n\n    Path Traced Quad Prism Traversal\n    --------------------------------\n\n    See \"Buffer A\" for an explanation.\n\n*/\n\n// This is an amalgamation of old blur and DOF functions with a couple of borrowed \n// lines from Dave Hoskins's much nicer Fibonacci based \"Bokeh disc\" function, which \n// you can find here: https://www.shadertoy.com/view/4d2Xzw\n//\n// This function is only really suitable for this example. If you're interested in \n// bokeh, Dave's function above and some of Shadertoy user, Hornet's, are probably\n// the one's you should be looking at. Xor has some cool simple ones on here that I'm\n// yet to dig into, but they might worth a look also.\nvec4 bloom(sampler2D iCh, vec2 uv){\n\n\tvec4 tot = vec4(0);\n    \n    // UV based DOF. Focused on the horizontal line, then blurring further away.\n    //float r = smoothstep(0., 1., abs(uv.y - .57)/.57)*2.;\n    // Focal point and circle of confusion.\n    const float focD = 4.5, coc = 1.5;\n    // Linear distance from either side of the focal point.\n    float l = abs(texture(iCh, uv).w - focD - coc) - coc;\n    // Using it to calculate the DOF.\n    //float r = smoothstep(.1, .9, abs(uv.y - .5)*2.)*2.;\n    float r = clamp(l/coc, 0., 2.);\n    //float r = mix(clamp(l/coc, 0., 2.), smoothstep(0., 1., abs(uv.y - .5)*2.)*2., .5);\n    \n    const int n = 4;\n    for (int j = -n; j<=n; j++){\n        for (int i = -n; i<=n; i++){\n           \n            // Random offset contained within a disk or radius n.\n            vec2 rnd2 = vec2(hash21B(vec2(i, j)), hash21B(vec2(i, j) + .1)*6.2831853);\n            vec2 offs = float(n)*rnd2.x*vec2(cos(rnd2.y), sin(rnd2.y));\n            \n            vec4 c = texture(iCh, uv + offs/vec2(800, 450)*r, r*iResolution.y/450.*.7); \n            tot += mix(c, pow(c, vec4(1.25))*3.5, rnd2.x*rnd2.x); //ow(c, vec4(1.5))*4.\n            \n        }\n    }\n    \n\treturn tot/float((n*2 + 1)*(n*2 + 1));\n}\n\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    // Coordinates.\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    if(abs(uv.y - .5)>.425){ fragColor = vec4(0); return; }\n    \n    // Bloom.\n    vec4 col = bloom(iChannel0, uv);\n    //\n    // Retrieving the stored color.\n    //vec4 col = texture(iChannel0, uv);\n\n    // Subtle vignette.\n    //col *= pow(16.*uv.x*uv.y*(1. - uv.x)*(1. - uv.y) , 1./32.);\n  \n    // Rough gamma correction and screen presentation.\n    fragColor = pow(max(col, 0.), vec4(1./2.2));\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "\n// If you want things to wrap, you need a wrapping scale.  Wrapping is not much \n// different to regular mapping. You just need to put \"p = mod(p, gSc)\" in the hash \n// function for anything that's procedurally generated with random numbers. If you're \n// using a repeat texture, then that'll have to wrap too.\nconst vec3 gSc = vec3(6);\n\n// Maximum frames to perform the precalculation.\nint maxFrames = 1;\n\n// Cube map resolution.\n#define cubemapRes vec2(1024)\n\n\n/* \n// Reading into one of the cube faces, according to the face ID. To save on cycles,\n// I'd hardcode the face you're after into all but the least costly of situations.\n// This particular function is used just once for an update in the \"CubeA\" tab.\n//\n// The four cube sides - Left, back, right, front.\n// NEGATIVE_X, POSITIVE_Z, POSITIVE_X, NEGATIVE_Z\n// vec3(-.5, uv.yx), vec3(uv, .5), vec3(.5, uv.y, -uv.x), vec3(-uv.x, uv.y, -.5).\n//\n// Bottom and top.\n// NEGATIVE_Y, POSITIVE_Y\n// vec3(uv.x, -.5, uv.y), vec3(uv.x, .5, -uv.y).\nvec4 tx(samplerCube iCh, vec2 p, int id){    \n\n    vec4 rTx;\n    \n    vec2 uv = fract(p) - .5;\n    // It's important to snap to the pixel centers. The people complaining about\n    // seam line problems are probably not doing this.\n    //p = (floor(p*cubemapRes) + .5)/cubemapRes; \n    \n    vec3[6] fcP = vec3[6](vec3(-.5, uv.yx), vec3(.5, uv.y, -uv.x), vec3(uv.x, -.5, uv.y),\n                          vec3(uv.x, .5, -uv.y), vec3(-uv.x, uv.y, -.5), vec3(uv, .5));\n \n    \n    return texture(iCh, fcP[id]);\n}\n*/\n\n// Wrapping cube face conversion.\nvec2 convert(in vec2 p){ return fract((floor(p*cubemapRes) + .5)/cubemapRes) - .5; }\n\n// Cube face conversion with no wrapping.\nvec2 convert2(in vec2 p){ return ((floor(p*cubemapRes) + .5)/cubemapRes); }\n//float convert2(in float p){ return ((floor(p*cubemapRes.x) + .5)/cubemapRes.x); }\n\n\n// Cube face conversion with no wrapping.\nvec4 convert2(in vec4 p){ return ((floor(p*cubemapRes.xyxy) + .5)/cubemapRes.xyxy); }\n\n\nvec4 tx0(samplerCube iCh, vec2 p){\n    vec2 uv = convert(p);\n    return texture(iCh, vec3(-.5, uv.yx));\n \n}\n/*\nvec4 tx1(samplerCube iCh, vec2 p){\n\n    vec2 uv = convert(p);\n    return texture(iCh, vec3(.5, uv.y, -uv.x));\n}\n*/\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n\n// IQ's vec2 to float hash.\nfloat hash21B(vec2 p){  \n    return fract(sin(mod(dot(p, vec2(27.619, 57.583)), 6.2831853))*43758.5453); \n}\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){  \n    p = mod(p, gSc.xy);\n    return fract(sin(mod(dot(p, vec2(27.609, 57.583)), 6.2831853))*43758.5453); \n}\n\n\n///////////////////\n\n// Standard bit encoding and decoding... Every coder's favorite task! :D\n// It's used for a specific task involving packing four low resolution \n// floats (stored in the form of integers) into one channel. Normally, you \n// could pack four large integers into one vector slot, but texture storage \n// complicates things, which traslates to smaller integers and less float\n// resolution... I won't bore you with it. :)\nconst uint ni = 6U;\nconst float fi = float(ni);\n\nconst uvec4 bitEnc = uvec4(1, ni, ni*ni, ni*ni*ni);\nvec4 EncodeFloatRGBA(float v) {\n    \n    return mod(vec4(uvec4(v)/bitEnc), fi);\n}\n\nfloat DecodeFloatRGBA(vec4 v) {\n\n    //return float(uint(v.x) + uint(v.y)*ni + uint(v.z)*ni*ni + uint(v.w)*ni*ni*ni);\n    return dot(vec4(uvec4(v)), vec4(bitEnc));\n}\n\n\n\n// Quad bound: We don't need an actual distance, so can take some shortcuts.\n// I hacked this together, so there would be faster ways to do it.\nfloat sdQuadBound(in vec2 p, mat4x2 v){\n \n     \n    //e[0] = normalize(v[0] - v[1]).yx*vec2(1, -1);\n    //e[1] = normalize(v[1] - v[2]).yx*vec2(1, -1);\n    //e[2] = normalize(v[2] - v[3]).yx*vec2(1, -1);\n    //e[3] = normalize(v[3] - v[0]).yx*vec2(1, -1); \n    float d = dot(p - v[0], normalize(v[0] - v[1]).yx*vec2(1, -1));\n    d = max(d, dot(p - v[1], normalize(v[1] - v[2]).yx*vec2(1, -1)));\n    d = max(d, dot(p - v[2], normalize(v[2] - v[3]).yx*vec2(1, -1)));\n    d = max(d, dot(p - v[3], normalize(v[3] - v[0]).yx*vec2(1, -1)));\n    return d;\n\n}\n\n\n// Rectangle dimensions: Any numbers should work. Obviously, vec2(1)\n// will produce squares.\nvec2 s = 1./gSc.xy; //vec2(1, 1)/6.;\n\n// IQ's vec2 to float hash.\nvec2 hash22T(vec2 p){ \n    \n    p = mod(p, 1./s);    \n    \n    p = fract(sin(mod(vec2(dot(p, vec2(12.783, 78.137)), \n                           dot(p, vec2(41.581, 57.263))), 6.2831853))\n                          *vec2(43758.5453, 23421.6361));\n    \n    return mod(floor(p*float(ni)), float(ni));\n    \n    //return texture(iChannel0, p/64.).xy*2. - 1.; \n}\n\n\n\n\n\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "/*\n\n    Path Traced Quad Prism Traversal\n    --------------------------------\n    \n    This is a realtime path traced asymmetric quad prism grid traversal. I put\n    it together as a fun exercise to see whether it was possible to produce a \n    passable looking globally illuminated scene with just a few samples. As with\n    other examples, I've used IQ's temporal reprojection routine to give the \n    appearance of a higher sample count. I also wanted to post an offset quad\n    cell by cell traversal to Shadertoy.\n    \n    Since this is realtime path tracing, things aren't going to be perfect on an\n    average system -- and apologies in advance for those with slower systems. A \n    basic static path traced scene normally takes seconds to minutes to produce in \n    a fast application like Blender, but realtime requirements only allow for a \n    fraction of a second per frame, so perfect quality is a big ask.\n    \n    Asymmetric grid cell traversals are not common at all, but there are some\n    pretty clever people on here, so they do exist on Shadertoy. There are a few \n    Voronoi traversals, and Fizzer put together a really cool asymmetric triangle \n    example that I'll link to below. I'm pretty sure I haven't come across a quad \n    version before, and I'm definitely sure there are no path traced ones.\n    \n    The obvious advantage to a path traced approach is the pretty lighting. The\n    downside is debilitating your GPU with multiple passes. I attempted to speed \n    up this particular scene by traversing a precalculated texture. If you peruse \n    the code, you'll see that it's not exactly user friendly. Unfortunately, some \n    plane tilings are too complicated to produce in realtime, let alone path \n    trace, so precalculation is the only way to do it on current hardware.\n    \n  \n    \n    \n    Other examples:\n    \n    // An offset triangle prism traversal. Fizzer was able to put his \n    // example together almost instantly. I did not finish mine instantly. :D\n    Irregular Trianglular Prisms - fizzer\n    https://www.shadertoy.com/view/wtjfDt\n    \n    // Path tracing a heap of boxes in realtime with the help of camera\n    // reprojection -- It's one of IQ's many understated examples that \n    // does something amazing.\n    Some boxes - iq\n    https://www.shadertoy.com/view/Xd2fzR\n\n\n*/\n\n\n\n// Unfortunately, if you have a slow machine IQ's temporal reprojection option\n// will usually result in blur. Regular accumulation might work, but you'll \n// probably have to use straight samples (BUFF_ACCUM 0).\n// Buffer accumulation style:\n// 0: No accumulation -- Noisy, sharper picture, but with no blur. \n// 1: Regular accumulation with no reprojection -- A mixture.\n// 2: Temporal reprojection. -- Smoother for faster machines.\n#define BUFF_ACCUM 2\n\n\n// Far plane. I've kept it close.\n#define FAR 25.\n\n\n///////////////\n\n// Random seed value.\nvec2 seed = vec2(.143, .217);\n\n \n// A slight variation on a function from Nimitz's hash collection, here: \n// Quality hashes collection WebGL2 - https://www.shadertoy.com/view/Xt3cDn\nvec2 hash22(){\n\n    // I should probably use a \"uvec2\" seed, but I hacked this from an old\n    // example. I'll update it later.\n    seed = fract(seed + vec2(.7123, .6457));\n    uvec2 p = floatBitsToUint(seed);\n    \n    // Modified from: iq's \"Integer Hash - III\" (https://www.shadertoy.com/view/4tXyWN)\n    // Faster than \"full\" xxHash and good quality.\n    p = 1103515245U*((p>>1U)^(p.yx));\n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    uint n = h32^(h32>>16);\n\n    uvec2 rz = uvec2(n, n*48271U);\n    // Standard uvec2 to vec2 conversion with wrapping and normalizing.\n    return vec2((rz>>1)&uvec2(0x7fffffffU))/float(0x7fffffff);\n}\n\n\n \n\n \n// A nice random hemispherical routine taken out of one of IQ's examples.\n// The routine itself was written by Fizzer.\nvec3 cosDir( in float seed, in vec3 n){\n\n    vec2 rnd = hash22();\n    float u = rnd.x;\n    float v = rnd.y;\n    \n    // Method 1 and 2 first generate a frame of reference to use with an arbitrary\n    // distribution, cosine in this case. Method 3 (invented by fizzer) specializes \n    // the whole math to the cosine distribution and simplfies the result to a more \n    // compact version that does not depend on a full frame of reference.\n\n    // Method by fizzer: http://www.amietia.com/lambertnotangent.html\n    float a = 6.2831853*v;\n    u = 2.*u - 1.;\n    return normalize(n + vec3(sqrt(1. - u*u)*vec2(cos(a), sin(a)), u));\n    \n}\n\n\n\n// The following is based on John Hable's Uncharted 2 tone mapping, which\n// I feel does a really good job at toning down the high color frequencies\n// whilst leaving the essence of the gamma corrected linear image intact.\n//\n// To arrive at this non-tweakable overly simplified formula, I've plugged\n// in the most basic settings that work with scenes like this, then cut things\n// right back. Anyway, if you want to read about the extended formula, here\n// it is.\n//\n// http://filmicworlds.com/blog/filmic-tonemapping-with-piecewise-power-curves/\n// A nice rounded article to read. \n// https://64.github.io/tonemapping/#uncharted-2\nvec4 uTone(vec4 x){\n    return ((x*(x*.6 + .1) + .004)/(x*(x*.6 + 1.)  + .06) - .0667)*1.933526;    \n}\n\n\n////////////////\n\n\n// Ray origin, ray direction, point on the line, normal. \nfloat rayLine(vec2 ro, vec2 rd, vec2 p, vec2 n){\n   \n   // This it trimmed down, and can be trimmed down more. Note that \n   // \"1./dot(rd, n)\" can be precalculated outside the loop. However,\n   // this isn't a GPU intensive example, so it doesn't matter here.\n   //return dot(p - ro, n)/dot(rd, n);\n   float dn = dot(rd, n);\n   return dn>0.? dot(p - ro, n)/dn : 1e8;   \n\n}\n\n// Height function.\nfloat h(vec2 p){\n\n    //float f = dot(sin(p*.75 - cos(p.yx)*1.5), vec2(.25)) + .5;\n    //return f*3. + hash21(p)*1.;\n    \n    // Keeping things cheap and simple with only one texture read.\n    float h = texture(iChannel0, p/64.).x;\n    //h = mix(h - .1, h, smoothstep(.8, .9, sin(h*6.2831853 + iTime)));\n    return h*5.;\n}\n\nvec2 getUV(vec2 p){\n\n    // Cube map texture coordinate conversion.\n    p *= cubemapRes;\n    return fract((floor(p) + .5)/cubemapRes) - .5;\n    \n}\n\n// Rectangle scale: This was hacked in at the last minute and is a little\n// fickle. Sizes one to about 8 are OK. Lower numbers mean smaller rectangles,\n// which require more traversal steps in the \"raycast\" function.\nconst vec2 txSc = vec2(4);\n\n// Grid offset.\nmat4x2 gV;\n\n// Grid cell function.\nvec4 gridID(vec2 p){\n\n    // Same size squares, for comparison. \n    //return vec4(floor(p/txSc) + .5, txSc);\n\n    // Texture multiple ID.\n    vec2 p0 = (floor(p/txSc)*txSc.xy);\n\n    // Texture grid information -- Cube map faces are annoying to read into.\n    vec2 uv = getUV(p/txSc);\n    \n    // Read the texture face information.\n    vec4 hm2 = texture(iChannel3, vec3(-.5, uv.yx)); \n    // Converting to exact pixel positions for wrapping purposes.\n    hm2.xy = convert2(hm2).xy*txSc.xy;\n    //hm2.zw = convert2(hm2).zw*txSc.xy;\n\n    \n    // Read in and encode the vertex information.\n    vec4 v4A = EncodeFloatRGBA(hm2.z);\n    vec4 v4B = EncodeFloatRGBA(hm2.w);\n    mat4x2 sv = mat4x2(v4A, v4B);\n    \n    // Recreate the quad vertices.\n    gV = mat4x2(vec2(-.5), vec2(-.5, .5), vec2(.5), vec2(.5, -.5)); \n    gV += ((sv/float(ni))*2. - 1.)*.25;\n    // Scale.\n    //gV[0] *= s*txSc; gV[1] *= s*txSc; gV[2] *= s*txSc; gV[3] *= s*txSc;\n    gV *= s.x*txSc.x; // Only works for square dimensions, which is the case here.\n    \n    // Return the central position and dimension of the nearest quad.\n    return vec4((p0 + hm2.xy), hm2.zw);\n\n}\n\n\n\n// Sign function without the zero, which can cause problems for some routines.\nvec3 sign2(in vec3 p){ return vec3(p.x<0.? -1 : 1, p.y<0.? -1 : 1,  p.z<0.? -1 : 1); }\n//vec2 sign2(in vec2 p){ return vec2(p.x<0.? -1 : 1, p.y<0.? -1 : 1); }\n\nvec4 gGrid;\nvec3 gN = vec3(0);\n// A standard square cell by cell traversal. Not optimized enough for path tracing\n// purposes, but it's reasonable quick otherwise.\nvec4 raycast(vec3 ro, vec3 rd){\n \n    // Initializing to far.\n    vec4 res = vec4(FAR);\n    \n    \n    vec3 srd = sign2(rd);\n    \n   \n    // Initiate the ray position at the ray origin.\n    vec3 pos = ro;\n    \n    // Obtain the coordinates of the cell that the current ray position \n    // is contained in -- I've arranged for the cell coordinates to \n    // represent the cell center to make things easier.\n    //\n    // I found the following fudge in an old example of mine, and it gets rid \n    // of banding. It took ages to realize what I was thinking at the time. My \n    // notes mention stepping forward by a pixel (or scaled pixels) to the next \n    // cell. If you don't, your reflected rays, shadow rays, etc, risk counting\n    // the initial cell again -- This is the equivalent of a self-collision,\n    // which results in banded shadows, etc... Another explanation is, just make \n    // sure you do it. :D\n    vec4 ip4 = gridID(pos.xz + srd.xz*txSc/1024.);\n    vec2 ip = ip4.xy;\n    gGrid = ip4;\n    \n    // Set all distances to the maximum.\n    float t1 = 1e8, t2 = 1e8, t3 = 1e8, t4 = 1e8, tT = 1e8;\n    \n    // Clockwise edge direction vectors -- Used for jumping from cell to cell.\n    vec2 nn1 = vec2(-1, 0), nn2 = vec2(0, 1), nn3 = vec2(1, 0), nn4 = vec2(0, -1);\n    // Offset edge normal vectors.\n    vec2 n1, n2, n3, n4;\n  \n    \n    vec3 tn;\n    \n    int hit = 0;\n    \n    \n    // Iterate through the cells -- Obviously, if the cells were smaller,\n    // you'd need more to cover the distance.\n    for(int i = 0; i<32; i++){ \n\n         \n        // Height. \n        ip = ip4.xy;\n        float ma = h(ip);\n        \n         \n        // At this point, we haven't advanced the ray to the back of the cell boundary,\n        // so we're at one of the front cell face positions. Therefore, check to see if \n        // we're under the pylon height. If so, we've hit a face, so mark the face as hit, \n        // then break.\n        if(pos.y<ma){\n            // Hit a side.\n            hit = 1;\n            break; \n        \n        } \n        \n\n \n        // Edge normal calculation: You could precalculate these, but for some reason, \n        // it's faster on my machine to recalculate them in situ... No idea why, but \n        // probably special GPU cache reasons. :)\n        n1 = normalize((gV[1] - gV[0]).yx*vec2(1, -1));  \n        n2 = normalize((gV[2] - gV[1]).yx*vec2(1, -1));\n        n3 = normalize((gV[3] - gV[2]).yx*vec2(1, -1)); \n        n4 = normalize((gV[0] - gV[3]).yx*vec2(1, -1)); \n      \n\n       \n        // Ray intersection from the currect cell position to each of the \n        // visible cell walls. Normals face inward.\n        // You pass in the current position, the unit direction ray, a known \n        // point on the cell wall (any will do) and the cell wall's normal.\n        t1 = rayLine(pos.xz, rd.xz, (ip) + gV[0], -n1);\n        t2 = rayLine(pos.xz, rd.xz, (ip) + gV[1], -n2);\n        t3 = rayLine(pos.xz, rd.xz, (ip) + gV[2], -n3);\n        t4 = rayLine(pos.xz, rd.xz, (ip) + gV[3], -n4); \n        \n        // Determine the closest edge then record the closest distance and\n        // asign its normal index.         \n        tn = t1<t2 && t1<t3? vec3(t1, -nn1) : t2<t3? vec3(t2, -nn2) : vec3(t3, -nn3);\n        if(t4<tn.x) tn = vec3(t4, -nn4); \n        \n        //tn.x = min(min(t1, t2), min(t3, t4));\n         \n         \n        \n        \n        // Top face distance.\n        tT = (ma - pos.y)/rd.y;\n        tT = tT>0.? tT : 1e8;\n        \n        \n        // We've now advanced to one of the back faces of the cell. Check to see whether\n        // we're still under the pylon height, and if so, we've hit the top face --  \n        // I always have to think about this, but the logic is that we haven't hit a front\n        // cell face and we're still under the height, so we've hit the top. Anyway, mark \n        // the top face as hit, advance the distance in the Y direction to the top face, \n        // then break.\n        if(tT<tn.x){\n            gN = vec3(0, 1, 0);\n            //dist += tT;\n            pos += rd*tT; \n            hit = 2;\n            break;\n             \n        }       \n   \n        \n        // Advance the cell index position by the indices of the \n        // cell wall normal that you hit. \n        //ip += tn.yz;\n        // Advance the ray position by the distance to the next cell wall.\n        pos += rd*tn.x;\n        \n        // Textures have fixed size, so increasing the scale affects stepping from\n        // one grid cell to the next. Hence, the \"txSc\" variable.\n        ip4 = gridID((ip -  tn.yz*(txSc*s)));\n         \n        gGrid = ip4;\n    }\n    \n    // If we've hit one of the prism sides, return the correct side normal.\n    if(hit==1){\n    \n        tn = t1<t2? vec3(t1, n1) : vec3(t2, n2);\n        if(t3<tn.x) tn = vec3(t3, n3);\n        if(t4<tn.x) tn = vec3(t4, n4);\n        gN = normalize(vec3(tn.y, 0, tn.z));\n        \n    }\n  \n    \n    // Face ID.\n    float fID = tT<t1 && tT<t2 && tT<t3 && tT<t4? 0. : \n    t1<t2 && t1<t3 && t1<t4? 1. : t2<t3 && t2<t4? 2. : t3<t4? 3. : 4.;\n    \n    \n    // Distance.\n    res.x = length(pos - ro);\n    // If we haven't hit anything, set it to the maxium ray distance.\n    if(hit == 0) res.x = FAR;\n    \n    // Return the distance, face ID, and central position based ID.\n    return vec4(res.x, fID, ip);\n    \n}\n\n// Standard normal function.\nvec3 nr(float fID, vec3 rd) {\n\n    return gN;\n/*\n    if(fID==0.) return vec3(0, 1, 0);\n    vec2 n1, n2, n3, n4;\n    n1 = (gV[1] - gV[0]);\n    n2 = (gV[2] - gV[1]);\n    n3 = (gV[3] - gV[2]);\n    n4 = (gV[0] - gV[3]);\n \n    vec2 n = fID == 1.? n1 : n2;\n    if(fID==3.) n = n3;\n    if(fID==4.) n = n4;\n \n    // Tangent to normal conversion.\n    n = n.yx*vec2(1, -1);\n\treturn normalize(vec3(n.x, 0, n.y));*/\n}\n\n// mat3 rotation... I did this in a hurry, but I think it's right. :)\n// I have a much better one than this somewhere. \nmat3 rot(vec3 ang){\n    \n    vec3 c = cos(ang), s = sin(ang);\n\n    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,\n                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,\n                c.y*s.z, -s.y, c.y*c.z);    \n}\n\nvoid mainImage(out vec4 fragColor, vec2 fragCoord){\n\n\n\n    #if BUFF_ACCUM == 2\n    // Initial hit point and distance.\n    vec3 resPos = vec3(0);\n    #endif\n    float resT = 0.;\n\n    // Screen pixel coordinates.\n    vec2 uv0 = (fragCoord - iResolution.xy*.5)/iResolution.y;\n    \n\n    // Initializing the seed value. It needs to be different every frame.\n    seed = uv0 + vec2(fract(iTime/113.671)*.123, fract(iTime/57.913)*.14527);\n    \n    // Ray origin.\n    vec3 ro = vec3(iTime*.2, 8., iTime*.2); \n    // Setting the camera to the ray origin. The ray origin vector will change\n    // from bounce to bounce, so we'll need a record of the initial camera position.\n    vec3 cam = ro;\n    \n    \n    // Using the above to produce the unit ray-direction vector.\n    float FOV = 1.; // FOV - Field of view.\n    \n    // Lazy identity camera -- No to and from. I might update it later.\n    mat3 mCam = mat3(vec3(1, 0, 0), vec3(0, 1, 0), vec3(0, 0, 1));\n\n \n    mCam *= rot(vec3(0, 0, cos(iTime/8.*.25)/4. + .35)); // Camera yaw.\n    mCam *= rot(vec3(-sin(iTime/4.*.25)/8., 0, 0)); // Camera roll.\n    mCam *= rot(vec3(0, 1, 0)); // Y axis tilt, or pitch.\n    \n     \n    // Artistic black movie strips. 15% faster \"1337\" democoder move. :D\n    if(abs(uv0.y)>.425) { \n        ivec2 q = ivec2(fragCoord);\n        vec4 c = vec4(0, 0, 0, 1); \n    \tif(q.y == 0 && q.x<3){\n    \n    \t// Camera matrix in lower left three pixels, for next frame.\n        if(q.x == 0) c = vec4(mCam[0], -dot(mCam[0], cam));\n        else if(q.x == 1) c = vec4( mCam[1], -dot(mCam[1], cam));\n        else c = vec4( mCam[2], -dot(mCam[2], cam));\n        } \n        fragColor = c;\n        return; \n    }\n \n    \n    // Accumulative color and sample number.  Some computers would be able to \n    // handle more and others less.\n    vec3 atot = vec3(0);\n    const int sampNum = 3;\n    \n    for(int j = min(0, iFrame); j<sampNum; j++){\n    \n    \n        //vec2 jit = vec2(hash21(uv0 + seed + vec2(j, j + 1)), \n        //                hash21(uv0 - seed + vec2(j + 5, j + 7))) - .5;\n        \n        // Jittering for antialiasing.\n        vec2 jit = hash22() - .5;\n                        \n        vec2 uv = uv0 + jit/iResolution.y;\n    \n        // Unit direction vector.\n        vec3 rd = mCam*normalize(vec3(uv, 1./FOV)); \n        \n        /*      \n        // Depth of field. I hacked this in as an afterthought... It seems\n        // about right, but I'll have to take a closer look later.\n        float fDist = 6.;\n        vec2 jitDOF = hash22()*2. - 1.;\n        vec3 vDOF = mCam*vec3(jitDOF, 0.)*.06;\n        rd = normalize(rd - vDOF/fDist);\n        ro = cam + vDOF;\n        */        \n\n        ro = cam;\n        \n        // Accumulative, and thoughput.\n        vec3 acc = vec3(0);\n        \n        // Throughput -- Initialized to one.\n        vec3 through = vec3(1);\n\n        // First hit distance. It's used for fog, amongst other things.\n        float t0; \n        \n  \n        for(int i = min(0, iFrame); i<2; i++){\n\n            // Raycasting\n            vec4 res = raycast(ro, rd);\n\n            // Distance, face ID and central position based ID.\n            float t = res.x;\n            float fID = res.y;\n            vec2 id = res.zw;\n            \n            // Saving the face normal and vertices.\n            vec3 svN = gN;\n            mat4x2 svV = gV; \n            \n           \n            t = min(t, FAR); // Clipping to the far distance, which helps avoid artifacts.\n\n            if(i == 0) t0 = t; // Recording the first hit distance.\n\n\n            // Hit point.\n            vec3 p = ro + rd*t;\n            \n            if(i==0){\n                #if BUFF_ACCUM == 2\n                // Only save the initial hit point and distance. Ignore other bounces.\n                resPos += p/float(sampNum); // Accumulative position.\n                #endif\n                resT += t/float(sampNum); // Accumulative distance.\n            }\n            \n    \n            // If we've hit an object, light it up.\n            if(t<FAR){\n            \n                \n                // Surface normal.\n                 \n                vec3 n = nr(fID, rd);//normalize(svN);//\n                 \n                // Scene object color.\n\n                vec2 qq = p.xz - id;\n                // Edging routine.\n                float h0 = h(id); // Square prism height.\n\n                \n                 // Local coordinates.\n                vec2 lc = p.xz - id*s;\n                \n                // Texture coordinates.\n                vec2 rp = lc*rot2(atan(n.x, n.z));\n                vec2 tuv = fID == 0.? p.xz : vec2(rp.x, p.y);\n                vec3 tx = texture(iChannel1, tuv/2.).xyz; tx *= tx;\n       \n                vec3 oCol = .125 + tx*2.5;\n                oCol *= vec3(.6, .8, 1.1)/4.;\n            \n                // Edge construction.\n              \n                \n                // Face edges.\n                /////\n                float fEdge = sdQuadBound(qq, svV);\n                fEdge = max(abs(fEdge), -(p.y - h0)) - .02;\n                // Side edges.\n                /////\n                float sEdge = 1e5;\n                for(int j = 0; j<4; j++){\n                    // Current vertex.\n                    vec2 g = svV[j];\n                    float ang = atan(g.y, g.x);\n                    // Polar transform to the corner.\n                    vec2 nP = qq - vec2(cos(ang), sin(ang))*length(g);\n                    // Corner edge.\n                    sEdge = min(sEdge, length(nP) - .02);\n                    \n                    /* \n                    // Corner dots.\n                    vec2 tn0 = normalize(svV[j] - svV[(j + 3)&3]);\n                    vec2 tn1 = normalize(svV[j] - svV[(j + 1)&3]);\n                    nP = qq - svV[j] + (tn0 + tn1)*.11;                    \n                    sEdge = min(sEdge, length(nP) - .035);\n                    */\n                }\n                /////////////\n                \n                \n           \n                // Smoothing facor... Not even sure if it's needed in a multisample\n                // example, but it's here anyway.\n                float sf = .02;//*(1. + res.x*res.x*.05);\n                \n                // Combining the side and face edges, then smoothstepping.\n                fEdge = min(fEdge, sEdge);\n                \n                // Lighter inner edges.\n                oCol = mix(oCol, oCol*3., (1. - smoothstep(0., sf, fEdge - .02)));\n \n                // Surface roughness. Larger values are duller in appearance, and lower\n                // values are more relective.\n                float rough = .9;\n\n                // Substance emissive color. Initialized to zero.\n                vec3 emissive = vec3(0);\n               \n                // Color random prisms and set their emission color. \n                if(hash21(id + .103)<.1){\n                //if(hash21(id + .103)<.2 && abs(p.y - h0 + .4) < .1){ // Strips only.\n                    \n                \n                    // Random emitter color.\n                    vec3 eCol = .5 + .45*cos(6.2831853*hash21(id +.17)/24. + \n                                vec3(0, 1.4, 2) + 1.);\n                  \n                    // Color variations.\n                    // Random alternate hues.\n                    //if(hash21(id + .027)<.25) eCol = mix(eCol, eCol.yzx, .25); \n                    // Height or screen height based color mixing.\n                    //eCol = mix(eCol.xzy, eCol, smoothstep(0., 2., p.y*.7)*.4 + .6);\n                    //eCol = mix(eCol, eCol.zyx, smoothstep(0., 1., uv0.y + .15));\n                    \n                    // Ramping it up.\n                    eCol *= eCol*4.;  \n                    \n                    \n                    // Randomly turn lights on and off for some visual interest.\n                    float blink = smoothstep(-.6, -.4, sin(hash21(id + .2)*6.2831853 + iTime));\n                    \n                    \n                   \n                    // Apply the edges.\n                    vec3 edCol = mix(eCol/32., vec3(0), blink);\n                    //oCol = mix(vec3(gre), oCol, blink);\n                    //oCol = mix(oCol, edCol, (1. - smoothstep(0., sf, fEdge))*.9);\n                    \n                    // Apply the edges.                    \n                    oCol = mix(oCol, edCol, (1. - smoothstep(0., sf, fEdge)));\n                    \n                    // Blinking emissive color -- ramped up to really glow.\n                    emissive = oCol*eCol*mix(1., 0., blink)*48.; // Fiery hues.\n                    \n                    // Make the glowing pylons less rough, and randomize a bit.\n                    rough = mix(.5, rough, blink); //hash21(id + .21)*.5 + .25;\n                    \n                }\n                else {\n                \n                    // Subtly Color the other pylons.\n                    oCol *= .9 + .2*hash21(id + .06);\n                    \n                     // Apply the edges.\n                    oCol = mix(oCol, vec3(0), (1. - smoothstep(0., sf, fEdge)));\n\n                }\n            \n                // Applying the edging to the emission value. You don't have to, \n                // but it looks better. \n                //emissive = mix(emissive, vec3(0), (1. - fEdge)*.5);\n \n                // Tapering emission into the distance.\n                //emissive = mix(emissive, vec4(0), smoothstep(.25, .99, t0/FAR));\n\n                // If an emissive sustance has been hit, use it to light the surface.\n                acc += emissive*through;\n                through *= oCol; // Integrate colors from previous surfaces. \n \n              \n                vec3 ref = reflect(rd, n); // Purely reflected vector.\n                vec3 rrd = cosDir(0., n); // Random half hemisphere vector.\n \n                // Mimicking surface inconsistancies with fuzzy reflections.\n                // Rougher surfaces have a greater chance of random reflecting at any \n                // direction and smoother surfaces are more likely to purely reflect.\n                float rChance = step(0., rough - hash21(uv + vec2(i*277, j*113) + \n                                fract(iTime*.97 + .137)));\n                rd = (mix(ref, rrd, rChance));\n                // Other variations. Not physically correct, but they have their purposes.\n                //float rChance = hash21(uv + vec2(i*277, j*113) + \n                //                  fract(iTime*.97 + .137))*rough;\n                //rd = normalize(ref + rrd*rChance);\n                //rd = normalize(mix(ref, rrd, rough));\n                //rd = normalize(ref + normalize(rnd23() - .5)*rChance);  \n                //rd = normalize(ref + rrd*rough*4.);\n\n                // Bump the ray off of the hit surface to avoid self collision.\n                ro = p + n*.001;\n\n            }\n            else { \n                // If the scene hasn't been hit, add a touch of atmospheric haze, then quit.\n                vec3 aCol = .2 + vec3(.03, .025, .035)*5.;//tx*.2;//vec3(.1);\n                acc += aCol*through/2.;//*.05; \n                \n                break;\n            }\n\n    \n        }\n       \n        // Very simple sky fog, or whatever. Not really the way you apply atmosphere \n        // in a path tracer, but way, way cheaper. :)\n        //vec3 sky = mix(vec3(1, .7, .5), vec3(.4, .6, 1), uv0.y*2.5 - .15);\n        //acc = mix(acc, sky/4., smoothstep(.35, .99, t0/FAR));\n        \n        \n        // Add this sample to the running total.\n        atot += acc;\n        \n    }\n    \n    // Average the samples.\n    vec3 col = atot/float(sampNum);\n    \n    \n    \n    // Toning down the high frequency values. A simple Reinhard toner would \n    // get the job done, but I've dropped in a heavily modified and trimmed \n    // down Uncharted 2 tone mapping formula.\n    col = uTone(col.xyzx).xyz;\n   \n    \n    // This is IQ's temporal reprojection code: It's well written and\n    // it makes sense. I wrote some 2D reprojection code and was not\n    // looking forward to writing the 3D version, and then this \n    // suddenly appeared on Shadertoy. If you're interested in rigid \n    // realtime path traced scenes with slowly moving cameras, this is \n    // much appreciated. :)\n    //\n    #if BUFF_ACCUM == 2\n    //-----------------------------------------------\n\t// Reproject to previous frame and pull history.\n    //-----------------------------------------------\n    \n    float kFocLen = 1./FOV;\n    vec3 pos = resPos;\n    ivec2 q = ivec2(fragCoord);\n    col = clamp(col, 0., 1.);\n\n    // Fetch previous camera matrix from the bottom left three pixels.\n    mat3x4 oldCam = mat3x4(texelFetch(iChannel2, ivec2(0, 0), 0),\n                           texelFetch(iChannel2, ivec2(1, 0), 0),\n                           texelFetch(iChannel2, ivec2(2, 0), 0));\n    // World space point.\n    vec4 wpos = vec4(pos, 1.);\n    // Convert to camera space (note inverse multiply).\n    vec3 cpos = wpos*oldCam;\n    // Convert to NDC space (project).\n    vec2 npos = (kFocLen*2.)*cpos.xy/cpos.z;//*iRes/iResolution.y;\n    // Convert to screen space.\n    vec2 spos = .5 + .5*npos*vec2(iResolution.y/iResolution.x, 1);\n\t// Convert to raster space.\n    vec2 rpos = spos*iResolution.xy;\n\n    // Read color+depth from this point's previous screen location.\n    vec4 ocolt = textureLod( iChannel2, spos, 0.);\n    // If we consider the data contains the history for this point.\n    if(iFrame>0 && resT<FAR && (rpos.y>1.5 ||rpos.x>3.5)){\n    \n        // Blend with history (it's an IIR low pas filter really).\n        col = mix( ocolt.xyz, col, 1./12.);\n    }\n    \n    // Color and depth.\n    fragColor = vec4(col, resT);\n    \n    // Output.\n\tif(q.y == 0 && q.x<3){\n    \n    \t// Camera matrix in lower left three pixels, for next frame.\n        if(q.x == 0) fragColor = vec4(mCam[0], -dot(mCam[0], cam));\n        else if(q.x == 1) fragColor = vec4( mCam[1], -dot(mCam[1], cam));\n        else fragColor = vec4( mCam[2], -dot(mCam[2], cam));\n    } \n    #elif BUFF_ACCUM == 1\n    // Mix the previous frames in with no camera reprojection.\n    // It's OK, but full temporal blur will be experienced.\n    vec4 preCol = texelFetch(iChannel2, ivec2(fragCoord), 0);\n    float blend = (iFrame < 2) ? 1. : 1./4.; \n    fragColor = mix(preCol, vec4(clamp(col, 0., 1.), 1), blend);\n    #else\n    // No reprojection or temporal blur, for comparisson.\n    fragColor = vec4(clamp(col, 0., 1.), 1);\n    #endif\n    \n\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 3,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/95b90082f799f48677b4f206d856ad572f1d178c676269eac6347631d4447258.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "texture",
                        "id": 16,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png"
                    },
                    {
                        "channel": 3,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// The irregular quad pattern.\n\nvec4 gVal; // Storage for the cell contents.\n//vec2 gSID; // Static ID.\n\n\n\n// The asymmetric quad grid. \nvec4 pattern(vec2 p, vec2 sc){    \n    // Distance and edge width.\n    \n    float d = 1e5;\n    \n     \n    // Centers for all four tiles.\n    const mat4x2 cntr = mat4x2(vec2(-.5), vec2(-.5, .5), vec2(.5), vec2(.5, -.5)); \n    \n    // Because the asymmetric boundaries of the quads overlap neighboring cells, \n    // neighbors need to be considered. In this case four cell renders will do.\n    //const int n = 2;\n    //const float m = floor(float(n)/2. + .001) - .5;\n    for(int i = 0; i<4; i++){\n\n        // Local coordinates and ID.\n        vec2 q = p.xy;\n        vec2 iq = floor(q/sc - cntr[i]) + .5; \n        q -= (iq)*sc;\n        \n        // The four vertices for this cell.\n        mat4x2 v = cntr;\n        \n        // Offset vertices.\n        mat4x2 sv = mat4x2(hash22T(iq + v[0]), hash22T(iq + v[1]), \n                           hash22T(iq + v[2]), hash22T(iq + v[3]));\n        \n        // Offset the vertices.\n        v += (sv/float(ni)*2. - 1.)*.25;\n\n        // Scale.\n        v[0] *= sc; v[1] *= sc; v[2] *= sc; v[3] *= sc;        \n        \n\n        // Quad boundary normals.\n        mat4x2 e = v - mat4x2(v[1], v[2], v[3], v[0]);\n        e[0] = normalize(e[0]).yx*vec2(1, -1);\n        e[1] = normalize(e[1]).yx*vec2(1, -1);\n        e[2] = normalize(e[2]).yx*vec2(1, -1);\n        e[3] = normalize(e[3]).yx*vec2(1, -1);\n        \n        // Quad distance.\n        float d2 = dot(q - v[0], e[0]);\n        d2 = max(d2, dot(q - v[1], e[1]));\n        d2 = max(d2, dot(q - v[2], e[2]));\n        d2 = max(d2, dot(q - v[3], e[3]));\n  \n        // If this quad distance is nearer, update.\n        if(d2<d){\n            \n            // New distance, static ID and moving ID.\n            // The zero field is an unused height value holder.\n            d = d2;\n            //gSID = iq + (v[0] + v[1] + v[2] + v[3])/4./s;\n            \n            // Storing the four quad vertices into the final two channels.\n            vec2 gQV;\n            gQV.x = DecodeFloatRGBA(vec4(sv[0], sv[1]));\n            gQV.y = DecodeFloatRGBA(vec4(sv[2], sv[3]));\n            \n            // Saving the central coordinates and four vertices of the nearest quad. \n            // \"sc\" needs to be there for wrapping purposes.\n            gVal = vec4(iq*sc, gQV);\n        }\n    \n    }\n    \n    \n    // Combining the floor with the extruded object.\n    return  gVal;\n \n}\n\n\n\nvec4 funcFace0(vec3 q3){\n\n    // Cube map face pattern.\n    return pattern(q3.xy, s);\n}\n\n\n\n// Cube mapping - Adapted from one of Fizzer's routines. \nint CubeFaceCoords(vec3 p){\n\n    // Elegant cubic space stepping trick, as seen in many voxel related examples.\n    vec3 f = abs(p); f = step(f.zxy, f)*step(f.yzx, f); \n    \n    ivec3 idF = ivec3(p.x<.0? 0 : 1, p.y<.0? 2 : 3, p.z<0.? 4 : 5);\n    \n    return f.x>.5? idF.x : f.y>.5? idF.y : idF.z; \n}\n\n\n\nvoid mainCubemap(out vec4 fragColor, in vec2 fragCoord, in vec3 rayOri, in vec3 rayDir){\n    \n    \n    \n    \n    // Adapting one of Fizzer's old cube mapping routines to obtain the cube face ID \n    // from the ray direction vector.\n    int faceID = CubeFaceCoords(rayDir);\n    \n    // We're only using one cube map face, so don't calculate any others...\n    // or give the annoying compiler a chance to calculate others.\n    if(faceID > 0) return;\n    \n    \n    // UV coordinates.\n    //\n    // For whatever reason (which I'd love expained), the Y coordinates flip each\n    // frame if I don't negate the coordinates here -- I'm assuming this is internal, \n    // a VFlip thing, or there's something I'm missing. If there are experts out there, \n    // any feedback would be welcome. :)\n    vec2 uv = fract(fragCoord/iResolution.y*vec2(1, -1));\n  \n  \n    // Pixel storage.\n    vec4 col = vec4(0);\n    \n    \n    \n    // Precalculation flag: GPUs are annoying. Sometimes, they'll will calculate\n    // both the \"if\" and \"else\" statements every time. The \"if\" part here is extremely\n    // expensive, so we don't want that. The solution is to not have an \"if-else\"\n    // statement at all.\n    int preCalc = 0;\n    \n\n    // Initial conditions -- Performed upon initiation.\n    //if(abs(tx(iChannel0, uv, 5).w - iResolution.y)>.001){\n    //if(iFrame<1){\n    //\n    // Great hack, by IQ, to ensure that this loads either on the first frame, or in the\n    // event that the texture hasn't loaded (this happens a lot), wait, then do it...\n    // Well kind of. Either way, it works. It's quite clever, which means that it's \n    // something I never would have considered. :)\n    if(textureSize(iChannel0, 0).x<2 || iFrame<maxFrames){\n        \n        //if(iFrame>=maxFrames) return;        \n        \n        // Fill the first cube face with a custom function.\n        if(faceID==0){\n            \n            //vec3 p = convert2DTo3D(uv);      \n            vec3 p = vec3(uv, 0);      \n            \n            col = funcFace0(p);\n            \n            preCalc = 1;\n           \n        }\n        \n    }\n    \n    // If precalculation has already occurred, read in the texture.\n    if(preCalc == 0) col = tx0(iChannel0, uv);\n    \n    \n    \n    // Update the cubemap faces.\n    fragColor = col;\n    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    }
                ],
                "name": "Cube A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 41
                    }
                ],
                "type": "cubemap"
            }
        ],
        "ver": "0.1"
    }
}