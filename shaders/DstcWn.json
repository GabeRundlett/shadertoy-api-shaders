{
    "Shader": {
        "info": {
            "date": "1695046049",
            "description": "Using a pseudo path tracing technique to produce a simple realtime scene lit up with multiple emitters.",
            "flags": 32,
            "hasliked": 0,
            "id": "DstcWn",
            "likes": 142,
            "name": "Raytraced Rolling Ball",
            "published": 3,
            "tags": [
                "global",
                "illumination",
                "ball",
                "tracing",
                "realtime",
                "path",
                "quad",
                "rolling",
                "faux",
                "emissive"
            ],
            "usePreview": 1,
            "username": "Shane",
            "viewed": 3315
        },
        "renderpass": [
            {
                "code": "/*\n\n    Raytraced Rolling Ball\n    ----------------------\n\n    See \"Buffer A\" for an explanation.\n\n*/\n\n\n \n// Just a very basic depth of field routine -- I find a lot of it is\n// common sense. Basically, you store the scene distance from the camera \n// in the fourth channel, then use it to determine how blurry you want\n// your image to be at that particular distance.\n//\n// For instance, in this case, I want pixels that are 2.25 units away from \n// the camera to be in focus (not blurred) and for things to get more \n// blurry as you move away from that point -- aptly named the focal point \n// for non camera people. :)\n//\n// I based this on old code of mine, but adopted things that I found in \n// IQ and Nesvi7's examples, which you can find here:\n//\n// Ladybug - IQ\n// https://www.shadertoy.com/view/4tByz3\n//\n// Cube surface II - Nesvi7\n// https://www.shadertoy.com/view/Mty3DV\n//\nvec3 DpthFld(sampler2D iCh, vec2 uv){\n\t\n    // Focal point and circle of confusion.\n    const float focD = 3.5, coc = 2.;\n    // Linear distance from either side of the focal point.\n    float l = abs(texture(iCh, uv).w - focD - coc) - coc;\n    // Using it to calculate the DOF.\n    float dof = clamp(l/coc, 0., 1.);\n    //dof *= smoothstep(0., .25, length(uv - .5));\n\n    \n    // Combine samples. Samples with a larger DOF value are taken further \n    // away from the original point, and as such, appear blurrier.\n    vec3 acc = vec3(0);\n\n    for(int i = 0; i<25; i++){\n        // Accumulate samples.\n        acc += texture(iCh, uv + (vec2(i/5, i%5) - 2.)/vec2(800, 450)*dof).xyz;\n        //acc.x *= dof/2.;\n    }\n\n    // Return the new variably blurred value.\n    return acc /= 25.;\n    // Visual debug representation of DOF value.\n    //return vec3(dof);\n}\n\n \n/*\n// Standard 2D rotation formula.\n//mat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n// IQ's float to float hash. I've added an extra sine wrapping modulo to\n// cater for my annoying AMD based system, which can't wrap sine with a \n// proper degree of accuracy.\nfloat hash11B(float x){ return fract(sin(mod(x, 6.2831853))*43758.5453); }\n\n// This is an amalgamation of old blur and DOF functions with a heap of borrowed \n// lines from Dave Hoskins's much nicer Fibonacci based \"Bokeh disc\" function, which \n// you can find here: https://www.shadertoy.com/view/4d2Xzw\n//\n// If you're interested in bokeh, Dave's function above and some of Shadertoy user, \n// Hornet's, are probably the one's you should be looking at. Xor has some cool simple \n// ones on here too.\n//\nvec4 bokeh(sampler2D iCh, vec2 uv){\n\n    \n    vec4 colOrig = texture(iCh, uv);\n\n    // UV based DOF. Focused on the horizontal line, then blurring further away.\n    //float r = smoothstep(0., 1., abs(uv.y - .57)/.57)*2.;\n    // Focal point and circle of confusion.\n    const float focD = 3.5, coc = 1.25;\n    // Linear distance from either side of the focal point.\n    float l = abs(colOrig.w - focD - coc) - coc;\n \n    // Using it to calculate the DOF.\n    float ra = clamp(l/coc, 0., 2.);\n    //float ra = smoothstep(.3, 1., abs(uv.y - .5)*2.);\n    //float ra = mix(clamp(l/coc, 0., 2.), smoothstep(.3, 1., abs(uv.y - .5)*2.), .5);\n    ra *= smoothstep(0., .1, length(uv - .5) - .25);\n\n    // Standard Fibonacci distribution calculations, compliments of Dave Hoskins.\n    const int iter = 96;\n    float rad = 1.6;//max(2.*ra, .5); // Bokeh radius.\n    float r = 1.;\n\tvec4 tot = vec4(0), div = tot;\n    vec2 vangle = vec2(0., rad*.01/sqrt(float(iter)));\n    #define GA 2.3999632 // Golden angle.\n    const mat2 rot = mat2(cos(GA), sin(GA), -sin(GA), cos(GA));\n\n    // Aspect ratio.\n    vec2 aspect = vec2(iResolution.y/iResolution.x, 1);\n    \n    \n\tfor (int i = 0; i<iter; i++){\n        \n        #if 1\n        \n        // Dave Hoskin's Fibonacci based scattering. Cheaper and much nicer, so\n        // it's set as the default.\n        // The approx increase in the scale of sqrt(0, 1, 2, 3...).\n        r += 1./r;\n\t    vangle = rot*vangle;\n        vec4 col = texture(iCh, uv - (r - 1.)*vangle*aspect, iResolution.y/450.*1.5);\n        \n        \n        #else\n        \n        // A hash based random distribution, for anyone who wants to try it.\n        //int ii = i%10; // For square bokeh.\n        //int jj = i/10;\n    \n        // Random offset contained within a disk or radius n.\n        float fi = float(i) + fract(iTime);\n        //vec2 fi = vec2(ii, jj) - 5. + fract(iTime);\n        vec2 rnd2 = vec2(hash11B(fi), hash11B(fi + .1)*6.2831);\n        vec2 offs = 6.*sqrt(rnd2.x)*vec2(cos(rnd2.y), sin(rnd2.y));\n        ////////\n         \n        // Polygons, if desired. Comment out the line above and comment in\n        // the \"rot2\" formula above, if using it.\n        //const float N = 6.;\n        //float ra = rnd2.y;\n        //float a = (floor(ra*N) + .5)*6.2831859/N;\n        //vec2 offs  = mix(rot2(a)*vec2(0, 1), rot2(a + 6.2831859/N)*vec2(0, 1), \n        //                 fract(ra*N));\n        //offs *= 6.*sqrt(rnd2.x);\n        ////////\n        offs *= rad;\n        //offs = rad*(offs + (vec2(hash11B(fi), hash11B(fi + .21)) - .5));\n        vec4 col = texture(iCh, uv - offs/iResolution.xy, iResolution.y/450.*1.5);  \n  \n        #endif\n         \n        // Thanks to Dave for figuring out how to tweak the colors to produce brighter \n        // contrast. It's common sense... once someone figures it out for you. :D \n        vec4 bokeh = pow(col, vec4(2));\n\t\ttot += bokeh*col*col;\n\t\tdiv += bokeh;\n        \n\t}\n    \n    \n    // Mixing the original value with the bokeh tweaked value according\n    // to the depth of field.\n    \n    // Not entirely correct, but no one will notice here. :)\n\treturn mix(colOrig, colOrig*.25 + tot/div*4., ra);\n}\n\n*/\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n    // Screen oordinates.\n    vec2 uv = fragCoord/iResolution.xy;\n    \n     // Retrieving the stored color only.\n    //vec4 col = texture(iChannel0, uv);\n\n    // Depth of field.\n    vec4 col = DpthFld(iChannel0, uv).xyzz;\n    \n    \n   \n    // Mixing in some bokeh. I thought it was a bit much for\n    // this example (The \"bokeh\" function would need to be \n    // commented back in first).\n    //vec4 col2 = bokeh(iChannel0, uv);\n    //col = mix(col, col2, .35);\n    \n     \n    /*\n    // Chromatic aberration. Not for this example, but interesting.\n    #if 0\n    const float focD = 3.5, coc = 1.25;\n    // Linear distance from either side of the focal point.\n    float l = abs(texture(iChannel0, uv).w - focD - coc) - coc;\n    // Using it to calculate the DOF.\n    float ra = clamp(l/coc, 0., 1.);\n    vec2 e = ra*4./iResolution.xy;\n    #else\n    vec2 e = 4./iResolution.xy;\n    #endif\n    vec4 colX = texture(iChannel0, uv + e.xy);\n    vec4 col = texture(iChannel0, uv);\n    vec4 colZ = texture(iChannel0, uv - e.xy);\n    col = vec4(colX.x, col.y, colZ.z, 1);\n    */\n\n    // Subtle vignette. Designers use them to frame things and guide\n    // the viewer's eyes toward the center... or something like that.\n    //col *= pow(16.*uv.x*uv.y*(1. - uv.x)*(1. - uv.y) , 1./32.);\n    // Colored vignette.\n    col = mix(col, col.yzxw, smoothstep(.35, .6, length(uv - .5)));\n\n\n    // Rough gamma correction and screen presentation.\n    fragColor = pow(max(col, 0.), vec4(1./2.2)); \n    \n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\n\n    Raytraced Rolling Ball\n    ----------------------\n    \n    Using a pseudo path tracing technique to produce a simple realtime scene \n    lit up with multiple emitters.\n    \n    Some time ago, Xor wrote a minimal shader featuring a glitch texture that\n    I was pretty taken with, and figured it'd look interesting in some kind of \n    globally illuminated setting, so I quickly repurposed an old example and \n    put this together the same day... then got side tracked (probably by some \n    other Shadertoy post) and forgot about it. :)\n    \n    Anyway, I came across it today, so quickly tidied it up and added commnents.\n    Rolling spheres down a corridor are a bit of a raytracing cliche, but \n    they're visually effective. There's nothing in here that hasn't been covered \n    before, but someone might get something out of it.\n    \n    I wanted the code to be partly readable, so didn't optimize things as much\n    as I probably should have. However, I'll tweak it later.\n    \n    \n    \n    Based on:\n    \n    // Beautiful in its simplicity. Less is more, as they say. \n    Gltch [291 Chars] - Xor\n    https://www.shadertoy.com/view/mdfGRs\n    \n    // A lot of the realtime path tracing demos out there\n    // are based on elements from this example.\n    past racer by jetlag - w23\n    https://www.shadertoy.com/view/Wts3W7\n\n    \n\n*/\n\n\n// Sample number and blend number: The trick is to find a balance between the\n// two, or use a faster computer. :)\n\n// Number of samples: My computer can handle more. If yours is struggling, you \n// can lower this. Naturally, sample number is proportional to noise quality.\n#define sampNum 12\n\n\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n// Fabrice's fork of \"Integer Hash - III\" by IQ: https://shadertoy.com/view/4tXyWN\nfloat hash21(vec2 f){\n\n    // Depending on your machine, this should be faster than\n    // the block below it.\n    return texture(iChannel1, f*vec2(.2483, .1437)).x;\n    /*\n    uvec2 p = floatBitsToUint(f);\n    p = 1664525U*(p>>1U^p.yx);\n    return float(1103515245U*(p.x^(p.y>>3U)))/float(0xffffffffU);\n    */\n}\n\n// IQ's \"uint\" based uvec3 to float hash.\nfloat hash31(vec3 f){\n\n    uvec3 p = floatBitsToUint(f);\n    p = 1103515245U*((p >> 2U)^(p.yzx>>1U)^p.zxy);\n    uint h32 = 1103515245U*(((p.x)^(p.y>>3U))^(p.z>>6U));\n\n    uint n = h32^(h32 >> 16);\n    return float(n & uint(0x7fffffffU))/float(0x7fffffff);\n}\n\n// Random seed.\nvec2 seed = vec2(.183, .257);\n\n\n// A slight variation on a function from Nimitz's hash collection, here: \n// Quality hashes collection WebGL2 - https://www.shadertoy.com/view/Xt3cDn\nvec2 hash22(){\n\n    // I should probably use a \"uvec2\" seed, but I hacked this from an old\n    // example. I'll update it later.\n    seed = fract(seed + vec2(.7123, .6457));\n    uvec2 p = floatBitsToUint(seed);\n    \n    // Modified from: iq's \"Integer Hash - III\" (https://www.shadertoy.com/view/4tXyWN)\n    // Faster than \"full\" xxHash and good quality.\n    p = 1103515245U*((p>>1U)^(p.yx));\n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    uint n = h32^(h32>>16);\n\n    uvec2 rz = uvec2(n, n*48271U);\n    // Standard uvec2 to vec2 conversion with wrapping and normalizing.\n    return vec2((rz>>1)&uvec2(0x7fffffffU))/float(0x7fffffff);\n}\n\n/*\n// A slight variation on a function from Nimitz's hash collection, here: \n// Quality hashes collection WebGL2 - https://www.shadertoy.com/view/Xt3cDn\nvec3 hash23(vec2 f){\n\n\tuvec2 p = floatBitsToUint(f);\n    p = 1664525U*(p>>1U^p.yx); \n    \n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    uint n = h32^(h32>>16);\n    \n    // See: http://random.mat.sbg.ac.at/results/karl/server/node4.html\n    uvec3 rz = uvec3(n, n*16807U, n*48271U); \n    return vec3((rz >> 1) & uvec3(0x7fffffffU))/float(0x7fffffff);\n}\n*/\n\n// IQ's box routine.\nfloat sBox(in vec2 p, in vec2 b, float r){\n\n  vec2 d = abs(p) - b + r;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - r;\n}\n\n \n// A nice random hemispherical routine taken out of one of IQ's examples.\n// The routine itself was written by Fizzer.\nvec3 cosDir( in float seed, in vec3 n){\n\n    vec2 rnd = hash22();\n    float u = rnd.x;\n    float v = rnd.y;\n    \n    // Method 1 and 2 first generate a frame of reference to use with an arbitrary\n    // distribution, cosine in this case. Method 3 (invented by fizzer) specializes \n    // the whole math to the cosine distribution and simplfies the result to a more \n    // compact version that does not depend on a full frame of reference.\n\n    // Method by fizzer: http://www.amietia.com/lambertnotangent.html\n    float a = 6.2831853*v;\n    u = 2.*u - 1.;\n    return normalize(n + vec3(sqrt(1. - u*u)*vec2(cos(a), sin(a)), u));\n    \n}\n\n\n// Sphere normal.\nvec3 sphereNorm(vec3 p, float id, vec4 sph){\n   \n    return (p - sph.xyz)/sph.w; \n}\n \n// Hitting a number of walls from the inside: You could simply raytrace four\n// planes, but this is a little more concise. I was too lazy to write my own\n// routine, so quickly adapted a working one (sadly, not many of those around) \n// from one of PublicIntI's examples. At some stage, I'll get in amongst it and \n// rewrite one, or find one of my older routines. Alternatively, if someone\n// knows of a concise reliable function or sees a way to tidy the following up, \n// feel free to let me know. :)\n//\n// crystal exhibit(pathtraced) - public_int_i \n// https://www.shadertoy.com/view/wljSRz\n//\n// Ray-box intersection: The function take in the ray origin (offset if needed)\n// the unit direction ray and the box dimensions, then returns the distance and \n// normal.\n//\nvec4 boxIntersect(vec3 ro, vec3 rd, vec3 dim) {\n\n    const float maxT = 1e8; // Maximum distance.\n \n    vec3 minD = (ro + dim)/rd, maxD = (ro - dim)/rd;\n\tminD = -(minD - step(vec3(-1e-6), minD)*(minD + maxT));\n\tmaxD = -(maxD - step(vec3(-1e-6), maxD)*(maxD + maxT));\n\tminD = min(minD, maxD);\n    \n    // Result: Distance and normal.\n    vec4 res = vec4(maxT, 0, 0, 0);\n    \n    // Performing some ray-plane intersections, modified to handle\n    // two planes at once. I'd imagine you could cleverly combine this\n    // into just one test, but I'm not clever, so I'll leave that to \n    // someone else. :D\n    \n    // We don't need the left and right walls for this example.\n    if (minD.x<maxT){\n        float pd = abs(ro.y + rd.y*minD.x) - dim.y;\n        if(pd<0.) res = vec4(minD.x, -sign(rd.x), 0, 0);\n    }\n    \n    // Top and bottom surfaces, or ceiling and floor, if you prefer.\n    if (minD.y<maxT){\n        float pd = abs(ro.x + rd.x*minD.y) - dim.x;\n        if(pd<0.) res = vec4(minD.y, 0., -sign(rd.y), 0.);\n    }\n\n    \n    // Return the distance and normal.\n    return res;\n}\n \n \n// Sphere intersection: Pretty standard, and adapted from one\n// of IQ's formulae.\nvec2 sphereIntersect(in vec3 ro, in vec3 rd, in vec4 sph){\n\n    vec3 oc = ro - sph.xyz;\n\tfloat b = dot(oc, rd);\n    if(b > 0.) return vec2(1e8, 0.);\n\tfloat c = dot(oc, oc) - sph.w*sph.w;\n\tfloat h = b*b - c;\n\tif(h<0.) return vec2(1e8, 0.);\n\treturn vec2(-b - sqrt(h), 1.); \n    \n}\n\n\n// Sphere position and radius.\nconst float ballRad = .5;\nvec4 sph4 = vec4(0, ballRad - 1., 1., ballRad);\n\n// Hacking in a normal for the box equation.\nvec3 boxNrm;\n\n// Scene normal logic: Not that exciting for this example. :)\nvec3 getNorm(vec3 p, float id){\n    \n    return (id<.5)? sphereNorm(p, id, sph4) : boxNrm; \n}\n\n\n// Intersection logic for all objects.\nvec3 intersect(vec3 ro, vec3 rd){\n    \n    // Containers for two objects. Usually there'd be more.\n    vec2[2] q;\n    \n    // The sphere.\n    q[0] = sphereIntersect(ro, rd, sph4);//vec2(1e5);//\n    //q[0].x = 1e5;\n\n    // The box tube object, or 4 walls at once, if you prefer. :)\n    vec4 bx = boxIntersect(ro - vec3(0, 1.5 - 1., -.5*0.), rd, vec3(2, 1.5, 1e8));\n    q[1] = vec2(bx.x, 1);\n    boxNrm = bx.yzw; \n   \n    \n    // Returning the object distance, a hit ID (inside surface, etc, and redundant \n    // for this example) and the object ID used for materials and so forth.\n    return q[0].x<q[1].x? vec3(q[0], 0) : vec3(q[1], 1);\n    \n    /*\n    // For more objects, you need to do a little more work.\n    vec3 d = vec3(1e5);\n    \n    for(int i = 0; i<2; i++){\n       if(q[i].x< d.x) d = vec3(q[i], i);\n    }\n        \n    return d;\n    */\n    \n}\n\n\n// The wall and floor pattern, which is just something quick and effective\n// that I picked up from Xor's example, here:\n//\n// Gltch [291 Chars] - Xor\n// https://www.shadertoy.com/view/mdfGRs\nvec3 distField2(vec2 p, float scl, float rndZ, float oID){\n    \n    // Edge width.\n    float ew = .0125; \n     \n    // Outer boundaries, prior to partitioning.\n    vec2 pp = abs(fract(p) - .5);\n    float sq = abs(max(pp.x, pp.y) - .5) - ew*2.;\n    \n    // Scale.\n    vec2 sc = vec2(1, 1)/scl; \n \n    // Cell ID and local coordinates.\n    vec2 ip = floor(p/sc);\n    p -= (ip + .5)*sc;\n    \n    \n    // Rounded square.\n    float d = sBox(p, sc/2. - ew, .1*min(sc.x, sc.y)*0.);\n    //float d = length(p) - sc.x/2. + ew;\n   \n    // Randomly rotated and scaled lines.\n    if(hash21(ip + rndZ*.123 + oID + .055)<.65){\n        float f = scl*4.;\n        //float n = floor((floor(hash21(ip + .043)*64.)*2.) + 1.)*3.14159/4.;\n        float n = floor(hash21(ip + rndZ*.401 + oID + .043)*64.)*3.14159/4.;\n        vec2 uv = rot2(n)*(p + vec2(f/2., 0));\n        float g = (abs(fract(uv.x*f + n*f*0.) - .5) - .175)/f;\n        d = max(d, g);\n        \n    }\n    \n    if(oID==0.) d = max(d, -sq);\n    \n    // Putting a hole in it just to break things up.\n    //d = max(d, -(length(p) - .2*sc.x));\n    \n    // Rings.\n    //d = abs(d + .1*sc.x) - .1*sc.x;\n    \n    \n    \n    // Returning the distance and local cell ID. Note that the \n    // distance has been rescaled by the scaling factor.\n    return vec3(d, ip*sc);\n}\n\n\n// A simple rotated stripey pattern, like above.\nvec3 distField(vec2 p, float scl, float oID){\n    \n\n    //Noise macro\n    #define N(u) hash21(floor(u) + oID*.123) //texture(iChannel0, (u)/64.).x\n   \n    \n    p *= scl;\n    float rnd = N(p);\n    \n    \n    vec2 p2 = p/(rnd + .1);\n    \n    vec2 pp = fract(p2) - .5;\n    float sq = (abs(max(abs(pp.x), abs(pp.y)) - .5) - 1./40.)/2.*(rnd + .1);;\n    rnd = N(p2);\n    // Random quarter turn rotation.\n    float n = floor(rnd*64.)*3.14159/4.;\n    vec2 id = rnd + ceil(p2);\n    // Random stripe frequency.\n    float f = 1./N(id)/3.14159; \n    //float f = 4.;\n\n    // Random quarter rotation stripes of random frequency.\n    //float g = ceil(cos((rot2(n)*p).x*f));\n    //float g = cos((rot2(n)*p).x*f);\n    float g = (abs(fract((rot2(n)*p).x*f) - .5) - .25)/f; \n\n    g = max(g, -sq); \n    \n    return vec3(g, id);\n\n}\n\n\n// IQ's signed square formula with some roundness thrown in. \nfloat sBoxS(in vec2 p, in vec2 b, in float rf){\n  \n  vec2 d = abs(p) - b + rf;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - rf;\n    \n}\n\n\n// mat3 rotation... I did this in a hurry, but I think it's right. :)\n// I have a much better version of this that I'll have to find.\nmat3 rot(vec3 ang){\n    \n    vec3 c = cos(ang), s = sin(ang);\n\n    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,\n                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,\n                c.y*s.z, -s.y, c.y*c.z);\n    \n}\n\n\n// Cube mapping - Adapted from one of Fizzer's routines. \nvec4 cubeMap(vec3 p){\n\n    // Elegant cubic space stepping trick, as seen in many voxel related examples.\n    vec3 f = abs(p); f = step(f.zxy, f)*step(f.yzx, f); \n    \n    ivec3 idF = ivec3(p.x<.0? -1 : 1, p.y<.0? -1 : 1, p.z<0.? -1 : 1);\n    \n    ivec3 faceID = (idF + 1)/2 + ivec3(0, 2, 4);\n    \n    return f.x>.5? vec4(p.yz/p.x, idF.x, faceID.x) : \n           f.y>.5? vec4(p.xz/p.y, idF.y, faceID.y) : vec4(p.xy/p.z, idF.z, faceID.z); \n}\n \nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n\n     \n    float sf = 1./iResolution.y;\n        \n    // Screen pixel coordinates.\n    float iRes = iResolution.y;\n    vec2 seed0 = fract(iTime/vec2(111.13, 57.61))*vec2(-.143, .457);\n    vec2 uv0 = (fragCoord - iResolution.xy*.5)/iRes;\n    \n  \n    float FOV = 1.; // FOV - Field of view.\n    vec3 ro = vec3(0, 0, iTime*2. + sin(iTime)*.125);\n    // \"Look At\", \"forward\" and \"up\" vectors.\n    vec3 lk = ro + vec3(0, -.01, .25);\n    vec3 fwd = normalize(lk - ro);\n    vec3 rgt = normalize(vec3(fwd.z, 0., -fwd.x )); \n    vec3 up = cross(fwd, rgt); \n\n    \n    // Camera.\n    mat3 mCam = mat3(rgt, up, fwd);\n    // There are ways to rotate the camera all at once, but these will do.\n    mCam *= rot(vec3(0, .05, 0)); \n    mCam *= rot(vec3(0, 0, -sin(iTime/2.)*.25)); \n    mCam *= rot(vec3(-cos(iTime/2.)*.25, 0, 0)); \n    \n    // Mouse driven camera movement.\n    if(iMouse.z>0.){\n        vec2 ms = (iMouse.xy/iResolution.xy - .5)*vec2(3.14159/2.);\n        mCam *= rot(vec3(0, ms.y/2., -ms.x));\n    }\n    \n    // Positioning the rolling ball.\n    sph4.x -= cos(iTime/2.)*.25; // Left to right.\n    sph4.z = ro.z + 4.; // In front of the camera.\n    \n    // Accumulative color.\n    vec3 aCol = vec3(0);\n    \n    float gT = 1e8;\n    float avgT = 0.;\n    \n    \n    for(int j = min(0, iFrame); j<sampNum; j++){\n        \n        // Seed value and jitter.\n        seed = uv0 + seed0 + vec2(j*57, j*27)/1321.;\n        vec2 jit = hash22()*2. - 1.;\n        \n        // Jittered UV coordinate.\n        vec2 uv = uv0 - jit/iResolution.y;\n\n        // Using the above to produce the unit ray-direction vector.\n        vec3 rd = mCam*normalize(vec3(uv, 1./FOV));\n\n        // Camera position. Initially set to the ray origin.\n        vec3 cam = ro;\n        // Surface postion. Also initially set to the ray origin.\n        vec3 sp = ro;\n\n        vec3 col = vec3(0);\n        \n        // Emissive, throughput and sample colors.\n        vec3 emissive = vec3(0);\n        vec3 through = vec3(1);\n        vec3 sCol = vec3(0);\n        \n        // Fog.\n        float fogD = 1e8;\n       \n        \n        // Just three bounces. More looks better, but the extra randomess\n        // requires more samples. For static scenes, that's not a problem,\n        // but this is a realtime one.\n        for(int i = min(0, iFrame); i<3; i++){\n\n            \n            vec3 scene = intersect(sp, rd); // Scene intersection.\n\n            float t = scene.x; // Scene distance.\n            float retVal = scene.y; // Redundant here, but used when refraction is involved.\n            float id = scene.z;// Object ID.\n            \n            // Set the fog distance on the first pass.\n            if(i==0){ \n                fogD = t;\n                avgT += t/float(sampNum);\n               if(j==0) gT = fogD;\n               \n            }\n\n            sp += rd*t; // Advance the ray position.\n\n  \n            if(t<1e8){\n\n                \n                vec3 sn = getNorm(sp, id); // Normal.\n\n                vec3 oCol = vec3(0), emissive = vec3(0); // Object color, and emissivity.\n\n                emissive = vec3(0);\n                float rough = 0.;\n\n               \n                if(id<.5) { \n                   \n                    // Placing an offset subdivided grid pattern on the sphere,\n                    // then randomly lighting up random cells.\n \n                    // Texture coordinates.\n                    vec3 txP = sp - sph4.xyz;\n                    // Rotation.\n                    txP.xy *= rot2(sph4.x/(sph4.w)/2.);\n                    txP.yz *= rot2(-sph4.z/(sph4.w));\n                    \n                    // An icosahedral mapping would probably look nicer, but I\n                    // wanted to do something different for this example.\n                    vec4 q3 = cubeMap(txP);\n                    float faceID = q3.w;\n                    \n                    // Distance field pattern:\n                    // Returns the distance field and cell ID.\n                    //vec3 d3 = distField((q3.xy/2. + .5), 2., q3.z);\n                    vec3 d3 = distField2((q3.xy/2. + .5), 6., q3.z, faceID);\n                    // Distance field isoline boundary.\n                    d3.x = smoothstep(0., sf, d3.x);\n\n                    float rnd2 = hash21(d3.yz + q3.z*.051 + faceID + .024);;\n                    float sRnd = rnd2;\n                    rnd2 = smoothstep(.4, .45, sin(6.2831*rnd2 + iTime/1.));\n                  \n \n                    // Render the pattern on the walls, ceiling and floor.\n                    vec3 wCol = .5 + .5*cos(6.2831*hash21(d3.yz + q3.z*5.51 + \n                                            faceID + .374)/2. + vec3(0, 1, 2)*1.1 - 0.);\n                    oCol = mix(vec3(.9, .95, 1)*(hash21(d3.yz + q3.z*2.035 + \n                                                faceID + .144)*.5 + .5), vec3(.1), d3.x);\n           \n                    wCol = wCol*vec3(4, 2, 1);  \n                   \n                    // Classier toned down colors.\n                    //wCol = mix(vec3(1), vec3(1, .4, .2), hash21(d3.yz + .14));\n                    // Flipping colors.\n                    //wCol =  mix(wCol, wCol.zyx, hash21(d3.yz + .14));   \n                    \n             \n                    emissive = mix(wCol*(rnd2*.785 + .015)*3.*vec3(1, .97, .92), \n                                    vec3(.005), d3.x);\n                     // Roughness.\n                    rough = hash21(d3.yz + q3.z + .11);\n                    //rough = smoothstep(.2, .8, rough)*.25;\n                    rough = rough*rough*.3 + .025;\n                    \n                    // Individual pixel roughness.\n                    rough *= hash31(sp + .51)*.5 + .75;\n                    //rough = min(rough + hash31(sp + .31)*.025, 1.);\n                    \n                   \n                    if(hash21(d3.yz + faceID + .063)<.5){\n                        oCol = vec3(1)*dot(oCol, vec3(.299, .587, .114));\n                        emissive = vec3(1)*dot(emissive, vec3(.299, .587, .114));\n                    }\n \n                   \n       \n          \n               }\n               else {\n\n                   \n                    // Producing a wall and floor pattern, coloring it, and using\n                    // parts to act as emitters.\n                    \n                    // Back wall or not.\n                    float sgn = (abs(sn.z)>.5)? 1. : -1.;\n                    // Wall ID.\n                    float wID = sgn < 0.? sp.y<0.? 0. : 2. : sp.z<0.? 1. : 3.;\n                    \n                    // UV coordinates for the walls and floors.\n                    vec2 q = sgn>.5? sp.xy : abs(sn.x)>.5? sp.yz : sp.xz;\n                    \n                    // Vertical strips and horizontal wall strips.\n                    float strip = abs(mod(sp.z, 4.) - 2.) - 3./6.;\n                    float yStrip = abs(sp.y - .5) - 1.5 + 1./6.;\n                    \n                    \n                    // Distance field pattern:\n                    // Returns the distance field and cell ID.\n                    vec3 d3;\n                    // \n                    if(strip<0. && yStrip<0.) d3 = distField2(q, 6., wID, id);\n                    else if(abs(sn.y)>.5) d3 = distField(q, 4., wID);\n                    else d3 = distField(q, 2., wID);\n                    \n                    //d3 = distField(q, 2., wID);\n                    \n                    // Distance field isoline boundary.\n                    d3.x = smoothstep(0., sf, d3.x);\n             \n \n                    // Cell and wall based colors.\n                    vec3 wCol = .5 + .5*cos(6.2831*hash21(d3.yz + wID*.054 + .274)/2. +\n                                            vec3(0, 1, 2)*1.1 - 1.5*1.);\n                    vec3 wCol2 = .5 + .5*cos(6.2831*hash21(d3.yz + wID*.054 + .273)/2. + \n                                             vec3(0, 1, 2)*1.1);\n   \n                    // Vertical colors and greyscale areas.\n                    if(strip>0.) wCol = vec3(1)*dot(wCol2, vec3(.299, .587, .114));\n                    else wCol = wCol2*vec3(4, 2, 1);\n\n                    // Greyscale the wall entirely.\n                    //wCol = vec3(1)*dot(wCol, vec3(.299, .587, .114));\n                    // Flipping wall colors.\n                    //wCol =  mix(wCol, wCol.zyx, hash21(d3.yz + .14));\n                    // Classier toned down colors.\n                    //wCol = mix(vec3(1), vec3(1, .4, .2), hash21(d3.yz + .14));\n                    \n   \n                    \n                    // The wall color pattern.\n                    oCol = mix(vec3(.9, .95, 1)*(hash21(d3.yz + wID*.054 + .174)*.5 + .5), \n                                                 vec3(.1), d3.x);\n\n                   \n                    // Emissivity.\n                    float rnd2 = hash21(d3.yz + .067); \n                    // Periodically blinking emissive colors.\n                    rnd2 = smoothstep(.4, .47, sin(6.2831*rnd2 + iTime/1.)*.5);\n                  \n                    // Pattern based emissivity -- It doesn't always have to be object \n                    // based. Only adding emissivity to the left and right wall strips.\n                    if(abs(sn.y)<.5 && yStrip<0.)\n                       emissive = mix(wCol*rnd2*4.*vec3(1, .97, .92), vec3(.005), d3.x);\n                    // More orange light.\n                    //if(abs(mod(sp.z, 4.) - 2.)<.5) \n                    //     emissive *= mix(wCol2*6.*vec3(1, .97, .92), vec3(.0), d3.x); \n                  \n                   \n                    // Dark strips.\n                    if(abs(sn.x)>.5 && abs(yStrip - .015) - .015<0.){ oCol *= 0.; }   \n      \n                     \n                    // Roughness.\n                    rough = hash21(d3.yz + wID*.021 + .11);\n                    rough = rough*rough*.3 + .025;\n                    // Individual pixel roughness.\n                    rough *= hash31(sp + .41)*.5 + .75;\n                     \n                }\n                \n                // Different emissivity variations.\n                //emissive = mix(emissive, emissive.zyx, .7).yxz;\n                //emissive = mix(emissive.zyx, emissive, uv0.y*1.5 + .5);\n                //emissive = vec3(1)*dot(emissive, vec3(.299, .587, .114));\n  \n                   \n  \n                // I definitely like the more natural way in which colors are applied\n                // when rendering this way. We only add surface color when it's been\n                // hit by a ray that has visited a light source at some point.\n                sCol += emissive*through;\n                // Applying this bounce's color to future bounces. For instance, if we\n                // hit a pink emitter then hit another surface later, that surface will\n                // incorporate a bit of pink into it.\n                through *= oCol;\n\n \n                vec3 ref = reflect(rd, sn); // Purely reflected vector.\n                vec3 rrd = cosDir(0., sn); // Random half hemisphere vector.\n                //vec3 rrd = normalize(hash23() - .5); // Less evenly distributed.\n\n         \n                // Mimicking surface inconsistancies with fuzzy reflections.\n                // Rougher surfaces have a greater chance of randomly reflecting at any \n                // direction and smoother surfaces are more likely to purely reflect.\n                //float rChance = step(rough*2. + .4, hash21(uv + vec2(i*277, j*113) + \n                //                     fract(iTime*.977 + .137)));\n                //rd = (mix(rrd, ref, rChance));\n                //rd = normalize(mix(ref, rrd, rough));\n             \n               \n                //rd = normalize(ref + rrd*rough);\n                rd = normalize(mix(ref, rrd, rough));\n                // Not sure this line matters too much, but with the fake random\n                // bounce above, I guess rays could head into the surface, so \n                // it's there, just in case.\n                if(dot(rd, sn)<0.) rd = -rd; \n\n\n                sp += sn*1e-5;\n                //rd = ref; // Pure reflection override.\n\n            } \n            \n            \n             if(aCol.x>1e5) break; // Attempting to reduce compile time. \n        }\n      \n        // Applying some fog, if necessary. You don't actually see this, but\n        // I want it there for completeness.\n        sCol = mix(vec3(0), sCol, 1./(1. + fogD*fogD*.02));\n\n        \n        // Accumulate the sample color.\n        aCol += sCol;\n        \n        if(sCol.x>1e5) break; // Attempting to reduce compile time.\n        \n        \n    }\n    \n    // Average color over all samples.\n    aCol /= float(sampNum);\n    \n    \n  \n    \n    // Mix the previous frames in with no camera reprojection.\n    // It's OK, but full temporal blur will be experienced.\n    vec4 preCol = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    float blend = (iFrame < 2) ? 1. : 1./2.;//1./(1. + length(uv0)*3.); \n    fragColor = mix(preCol, vec4(max(aCol, 0.), avgT), blend);\n    \n    // No temporal blur, for comparisson.\n    //fragColor = vec4(max(aCol, 0.), 1);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 17,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/0c7bf5fe9462d5bffbd11126e82908e39be3ce56220d900f633d58fb432e56f5.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}