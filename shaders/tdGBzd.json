{
    "Shader": {
        "info": {
            "date": "1607716466",
            "description": "A simple example of how to allow the user to fly through a raymarched scene. I hope the comments aren't too excessive, I was trying to explain it as much as possible.",
            "flags": 48,
            "hasliked": 0,
            "id": "tdGBzd",
            "likes": 2,
            "name": "Simple Flythrough Example",
            "published": 3,
            "tags": [
                "3d",
                "raymarching",
                "example",
                "tutorial",
                "flythrough"
            ],
            "usePreview": 0,
            "username": "oneshade",
            "viewed": 141
        },
        "renderpass": [
            {
                "code": "/*\nUse the mouse to rotate the camera and the arrow keys to move it.\n\nCommon: contains all of the settings and helper functions for texture lookups\nBuffer A: contains the code for updating the camera position and yaw/pitch rotationa\nImage: contains the raymarching code (for a more in-depth raymarching tutorial, visit Jamie Wong's amazing website: http://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/)\n*/\n\nfloat mapScene(in vec3 p) {\n    p = mod(p, 2.0) - 1.0; // Repeat the scene infinitely with a spacing of 2 units (the -1 is to center it)\n    return length(p) - 0.25; // Sphere with a radius of 0.25 units\n}\n\nvec3 getNormal(in vec3 p) {\n    return normalize(vec3(mapScene(p + SMALL_STEP.xyy) - mapScene(p - SMALL_STEP.xyy),   // How much the distance changes in the x direction\n                          mapScene(p + SMALL_STEP.yxy) - mapScene(p - SMALL_STEP.yxy),   // How much the distance changes in the y direction\n                          mapScene(p + SMALL_STEP.yyx) - mapScene(p - SMALL_STEP.yyx))); // How much the distance changes in the z direction\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    // Center and normalize uv (with aspect ratio so there is no squashing)\n    vec2 uv = (fragCoord - 0.5 * iResolution.xy) / iResolution.y;\n\n    // Generate a ray for the pixel:\n    vec3 rayOrigin = getViewPosition();\n    mat3 camera = getCamera(getViewDirection());\n    vec3 rayDirection = normalize(FOCAL_LENGTH * camera[2] + uv.x * camera[0] + uv.y * camera[1]);\n\n    fragColor = vec4(0.0, 0.0, 0.0, 1.0);\n    float distanceTraveled = 0.0;\n    for (int iteration=0; iteration < MAX_ITERATIONS; iteration++) {\n        vec3 position = rayOrigin + rayDirection * distanceTraveled;\n        float sceneDistance = mapScene(position);\n\n        // Is the ray close enough to be hitting?\n        if (sceneDistance < MIN_HIT_DISTANCE) {\n            vec3 normal = getNormal(position);\n            vec3 light = normalize(vec3(-1.0, 1.0, 1.0));\n            fragColor.rgb = vec3(max(0.0, dot(normal, light))); // Diffuse shading\n            break;\n        }\n\n        // Has the ray gone too far?\n        if (distanceTraveled > MAX_TRACE_DISTANCE) {\n            break;\n        }\n\n        // Move forward maximum distance possible without missing anything:\n        distanceTraveled += sceneDistance;\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\nThe camera rotation is stored as yaw/pitch rotations. Yaw is spin and pitch is tilt.\nIf you need help visualizing this, this image should help:\nhttps://upload.wikimedia.org/wikipedia/commons/c/c1/Yaw_Axis_Corrected.svg\n*/\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    fragColor = vec4(0.0, 0.0, 0.0, 1.0);\n\n    // Have the viewing position and direction been initialized?\n    if (iFrame > 0) {\n        ivec2 address = ivec2(fragCoord);\n\n        // Should this pixel store the view position?\n        if (address == VIEW_POSITION_ADDR) {\n            fragColor = vec4(getViewPosition(), 1.0);\n            mat3 camera = getCamera(getViewDirection());\n \n            // Update the view position based on keypresses:\n            if (keyUpPressed()) {\n                fragColor.xyz += camera[2] * STEP_SIZE; // Move STEP_SIZE units in the camera's forward direction\n            }\n\n            if (keyDownPressed()) {\n                fragColor.xyz -= camera[2] * STEP_SIZE; // Move STEP_SIZE units opposite the camera's forward direction\n            }\n\n            if (keyRightPressed()) {\n                fragColor.xyz += camera[0] * STEP_SIZE; // Move STEP_SIZE units in the camera's right direction\n            }\n\n            if (keyLeftPressed()) {\n                fragColor.xyz -= camera[0] * STEP_SIZE; // Move STEP_SIZE units opposite the camera's right direction\n            }\n        }\n\n        // Should this pixel store the view direction?\n        if (address == VIEW_DIRECTION_ADDR) {\n            // Center and normalize mouse position, multiply by two pi for rotation from -180 to 180, then scale it by ROTATION_SPEED\n            vec2 viewDirection = (iMouse.xy - 0.5 * iResolution.xy) / iResolution.y * TWO_PI * ROTATION_SPEED;\n            fragColor = vec4(viewDirection, 0.0, 1.0);\n        }\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// Raymarching constants:\nconst vec3 SMALL_STEP = vec3(0.001, 0.0, 0.0);\nconst float MAX_TRACE_DISTANCE = 100.0;\nconst float MIN_HIT_DISTANCE = 0.001;\nconst int MAX_ITERATIONS = 50;\nconst float FOCAL_LENGTH = 1.0;\n\n// Math constants (only two pi in this case):\nconst float TWO_PI = 6.2832;\n\n// Amount by which the camera moves and rotates:\nconst float STEP_SIZE = 0.1;\nconst float ROTATION_SPEED = 0.5;\n\n// Addresses to viewing data:\nconst ivec2  VIEW_POSITION_ADDR = ivec2(0, 0);\nconst ivec2 VIEW_DIRECTION_ADDR = ivec2(1, 0);\n\n// Key codes from iq's keyboard input demo (https://www.shadertoy.com/view/lsXGzf):\nconst int    KEY_UP = 38;\nconst int  KEY_DOWN = 40;\nconst int KEY_RIGHT = 39;\nconst int  KEY_LEFT = 37;\n\n// A bunch of crazy macros because they are the only way to define texelFetches in Common :(\n#define  getViewPosition() texelFetch(iChannel0, VIEW_POSITION_ADDR, 0).xyz\n#define getViewDirection() texelFetch(iChannel0, VIEW_DIRECTION_ADDR, 0).xy\n\n#define     keyUpPressed() bool(texelFetch(iChannel1, ivec2(38, 0), 0).x)\n#define   keyDownPressed() bool(texelFetch(iChannel1, ivec2(40, 0), 0).x)\n#define  keyRightPressed() bool(texelFetch(iChannel1, ivec2(39, 0), 0).x)\n#define   keyLeftPressed() bool(texelFetch(iChannel1, ivec2(37, 0), 0).x)\n\n// Calculates camera axes:\nmat3 getCamera(in vec2 viewDirection) {\n    vec2 c = cos(viewDirection); vec2 s = sin(viewDirection);\n    return mat3(vec3(       c.x, 0.0,         s.x),  // Camera right axis (x)\n                vec3(s.x * -s.y, c.y, -c.x * -s.y),  // Camera up axis (y)\n                vec3(s.x *  c.y, s.y, -c.x *  c.y)); // Camera forward axis (z)\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}