{
    "Shader": {
        "info": {
            "date": "1682276485",
            "description": "An auto-VJ based on a spectrogram in polar coordinates. Utilizing compression for colors & lighting.\n\n - use with audio in iChannel0 of Buffer A -",
            "flags": 96,
            "hasliked": 0,
            "id": "dlt3Wr",
            "likes": 7,
            "name": "Rorschach Of Sound",
            "published": 3,
            "tags": [
                "2d",
                "music",
                "buffer",
                "spectrogram"
            ],
            "usePreview": 0,
            "username": "QuantumSuper",
            "viewed": 358
        },
        "renderpass": [
            {
                "code": "// Rorschach Of Sound 0.51.230426 by QuantumSuper\n// auto-vj which doubles as a spectrogram visualizer\n// \n// - use with audio in iChannel0 of Buffer A -\n\n#define zoom (400./iResolution.x)\n#define PI 3.14159265359 \n\nfloat compressDat(vec2 pos, vec2 stepSize, float steps){ //reads & sums up iChannel1.r/b from pos until pos+stepSize*steps in .y domain\n    float maxVal,curVal = 0.;\n    \n    for (float n=0.; n<steps; n++){\n        maxVal = getDat( iChannel1, pos+stepSize*n).b;\n        curVal += (maxVal>.0)? clamp( getDat( iChannel1, pos+stepSize*n).r/maxVal, .0, 1.) : getDat( iChannel1, pos+stepSize*n).r; //normalize over maximum estimation\n    }\n    \n    return curVal/steps; //normalize over steps\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n\n    // Prepare view\n    vec2 uv = (2.*fragCoord-iResolution.xy) / max(iResolution.x,iResolution.y); //long edge -1 to 1\n    uv *= max(iResolution.x,iResolution.y)/sqrt(iResolution.x*iResolution.x+iResolution.y*iResolution.y) * zoom; // stretch to fill screen & zoom\n    uv = vec2(uv.y,-abs(uv.x)); //symmetry & domain flip\n    \n    \n    // Polar coordinates\n    float r = mod(float(iFrame)/iResolution.x-length(uv),1.);\n    float rho =  (atan(uv.y,uv.x)/PI+1.);\n    \n    \n    // Compression (assume sound texture with 44.1kHz in 512 texels)\n    float tc = mod(float(iFrame)+.001,iResolution.x); //latest texture position\n    vec4 fft = vec4(\n        compressDat( vec2(tc, 1), vec2(0,  1), 2.), //bass, 0-517Hz, reduced to 86-258Hz\n        compressDat( vec2(tc, 6), vec2(0,  1), 2.)+ //speech I, 517-689Hz\n        compressDat( vec2(tc, 8), vec2(0,  2), 3.)+ //speech II, 689-1206Hz\n        compressDat( vec2(tc,14), vec2(0,  4), 3.), //speech III, 1206-2067Hz\n        compressDat( vec2(tc,24), vec2(0, 10), 8.), //presence, 2067-8183Hz, tenth sample\n        compressDat( vec2(tc,95), vec2(0,100), 5.)); //brilliance, 8183-44100Hz, tenth2 sample\n    fft.y/=3.; //finalize normalization\n    \n    \n    // View manipulation\n    float wave = getDat( iChannel1, vec2(mod(float(iFrame)+.001,iResolution.x) ,rho*iResolution.y)).g;\n    if (wave == .0) wave = dot( fft, cos(2.*PI*(iTime*vec4(86,517,2067,8183)+rho)))/8. + .5; //catch if no waveform found, synthesize crude approximation        \n    r = .94*r + .06*length(uv) * wave; //wobble by waveform\n    rho = (pow(10.,rho)-1.)/9.; //exponential frequency scale of pow10 to increase visibility of lower frequencies\n  \n\n    // Compression manipulation\n    fft.yzw = 2.*fft.yzw-fft.zwy-fft.wyz; //get differences\n    fft.yzw /= max(abs(fft.y),max(abs(fft.z),max(abs(fft.w),.001))); //normalize\n    \n    fft.x = pow(fft.x,6.); //weaken weaker bass (exaggerate movement)\n    \n    \n    // Draw image\n    float amp = getDat( iChannel1, vec2( r, rho) * iResolution.xy).r;\n    amp *= amp*amp*amp; //increase contrast\n    \n    float d = 10.*length(uv/zoom)+1.5; d *= d; //offset distance factor\n    vec3 col = amp * 10./d * (1.-cos(fft.zwy*PI)); //vignette & color\n    \n    d *= d;\n    col = vec3(10.+20.*fft.x)/d * (.8+.2*col) + col*(1.-1./d); //center light\n    \n    col *= abs(cos(.06666*iTime+vec3(0,.7854,1.571))); //color shift \n    col = pow(col, vec3(.4545)); //gamma correction\n    fragColor = vec4( col, 1.); //output\n    \n    \n    // Utility\n    //fragColor = vec4(getDat( iChannel1, fragCoord).rrr,1); //audio spectrum over time\n    //fragColor = vec4(getDat( iChannel1, fragCoord).ggg,1); //wave form over time\n    //fragColor = vec4(getDat( iChannel1, fragCoord).bbb,1); //average amplitude over time\n    //fragColor = vec4(step(.0,(fragCoord.y/iResolution.y-.9)),vec2(dot(step(.0,fft-abs(floor(fragCoord.x/iResolution.x*4.-vec4(0,1,2,3)))-fragCoord.y/iResolution.y/.9),vec4(1))),1); //final compression data\n    //fragColor = vec4(vec3(step(abs(wave-fragCoord.x/iResolution.x)-.01,.0)),1); //polar waveform\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// COMMON (0.0) of Rorschach Of Sound by QuantumSuper\n// \n// - use with audio in iChannel0 of Buffer A -\n\n#define getDat(buf,addr) texelFetch( buf, ivec2(addr), 0)",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// BUFFER A (0.3) of Rorschach Of Sound by QuantumSuper\n// audio spectrum over time\n// red: amplitude by brightness of frequency by y-axis at time by x-axis\n// green: waveform by brightness of frequency by y-axis at time by x-axis\n// blue: average amplitude by brightness of frequency by y-axis at time by x-axis\n// \n// - use with audio in iChannel0 of Buffer A -\n\n#define TRACKDURATIONINFRAMES 3600.\n\nfloat estMax(float p){ //estimate changing maximum over time of sound texel by weighted amplitude tracking\n    float curVal = clamp( getDat( iChannel0, vec2( p/iResolution.y*512., 0)).x, .0, 1.); //current amplitude\n    float maxVal = clamp( getDat( iChannel1, vec2( (mod(float(iFrame-1)+.001,iResolution.x)), p)).z, .0, 1.); //latest max amp\n    \n    if (curVal >= maxVal) maxVal = 0.; //check for new max    \n    \n    if (maxVal != 0.) //avoid uninitialized state & deprecated maxVal\n        curVal *=    1./TRACKDURATIONINFRAMES,\n        maxVal *= 1.-1./TRACKDURATIONINFRAMES;\n  \n    return maxVal+curVal; //returns value between 0 and 1\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord){\n    fragColor = (mod(fragCoord.x-float(iFrame)+.001,iResolution.x)<1.)? vec4( \n        getDat( iChannel0, vec2( fragCoord.y/iResolution.y*512., 0)).x, //amplitudes\n        getDat( iChannel0, vec2( fragCoord.y/iResolution.y*512., 1)).x, //waveform\n        estMax( fragCoord.y), //average amplitude\n        1)\n        : getDat( iChannel1, fragCoord); //carry over \"long-term\" memory    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "musicstream",
                        "id": 33124,
                        "published": 0,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "https://soundcloud.com/dvskrecords/rec003wav"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// BUFFER B (0.0) of Rorschach Of Sound by QuantumSuper\n// workaround to avoid self-sampling of Buffer A\n// \n// - use with audio in iChannel0 of Buffer A -\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    fragColor = getDat( iChannel1, fragCoord);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}