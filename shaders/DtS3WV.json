{
    "Shader": {
        "info": {
            "date": "1673901763",
            "description": "Port of VRChat audiolink\n[url=https://github.com/llealloo/vrc-udon-audio-link]vrc-udon-audio-link[/url]\n\nUse the circles to move the capture regions.\n\nThe UI is bad, but it's just a proof of concept.",
            "flags": 32,
            "hasliked": 0,
            "id": "DtS3WV",
            "likes": 2,
            "name": "VRC Audiolink port V3",
            "published": 3,
            "tags": [
                "audiolink"
            ],
            "usePreview": 1,
            "username": "Iliana",
            "viewed": 194
        },
        "renderpass": [
            {
                "code": "// Mechanism to index into texture.\n#ifdef AUDIOLINK_STANDARD_INDEXING\n    sampler2D _AudioTexture;\n    #define AudioLinkData(xycoord) tex2Dlod(_AudioTexture, vec4(uvec2(xycoord) * _AudioTexture_TexelSize.xy, 0., 0.))\n#else\n    #define _AudioTexture iChannel0\n    #define AudioLinkData(xycoord) texelFetch(_AudioTexture, ivec2(xycoord), 0)\n#endif\n\n\n\n\n\n// Convenient mechanism to read from the AudioLink texture that handles reading off the end of one line and onto the next above it.\nvec4 AudioLinkDataMultiline(uvec2 xycoord) { return AudioLinkData(uvec2(xycoord.x % uint(AUDIOLINK_WIDTH), xycoord.y + xycoord.x/uint(AUDIOLINK_WIDTH))); }\n\n// Mechanism to sample between two adjacent pixels and lerp between them, like \"linear\" supesampling\nvec4 AudioLinkLerp(vec2 xy) { return lerp( AudioLinkData(xy), AudioLinkData(ivec2(xy)+ivec2(1,0)), fract( xy.x ) ); }\n\n// Same as AudioLinkLerp but properly handles multiline reading.\nvec4 AudioLinkLerpMultiline(vec2 xy) { return lerp(AudioLinkDataMultiline(uvec2(xy)), AudioLinkDataMultiline(uvec2(xy+vec2(1.,0.))), fract(xy.x)); }\n\n\n\n//Get version of audiolink present in the world, 0 if no audiolink is present\nfloat AudioLinkGetVersion()\n{\n    ivec2 dims = ivec2(iResolution.xy);\n    /*#if !defined(AUDIOLINK_STANDARD_INDEXING)\n        _AudioTexture.GetDimensions(dims.x, dims.y);\n    #else\n        dims = _AudioTexture_TexelSize.zw;\n    #endif*/\n\n    if (dims.x >= 128)\n        return float(AudioLinkData(ALPASS_GENERALVU).x);\n    else if (dims.x > 16)\n        return 1.;\n    else\n        return 0.;\n}\n\n// Extra utility functions for time.\nuint AudioLinkDecodeDataAsUInt(uvec2 indexloc)\n{\n    uvec4 rpx = uvec4(AudioLinkData(indexloc));\n    return rpx.x + rpx.y*uint(1024) + rpx.z * uint(1048576) + rpx.w * uint(1073741824);\n}\n\nvoid renderCircle(inout vec4 col, in vec2 coord, vec2 c, float r, vec4 lineColor)\n{\n    float t = lineThickness/2.;\n    float l = length(coord - c);\n    if (l < r+t)\n    {\n        col = vec4(0.);\n    }\n    if (compare(l, r, t))\n    {\n        col = mix(col, lineColor, lineColor.a);\n    }\n}\n\nvoid renderHorizSlider(inout vec4 col, in vec2 uv, inout Slider horiz, float fmin, float fmax, vec4 lineColor)\n{\n    if (compare(uv.y, horiz.val, lineThickness / iResolution.y) && inRange(uv.x, fmin, fmax))\n    {\n        col = mix(col, lineColor, lineColor.a);\n    }\n    renderCircle(col, uv*iResolution.xy, vec2(fmin + (fmax-fmin)/2., horiz.val)*iResolution.xy, 15., lineColor);\n    \n}\n\nvoid renderVertiSlider(inout vec4 col, in vec2 uv, inout Slider verti, vec4 lineColor)\n{\n    if (compare(uv.x, verti.val, lineThickness / iResolution.x))\n    {\n        col = mix(col, lineColor, lineColor.a);\n    }\n    renderCircle(col, uv*iResolution.xy, vec2(verti.val, 0.5)*iResolution.xy, 15., lineColor);\n}\n\nvec4 getBand(float u)\n{\n    vec4 d = AudioLinkGetSelfPixelData(uvec2(u*float(AUDIOLINK_WIDTH), ALPASS_DFT.y));\n    return d;\n}\n\nfloat avgThresh(float fmin, float fmax, float thresh)\n{\n    float sum = 0.;\n    for (float i = fmin; i < fmax; i+=(1./iResolution.x))\n    {\n        float b = getBand(i).r;\n        if (b > thresh) sum+=b;\n    }\n    return max(sum / ((fmax-fmin)*10.),0.5);\n}\n\nvoid mainImage(out vec4 O, in vec2 I)\n{\n    vec2 uv = I/iResolution.xy;\n    Zones z;\n    int i = 0;\n    decodeZones(iChannel1, z, i);\n    \n    O = vec4(0.0);\n    \n    \n    float b0 = avgThresh(z.x0.val, z.x1.val, z.t0.val);\n    float b1 = avgThresh(z.x1.val, z.x2.val, z.t1.val);\n    float b2 = avgThresh(z.x2.val, z.x3.val, z.t2.val);\n    float b3 = avgThresh(z.x3.val, 1., z.t3.val);\n    \n    \n    //O = vec4(0.);\n    vec4 band = getBand(uv.x);\n    if (uv.y < band.r) O = band;\n    //O.r = getBand(uv.x);\n    vec4 ui = vec4(0);\n    \n    renderHorizSlider(ui, uv, z.t0, z.x0.val, z.x1.val, vec4(T0COLOR*b0, 0.8));\n    renderHorizSlider(ui, uv, z.t1, z.x1.val, z.x2.val, vec4(T1COLOR*b1, 0.8));\n    renderHorizSlider(ui, uv, z.t2, z.x2.val, z.x3.val, vec4(T2COLOR*b2, 0.8));\n    renderHorizSlider(ui, uv, z.t3, z.x3.val, 1., vec4(T3COLOR*b3, 0.8));\n    \n    renderVertiSlider(ui, uv, z.x0, vec4(vec3(0.8), 0.8));\n    renderVertiSlider(ui, uv, z.x1, vec4(vec3(0.8), 0.8));\n    renderVertiSlider(ui, uv, z.x2, vec4(vec3(0.8), 0.8));\n    renderVertiSlider(ui, uv, z.x3, vec4(vec3(0.8), 0.8));\n    O = mix(O, ui, ui.a);\n    O.a = 1.;\n    \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "//#include \"Common.glsl\"\n//#iChannel0 \"file://C:\\\\Users\\\\civel\\\\DownloadsTeminite - Ghost Ship.mp3\"\n//#iChannel1 \"self\"\n\nfloat _Gain /*Range(0, 2))*/ = 1.0;\nfloat _FadeLength /*Range(0 , 1))*/ = 0.8;\nfloat _FadeExpFalloff /*Range(0 , 1))*/ = 0.3;\nfloat _Bass /*Range(0 , 4))*/ = 1.0;\nfloat _Treble /*Range(0 , 4))*/ = 1.0;\nfloat _X0 /*Range(0.0, 0.168))*/ = 0.25;\nfloat _X1 /*Range(0.242, 0.387))*/ = 0.25;\nfloat _X2 /*Range(0.461, 0.628))*/ = 0.5;\nfloat _X3 /*Range(0.704, 0.953))*/ = 0.75;\nfloat _Threshold0 /*Range(0.0, 1.0))*/ = 0.45;\nfloat _Threshold1 /*Range(0.0, 1.0))*/ = 0.45;\nfloat _Threshold2 /*Range(0.0, 1.0))*/ = 0.45;\nfloat _Threshold3 /*Range(0.0, 1.0))*/ = 0.45;\nbool _EnableAutogain = true;\nfloat _AutogainDerate /*Range(.001, .5)*/ = 0.1;\nfloat _SourceVolume = 1.;\nfloat _SourceDistance = 1.;\nfloat _SourceSpatialBlend = 0.; //0-1 = 2D -> 3D curve;\nvec4 _SourcePosition = vec4(0.);\n\nint _ThemeColorMode = 0;\nvec4 _CustomThemeColor0 = vec4(1.0,1.0,0.0,1.0);\nvec4 _CustomThemeColor1 = vec4(0.0,0.0,1.0,1.0);\nvec4 _CustomThemeColor2 = vec4(1.0,0.0,0.0,1.0);\nvec4 _CustomThemeColor3 = vec4(0.0,1.0,0.0,1.0);\n\n#if defined(UNITY_UV_STARTS_AT_TOP) || defined(SHADER_API_GLES3)\n#define AUDIO_LINK_ALPHA_START(BASECOORDY) \\\n    vec2 guv = IN.xy; \\\n    uvec2 coordinateGlobal = uvec2(round(guv * _SelfTexture2D_TexelSize.zw - 0.5)); \\\n    uvec2 coordinateLocal = uvec2(coordinateGlobal.x - BASECOORDY.x, coordinateGlobal.y - BASECOORDY.y);\n#else\n#define AUDIO_LINK_ALPHA_START(BASECOORDY) \\\n    vec2 guv = IN.xy; \\\n    guv.y = 1.-guv.y; \\\n    uvec2 coordinateGlobal = uvec2(round(guv * _SelfTexture2D_TexelSize.zw - 0.5)); \\\n    uvec2 coordinateLocal = uvec2(coordinateGlobal.x - BASECOORDY.x, coordinateGlobal.y - BASECOORDY.y);\n#endif\n\n// Mechanism to index into texture.\n#ifdef AUDIOLINK_STANDARD_INDEXING\n    sampler2D _AudioTexture;\n    #define AudioLinkData(xycoord) tex2Dlod(_AudioTexture, vec4(uvec2(xycoord) * _AudioTexture_TexelSize.xy, 0., 0.))\n#else\n    #define _AudioTexture iChannel0\n    #define AudioLinkData(xycoord) texelFetch(_AudioTexture, ivec2(xycoord), 0)\n#endif\n\n\n\n// Convenient mechanism to read from the AudioLink texture that handles reading off the end of one line and onto the next above it.\nvec4 AudioLinkDataMultiline(uvec2 xycoord) { return AudioLinkData(uvec2(xycoord.x % uint(AUDIOLINK_WIDTH), xycoord.y + xycoord.x/uint(AUDIOLINK_WIDTH))); }\n\n// Mechanism to sample between two adjacent pixels and lerp between them, like \"linear\" supesampling\nvec4 AudioLinkLerp(vec2 xy) { return lerp( AudioLinkData(xy), AudioLinkData(ivec2(xy)+ivec2(1,0)), fract( xy.x ) ); }\n\n// Same as AudioLinkLerp but properly handles multiline reading.\nvec4 AudioLinkLerpMultiline(vec2 xy) { return lerp(AudioLinkDataMultiline(uvec2(xy)), AudioLinkDataMultiline(uvec2(xy+vec2(1.,0.))), fract(xy.x)); }\n\n\n\n//Get version of audiolink present in the world, 0 if no audiolink is present\nfloat AudioLinkGetVersion()\n{\n    ivec2 dims = ivec2(iResolution.xy);\n    /*#if !defined(AUDIOLINK_STANDARD_INDEXING)\n        _AudioTexture.GetDimensions(dims.x, dims.y);\n    #else\n        dims = _AudioTexture_TexelSize.zw;\n    #endif*/\n\n    if (dims.x >= 128)\n        return float(AudioLinkData(ALPASS_GENERALVU).x);\n    else if (dims.x > 16)\n        return 1.;\n    else\n        return 0.;\n}\n\n// This pulls data from this texture.\n#ifndef AudioLinkGetSelfPixelData\n    #define AudioLinkGetSelfPixelData(xy) texelFetch(_SelfTexture2D, ivec2(xy),0)\n#endif\n\n// Extra utility functions for time.\nuint AudioLinkDecodeDataAsUInt(uvec2 indexloc)\n{\n    uvec4 rpx = uvec4(AudioLinkData(indexloc));\n    return rpx.x + rpx.y*uint(1024) + rpx.z * uint(1048576) + rpx.w * uint(1073741824);\n}\n\n//Note: This will truncate time to every 134,217.728 seconds (~1.5 days of an instance being up) to prevent floating point aliasing.\n// if your code will alias sooner, you will need to use a different function.  It should be safe to use this on all times.\nfloat AudioLinkDecodeDataAsSeconds(uvec2 indexloc)\n{\n    uint time = AudioLinkDecodeDataAsUInt(indexloc) & uint(0x7ffffff);\n    //Can't just divide by float.  Bug in Unity's HLSL compiler.\n    return float(time / uint(1000)) + float( time % uint(1000) ) / 1000.; \n}\n\n\n\n// Sample the amplitude of a given frequency in the DFT, supports frequencies in [13.75; 14080].\nvec4 AudioLinkGetAmplitudeAtFrequency(float hertz)\n{\n    float note = float(AUDIOLINK_EXPBINS) * log2(hertz / float(AUDIOLINK_BOTTOM_FREQUENCY));\n    return AudioLinkLerpMultiline(float(ALPASS_DFT) + vec2(note, 0.));\n}\n\n// Sample the amplitude of a given quartertone in an octave. Octave is in [0; 9] while quarter is [0; 23].\nvec4 AudioLinkGetAmplitudeAtQuarterNote(float octave, float quarter)\n{\n    return AudioLinkLerpMultiline(float(ALPASS_DFT) + vec2(octave * float(AUDIOLINK_EXPBINS) + quarter, 0.));\n}\n\n// Sample the amplitude of a given semitone in an octave. Octave is in [0; 9] while note is [0; 11].\nvec4 AudioLinkGetAmplitudeAtNote(float octave, float note)\n{\n    float quarter = note * 2.0;\n    return AudioLinkGetAmplitudeAtQuarterNote(octave, quarter);\n}\n\n// Sample the amplitude of a given quartertone across all octaves. Quarter is [0; 23].\nvec4 AudioLinkGetAmplitudesAtQuarterNote(float quarter)\n{\n    vec4 amplitude = vec4(0.);\n    //UNITY_UNROLL\n    for (int i = 0; i < AUDIOLINK_EXPOCT; i++)\n    {\n        amplitude += AudioLinkGetAmplitudeAtQuarterNote(float(i),quarter);\n    }\n    return amplitude;\n}\n\n// Sample the amplitude of a given semitone across all octaves. Note is [0; 11].\nvec4 AudioLinkGetAmplitudesAtNote(float note)\n{\n    float quarter = note * 2.0;\n    return AudioLinkGetAmplitudesAtQuarterNote(quarter);\n}\n\n// Get a reasonable drop-in replacement time value for _Time.y with the\n// given chronotensity index [0; 7] and AudioLink band [0; 3].\nfloat AudioLinkGetChronoTime(uint index, uint band)\n{\n    return float(AudioLinkDecodeDataAsUInt(ALPASS_CHRONOTENSITY + uvec2(index, band))) / 100000.0;\n}\n\n// Get a chronotensity value in the interval [0; 1], modulated by the speed input, \n// with the given chronotensity index [0; 7] and AudioLink band [0; 3].\nfloat AudioLinkGetChronoTimeNormalized(uint index, uint band, float speed)\n{\n    return fract(AudioLinkGetChronoTime(index, band) * speed);\n}\n\n// Get a chronotensity value in the interval [0; interval], modulated by the speed input, \n// with the given chronotensity index [0; 7] and AudioLink band [0; 3].\nfloat AudioLinkGetChronoTimeInterval(uint index, uint band, float speed, float interval)\n{\n    return AudioLinkGetChronoTimeNormalized(index, band, speed) * interval;\n}\n\n// Get time of day. The return value is a vec4 with the values vec3(hour, minute, second).\nvec3 AudioLinkGetTimeOfDay()\n{\n    /*float value = AudioLinkDecodeDataAsSeconds(ALPASS_GENERALVU_UNIX_SECONDS);\n    float hour = floor(value / 3600.0);\n    float minute = float(int(floor(value / 60.0)) % 60);\n    float second = value % 60.0;*/\n    return iDate.gba;\n}\n\n// Get a character from a globally synced string, given an index of string in range [0; 3], and\n// a character index in range [0; 31]. The string at the 0th index is the local player name.\n// The 1st index is the master name, and index 2 and 3 are custom strings.\n// Returns a unsigned integer represented a unicode codepoint, i.e. UTF32.\nuint AudioLinkGetGlobalStringChar(uint stringIndex, uint charIndex)\n{\n    uvec4 fourChars = uvec4(AudioLinkData(ALPASS_GLOBAL_STRINGS + uvec2(charIndex / uint(4), stringIndex)));\n    return fourChars[charIndex % uint(4)];\n}\n\n// Get a character from the local player name given a character index in the range [0; 31].\n// Returns a unsigned integer represented a unicode codepoint, i.e. UTF32.\nuint AudioLinkGetLocalPlayerNameChar(uint charIndex)\n{\n    return AudioLinkGetGlobalStringChar(uint(AUDIOLINK_STRING_LOCALPLAYER), charIndex);\n}\n\n// Get a character from the master player name given a character index in the range [0; 31].\n// Returns a unsigned integer represented a unicode codepoint, i.e. UTF32.\nuint AudioLinkGetMasterNameChar(uint charIndex)\n{\n    return AudioLinkGetGlobalStringChar(uint(AUDIOLINK_STRING_MASTER), charIndex);\n}\n\n// Get a character from the first custom string given a character index in the range [0; 31].\n// Returns a unsigned integer represented a unicode codepoint, i.e. UTF32.\nuint AudioLinkGetCustomString1Char(uint charIndex)\n{\n    return AudioLinkGetGlobalStringChar(uint(AUDIOLINK_STRING_CUSTOM1), charIndex);\n}\n\n// Get a character from the second custom string given a character index in the range [0; 31].\n// Returns a unsigned integer represented a unicode codepoint, i.e. UTF32.\nuint AudioLinkGetCustomString2Char(uint charIndex)\n{\n    return AudioLinkGetGlobalStringChar(uint(AUDIOLINK_STRING_CUSTOM2), charIndex);\n}\n\n// Returns the position of the AudioLink AudioSource in world space.\nvec4 AudioLinkGetAudioSourcePosition()\n{\n    return vec4(AudioLinkData(ALPASS_GENERALVU_SOURCE_POS).xyz,1);\n}\n\n// #pragma target 4.0\n// #pragma vertex CustomRenderTextureVertexShader\n// #pragma fragment frag\n\n// This changes _SelfTexture2D in 'UnityCustomRenderTexture.cginc' to Texture2D instead of sampler2D\n// Thanks Lyuma!\n// #define _SelfTexture2D _JunkTexture\n// #include \"UnityCustomRenderTexture.cginc\"\n// #undef _SelfTexture2D\n#define _SelfTexture2D iChannel1\n\n// #include \"UnityCG.cginc\"\n// #include \"AudioLink.cginc\"\nuniform vec4 _SelfTexture2D_TexelSize;\n\n// AudioLink 4 Band\n// uniform float _FadeLength;\n// uniform float _FadeExpFalloff;\n// uniform float _Gain;\n// uniform float _Bass;\n// uniform float _Treble;\n// uniform float _X0;\n// uniform float _X1;\n// uniform float _X2;\n// uniform float _X3;\n// uniform float _Threshold0;\n// uniform float _Threshold1;\n// uniform float _Threshold2;\n// uniform float _Threshold3;\n// uniform float _SourceVolume;\n// uniform float _SourceDistance;\n// uniform float _SourceSpatialBlend;\n// uniform vec4 _SourcePosition;\n// uniform uint _ThemeColorMode;\n// uniform vec4 _CustomThemeColor0;\n// uniform vec4 _CustomThemeColor1;\n// uniform vec4 _CustomThemeColor2;\n// uniform vec4 _CustomThemeColor3;\n\n// Global strings\nuniform vec4 _StringLocalPlayer[8];\nuniform vec4 _StringMasterPlayer[8];\nuniform vec4 _StringCustom1[8];\nuniform vec4 _StringCustom2[8];\n\n// Extra Properties\n// uniform float _EnableAutogain;\n// uniform float _AutogainDerate;\n\n// Set by Udon\nuniform vec4 _AdvancedTimeProps0;\nuniform vec4 _AdvancedTimeProps1;\nuniform vec4 _VersionNumberAndFPSProperty;\nuniform vec4 _PlayerCountAndData;\n\n\nfloat _Samples0(int i)\n{\n    return texelFetch(iChannel0, ivec2((float(i))/4092.*512.,0),0).r;\n}\nfloat _Samples1(int i)\n{\n    return texelFetch(iChannel0, ivec2((float(i)+1023.)/4092.*512.,0),0).r;\n}\nfloat _Samples2(int i)\n{\n    return texelFetch(iChannel0, ivec2((float(i)+2045.)/4092.*512.,0),0).r;\n}\nfloat _Samples3(int i)\n{\n    return texelFetch(iChannel0, ivec2((float(i)+3069.)/4092.*512.,0),0).r;\n}\n//Raw audio data.\n// cbuffer LeftSampleBuffer {\n    //float _Samples0L[1023];\n    //float _Samples1L[1023];\n    //float _Samples2L[1023];\n    //float _Samples3L[1023];\n// };\n// cbuffer RightSampleBuffer {\n    //float _Samples0R[1023];\n    //float _Samples1R[1023];\n    //float _Samples2R[1023];\n    //float _Samples3R[1023];\n// };\n\n// These may become uniforms set by the controller, keep them named like this for now\nconst float _LogAttenuation = 0.68;\nconst float _ContrastSlope = 0.63;\nconst float _ContrastOffset = 0.62;\n\nconst float _WaveInClampValue = 2.0;\n\n// Encodes a uint so it can be read-out by AudioLinkDecodeDataAsUInt().\nvec4 AudioLinkEncodeUInt(uint val)\n{\n    return vec4(\n        float((val) & uint(0x3ff)),\n        float((val >> uint(10)) & uint(0x3ff)),\n        float((val >> uint(20)) & uint(0x3ff)),\n        float((val >> uint(30)) & uint(0x3ff))\n    );\n}\n\nfloat ReadLeft( int s )\n{\n    if( s < 1023 )\n        return _Samples0(s);\n    else if( s < 2046 )\n        return _Samples1(s-1023);\n    else if( s < 3069 )\n        return _Samples2(s-2046);\n    else if( s < 4092 )\n        return _Samples3(s-3069);\n    else\n        return 0.;\n}\nfloat ReadRight( int s )\n{\n    if( s < 1023 )\n        return _Samples0(s);\n    else if( s < 2046 )\n        return _Samples1(s-1023);\n    else if( s < 3069 )\n        return _Samples2(s-2046);\n    else if( s < 4092 )\n        return _Samples3(s-3069);\n    else\n        return 0.;\n}\n\n// Name \"Pass1AudioDFT\"\n// CGPROGRAM\n//uniform float lut[240];\nfloat lut(int i)\n{\n\n    if (i == 0) return 0.000;\n    if (i == 1) return 0.000;\n    if (i == 2) return 0.000;\n    if (i == 3) return 0.000;\n    if (i == 4) return 0.000;\n    if (i == 5) return 0.000;\n    if (i == 6) return 0.000;\n    if (i == 7) return 0.000;\n    if (i == 8) return 0.000;\n    if (i == 9) return 0.000;\n    if (i == 10) return 0.000;\n    if (i == 11) return 0.000;\n    if (i == 12) return 0.000;\n    if (i == 13) return 0.000;\n    if (i == 14) return 0.000;\n    if (i == 15) return 0.000;\n    if (i == 16) return 0.000;\n    if (i == 17) return 0.000;\n    if (i == 18) return 0.000;\n    if (i == 19) return 0.000;\n    if (i == 20) return 0.000;\n    if (i == 21) return 0.000;\n    if (i == 22) return 0.000;\n    if (i == 23) return 0.000;\n    if (i == 24) return 0.000;\n    if (i == 25) return 0.000;\n    if (i == 26) return 0.000;\n    if (i == 27) return 0.000;\n    if (i == 28) return 0.000;\n    if (i == 29) return 0.000;\n    if (i == 30) return 0.000;\n    if (i == 31) return 0.000;\n    if (i == 32) return 0.000;\n    if (i == 33) return 0.000;\n    if (i == 34) return 0.000;\n    if (i == 35) return 0.000;\n    if (i == 36) return 0.000;\n    if (i == 37) return 0.000;\n    if (i == 38) return 0.000;\n    if (i == 39) return 0.000;\n    if (i == 40) return 0.000;\n    if (i == 41) return 0.000;\n    if (i == 42) return 0.000;\n    if (i == 43) return 0.000;\n    if (i == 44) return 0.000;\n    if (i == 45) return 0.000;\n    if (i == 46) return 0.000;\n    if (i == 47) return 0.000;\n    if (i == 48) return 0.000;\n    if (i == 49) return 0.000;\n    if (i == 50) return 0.000;\n    if (i == 51) return 0.000;\n    if (i == 52) return 0.001;\n    if (i == 53) return 0.002;\n    if (i == 54) return 0.003;\n    if (i == 55) return 0.004;\n    if (i == 56) return 0.005;\n    if (i == 57) return 0.006;\n    if (i == 58) return 0.008;\n    if (i == 59) return 0.010;\n    if (i == 60) return 0.012;\n    if (i == 61) return 0.014;\n    if (i == 62) return 0.017;\n    if (i == 63) return 0.020;\n    if (i == 64) return 0.022;\n    if (i == 65) return 0.025;\n    if (i == 66) return 0.029;\n    if (i == 67) return 0.032;\n    if (i == 68) return 0.036;\n    if (i == 69) return 0.040;\n    if (i == 70) return 0.044;\n    if (i == 71) return 0.048;\n    if (i == 72) return 0.053;\n    if (i == 73) return 0.057;\n    if (i == 74) return 0.062;\n    if (i == 75) return 0.067;\n    if (i == 76) return 0.072;\n    if (i == 77) return 0.078;\n    if (i == 78) return 0.083;\n    if (i == 79) return 0.089;\n    if (i == 80) return 0.095;\n    if (i == 81) return 0.101;\n    if (i == 82) return 0.107;\n    if (i == 83) return 0.114;\n    if (i == 84) return 0.121;\n    if (i == 85) return 0.128;\n    if (i == 86) return 0.135;\n    if (i == 87) return 0.142;\n    if (i == 88) return 0.149;\n    if (i == 89) return 0.157;\n    if (i == 90) return 0.164;\n    if (i == 91) return 0.172;\n    if (i == 92) return 0.180;\n    if (i == 93) return 0.188;\n    if (i == 94) return 0.196;\n    if (i == 95) return 0.205;\n    if (i == 96) return 0.213;\n    if (i == 97) return 0.222;\n    if (i == 98) return 0.230;\n    if (i == 99) return 0.239;\n    if (i == 100) return 0.248;\n    if (i == 101) return 0.257;\n    if (i == 102) return 0.266;\n    if (i == 103) return 0.276;\n    if (i == 104) return 0.285;\n    if (i == 105) return 0.294;\n    if (i == 106) return 0.304;\n    if (i == 107) return 0.313;\n    if (i == 108) return 0.323;\n    if (i == 109) return 0.333;\n    if (i == 110) return 0.342;\n    if (i == 111) return 0.352;\n    if (i == 112) return 0.362;\n    if (i == 113) return 0.372;\n    if (i == 114) return 0.381;\n    if (i == 115) return 0.391;\n    if (i == 116) return 0.401;\n    if (i == 117) return 0.411;\n    if (i == 118) return 0.421;\n    if (i == 119) return 0.431;\n    if (i == 120) return 0.441;\n    if (i == 121) return 0.451;\n    if (i == 122) return 0.460;\n    if (i == 123) return 0.470;\n    if (i == 124) return 0.480;\n    if (i == 125) return 0.490;\n    if (i == 126) return 0.499;\n    if (i == 127) return 0.509;\n    if (i == 128) return 0.519;\n    if (i == 129) return 0.528;\n    if (i == 130) return 0.538;\n    if (i == 131) return 0.547;\n    if (i == 132) return 0.556;\n    if (i == 133) return 0.565;\n    if (i == 134) return 0.575;\n    if (i == 135) return 0.584;\n    if (i == 136) return 0.593;\n    if (i == 137) return 0.601;\n    if (i == 138) return 0.610;\n    if (i == 139) return 0.619;\n    if (i == 140) return 0.627;\n    if (i == 141) return 0.636;\n    if (i == 142) return 0.644;\n    if (i == 143) return 0.652;\n    if (i == 144) return 0.660;\n    if (i == 145) return 0.668;\n    if (i == 146) return 0.676;\n    if (i == 147) return 0.684;\n    if (i == 148) return 0.691;\n    if (i == 149) return 0.699;\n    if (i == 150) return 0.706;\n    if (i == 151) return 0.713;\n    if (i == 152) return 0.720;\n    if (i == 153) return 0.727;\n    if (i == 154) return 0.734;\n    if (i == 155) return 0.741;\n    if (i == 156) return 0.747;\n    if (i == 157) return 0.754;\n    if (i == 158) return 0.760;\n    if (i == 159) return 0.766;\n    if (i == 160) return 0.772;\n    if (i == 161) return 0.778;\n    if (i == 162) return 0.784;\n    if (i == 163) return 0.790;\n    if (i == 164) return 0.795;\n    if (i == 165) return 0.801;\n    if (i == 166) return 0.806;\n    if (i == 167) return 0.811;\n    if (i == 168) return 0.816;\n    if (i == 169) return 0.821;\n    if (i == 170) return 0.826;\n    if (i == 171) return 0.831;\n    if (i == 172) return 0.835;\n    if (i == 173) return 0.840;\n    if (i == 174) return 0.844;\n    if (i == 175) return 0.848;\n    if (i == 176) return 0.853;\n    if (i == 177) return 0.857;\n    if (i == 178) return 0.861;\n    if (i == 179) return 0.864;\n    if (i == 180) return 0.868;\n    if (i == 181) return 0.872;\n    if (i == 182) return 0.875;\n    if (i == 183) return 0.879;\n    if (i == 184) return 0.882;\n    if (i == 185) return 0.885;\n    if (i == 186) return 0.888;\n    if (i == 187) return 0.891;\n    if (i == 188) return 0.894;\n    if (i == 189) return 0.897;\n    if (i == 190) return 0.899;\n    if (i == 191) return 0.902;\n    if (i == 192) return 0.904;\n    if (i == 193) return 0.906;\n    if (i == 194) return 0.909;\n    if (i == 195) return 0.911;\n    if (i == 196) return 0.913;\n    if (i == 197) return 0.914;\n    if (i == 198) return 0.916;\n    if (i == 199) return 0.918;\n    if (i == 200) return 0.919;\n    if (i == 201) return 0.921;\n    if (i == 202) return 0.922;\n    if (i == 203) return 0.924;\n    if (i == 204) return 0.925;\n    if (i == 205) return 0.926;\n    if (i == 206) return 0.927;\n    if (i == 207) return 0.928;\n    if (i == 208) return 0.928;\n    if (i == 209) return 0.929;\n    if (i == 210) return 0.929;\n    if (i == 211) return 0.930;\n    if (i == 212) return 0.930;\n    if (i == 213) return 0.930;\n    if (i == 214) return 0.931;\n    if (i == 215) return 0.931;\n    if (i == 216) return 0.930;\n    if (i == 217) return 0.930;\n    if (i == 218) return 0.930;\n    if (i == 219) return 0.930;\n    if (i == 220) return 0.929;\n    if (i == 221) return 0.929;\n    if (i == 222) return 0.928;\n    if (i == 223) return 0.927;\n    if (i == 224) return 0.926;\n    if (i == 225) return 0.925;\n    if (i == 226) return 0.924;\n    if (i == 227) return 0.923;\n    if (i == 228) return 0.922;\n    if (i == 229) return 0.920;\n    if (i == 230) return 0.919;\n    if (i == 231) return 0.917;\n    if (i == 232) return 0.915;\n    if (i == 233) return 0.913;\n    if (i == 234) return 0.911;\n    if (i == 235) return 0.909;\n    if (i == 236) return 0.907;\n    if (i == 237) return 0.905;\n    if (i == 238) return 0.903;\n    if (i == 239) return 0.900;\n}\n\n//#define lut(i) (int(i) < 51? 0. : 0.5+0.5*sin(float(int(i)-127)/239.*UNITY_TWO_PI/2.*1.6))\n//#define lut(i) lut[i]\n\nvec4 frag (in vec2 IN, in vec4 OUT)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_DFT)\n    \n    int note = int(coordinateLocal.y) * AUDIOLINK_WIDTH + int(coordinateLocal.x);\n    vec4 last = AudioLinkGetSelfPixelData(coordinateGlobal);\n    vec2 amplitude = vec2(0.);\n    float phase = 0.;\n    float phaseDelta = pow(2., float(note)/(float(AUDIOLINK_EXPBINS)));\n    phaseDelta = ((phaseDelta * float(AUDIOLINK_BOTTOM_FREQUENCY)) / float(AUDIOLINK_SPS)) * UNITY_TWO_PI * 2.; // 2 here because we're at 24kSPS\n    phase = -phaseDelta * float(AUDIOLINK_SAMPHIST)/2.;     // Align phase so 0 phase is center of window.\n\n    // DFT Window\n    float halfWindowSize = AUDIOLINK_DFT_Q / (phaseDelta / UNITY_TWO_PI);\n    int windowRange = int(floor(halfWindowSize)) + 1;\n    float totalWindow = 0.;\n\n    // For ??? reason, this is faster than doing a clever indexing which only searches the space that will be used.\n    /*uint idx;\n    for(idx = uint(0); idx < uint(AUDIOLINK_SAMPHIST / 2); ++idx)\n    {\n        // XXX TODO: Try better windows, this is just a triangle.\n        float window = max(0., halfWindowSize - abs(float(idx) - (float(AUDIOLINK_SAMPHIST) / 2. - halfWindowSize)));\n        float af = AudioLinkGetSelfPixelData(uvec2(ALPASS_WAVEFORM) + uvec2(idx % uint(AUDIOLINK_WIDTH), idx / uint(AUDIOLINK_WIDTH))).x;\n\n        // Sin and cosine components to convolve.\n        vec2 sinCos = vec2(sin(phase), cos(phase));\n\n        // Step through, one sample at a time, multiplying the sin and cos values by the incoming signal.\n        amplitude += sinCos * af * window;\n        totalWindow += window;\n        phase += phaseDelta;\n    }*/\n    //float mag = (length(amplitude) / totalWindow) * AUDIOLINK_BASE_AMPLITUDE * _Gain;\n    float mag = texelFetch(iChannel0, ivec2(float(IN.x)*512./float(AUDIOLINK_WIDTH),0), 0).r;\n\n    // Treble compensation\n    float lfac = lut(min(note, 239));\n    if (lfac <= 0.05)\n    {\n        lfac = (lut(158-note+72)-0.76) *2.;\n    }\n    else lfac *= AUDIOLINK_TREBLE_CORRECTION;\n    \n    mag *= (lfac*3. + 5.);\n\n    // Filtered output, also use FadeLength to lerp delay coefficient min/max for added smoothing effect\n    float magFilt = lerp(mag, last.z, lerp(AUDIOLINK_DELAY_COEFFICIENT_MIN, AUDIOLINK_DELAY_COEFFICIENT_MAX, _FadeLength));\n\n    // Filtered EQ'd output, used by AudioLink 4 Band\n    float freqNormalized = float(note) / float(AUDIOLINK_EXPOCT * AUDIOLINK_EXPBINS);\n    float magEQ = magFilt * (((1.0 - freqNormalized) * _Bass) + (freqNormalized * _Treble));\n\n    // Red:   Spectrum power, served straight up\n    // Green: Filtered power EQ'd, used by AudioLink 4 Band\n    // Blue:  Filtered spectrum\n    return vec4(mag, magEQ, magFilt, 1);\n}\n\n// Name \"Pass2WaveformData\"\n// CGPROGRAM\n\n\n\nvec4 fragwave (in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_WAVEFORM)\n    int frame = int(coordinateLocal.x + coordinateLocal.y * uint(AUDIOLINK_WIDTH));\n    return vec4(texelFetch(iChannel0, ivec2(int(IN.x/512.*float(AUDIOLINK_WIDTH)), 0), 0));\n\n    float incomingGain = 1.;\n    // Scales the gain by the audio source component Volume to prevent data changing when changing the volume.\n    // Clamped to 0.001 to prevent division by 0 because that will make it 'splode and we don't want that now do we?\n    incomingGain *= 1./clamp(_SourceVolume, 0.001, 1.);\n    if(_EnableAutogain)\n    {\n        vec4 lastAutoGain = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(11, 0));\n\n        // Divide by the running volume.\n        incomingGain *= 1. / (lastAutoGain.x + _AutogainDerate);\n    }\n\n    // Downsampled to 24k and 12k samples per second by averaging, limiting frame to prevent overflow\n    vec4 ret = vec4(0.); // [ downsampled 24k mono, native 48k mono, down sampled to 12k mono, difference between left and right at 24k]\n    if( frame < 2046 )\n    {\n        ret.x = (\n            ReadLeft(frame * 2 + 0) + ReadRight(frame * 2 + 0) +\n            ReadLeft(frame * 2 + 1) + ReadRight(frame * 2 + 1) ) / 4.;\n    }\n    if( frame < 4092 )\n    {\n        ret.y = ( ReadLeft(frame) + ReadRight(frame) ) / 2.;\n    }\n    if( frame < 1023 )\n    {\n        ret.z = (\n            ReadLeft(frame * 4 + 0) + ReadRight(frame * 4 + 0) +\n            ReadLeft(frame * 4 + 1) + ReadRight(frame * 4 + 1) +\n            ReadLeft(frame * 4 + 2) + ReadRight(frame * 4 + 2) +\n            ReadLeft(frame * 4 + 3) + ReadRight(frame * 4 + 3) ) / 8.;\n    }\n    if( frame < 2046 )\n    {\n        ret.w = (\n            ReadLeft(frame * 2 + 0) - ReadRight(frame * 2 + 0) +\n            ReadLeft(frame * 2 + 1) - ReadRight(frame * 2 + 1) ) / 4.;\n    }\n\n    return (vec4(_WaveInClampValue) + clamp( ret * incomingGain, -_WaveInClampValue, _WaveInClampValue ))/ (2.* _WaveInClampValue);\n}\n\n//Name \"Pass3AudioLink4Band\"\n//CGPROGRAM\n\nvec4 fraglink (in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_AUDIOLINK)\n\n    float audioBands[4];\n    audioBands[0] = _X0; audioBands[1] = _X1; audioBands[2] = _X2; audioBands[3] = _X3;\n    float audioThresholds[4];\n    audioThresholds[0] = _Threshold0; audioThresholds[1] = _Threshold1; audioThresholds[2] = _Threshold2; audioThresholds[3] = _Threshold3;\n    \n    int band = int(min(coordinateLocal.y, uint(3)));\n    int delay = int(coordinateLocal.x);\n    if (delay == 0)\n    {\n        // Get average of samples in the band\n        float total = 0.;\n        uint totalBins = uint(AUDIOLINK_EXPBINS * AUDIOLINK_EXPOCT);\n        uint binStart = uint(AudioLinkRemap(audioBands[band], 0., 1., AUDIOLINK_4BAND_FREQFLOOR * float(totalBins), float(AUDIOLINK_4BAND_FREQCEILING) * float(totalBins)));\n        uint binEnd = (band != 3) ? uint(AudioLinkRemap(audioBands[band + 1], 0., 1., AUDIOLINK_4BAND_FREQFLOOR * float(totalBins), float(AUDIOLINK_4BAND_FREQCEILING) * float(totalBins))) : uint(float(AUDIOLINK_4BAND_FREQCEILING) * float(totalBins));\n        float threshold = audioThresholds[band];\n        for (uint i=binStart; i<binEnd; i++)\n        {\n            ivec2 spectrumCoord = ivec2(int(i) % AUDIOLINK_WIDTH, int(i) / AUDIOLINK_WIDTH);\n            float rawMagnitude = AudioLinkGetSelfPixelData(ivec2(ALPASS_DFT) + spectrumCoord).y;\n            total += rawMagnitude;\n        }\n        float magnitude = total / float(binEnd - binStart);\n\n        // Log attenuation\n        magnitude = saturate(magnitude * (log(1.1) / (log(1.1 + pow(_LogAttenuation, 4.) * (1.0 - magnitude))))) / pow(threshold, 2.);\n\n        // Contrast\n        magnitude = saturate(magnitude * tan(1.57 * _ContrastSlope) + magnitude + _ContrastOffset * tan(1.57 * _ContrastSlope) - tan(1.57 * _ContrastSlope));\n\n        // Fade\n        float lastMagnitude = AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(0, band)).y;\n        lastMagnitude -= -1.0 * pow(_FadeLength-1.0, 3.);                                                                            // Inverse cubic remap\n        lastMagnitude = saturate(lastMagnitude * (1.0 + (pow(lastMagnitude - 1.0, 4.0) * _FadeExpFalloff) - _FadeExpFalloff));     // Exp falloff\n\n        magnitude = max(lastMagnitude, magnitude);\n\n        return vec4(magnitude, magnitude, magnitude, 1.);\n\n    // If part of the delay\n    } else {\n        // Slide pixels (coordinateLocal.x > 0)\n        vec4 lastvalTiming = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(4, 1)); // Timing for 4-band, move at 90 Hz.\n        lastvalTiming.x += iTimeDelta * AUDIOLINK_4BAND_TARGET_RATE;\n        uint framesToRoll = uint(floor( lastvalTiming.x ));\n\n        if( framesToRoll == uint(0) )\n        {\n            return AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(coordinateLocal.x, coordinateLocal.y));\n        }\n        else // 1 or more.\n        {\n            if( coordinateLocal.x > framesToRoll )\n            {\n                // For the rest of the line, move by the appropriate speed\n                return AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(coordinateLocal.x - framesToRoll, coordinateLocal.y));\n            }\n            else\n            {\n                // For the first part, extrapolate the cells.\n                float last = length(AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(0, coordinateLocal.y)));\n                float next = length(AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(1, coordinateLocal.y)));\n                float lprev = float(int(coordinateLocal.x) - 1) / float(framesToRoll);\n                return vec4(lerp( last, next, lprev ));\n            }\n        }\n    }\n}\n//Name \"Pass5-VU-Meter-And-Other-Info\"\n//CGPROGRAM\n// The structure of the output is:\n// RED CHANNEL: Peak Amplitude\n// GREEN CHANNEL: RMS Amplitude.\n// BLUE CHANNEL: RESERVED.\n\nvec4 fraggenvu (in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_GENERALVU)\n\n    vec2 total = vec2(0.);\n    vec2 peak = vec2(0.);\n\n    // Only VU over 1024 24kSPS samples\n    int i;\n    for( i = 0; i < 1024; i++ )\n    {\n        vec4 audioFrame = AudioLinkGetSelfPixelData(ALPASS_WAVEFORM + uvec2(i % AUDIOLINK_WIDTH, i / AUDIOLINK_WIDTH));\n        vec2 leftright = audioFrame.x + vec2( audioFrame.a, -audioFrame.a );\n        total += leftright * leftright;\n        peak = max(peak, abs(leftright));\n    }\n\n    vec2 RMS = sqrt(total / float(i));\n    \n    vec4 markerValue = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(9, 0));\n    vec4 markerTimes = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(10, 0));\n    vec4 lastAutogain = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(11, 0));\n\n    markerTimes.xyzw += vec4(iTimeDelta);\n    //markerTimes = (markerTimes>1.) ? vec4(-1, -1, -1, -1) : markerTimes;\n    vec4 RMSPeak = vec4( RMS.x, peak.x, RMS.y, peak.y );\n#if 0\n    if(markerValue.x < RMSPeak.x || markerTimes.x > 1. )\n    {\n        markerValue.x = RMSPeak.x;\n        markerTimes.x = 0;\n    }\n    if(markerValue.y < RMSPeak.y || markerTimes.y > 1. )\n    {\n        markerValue.y = RMSPeak.y;\n        markerTimes.y = 0;\n    }\n    if(markerValue.z < RMSPeak.z || markerTimes.z > 1. )\n    {\n        markerValue.z = RMSPeak.z;\n        markerTimes.z = 0;\n    }\n    if(markerValue.w < RMSPeak.w || markerTimes.w > 1.)\n    {\n        markerValue.w = RMSPeak.a;\n        markerTimes.w = 0;\n    }\n#endif\n    \n    bvec4 peakout;\n    vec4Operation(i, {peakout[i] = (markerValue[i] < RMSPeak[i] || markerTimes[i] > 1. );})\n    vec4Operation(i, {if (peakout[i]) markerTimes[i] = 0.;})\n    \n    vec4Operation(i, {markerValue[i] = peakout[i]?RMSPeak[i]:markerValue[i];})\n\n    if( coordinateLocal.y == uint(0) )\n    {\n        if(coordinateLocal.x >= uint(8))\n        {\n            if(coordinateLocal.x == uint(8))\n            {\n                // First pixel: Current value.\n                return RMSPeak;\n            }\n            else if(coordinateLocal.x == uint(9))\n            {\n                // Second pixel: Limit Output\n                return markerValue;\n            }\n            else if(coordinateLocal.x == uint(10))\n            {\n                // Second pixel: Limit time\n                return markerTimes;\n            }\n            else if(coordinateLocal.x == uint(11))\n            {\n                // Third pixel: Auto Gain / Volume Monitor for ColorChord\n\n                // Compensate for the fact that we've already gain'd our samples.\n                float deratePeak = length(peak / (lastAutogain.x + _AutogainDerate));\n\n                if(deratePeak > lastAutogain.x)\n                {\n                    lastAutogain.x = lerp(deratePeak, lastAutogain.x, .5); //Make attack quick\n                }\n                else\n                {\n                    lastAutogain.x = lerp(deratePeak, lastAutogain.x, .995); //Make decay long.\n                }\n\n                lastAutogain.y = lerp(length(peak), lastAutogain.y, 0.95);\n                return lastAutogain;\n            }\n        }\n        else\n        {\n            if(coordinateLocal.x == uint(0))\n            {\n                // Pixel 0 = Version\n                return _VersionNumberAndFPSProperty;\n            }\n            else if(coordinateLocal.x == uint(1))\n            {\n                // Pixel 1 = Frame Count, if we did not repeat, this would stop counting after ~51 hours.\n                // So, instead we just reset it every 24 hours.  Note this is after 24 hours in an instance.\n                // Note: This is also used to measure FPS.\n\n                vec4 lastVal = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(1, 0));\n                float frameCount = lastVal.x;\n                float frameCountFPS = lastVal.y;\n                float frameCountLastFPS = lastVal.z;\n                float lastTimeFPS = lastVal.a;\n                frameCount++;\n                if(frameCount >= 7776000.) //~24 hours.\n                    frameCount = 0.;\n                frameCountFPS++;\n\n                // See if we've been reset.\n                if(lastTimeFPS > iTime)\n                {\n                    lastTimeFPS = 0.;\n                }\n\n                // After one second, take the running FPS and present it as the now FPS.\n                if(iTime > lastTimeFPS + 1.)\n                {\n                    frameCountLastFPS = frameCountFPS;\n                    frameCountFPS = 0.;\n                    lastTimeFPS = iTime;\n                }\n                return vec4(frameCount, frameCountFPS, frameCountLastFPS, lastTimeFPS);\n            }\n            else if(coordinateLocal.x == 2u)\n            {\n                // Output of this is daytime, in milliseconds\n                // This is done a little awkwardly as to prevent any overflows.\n                uint dtms = uint(_AdvancedTimeProps0.x * 1000.);\n                uint dtms2 = uint(_AdvancedTimeProps0.y * 1000.) + (dtms >> 10u);\n                // Specialized implementation, similar to AudioLinkEncodeUInt\n                return vec4(\n                    float(dtms & 0x3ffu),\n                    float((dtms2) & 0x3ffu),\n                    float((dtms2 >> 10u) & 0x3ffu),\n                    float((dtms2 >> 20u) & 0x3ffu)\n                );\n            }\n            else if(coordinateLocal.x == 3u)\n            {\n                // Current time of day, in local time.\n                // Generally this will not exceed 90 million milliseconds. (25 hours)\n                int ftpa = int(_AdvancedTimeProps0.z * 1000.);\n                // Specialized implementation, similar to AudioLinkEncodeUInt\n                return vec4(ftpa & 0x3ff, (ftpa >> 10) & 0x3ff, (ftpa >> 20) & 0x3ff, 0 );\n            }\n            else if(coordinateLocal.x == 4u)\n            {\n                // Time sync'd off of Networking.GetServerTimeInMilliseconds()\n                float fractional = _AdvancedTimeProps1.x;\n                float major = _AdvancedTimeProps1.y;\n                if( major < 0. )\n                    major = 65536. + major;\n                uint currentNetworkTimeMS = (uint(fractional)) | ((uint(major))<<16u);\n                return AudioLinkEncodeUInt(currentNetworkTimeMS);\n            }\n            else if(coordinateLocal.x == 6u)\n            {\n                //.x = Player Count\n                //.y = IsMaster\n                //.z = IsInstanceOwner\n                return vec4( _PlayerCountAndData );\n            }\n            else if(coordinateLocal.x == 7u)\n            {\n                //General Debug Register\n                //Use this for whatever.\n                return vec4( _AdvancedTimeProps0.w, iTimeDelta, markerTimes.y, 1. );\n            }\n        }\n    }\n    else\n    {\n        //Second Row y = 1\n        if( coordinateLocal.x < 4u )\n        {\n            if( _ThemeColorMode == 1 )\n            {\n                if( coordinateLocal.x == 0u ) return _CustomThemeColor0;\n                if( coordinateLocal.x == 1u ) return _CustomThemeColor1;\n                if( coordinateLocal.x == 2u ) return _CustomThemeColor2;\n                if( coordinateLocal.x == 3u ) return _CustomThemeColor3;\n            }\n            else\n            {\n                return AudioLinkGetSelfPixelData(ALPASS_CCCOLORS+uvec2(coordinateLocal.x,0));\n            }\n        }\n        else if( coordinateLocal.x == 4u )\n        {\n            // Computation for history timing.\n            vec4 lastval = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(4, 1)); // Timing for 4-band, move at 90 Hz.\n            lastval.x += iTimeDelta * AUDIOLINK_4BAND_TARGET_RATE;\n            // This looks like a frac() but I want to make sure the math gets done the same here\n            // to prevent any possible mismatch between here and the use of finding the int.\n            int framesToRoll = int(floor( lastval.x ));\n            lastval.x -= float(framesToRoll);\n            return lastval;\n        }\n        else if( coordinateLocal.x == 5u )\n        {\n            // UTC Day number\n            return AudioLinkEncodeUInt(uint(_AdvancedTimeProps1.z));\n        }\n        else if( coordinateLocal.x == 6u )\n        {\n            return AudioLinkEncodeUInt(uint(_AdvancedTimeProps1.w * 1000.));\n        }\n        else if( coordinateLocal.x == 7u)\n        {\n            // Audio Source Position\n            return _SourcePosition;\n        }\n    }\n\n    // Reserved\n    return vec4(0.);\n}\n\nfloat NoteWrap(float note1, float note2)\n{\n    float diff = note2 - note1;\n    diff = glsl_mod(diff, float(AUDIOLINK_EXPBINS));\n    if(diff > float(AUDIOLINK_EXPBINS) / 2.)\n        return diff - float(AUDIOLINK_EXPBINS);\n    else\n        return diff;\n}\n\nvec4 fragccinternal (vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_CCINTERNAL)\n\n    float vuAmplitude = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(8, 0)).y * _Gain;\n    float noteMinimum = 0.00 + 0.1 * vuAmplitude;\n\n    //Note structure:\n    // .x = Note frequency (0...AUDIOLINK_ETOTALBINS, but floating point)\n    // .y = The incoming intensity.\n    // .z = Lagged intensity.         ---> This is what decides if a note is going to disappear.\n    // .w = Quicker lagged intensity.\n\n    //NoteB Structure\n    // .x = Note Number  ::: NOTE if .y < 0 this is the index of where this note _went_ or what note it was joined to.\n    // .y = Time this note has existed.\n    // .z = Sorted-by-frequency position. (With note 0 being the 0th note)\n\n    //Summary:\n    // .x = Total number of notes.\n    // .y .z .w = sum of note's yzw.\n\n    //SummaryB:\n    // .x = Latest note number.\n    // .y = AUDIOLINK_ROOTNOTE\n    // .z = number of populated notes.\n\n    vec4 notes[COLORCHORD_MAX_NOTES];\n    vec4 notesB[COLORCHORD_MAX_NOTES];\n\n    int i;\n    for(i = 0; i < COLORCHORD_MAX_NOTES; i++)\n    {\n        notes[i] = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(i + 1, 0)) * vec4(1, 0, 1, 1);\n        notesB[i] = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(i + 1, 1));\n    }\n\n    vec4 noteSummary = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL);\n    vec4 noteSummaryB = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(0, 1));\n    float lastAmplitude = AudioLinkGetSelfPixelData(ALPASS_DFT + uvec2(AUDIOLINK_EXPBINS, 0)).z;\n    float thisAmplitude = AudioLinkGetSelfPixelData(ALPASS_DFT + uvec2(1 + AUDIOLINK_EXPBINS, 0)).z;\n\n    for(i = AUDIOLINK_EXPBINS + 2; i < COLORCHORD_EMAXBIN; i++)\n    {\n        float nextAmplitude = AudioLinkGetSelfPixelData(ALPASS_DFT + uvec2(i % AUDIOLINK_WIDTH, i / AUDIOLINK_WIDTH)).z;\n        if(thisAmplitude > lastAmplitude && thisAmplitude > nextAmplitude && thisAmplitude > noteMinimum)\n        {\n            // Find actual peak by looking ahead and behind.\n            float diffA = thisAmplitude - nextAmplitude;\n            float diffB = thisAmplitude - lastAmplitude;\n            float noteFreq = glsl_mod(float(i - 1), float(AUDIOLINK_EXPBINS));\n            if(diffA < diffB)\n            {\n                // Behind\n                noteFreq -= 1. - diffA / diffB; //Ratio must be between 0 .. 0.5\n            }\n            else\n            {\n                // Ahead\n                noteFreq += 1. - diffB / diffA;\n            }\n\n            int j;\n            int closestNote = -1;\n            int freeNote = -1;\n            float closestNoteDistance = COLORCHORD_NOTE_CLOSEST;\n\n            // Search notes to see what the closest note to this peak is.\n            // also look for any empty notes.\n            for(j = 0; j < COLORCHORD_MAX_NOTES; j++)\n            {\n                float dist = abs(NoteWrap(notes[j].x, noteFreq));\n                if(notes[j].z <= 0.)\n                {\n                    if(freeNote == -1)\n                        freeNote = j;\n                }\n                else if(dist < closestNoteDistance)\n                {\n                    closestNoteDistance = dist;\n                    closestNote = j;\n                }\n            }\n\n            float thisIntensity = thisAmplitude * COLORCHORD_NEW_NOTE_GAIN;\n\n            if(closestNote != -1)\n            {\n                // Note to combine peak to has been found, roll note in.\n                vec4 n = notes[closestNote];\n                float drag = NoteWrap(n.x, noteFreq) * 0.05;\n\n                float mn = max(n.y, thisAmplitude * COLORCHORD_NEW_NOTE_GAIN)\n                    // Technically the above is incorrect without the below, additional notes found should contribute.\n                    // But I'm finding it looks better w/o it.  Well, the 0.3 is arbitrary.  But, it isn't right to\n                    // only take max.\n                    + thisAmplitude * COLORCHORD_NEW_NOTE_GAIN * 0.3;\n\n                notes[closestNote] = vec4(n.x + drag, mn, n.z, n.w);\n            }\n            else if(freeNote != -1)\n            {\n\n                int jc = 0;\n                int ji = 0;\n                // uuuggghhhh Ok, so this's is probably just me being paranoid\n                // but I really wanted to make sure all note IDs are unique\n                // in case another tool would care about the uniqueness.\n                for(ji = 0; ji < COLORCHORD_MAX_NOTES && jc != COLORCHORD_MAX_NOTES; ji++)\n                {\n                    noteSummaryB.x = noteSummaryB.x + 1.;\n                    if(noteSummaryB.x > 1023.) noteSummaryB.x = 0.;\n                    for(jc = 0; jc < COLORCHORD_MAX_NOTES; jc++)\n                    {\n                        if(notesB[jc].x == noteSummaryB.x)\n                            break;\n                    }\n                }\n\n                // Couldn't find note.  Create a new note.\n                notes[freeNote]  = vec4(noteFreq, thisIntensity, thisIntensity, thisIntensity);\n                notesB[freeNote] = vec4(noteSummaryB.x, iTimeDelta, 0., 0.);\n            }\n            else\n            {\n                // Whelp, the note fell off the wagon.  Oh well!\n            }\n        }\n        lastAmplitude = thisAmplitude;\n        thisAmplitude = nextAmplitude;\n    }\n\n    vec4 newNoteSummary = vec4(0.);\n    vec4 newNoteSummaryB = noteSummaryB;\n    newNoteSummaryB.y = float(AUDIOLINK_ROOTNOTE);\n\n    for(i = 0; i < COLORCHORD_MAX_NOTES; i++)\n    {\n        int j;\n        vec4 n1 = notes[i];\n        vec4 n1B = notesB[i];\n\n        for(j = 0; j < COLORCHORD_MAX_NOTES; j++)\n        {\n            //  Shader compiler can't do triangular loops.\n            // We don't want to iterate over a cube just compare ith and jth note once.\n\n            vec4 n2 = notes[j];\n\n            if(n2.z > 0. && j > i && n1.z > 0.)\n            {\n                // Potentially combine notes\n                float dist = abs(NoteWrap(n1.x, n2.x));\n                if(dist < COLORCHORD_NOTE_CLOSEST)\n                {\n                    //Found combination of notes.  Nil out second.\n                    float drag = NoteWrap(n1.x, n2.x) * 0.5;//n1.z/(n2.z+n1.y);\n                    n1 = vec4(n1.x + drag, n1.y + thisAmplitude, n1.z, n1.w);\n\n                    //n1B unchanged.\n\n                    notes[j] = vec4(0.);\n                    notesB[j] = vec4(i, -1., 0., 0.);\n                }\n            }\n        }\n\n        #if 0\n        //Old values, framerate-invariant, assumed 60 FPS medium.\n        #define COLORCHORD_IIR_DECAY_1          0.90\n        #define COLORCHORD_IIR_DECAY_2          0.85\n        #define COLORCHORD_CONSTANT_DECAY_1     0.01\n        #define COLORCHORD_CONSTANT_DECAY_2     0.0\n        #else\n        // Calculated from above values using: 0.9 = pow( x, .016666 ), or new_component = x ^ 60\n        float COLORCHORD_IIR_DECAY_1 = pow( 0.0018, iTimeDelta );\n        float COLORCHORD_IIR_DECAY_2 = pow( 5.822e-5, iTimeDelta );\n        float COLORCHORD_CONSTANT_DECAY_1 = (0.01*60.)*iTimeDelta;\n        float COLORCHORD_CONSTANT_DECAY_2 = (0.0*60.)*iTimeDelta;\n        #endif\n        // Filter n1.z from n1.y.\n        if(n1.z >= 0.)\n        {\n            // Make sure we're wrapped correctly.\n            n1.x = glsl_mod(n1.x, float(AUDIOLINK_EXPBINS));\n\n            // Apply filtering\n            n1.z = lerp(n1.y, n1.z, COLORCHORD_IIR_DECAY_1) - COLORCHORD_CONSTANT_DECAY_1; //Make decay slow.\n            n1.w = lerp(n1.y, n1.w, COLORCHORD_IIR_DECAY_2) - COLORCHORD_CONSTANT_DECAY_2; //Make decay slow.\n\n            n1B.y += iTimeDelta;\n\n\n            if(n1.z < noteMinimum)\n            {\n                n1 = vec4(-1.);\n                n1B = vec4(0.);\n            }\n            //XXX TODO: Do uniformity calculation on n1 for n1.w.\n        }\n\n        if(n1.z >= 0.)\n        {\n            // Compute Y to create a \"unified\" value.  This is good for understanding\n            // the ratio of how \"important\" this note is.\n            n1.y = pow(max(n1.z - noteMinimum*10., 0.), 1.5);\n\n            newNoteSummary += vec4(1., n1.y, n1.z, n1.w);\n        }\n\n        notes[i] = n1;\n        notesB[i] = n1B;\n    }\n\n    // Sort by frequency and count notes.\n    // These loops are phrased funny because the unity shader compiler gets really\n    // confused easily.\n    float sortedNoteSlotValue = -1000.;\n    newNoteSummaryB.z = 0.;\n\n    for(i = 0; i < COLORCHORD_MAX_NOTES; i++)\n    {\n        //Count notes\n        newNoteSummaryB.z += (notes[i].z > 0.) ? 1. : 0.;\n\n        float closestToSlotWithoutGoingOver = 100.;\n        int sortID = -1;\n        int j;\n        for(j = 0; j < COLORCHORD_MAX_NOTES; j++)\n        {\n            vec4 n2 = notes[j];\n            float noteFreqB = glsl_mod(-notes[0].x + 0.5 + n2.x , float(AUDIOLINK_EXPBINS));\n            if(n2.z > 0. && noteFreqB > sortedNoteSlotValue && noteFreqB < closestToSlotWithoutGoingOver)\n            {\n                closestToSlotWithoutGoingOver = noteFreqB;\n                sortID = j;\n            }\n        }\n        sortedNoteSlotValue = closestToSlotWithoutGoingOver;\n        notesB[i] = notesB[i] * vec4(1, 1, 0, 1) + vec4(0, 0, sortID, 0);\n    }\n    // PIXEL LAYOUT:\n    //  Summary / Data[COLORCHORD_MAX_NOTES] / 0 / 0 / Colors[COLORCHORD_MAX_NOTES] / 0\n    // We now have a condensed list of all notes that are playing.\n    if( coordinateLocal.x < uint(COLORCHORD_MAX_NOTES)+1u )\n    {\n        if( coordinateLocal.x == 0u )\n        {\n            // Summary note.\n            return (coordinateLocal.y != 0u) ? newNoteSummaryB : newNoteSummary;\n        }\n        else\n        {\n            // Actual Note Data\n            return (coordinateLocal.y != 0u) ? notesB[coordinateLocal.x - 1u] : notes[coordinateLocal.x - 1u];\n        }\n    }\n    else if( coordinateLocal.x >= uint(COLORCHORD_MAX_NOTES+3) && coordinateLocal.x < uint(COLORCHORD_MAX_NOTES*2+4) && coordinateLocal.y == 0u )\n    {\n        uint id = coordinateLocal.x - uint(COLORCHORD_MAX_NOTES+2);\n        vec4 ThisNote = notes[id];\n        const float AudioLinkColorOutputIntensity = 0.4;\n        return vec4( AudioLinkCCtoRGB( glsl_mod(ThisNote.x,float(AUDIOLINK_EXPBINS)), ThisNote.z * AudioLinkColorOutputIntensity, AUDIOLINK_ROOTNOTE), 1.0 );\n    }\n    return vec4(0.);\n}\n\n// Name \"Pass7-AutoCorrelator\"\n// CGPROGRAM\n\n#define AUTOCORRELATOR_EMAXBIN 120\n#define AUTOCORRELATOR_EBASEBIN 0\n\nvec4 fragautocorr (in vec2 IN) \n{\n    AUDIO_LINK_ALPHA_START(ALPASS_AUTOCORRELATOR)\n\n    float wavePosition = float(coordinateLocal.x);\n    vec2 fvTotal = vec2(0.);\n    float fvr = 15.;\n\n    // This computes both the regular autocorrelator in the R channel\n    // as well as a uncorrelated autocorrelator in the G channel\n    int i;\n    for(i = AUTOCORRELATOR_EBASEBIN; i < AUTOCORRELATOR_EMAXBIN; i++)\n    {\n        float bin = AudioLinkGetSelfPixelData(ALPASS_DFT + uvec2(i % AUDIOLINK_WIDTH, i / AUDIOLINK_WIDTH)).z;\n        float frequency = pow(2., float(i) / 24.) * AUDIOLINK_BOTTOM_FREQUENCY / float(AUDIOLINK_SPS) * UNITY_TWO_PI;\n        vec2 csv = vec2(cos(frequency * wavePosition * fvr),  cos(frequency * wavePosition * fvr + float(i) * 0.32));\n        csv.y *= step(float(i % 4), 1.) * 4.;\n        fvTotal += csv * (bin * bin);\n    }\n\n    // Red:   Regular autocorrelator\n    // Green: Uncorrelated autocorrelator\n    // Blue:  Reserved\n    return vec4(fvTotal, 0, 1);\n}\n\n// Name \"Pass8-ColorChord-Linear\"\n// CGPROGRAM\n\nvec4 fragstrip (in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_CCSTRIP)\n\n    int p;\n\n    const float Brightness = .3;\n    const float RootNote = 0.;\n\n    vec4 NotesSummary = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL);\n\n    float TotalPower = 0.0;\n    TotalPower = NotesSummary.y;\n\n    float PowerPlace = 0.0;\n    for(p = 0; p < COLORCHORD_MAX_NOTES; p++)\n    {\n        vec4 NotesB = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(1 + p, 1));\n        vec4 Peak = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(1. + NotesB.z, 0));\n        if(Peak.y <= 0.) continue;\n\n        float Power = Peak.y/TotalPower;\n        PowerPlace += Power;\n        if(PowerPlace >= IN.x)\n        {\n            return vec4(AudioLinkCCtoRGB(Peak.x, Peak.w*Brightness, AUDIOLINK_ROOTNOTE), 1.0);\n        }\n    }\n\n    return vec4(0., 0., 0., 1.);\n}\n\n// Name \"Pass9-ColorChord-Lights\"\n// CGPROGRAM\n\nconst float _PickNewSpeed = 1.0;\n\nfloat tinyrand(vec3 uvw)\n{\n    return fract(cos(dot(uvw, vec3(137.945, 942.32, 593.46))) * 442.5662);\n}\n\nfloat SetNewCellValue(float a)\n{\n    return a*.5;\n}\n\nvec4 fraglights(in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_CCLIGHTS)\n\n    vec4 NotesSummary = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL);\n\n    #define NOTESUFFIX(n) n.y       //was pow(n.z, 1.5)\n\n    vec4 ComputeCell = AudioLinkGetSelfPixelData(ALPASS_CCLIGHTS + uvec2(coordinateLocal.x, 1));\n    //ComputeCell\n    //    .x = Mated Cell # (Or -1 for black)\n    //    .y = Minimum Brightness Before Jump\n    //    .z = ???\n\n    vec4 ThisNote = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(int(ComputeCell.x) + 1, 0));\n    //  Each element:\n    //   R: Peak Location (Note #)\n    //   G: Peak Intensity\n    //   B: Calm Intensity\n    //   A: Other Intensity\n\n    ComputeCell.y -= _PickNewSpeed * 0.01;\n\n    if(NOTESUFFIX(ThisNote) < ComputeCell.y || ComputeCell.y <= 0. || ThisNote.z < 0.)\n    {\n        //Need to select new cell.\n        float min_to_acquire = tinyrand(vec3(coordinateLocal.xy, iTime));\n\n        int n;\n        vec4 SelectedNote = vec4(0.);\n        int SelectedNoteNo = -1;\n\n        float cumulative = 0.0;\n        for(n = 0; n < COLORCHORD_MAX_NOTES; n++)\n        {\n            vec4 Note = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(n + 1, 0));\n            float unic = NOTESUFFIX(Note);\n            if(unic > 0.)\n                cumulative += unic;\n        }\n\n        float sofar = 0.0;\n        for(n = 0; n < COLORCHORD_MAX_NOTES; n++)\n        {\n            vec4 Note = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(n + 1, 0));\n            float unic = NOTESUFFIX(Note);\n            if( unic > 0. )\n            {\n                sofar += unic;\n                if(sofar/cumulative > min_to_acquire)\n                {\n                    SelectedNote = Note;\n                    SelectedNoteNo = n;\n                    break;\n                }\n            }\n        }\n\n        if(SelectedNote.z > 0.0)\n        {\n            ComputeCell.x = float(SelectedNoteNo);\n            ComputeCell.y = SetNewCellValue(NOTESUFFIX(SelectedNote));\n        }\n        else\n        {\n            ComputeCell.x = 0.;\n            ComputeCell.y = 0.;\n        }\n    }\n\n    ThisNote = AudioLinkGetSelfPixelData(ALPASS_CCINTERNAL + uvec2(ComputeCell.x + 1., 0.));\n\n    if(float(coordinateLocal.y) < 0.5)\n    {\n        // the light color output\n        if(ComputeCell.y <= 0.)\n        {\n            return vec4(0.);\n        }\n\n        //XXX TODO: REVISIT THIS!! Ths is an arbitrary value!\n        float intensity = ThisNote.w/3.;\n        return vec4(AudioLinkCCtoRGB(glsl_mod(ThisNote.x,float(AUDIOLINK_EXPBINS)),intensity, AUDIOLINK_ROOTNOTE), 1.0);\n    }\n    else\n    {\n        // the compute output\n        return ComputeCell;\n    }\n}\n\n// Name \"Filtered-AudioLinkOutput\"\n// CGPROGRAM\nvec4 fragfilteraudio (in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_FILTEREDAUDIOLINK)\n    vec4 AudioLinkBase = AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(0, coordinateLocal.y));\n    if( coordinateLocal.x < 16u )\n    {\n        // For pixels 0..15, filtered output.\n        vec4 Previous = AudioLinkGetSelfPixelData(ALPASS_FILTEREDAUDIOLINK + uvec2(coordinateLocal.x, coordinateLocal.y));\n        return lerp( AudioLinkBase, Previous, pow( pow(.55, iTimeDelta ), float(coordinateLocal.x+1u) ) ); //IIR-Filter\n    }\n    else if( coordinateLocal.x >= 16u &&  coordinateLocal.x < 24u )\n    {\n        // This section is for ALPASS_CHRONOTENSITY\n        uvec4 rpx = uvec4(AudioLinkGetSelfPixelData(coordinateGlobal.xy));\n\n        float ComparingValue = length((coordinateLocal.x & 1u) != 0u ? \n            AudioLinkGetSelfPixelData(ALPASS_FILTEREDAUDIOLINK + uvec2(4, coordinateLocal.y)) :\n            AudioLinkBase);\n\n        //Get a heavily filtered value to compare against.\n        float FilteredAudioLinkValue = length(AudioLinkGetSelfPixelData(ALPASS_FILTEREDAUDIOLINK + uvec2( 0, coordinateLocal.y ) ));\n        \n        float DifferentialValue = ComparingValue - FilteredAudioLinkValue;\n\n        float ValueDiff;\n\n        int mode = int(( coordinateLocal.x - 16u ) / 2u);\n\n        // Chronotensity is organized in a (4x2)x4 grid of accumulated values.\n        // Y is which band we are using.  X is as follows:\n        //\n        // x = 0, 1: Accumulates as a function of intensity of band.\n        //           The louder the band, the quicker the function increments.\n        // x = 0: Difference between base and heavily filtered.\n        // x = 1: Difference between slightly filtered and heavily filtered.\n        //\n        // x = 2, 3: Goes positive when band is higher, negative when lower.\n        // x = 2: Difference between base and heavily filtered.\n        // x = 3: Difference between slightly filtered and heavily filtered.\n        //\n        // x = 4, 5: Increments when respective filtered value is 0 or negative.\n        // x = 4: Difference between base and heavily filtered.\n        // x = 5: Difference between slightly filtered and heavily filtered.\n        //\n        // x = 6: Unfiltered, increments when band is above 0.05 threshold.\n        // x = 7: Unfiltered, increments when band is below 0.05 threshold.\n\n        if( mode == 0 )\n        {\n            ValueDiff = max( DifferentialValue, 0. );\n        }\n        else if( mode == 1 )\n        {\n            ValueDiff = DifferentialValue;\n        }\n        else if( mode == 2 )\n        {\n            ValueDiff = max( -DifferentialValue, 0. );\n        }\n        else\n        {\n            if( (coordinateLocal.x & 1u) != 0u)\n                ValueDiff = length(max((-(AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2( 0, coordinateLocal.y ) ) - vec4(0.05) )), 0. )*2.);\n            else\n                ValueDiff = length(max(((AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2( 0, coordinateLocal.y ) ) - 0.05 )), vec4(0) )*.5);\n        }\n        \n        uint Value = rpx.x + rpx.y * 1024u + rpx.z * 1048576u + rpx.w * 1073741824u;\n        Value += uint(ValueDiff * iTimeDelta * 1048576.);\n\n        return AudioLinkEncodeUInt(Value);\n    }\n    else\n    {\n        // Other features.\n        return vec4(0);\n    }\n}\n\n// Name \"Pass11-Filtered-VU\"\n// CGPROGRAM\nvec4 fragfilter (in vec2 IN, in vec4 OUT)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_FILTEREDVU)\n    if( coordinateLocal.x < 4u )\n    {\n        vec4 prev = AudioLinkGetSelfPixelData(ALPASS_FILTEREDVU + coordinateLocal.xy);\n        vec4 RMSPeak = AudioLinkGetSelfPixelData(ALPASS_GENERALVU + uvec2(8, 0));\n        vec4 lastFilteredRMSPeak = AudioLinkGetSelfPixelData(ALPASS_FILTEREDVU + uvec2(coordinateLocal.x, 0));\n        vec4 filteredRMSPeak = vec4(lerp(RMSPeak, lastFilteredRMSPeak, pow(pow(.046,iTimeDelta), float(coordinateLocal.x+1u))).x);\n\n        vec4 markerValue = AudioLinkGetSelfPixelData(ALPASS_FILTEREDVU + uvec2(coordinateLocal.x, 2));\n        vec4 timerValue = AudioLinkGetSelfPixelData(ALPASS_FILTEREDVU + uvec2(coordinateLocal.x, 3));\n        bvec4 peak;\n        vec4Operation(i, {filteredRMSPeak[i] > markerValue[i] || timerValue[i] > 0.5;})\n        // Filtered VU intensity\n        if(coordinateLocal.y == 0u)\n        {\n            return filteredRMSPeak;\n        }\n        // Filtered VU marker\n        else if (coordinateLocal.y == 1u)\n        {\n            // For linear fallof (we use exp now)\n            /*vec4 res =\n                abs(prev - markerValue) <= 0.01\n                    ? markerValue\n                    : prev < markerValue\n                        ? prev + 0.01 \n                        : prev - 0.01;*/\n\n            vec4 speed;\n            vec4Operation(i, {speed[i] = lerp(0.1, 0.05, abs(prev[i] - markerValue[i]));})\n            vec4 res;\n            vec4Operation(i, {res[i] = lerp(prev[i], markerValue[i], speed[i]);})\n            return max(filteredRMSPeak, res);\n        }\n        // VU markers values\n        else if (coordinateLocal.y == 2u)\n        {\n            vec4 res2;\n            vec4Operation(i, {res2[i] = peak[i] ? filteredRMSPeak[i] : markerValue[i];})\n            return res2;\n        }\n        // VU marker timers\n        else if (coordinateLocal.y == 3u)\n        {\n            vec4 res2;\n            vec4Operation(i, {res2[i] = peak[i] ? 0. : prev[i] + iTimeDelta;})\n            return res2;\n        }\n    }\n    else if (coordinateLocal.x == 4u)\n    {\n        // PEMA\n    }\n    else\n    {\n        // BEAT DETECTION STILL IN EARLY DEVELOPMENT - DO NOT USE\n        vec4 prev = AudioLinkGetSelfPixelData(coordinateGlobal.xy);\n        if( coordinateLocal.x == 5u )\n        {\n            float nowv = length(AudioLinkGetSelfPixelData(ALPASS_AUDIOLINK + uvec2(0, coordinateLocal.y)));\n            float beatdist = 0.;\n            if( prev.x > prev.y && prev.x > nowv )\n            {\n                beatdist = prev.z;\n                prev.z = 0.;\n            }\n            return vec4( nowv, prev.x, prev.z+1., beatdist );\n        }\n        else if( coordinateLocal.x == 6u )\n        {\n            uint y = coordinateLocal.y;\n            // for y = 0..3, each in decreasing levels of forced confidence\n            // used to enact a change on the one above.\n\n            for( int ib = 0; ib < 4; ib++ )\n            {\n                int beat = int(AudioLinkGetSelfPixelData(ALPASS_FILTEREDVU + uvec2( 4, ib ) ).x);\n                // Anywhere beat is nonzero is a data point.\n            }\n        }\n        else\n        {\n            vec4 this_bd_data = AudioLinkGetSelfPixelData(ALPASS_FILTEREDVU + uvec2(4, coordinateLocal.y));\n            //Assume beats in the range of 80..160 BPM only.\n        }\n    }\n    return OUT;\n}\n\n// Name \"Pass12-Global-Strings\"\n// CGPROGRAM\nvec4 fragstr (in vec2 IN)\n{\n    AUDIO_LINK_ALPHA_START(ALPASS_GLOBAL_STRINGS)\n    vec4 char4 = vec4(0.);\n    if (coordinateLocal.y == 0u) {\n        char4 = _StringLocalPlayer[coordinateLocal.x];\n    }\n    else if (coordinateLocal.y == 1u) {\n        char4 = _StringMasterPlayer[coordinateLocal.x];\n    }\n    else if (coordinateLocal.y == 2u) {\n        char4 = _StringCustom1[coordinateLocal.x];\n    } \n    else {\n        char4 = _StringCustom2[coordinateLocal.x];\n    }\n    return char4;\n}\n\nvoid mainImage(out vec4 O, in vec2 I)\n{\n    executeWhen(I, ALPASS_DFT, uvec2(AUDIOLINK_WIDTH,2)) O = frag(I, O);\n    executeWhen(I, ALPASS_WAVEFORM, uvec2(AUDIOLINK_WIDTH,16)) O = fragwave(I);\n    executeWhen(I, ALPASS_AUDIOLINK, uvec2(AUDIOLINK_WIDTH,4)) O = fraglink(I);\n    executeWhen(I, ALPASS_GENERALVU, uvec2(12,1)) O = fraggenvu(I);\n    executeWhen(I, ALPASS_CCINTERNAL, uvec2(12,2)) O = fragccinternal(I);\n    executeWhen(I, ALPASS_AUTOCORRELATOR, uvec2(AUDIOLINK_WIDTH,1)) O = fragautocorr(I);\n    executeWhen(I, ALPASS_CCSTRIP, uvec2(AUDIOLINK_WIDTH,1)) O = fragstrip(I);\n    executeWhen(I, ALPASS_CCLIGHTS, uvec2(AUDIOLINK_WIDTH,2)) O = fraglights(I);\n    executeWhen(I, ALPASS_FILTEREDAUDIOLINK, uvec2(16,4)) O = fragfilteraudio(I);\n    executeWhen(I, ALPASS_FILTEREDVU, uvec2(4,4)) O = fragfilter(I, O);\n    executeWhen(I, ALPASS_GLOBAL_STRINGS, uvec2(8,4)) O = fragstr(I);\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "music",
                        "id": 21,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/ec8a6ea755d34600547a5353f21f0a453f9f55ff95514383b2d80b8d71283eda.mp3"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "#ifndef AUDIOLINK_CGINC_INCLUDED\n#define AUDIOLINK_CGINC_INCLUDED\n// Map of where features in AudioLink are.\n#define ALPASS_DFT                      uvec2(0,4)  //Size: 128, 2\n#define ALPASS_WAVEFORM                 uvec2(0,6)  //Size: 128, 16\n#define ALPASS_AUDIOLINK                uvec2(0,0)  //Size: 128, 4\n#define ALPASS_AUDIOBASS                uvec2(0,0)  //Size: 128, 1\n#define ALPASS_AUDIOLOWMIDS             uvec2(0,1)  //Size: 128, 1\n#define ALPASS_AUDIOHIGHMIDS            uvec2(0,2)  //Size: 128, 1\n#define ALPASS_AUDIOTREBLE              uvec2(0,3)  //Size: 128, 1\n#define ALPASS_AUDIOLINKHISTORY         uvec2(1,0)  //Size: 127, 4\n#define ALPASS_GENERALVU                uvec2(0,22) //Size: 12, 1\n#define ALPASS_GENERALVU_INSTANCE_TIME  uvec2(2,22)\n#define ALPASS_GENERALVU_LOCAL_TIME     uvec2(3,22)\n#define ALPASS_GENERALVU_NETWORK_TIME   uvec2(4,22)\n#define ALPASS_GENERALVU_PLAYERINFO     uvec2(6,22)\n#define ALPASS_THEME_COLOR0             uvec2(0,23)\n#define ALPASS_THEME_COLOR1             uvec2(1,23)\n#define ALPASS_THEME_COLOR2             uvec2(2,23)\n#define ALPASS_THEME_COLOR3             uvec2(3,23)\n#define ALPASS_GENERALVU_UNIX_DAYS      uvec2(5,23)\n#define ALPASS_GENERALVU_UNIX_SECONDS   uvec2(6,23)\n#define ALPASS_GENERALVU_SOURCE_POS     uvec2(7,23)\n\n#define ALPASS_CCINTERNAL               uvec2(12,22) //Size: 12, 2\n#define ALPASS_CCCOLORS                 uvec2(25,22) //Size: 12, 1 (Note Color #0 is always black, Colors start at 1)\n#define ALPASS_CCSTRIP                  uvec2(0,24)  //Size: 128, 1\n#define ALPASS_CCLIGHTS                 uvec2(0,25)  //Size: 128, 2\n#define ALPASS_AUTOCORRELATOR           uvec2(0,27)  //Size: 128, 1\n#define ALPASS_FILTEREDAUDIOLINK        uvec2(0,28)  //Size: 16, 4\n#define ALPASS_CHRONOTENSITY            uvec2(16,28) //Size: 8, 4\n#define ALPASS_FILTEREDVU               uvec2(24,28) //Size: 4, 4\n#define ALPASS_FILTEREDVU_INTENSITY     uvec2(24,28) //Size: 4, 1\n#define ALPASS_FILTEREDVU_MARKER        uvec2(24,29) //Size: 4, 1\n#define ALPASS_GLOBAL_STRINGS           uvec2(40,28) //Size: 8, 4\n\n// Some basic constants to use (Note, these should be compatible with\n// future version of AudioLink, but may change.\n#define AUDIOLINK_SAMPHIST              3069        // Internal use for algos, do not change.\n#define AUDIOLINK_SAMPLEDATA24          2046\n#define AUDIOLINK_EXPBINS               24\n#define AUDIOLINK_EXPOCT                10\n#define AUDIOLINK_ETOTALBINS            (AUDIOLINK_EXPBINS * AUDIOLINK_EXPOCT)\n#define AUDIOLINK_WIDTH                 512\n#define AUDIOLINK_SPS                   44100       // Samples per second\n#define AUDIOLINK_ROOTNOTE              0\n#define AUDIOLINK_4BAND_FREQFLOOR       0.123\n#define AUDIOLINK_4BAND_FREQCEILING     1\n#define AUDIOLINK_BOTTOM_FREQUENCY      13.75\n#define AUDIOLINK_BASE_AMPLITUDE        2.5\n#define AUDIOLINK_DELAY_COEFFICIENT_MIN 0.3\n#define AUDIOLINK_DELAY_COEFFICIENT_MAX 0.9\n#define AUDIOLINK_DFT_Q                 4.0\n#define AUDIOLINK_TREBLE_CORRECTION     10.0\n#define AUDIOLINK_4BAND_TARGET_RATE     90.0\n\n// Text constants\n#define AUDIOLINK_STRING_MAX_CHARS      32\n#define AUDIOLINK_STRING_LOCALPLAYER    0\n#define AUDIOLINK_STRING_MASTER         1\n#define AUDIOLINK_STRING_CUSTOM1        2\n#define AUDIOLINK_STRING_CUSTOM2        3\n\n// ColorChord constants\n#define COLORCHORD_EMAXBIN              192\n#define COLORCHORD_NOTE_CLOSEST         3.0\n#define COLORCHORD_NEW_NOTE_GAIN        8.0\n#define COLORCHORD_MAX_NOTES            10\n\n// We use glsl_mod for most calculations because it behaves better\n// on negative numbers, and in some situations actually outperforms\n// HLSL's modf().\n#ifndef glsl_mod\n#define glsl_mod(x,y) (((x)-(y)*floor((x)/(y))))\n#endif\n\n#define UNITY_TWO_PI (3.141592653589*2.)\n#define saturate(x) clamp(x,0.,1.)\n\nuniform vec4               _AudioTexture_TexelSize;\n\n#ifdef SHADER_TARGET_SURFACE_ANALYSIS\n#define AUDIOLINK_STANDARD_INDEXING\n#endif\n\nbool inside(uvec2 v, uvec2 pos, uvec2 size)\n{\n    uvec2 pos2 = pos + size;\n    return v.x >= pos.x && v.y >= pos.y && v.x < pos2.x && v.y < pos2.y;\n}\n\n#define executeWhen(fragCoord, pos, size) if (inside(uvec2(fragCoord), uvec2(pos), uvec2(size)))\n#define aexecuteWhen(fragCoord, pos, size) //if (inside(uvec2(fragCoord), uvec2(pos), uvec2(size)))\n\nvec4 lerp(vec4 v1, vec4 v2, float f)\n{\n    return vec4(\n        smoothstep(v1.r, v2.r, f),\n        smoothstep(v1.g, v2.g, f),\n        smoothstep(v1.b, v2.b, f),\n        smoothstep(v1.a, v2.a, f)\n    );\n}\n\nvec3 lerp(vec3 v1, vec3 v2, float f)\n{\n    return vec3(\n        smoothstep(v1.r, v2.r, f),\n        smoothstep(v1.g, v2.g, f),\n        smoothstep(v1.b, v2.b, f)\n    );\n}\n\nvec2 lerp(vec2 v1, vec2 v2, float f)\n{\n    return vec2(\n        smoothstep(v1.r, v2.x, f),\n        smoothstep(v1.g, v2.y, f)\n    );\n}\n\nfloat lerp(float v1, float v2, float f)\n{\n    return smoothstep(v1, v2, f);\n}\n\n\n//Tests to see if Audio Link texture is available\nbool AudioLinkIsAvailable()\n{\n    return true;\n    // #if !defined(AUDIOLINK_STANDARD_INDEXING)\n    //     int width, height;\n    //     _AudioTexture.GetDimensions(width, height);\n    //     return width > 16;\n    // #else\n    //     return _AudioTexture_TexelSize.z > 16;\n    // #endif\n}\n\n\n#define ALDecodeDataAsSeconds( x ) AudioLinkDecodeDataAsSeconds( x )\n#define ALDecodeDataAsUInt( x ) AudioLinkDecodeDataAsUInt( x )\n#define vec4Operation(i,oper) for (int i = 0; i < 4; ++i) oper\n\nfloat AudioLinkRemap(float t, float a, float b, float u, float v) { return ((t-a) / (b-a)) * (v-u) + u; }\n\nvec3 AudioLinkHSVtoRGB(vec3 HSV)\n{\n    vec3 RGB = vec3(0.);\n    float C = HSV.z * HSV.y;\n    float H = HSV.x * 6.;\n    float X = C * (1. - abs(mod(H, 2.) - 1.));\n    if (HSV.y != 0.)\n    {\n        float I = floor(H);\n        if (I == 0.) { RGB = vec3(C, X, 0.); }\n        else if (I == 1.) { RGB = vec3(X, C, 0.); }\n        else if (I == 2.) { RGB = vec3(0., C, X); }\n        else if (I == 3.) { RGB = vec3(0., X, C); }\n        else if (I == 4.) { RGB = vec3(X, 0., C); }\n        else { RGB = vec3(C, 0., X); }\n    }\n    float M = HSV.z - C;\n    return RGB + M;\n}\n\nvec3 AudioLinkCCtoRGB(float bin, float intensity, int rootNote)\n{\n    float note = bin / float(AUDIOLINK_EXPBINS);\n\n    float hue = 0.0;\n    note *= 12.0;\n    note = glsl_mod(4. - note + float(rootNote), 12.0);\n    {\n        if(note < 4.0)\n        {\n            //Needs to be YELLOW->RED\n            hue = (note) / 24.0;\n        }\n        else if(note < 8.0)\n        {\n            //            [4]  [8]\n            //Needs to be RED->BLUE\n            hue = (note-2.0) / 12.0;\n        }\n        else\n        {\n            //             [8] [12]\n            //Needs to be BLUE->YELLOW\n            hue = (note - 4.0) / 8.0;\n        }\n    }\n    float val = intensity - 0.1;\n    return AudioLinkHSVtoRGB(vec3(mod(hue, 1.0), 1.0, clamp(val, 0.0, 1.0)));\n}\n\nstruct Slider\n{\n    float val;\n    float fmin;\n    float fmax;\n};\n\n\n\nvec3 sliderToVec(Slider val)\n{\n    return vec3(val.val, val.fmin, val.fmax);\n}\n\nSlider vecToSlider(vec3 val)\n{\n    Slider s;\n    s.val = val.r;\n    s.fmin = val.g;\n    s.fmax = val.b;\n    return s;\n}\n\nstruct Drag\n{\n    uint selectedID;\n    vec2 start;\n    vec2 last;\n    \n};\n\nstruct Zones\n{\n    Slider x0;\n    Slider x1;\n    Slider x2;\n    Slider x3;\n    Slider t0;\n    Slider t1;\n    Slider t2;\n    Slider t3;\n    \n};\n\nZones initZones()\n{\n    Zones z;\n    z.x0 = Slider(0., 0., 0.168);\n    z.x1 = Slider(0.38, 0.242, 0.387);\n    z.x2 = Slider(0.62, 0.461, 0.628);\n    z.x3 = Slider(0.8, 0.704, 0.953);\n    z.t0 = Slider(0.35, 0., 1.);\n    z.t1 = Slider(0.15, 0., 1.);\n    z.t2 = Slider(0.2, 0., 1.);\n    z.t3 = Slider(0.21, 0., 1.);\n    return z;\n}\n/*Zones initZones()\n{\n    Zones z;\n    z.x0 = Slider(0., 0., 0.15);\n    z.x1 = Slider(0.38, 0.02, 0.387);\n    z.x2 = Slider(0.62, 0.06, 0.628);\n    z.x3 = Slider(0.8, 0.2, 0.953);\n    z.t0 = Slider(0.35, 0., 1.);\n    z.t1 = Slider(0.15, 0., 1.);\n    z.t2 = Slider(0.2, 0., 1.);\n    z.t3 = Slider(0.21, 0., 1.);\n    return z;\n}*/\n\nconst float lineThickness = 5.;\n\n\n#define T0COLOR vec3(0.43359375, 0.40234375, 0.87109375)\n#define T1COLOR vec3(0.87109375, 0.40234375, 0.6015625)\n#define T2COLOR vec3(0.8359375, 0.87109375, 0.40234375)\n#define T3COLOR vec3(0.40234375, 0.87109375, 0.671875)\n\n#define AudioLinkGetSelfPixelData(xy) texelFetch(iChannel0, ivec2(xy),0)\n\n#define compare(v1,v2,thresh) (abs(v1-v2) <= thresh)\n\n#define inRange(v,fmin,fmax) (fmin <= v && v < fmax)\n\nvoid encode(inout vec4 O, in vec2 I, in vec3 v, inout int i)\n{\n    if (int(floor(I.x)) == i++)\n    {\n        O = vec4(v, 0.);\n    }\n}\n\nvoid encode(inout vec4 O, in vec2 I, in Slider v, inout int i)\n{\n    encode(O, I, sliderToVec(v), i);\n}\n\nvoid encode(inout vec4 O, in vec2 I, in Zones z, inout int i)\n{\n    encode(O, I, z.x0, i);\n    encode(O, I, z.x1, i);\n    encode(O, I, z.x2, i);\n    encode(O, I, z.x3, i);\n    encode(O, I, z.t0, i);\n    encode(O, I, z.t1, i);\n    encode(O, I, z.t2, i);\n    encode(O, I, z.t3, i);\n}\n\nvoid decodeVec3(sampler2D tex, out vec3 v, inout int i)\n{\n    v.rgb = texelFetch(tex, ivec2(i++,0),0).rgb;\n}\n\nvoid decodeSlider(sampler2D tex, out Slider v, inout int i)\n{\n    vec3 c;\n    decodeVec3(tex,c,i);\n    v = vecToSlider(c);\n}\n\nvoid decodeZones(sampler2D tex, out Zones z, inout int i)\n{\n    decodeSlider(tex, z.x0, i);\n    decodeSlider(tex, z.x1, i);\n    decodeSlider(tex, z.x2, i);\n    decodeSlider(tex, z.x3, i);\n    decodeSlider(tex, z.t0, i);\n    decodeSlider(tex, z.t1, i);\n    decodeSlider(tex, z.t2, i);\n    decodeSlider(tex, z.t3, i);\n}\n\n\n#endif\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// Mechanism to index into texture.\n#ifdef AUDIOLINK_STANDARD_INDEXING\n    sampler2D _AudioTexture;\n    #define AudioLinkData(xycoord) tex2Dlod(_AudioTexture, vec4(uvec2(xycoord) * _AudioTexture_TexelSize.xy, 0., 0.))\n#else\n    #define _AudioTexture iChannel0\n    #define AudioLinkData(xycoord) texelFetch(_AudioTexture, ivec2(xycoord), 0)\n#endif\n\nvoid vertiClickEvent(inout Slider s, vec2 pos, float r)\n{\n    vec2 mousePos = iMouse.xy/iResolution.xy;\n    if (abs(length(pos-mousePos)) < r/iResolution.x)\n    {\n        s.val = min(max(s.fmin, mousePos.x), s.fmax);\n    }\n}\n\nvoid horizClickEvent(inout Slider s, vec2 pos, float r)\n{\n    vec2 mousePos = iMouse.xy/iResolution.xy;\n    if (abs(length(pos-mousePos)) < r/iResolution.y)\n    {\n        s.val = min(max(s.fmin, mousePos.y), s.fmax);\n    }\n}\n\n\n\n// Convenient mechanism to read from the AudioLink texture that handles reading off the end of one line and onto the next above it.\nvec4 AudioLinkDataMultiline(uvec2 xycoord) { return AudioLinkData(uvec2(xycoord.x % uint(AUDIOLINK_WIDTH), xycoord.y + xycoord.x/uint(AUDIOLINK_WIDTH))); }\n\n// Mechanism to sample between two adjacent pixels and lerp between them, like \"linear\" supesampling\nvec4 AudioLinkLerp(vec2 xy) { return lerp( AudioLinkData(xy), AudioLinkData(ivec2(xy)+ivec2(1,0)), fract( xy.x ) ); }\n\n// Same as AudioLinkLerp but properly handles multiline reading.\nvec4 AudioLinkLerpMultiline(vec2 xy) { return lerp(AudioLinkDataMultiline(uvec2(xy)), AudioLinkDataMultiline(uvec2(xy+vec2(1.,0.))), fract(xy.x)); }\n\n\n\n//Get version of audiolink present in the world, 0 if no audiolink is present\nfloat AudioLinkGetVersion()\n{\n    ivec2 dims = ivec2(iResolution.xy);\n    /*#if !defined(AUDIOLINK_STANDARD_INDEXING)\n        _AudioTexture.GetDimensions(dims.x, dims.y);\n    #else\n        dims = _AudioTexture_TexelSize.zw;\n    #endif*/\n\n    if (dims.x >= 128)\n        return float(AudioLinkData(ALPASS_GENERALVU).x);\n    else if (dims.x > 16)\n        return 1.;\n    else\n        return 0.;\n}\n\n// This pulls data from this texture.\n#ifndef AudioLinkGetSelfPixelData\n    #define AudioLinkGetSelfPixelData(xy) texelFetch(_SelfTexture2D, ivec2(xy),0)\n#endif\n\n// Extra utility functions for time.\nuint AudioLinkDecodeDataAsUInt(uvec2 indexloc)\n{\n    uvec4 rpx = uvec4(AudioLinkData(indexloc));\n    return rpx.x + rpx.y*uint(1024) + rpx.z * uint(1048576) + rpx.w * uint(1073741824);\n}\n\n\n\n\nfloat delta(float v1, float v2)\n{\n    return v1 + (v2 - v1) / 2.;\n}\n\n\nvoid mainImage(out vec4 O, in vec2 I)\n{\n    Zones z;\n    if (iFrame == 0)\n    {\n        z = initZones();\n    }\n    else\n    {\n        int i = 0;\n        decodeZones(iChannel0, z, i);\n    }\n    horizClickEvent(z.t0, vec2(delta(z.x0.val,z.x1.val), z.t0.val), 30.);\n    horizClickEvent(z.t1, vec2(delta(z.x1.val,z.x2.val), z.t1.val), 30.);\n    horizClickEvent(z.t2, vec2(delta(z.x2.val,z.x3.val), z.t2.val), 30.);\n    horizClickEvent(z.t3, vec2(delta(z.x3.val,1.), z.t3.val), 30.);\n    vertiClickEvent(z.x0, vec2(z.x0.val, 0.5), 30.);\n    vertiClickEvent(z.x1, vec2(z.x1.val, 0.5), 30.);\n    vertiClickEvent(z.x2, vec2(z.x2.val, 0.5), 30.);\n    vertiClickEvent(z.x3, vec2(z.x3.val, 0.5), 30.);\n\n    int ii = 0;\n    encode(O, I, z, ii);\n    \n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}