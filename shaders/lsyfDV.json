{
    "Shader": {
        "info": {
            "date": "1530541706",
            "description": "Rendering noise flow field lines in realtime.",
            "flags": 32,
            "hasliked": 0,
            "id": "lsyfDV",
            "likes": 129,
            "name": "Noise Flow Lines",
            "published": 3,
            "tags": [
                "noise",
                "line",
                "hair",
                "fur",
                "flow",
                "field",
                "fiber"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 4400
        },
        "renderpass": [
            {
                "code": "/*\n\n\tNoise Flow Lines\n\t----------------\n\t\n\tDavidar's \"Wind Flow Map\" reminded me that I've had a few noise flow examples sitting \n\taround half finished, so I decided to finish one and post it... It's less polished \n\tthan I'd like, but it's more complete than it was. :) I have some static imagery, and\n\tsome animated particle versions that I'll post at some stage.\n\n\tI'm sure you've seen noise flow-field images before. This is a cheap recreation, but \n\tthe real ones look pretty cool. They're trivial to construct when you have random pixel \n\taccess -- Convert a noise value to a constant length direction vector, advance the\n    current position, render something at, or between, points, repeat the process, etc. \n\tThe problem, of course, is drawing a set of overlapping objects at a decent frame rate \n\tin a pixel shader. It's possible to produce some really nice particle based versions,\n\tbut you tend to lose the wind-swept fibrous animation along the way.\n\t\n\tIf realtime animation wasn't a concern, it'd be possible to recreate the beautiful\n    particle based equivalent precisely. A particle\\line array approach simply isn't \n\tpossible in this situation. This particular image requires the rendering of six lines \n\t9000 times over (I think) per pixel per frame. Taking a grid approach brings the total \n\tline count way down to the order of 300. Not ideal, and at the expense of quality, but \n\ta mid-range GPU can handle it easy enough.\n\n\tAs inferred, it's possible to render static noise field lines outside the pixel shader \n\tenvironment with very little effort, and since I hacked this method together on the fly, \n    I'd imagine there might be better ways to get the job done. However, this will suffice \n\tfor now. I know of a way that might increase efficiency considerably, but I'll have to \n\tconduct some experiments first.\n\n\tFor anyone who wants a start on noise flow, I stripped down IQ's \"Noise Blur\" example,\n\tand put in some quick comments. The example wasn't interesting enough to list, so the \n    link is private. \n    //\n\tDirectional Noise Blur - Shane\n\thttps://www.shadertoy.com/view/MdyfDc\n    //\n    The shader above is based largely on the following:\n\tNoise Blur - iq\n\thttps://www.shadertoy.com/view/4dlGDN\n\n    \n\tOther examples:\n\n\n\t// Real time particle flow.\n    //\n\tWind flow map - davidar \n\thttps://www.shadertoy.com/view/4sKBz3\n\n    // Very classy -- Nimitz is the kind of coder who can lift your coding skills. Wish\n\t// he posted more. For my own amusement, I've been meaning to port an old example \n\t// that's similar, but it involves too many particles, which means I'll have to \n\t// organize them into grid segments, etc... Too lazy for that at the moment. :)\n    //\n\tSinuous - nimitz\n\thttps://www.shadertoy.com/view/4sGSDw\n\n    // If you're not familiar with noise flow imagery, you can find a few examples here:\n    //\n    Getting Creative with Perlin Noise Fields - Sighack\n    https://sighack.com/post/getting-creative-with-perlin-noise-fields\n\n\n\n*/\n\n\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n    \n  \n    // Screen coordinates.\n    float iResY = min(iResolution.y, 800.);\n    vec2 uv = (fragCoord.xy - iResolution.xy*.5)/iResY;\n    \n    // Grid scale. Smaller numbers space the strands out more, and larger numbers pack them in.\n    // I thought this was about right for the 800 by 450 window. There's also a screen size factor\n    // that I fudged in to attempt to achieve the right scale when using fullscreen, etc. Sometimes,\n    // it'd be nice to just cater to one window size, but that's never happening. :)\n    float scSizeFactor = pow(iResY/450., .333); // Just a rough guess. No science whatsoever. :)\n    float scale = 72.*scSizeFactor;\n    \n    vec2 p = uv*scale; // Add \"iTime\" for scrolling, if desired.\n    \n    // The unique ID for each cell. Oddly enough, it's used to uniquely identify the cell. :)\n    vec2 ip = floor(p);\n    \n    p -= ip + .5; // The centered local cell coordinates. Same as: p = fract(p) - .5;\n    \n    \n    // Scene color. Intitialized to zero.\n    vec3 col = vec3(0);\n    \n        \t\n    // The joys of rendering things on a repeat grid. :) If the object in question fits within the confines of \n    // the local grid cell, then you only need render that grid cell. However, if it overlaps other grid cells,\n    // then you need to render those too. In this instance, the object is a strand of six lines that can overlap\n    // a whole heap of neighboring cells (7x7), so each have to be rendered. Not ideal, but the alternative is \n    // to iterate through the 7000 or so grid cells on the canvas.\n    for(int j = -3; j<=3; j++){\n    \tfor(int i = -3; i<=3; i++){\n        \n            // Cell coordinates we're covering. The unique identifier will be \n            // \"ip + o,\" which is used to index the various precalculated values, etc.\n            vec2 o = vec2(i, j);\n            \n            // Slight grid center offset, just to break the grid lines up a little.\n            o += hash22(o + ip, 64.)*.25;\n            \n            // Alpha value. Used to fade out the strand as it lengthens.\n            float alpha = 1.;\n            \n            // Layer color.\n            vec3 col2 = vec3(0);\n            \n            // Extra noise values for some strand coloring, shadowing, etc.\n            vec2 v = texture(iChannel0, (ip + o)/scale/16.).yz;\n            \n            // The texture strand color. Unique to each strand.\n            // Option one:\n            //vec3 tx = vec3(v.x*.2 + .8, v.x*.5 + .25, v.x)*vec3(2.4, 2, 1.6);\n            //tx *= smoothstep(0., .1, v.y - .4)*.4 + .8;\n            \n            // Option 2:\n            // Load \"Organic 3\" into iChannel1 to use this.\n            //vec3 tx = texture(iChannel1, ((ip + o)/scale/1.)*vec2(iResolution.y/iResolution.x, 1) + .5).xyz;\n            //tx *= tx;\n            //tx = smoothstep(-.05, .5, tx)*2.5;\n            \n            // Option 3: Using IQ's cosine palette.\n            vec3 tx = (.5 + .45*cos(6.2831*v.y*128. - vec3(0, 1, 2)*1.25))*3.;\n            \n            \n            // Drawing circles in every grid cell below the strands, but I decided against it.\n            //float circ = length(o - p) - .1;\n            //circ = max(circ, -(circ - .07));\n             \n            // Start off from the grid origin, obtain the noise value at that position, convert it to\n            // an angle in order to construct a constant lenth direction vector. Use the direction\n            // vector to advance to the new position and draw a line between them. Repeat the \n            // process. Very simple. However, slightly costly due to the overlapping line segments.\n            // Hence, the very small number of short segments.\n            \n            const int lNum = 6;\n            for(int n = 0; n<lNum; n++){\n        \t\n                // If grinding things to a halt by not precalculating is more your thing, swap the \n                // line below for this one. :D\n                //float a = (fBm((ip + o)/scale, 6., iTime/1.5) - .5)*6.2831*2.;\n               \n                // The precalulated angular noise value. Equivalent to the line above. \n                float a = texture(iChannel0, ((ip + o)/scale) + .0).x;\n                \n                // The length of the direction vector needs to be such that the total\n                // lines drawn don't exceed the NxN grid area boundaries.\n                const float rl = 3.5/6.; // 3.5/float(lNum);\n                \n                // Standard way to take an angle and convert it to a direction vector.\n                vec2 r = vec2(cos(a), sin(a))*rl;\n\n\n                // Drawing a line from one point to the next point in the segment. By the way, lines\n                // aren't mandatory. You could draw points, and so forth.\n                float l = distLine(o - p, o + r - p);\n                //float l = (dot(o - p, o - p))*2.;\n                //float l = distLine(o - p, o + r - p);\n                //float l = length(o + r/2. - p) - .1;\n\n                l = (1. - smoothstep(0., .0045/scSizeFactor, (l - .005)/scale));\n                //l = max(1. - l*4., 0.)*1.; // Alternate.\n                \n                // The \"alpha*(1. - alpha)\" is a weighted distribution trick that I'd forgotten about.\n                // You'll see IQ use it when he's layering things. You can also square the term. Anyway,\n                // it's not mandatory. Something like \"alpha*.2\" would work, but it tends to layer things \n                // in a less nice way, whereas weighted distribution layering alleviates the subtle grid\n                // marks.\n                l *= alpha*(1. - alpha)*.8;\n                //l *= alpha*.25;\n\n\n                // Max blend. No join marks with overlapping line segments. Some texture coloring\n                // is applied as well.\n                col2 = max(col2, tx*l);\n                \n                // Additive blend. You can see the overlapping joins when using this method...\n                // which might be preferable, in some cases.\n                //col2 += vec3(l)*tx*.8;\n\n                \n                // Advance the line position by the angular direction ray.\n                o += r;\n                \n                // Falloff with increasing strand length. \n                alpha -= 1./6.; // Hardcoding \"1./float(sNum);\"\n                \n                \n            }\n            \n            // How you blend the layers is up to you. I'm using a simple additive blend here, but\n            // max, screen, mixes, etc, are possible.\n            col += col2;\n            \n            // Layer mix. A little cleaner, but less vibrant.\n            //col = mix(col, vec3(1), col2);\n             \n            // Early pixel color threshold exit, if prefered, but I want more prominence in \n            // the streaks.\n            //if (col.x>=1.) break;\n\n    \t}\n    }\n    \n    // Very basic postprocessing.\n    //col += vec3(.03, .01, 0);\n    //col = pow(col, vec3(1.2))*1.2; // Vibrance.\n    // Toning down the highlights by just a touch.\n    //col = mix(col, 1. - exp(-col), .5);\n    \n    // Greyscale.\n    //col = vec3(1)*dot(col, vec3(.299, .587, .114));\n    \n \n    // Approximate gamma correction. Every now and again, someone will post a quick example explaining\n    // why this is necessary. If you don't know why, then I'd highly recommend reading up on it.\n    fragColor = vec4(sqrt(max(col, 0.)), 1);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// The Shadertoy variable \"iTime\" isn't recognized in the common tab, so this is a \n// hacky workaround. Take a look at the fBm function.\nfloat gTime;\n\n\n// Unsigned distance to the segment joining \"a\" and \"b.\"\nfloat distLine(vec2 a, vec2 b){\n    \n\tb = a - b;\n\tfloat h = clamp(dot(a, b) / dot(b, b), 0., 1.);\n    return length(a - b*h);\n}\n\n\nvec2 hash22(vec2 p, float repScale) {\n\n    // Repetition.\n    p = mod(p, repScale);\n    \n        // Faster, but doesn't disperse things quite as nicely. However, when framerate\n    // is an issue, and it often is, this is a good one to use. Basically, it's a tweaked \n    // amalgamation I put together, based on a couple of other random algorithms I've \n    // seen around... so use it with caution, because I make a tonne of mistakes. :)\n    float n = sin(dot(p, vec2(113, 1)));\n  \n    return (fract(vec2(262144, 32768)*n) - .5)*2. - 1.;\n}\n\n\n// Standard 2x2 hash algorithm... I'll replace this with Dave Hoskins's more reliable\n// one at some stage.\nvec2 hash22G(vec2 p, float repScale) {\n\n    // Repetition.\n    p = mod(p, repScale);\n    \n        // Faster, but doesn't disperse things quite as nicely. However, when framerate\n    // is an issue, and it often is, this is a good one to use. Basically, it's a tweaked \n    // amalgamation I put together, based on a couple of other random algorithms I've \n    // seen around... so use it with caution, because I make a tonne of mistakes. :)\n    float n = sin(dot(p, vec2(113, 1)));\n    \n    #ifdef STATIC\n    return (fract(vec2(262144, 32768)*n) - .5)*2. - 1.; \n    #else\n    // Animated.\n    p = fract(vec2(262144, 32768)*n); \n    // Note the \".45,\" insted of \".5\" that you'd expect to see. When edging, it can open \n    // up the cells ever so slightly for a more even spread. In fact, lower numbers work \n    // even better, but then the random movement would become too restricted. Zero would \n    // give you square cells.\n    return sin( p*6.2831853 + gTime); \n    #endif\n\n}\n\n// Gradient noise: Ken Perlin came up with it, or a version of it. Either way, this is\n// based on IQ's implementation. It's a pretty simple process: Break space into squares, \n// attach random 2D vectors to each of the square's four vertices, then smoothly \n// interpolate the space between them.\nfloat gradN2D(in vec2 f, float repScale){\n  \n   f *= repScale;\n    \n    // Used as shorthand to write things like vec3(1, 0, 1) in the short form, e.yxy. \n   const vec2 e = vec2(0, 1);\n   \n    // Set up the cubic grid.\n    // Integer value - unique to each cube, and used as an ID to generate random vectors for the\n    // cube vertiies. Note that vertices shared among the cubes have the save random vectors attributed\n    // to them.\n    vec2 p = floor(f);\n    f -= p; // Fractional position within the cube.\n    \n\n    // Smoothing - for smooth interpolation. Use the last line see the difference.\n    //vec2 w = f*f*f*(f*(f*6.-15.)+10.); // Quintic smoothing. Slower and more squarish, but derivatives are smooth too.\n    vec2 w = f*f*(3. - 2.*f); // Cubic smoothing. \n    //vec2 w = f*f*f; w = ( 7. + (w - 7. ) * f ) * w; // Super smooth, but less practical.\n    //vec2 w = .5 - .5*cos(f*3.14159); // Cosinusoidal smoothing.\n    //vec2 w = f; // No smoothing. Gives a blocky appearance.\n    \n    // Smoothly interpolating between the four verticies of the square. Due to the shared vertices between\n    // grid squares, the result is blending of random values throughout the 2D space. By the way, the \"dot\" \n    // operation makes most sense visually, but isn't the only metric possible.\n    float c = mix(mix(dot(hash22G(p + e.xx, repScale), f - e.xx), dot(hash22G(p + e.yx, repScale), f - e.yx), w.x),\n                  mix(dot(hash22G(p + e.xy, repScale), f - e.xy), dot(hash22G(p + e.yy, repScale), f - e.yy), w.x), w.y);\n    \n    // Taking the final result, and converting it to the zero to one range.\n    return c*.5 + .5; // Range: [0, 1].\n}\n\n// Gradient noise fBm.\nfloat fBm(in vec2 p, float repScale, float time){\n    \n    gTime = time;\n    \n    return gradN2D(p, repScale)*.57 + gradN2D(p, repScale*2.)*.28 + gradN2D(p, repScale*4.)*.15;\n    \n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \n    // Some of the noie values are accessed 300 times, so precalculation\n    // is necessary.\n    \n    vec2 uv = fragCoord/iResolution.xy;\n\n    // A bit of layers noise. The top is for the main flowing lines, and\n    // and the other is for a bit of coloring.    \n    float c = fBm(uv, 6., iTime/1.5);\n    float c2 = fBm(uv, 6.*2., 0.);\n    \n    // Angle, noise value, and noise color value.\n    fragColor = vec4((c - .5)*6.2831*2., c, c2, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}