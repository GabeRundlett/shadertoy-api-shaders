{
    "Shader": {
        "info": {
            "date": "1606598937",
            "description": "This is another edit of one of my cave fractals. This fractal has some interesting stalactite formations.\nUse the mouse to look around.",
            "flags": 40,
            "hasliked": 0,
            "id": "wsKBzh",
            "likes": 1,
            "name": "Ice caves",
            "published": 3,
            "tags": [
                "fractal",
                "ice",
                "cave",
                "snow",
                "stalactite"
            ],
            "usePreview": 0,
            "username": "jarble",
            "viewed": 376
        },
        "renderpass": [
            {
                "code": "//this is based on https://www.shadertoy.com/view/4tcGDr\n\n#define rot(spin) mat2(cos(spin),sin(spin),-sin(spin),cos(spin))\n\nconst int MAX_MARCHING_STEPS = 1000;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 10000.0;\nconst float EPSILON = 0.001;\n\n/**\n * Signed distance function describing the scene.\n * \n * Absolute value of the return value indicates the distance to the surface.\n * Sign indicates whether the point is inside or outside the surface,\n * negative indicating inside.\n */\n\nvec3 warp(vec3 p){\n    vec3 a = p/(1000.0);\n    return p+vec3((sin(a)))*500.0;\n}\n\nfloat planet_surface(vec3 p,float i){\n    p = (sin(sin(p.yzx/i)-cos(p*i)/i));\n    return length(p) - 1.0;\n}\n\nfloat sceneSDF(vec3 p,float anim) {\n    float result = 0.0;\n    p = warp(p);\n    for(float i = 1.0; i < 8.0; i *= 2.0){\n        result = max(result, -planet_surface(p*i,i)/(i));\n    }\n    //float result = sceneSDF1(p/1000.0+sceneSDF1(p/1000.0));\n    return result/2.0;\n}\n\nfloat sceneSDF(vec3 p){\n    \n\treturn sceneSDF(p,1.0);\n}\n\nvec3 surface_color(vec3 p)\n{\n    p *= 1.0;\n    return .4+sin(2.0*vec3(0.0,0.0,(sceneSDF(p*5.0,0.0))))+vec3(.4);\n}\n\n\n/**\n * Return the shortest distance from the eyepoint to the scene surface along\n * the marching direction. If no part of the surface is found between start and end,\n * return end.\n * \n * eye: the eye point, acting as the origin of the ray\n * marchingDirection: the normalized direction to march in\n * start: the starting distance away from the eye\n * end: the max distance away from the ey to march before giving up\n */\nfloat shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end) {\n    float depth = start;\n    float eps = EPSILON;\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n        float dist = sceneSDF(eye + depth * marchingDirection);\n        if (dist < eps*(1.0+depth*.1)) {\n\t\t\treturn depth-dist;\n        }\n        depth += dist;\n        eps *= 1.0+.001*(depth+1.0);\n        if (depth >= end) {\n            return end;\n        }\n    }\n    return end;\n}\n            \n\n/**\n * Return the normalized direction to march in from the eye point for a single pixel.\n * \n * fieldOfView: vertical field of view in degrees\n * size: resolution of the output image\n * fragCoord: the x,y coordinate of the pixel in the output image\n */\nvec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord) {\n    vec2 xy = fragCoord - size / 2.0;\n    float z = size.y / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n/**\n * Using the gradient of the SDF, estimate the normal on the surface at point p.\n */\nvec3 estimateNormal(vec3 p) {\n    //surface color for bump mapping\n    return normalize(vec3(\n        sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),\n        sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),\n        sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\n/**\n * Lighting contribution of a single point light source via Phong illumination.\n * \n * The vec3 returned is the RGB color of the light's contribution.\n *\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n * lightPos: the position of the light\n * lightIntensity: color/intensity of the light\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye,\n                          vec3 lightPos, vec3 lightIntensity) {\n    lightPos = eye;\n    vec3 N = estimateNormal(p);\n    vec3 L = normalize(lightPos - p);\n    vec3 V = normalize(eye - p);\n    vec3 R = normalize(reflect(-L, N));\n    \n    float dotLN = dot(L, N);\n    float dotRV = dot(R, V);\n    \n    if (dotLN < 0.0) {\n        // Light not visible from this point on the surface\n        return vec3(0.0, 0.0, 0.0);\n    } \n    \n    if (dotRV < 0.0) {\n        // Light reflection in opposite direction as viewer, apply only diffuse\n        // component\n        return lightIntensity * (k_d * dotLN);\n    }\n    return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));\n}\n\n/**\n * Lighting via Phong illumination.\n * \n * The vec3 returned is the RGB color of that point after lighting is applied.\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {\n    const vec3 ambientLight = 0.5 * vec3(1.0, 1.0, 1.0);\n    vec3 color = ambientLight * k_a;\n    \n    vec3 light1Pos = vec3(4.0,\n                          2.0,\n                          4.0);\n    vec3 light1Intensity = vec3(0.8);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light1Pos,\n                                  light1Intensity);   \n    return color;\n}\n\n/**\n * Return a transform matrix that will transform a ray from view space\n * to world coordinates, given the eye point, the camera target, and an up vector.\n *\n * This assumes that the center of the camera is aligned with the negative z axis in\n * view space when calculating the ray marching direction. See rayDirection.\n */\nmat3 viewMatrix(vec3 eye, vec3 center, vec3 up) {\n    // Based on gluLookAt man page\n    vec3 f = normalize(center - eye);\n    vec3 s = normalize(cross(f, up));\n    vec3 u = cross(s, f);\n    return mat3(s, u, -f);\n}\n\nvec3 depth_map(vec2 coord){\n    return texture(iChannel0, vec2((coord.x-image_scale/2.0)/iResolution.x/image_scale, (coord.y-image_scale/2.0)/iResolution.y/image_scale)).xyz;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{ \n    float speed = 10.0;\n\tvec3 eye = vec3(iTime,0,.5);\n    eye = warp(eye);\n    \n    \n    vec3 p = depth_map(fragCoord);\n    vec3 worldDir = normalize(p-eye);\n    float dist = shortestDistanceToSurface(eye, worldDir, length(eye-p), MAX_DIST);\n    if (dist > MAX_DIST - EPSILON) {\n        // Didn't hit anything\n        //vec3 s1 = surface_color(worldDir*10.0+iTime/10.0).yzx;\n        fragColor = vec4(0.0);\n\t\treturn;\n    }\n    p = eye+dist*worldDir;\n    \n    // Use the surface normal as the ambient color of the material\n    vec3 K_a = surface_color((p));\n    vec3 K_d = K_a;\n    vec3 K_s = vec3(1.0, 1.0, 1.0);\n    float shininess = 100.0;\n    \n    vec3 color = phongIllumination(K_a, K_d, K_s, shininess, p, eye);\n    \n    fragColor = vec4(color, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// http://countercomplex.blogspot.jp/2011/10/algorithmic-symphonies-from-one-line-of.html\n// http://wurstcaptures.untergrund.net/music/\n\nvec2 sound1(int t)\n{\n    t = 4*((t/((t/4096/4)%5+(t/4096/2)%3+(t/4096)%2)))|t>>4&t>>5|t>>6;\n    return vec2(float(t & 0xff - 128) / 128.);\n}\n\nvec2 mainSound( in int samp,float time){\n    time *= 16000.0;\n    float factor = .5;\n    vec2 result = vec2(0.0);\n    for(int i = 0; i < 3; i++){\n    \tresult += sound1(int(time*factor))*factor;\n        factor *= 1.5;\n    }\n    return result/10.0;\n}\n\n/*\nvec2 sound1(int t)\n{\n    int t1 = 4;\n    t *= t1;\n    t = t1*((t/((t/4096/t1)%t1+1)))|(t/t1)>>t1;\n    return vec2(float(t & 0xff - 128) / 128.);\n}\n\nvec2 mainSound( in int samp,float time){\n    time *= 16000.0/2.;\n    float factor = .5;\n    vec2 result = vec2(0.0);\n    for(int i = 0; i < 3; i++){\n    \tresult += sound1(int(time*factor))*factor;\n        factor *= 1.5;\n    }\n    return result/10.0;\n}\n*/",
                "description": "",
                "inputs": [],
                "name": "Sound",
                "outputs": [],
                "type": "sound"
            },
            {
                "code": "//this is based on https://www.shadertoy.com/view/4tcGDr\n\n#define rot(spin) mat2(cos(spin),sin(spin),-sin(spin),cos(spin))\n\nconst int MAX_MARCHING_STEPS = 1000;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 10000.0;\nconst float EPSILON = 0.001;\n\n/**\n * Signed distance function describing the scene.\n * \n * Absolute value of the return value indicates the distance to the surface.\n * Sign indicates whether the point is inside or outside the surface,\n * negative indicating inside.\n */\n\nvec3 warp(vec3 p){\n    vec3 a = p/(1000.0);\n    return p+vec3((sin(a)))*500.0;\n}\n\nfloat planet_surface(vec3 p,float i){\n    p = (sin(sin(p.yzx/i)-cos(p*i)/i));\n    return length(p) - 1.0;\n}\n\nfloat sceneSDF(vec3 p,float anim) {\n    float result = 0.0;\n    p = warp(p);\n    for(float i = 1.0; i < 8.0; i *= 2.0){\n        result = max(result, -planet_surface(p*i,i)/(i));\n    }\n    //float result = sceneSDF1(p/1000.0+sceneSDF1(p/1000.0));\n    return result/2.0;\n}\n\nfloat sceneSDF(vec3 p){\n    \n\treturn sceneSDF(p,1.0);\n}\n\nvec3 surface_color(vec3 p)\n{\n    p *= 1.0;\n    return .4+sin(2.0*vec3(0.0,0.0,(sceneSDF(p*5.0,0.0))))+vec3(.4);\n}\n\n\n/**\n * Return the shortest distance from the eyepoint to the scene surface along\n * the marching direction. If no part of the surface is found between start and end,\n * return end.\n * \n * eye: the eye point, acting as the origin of the ray\n * marchingDirection: the normalized direction to march in\n * start: the starting distance away from the eye\n * end: the max distance away from the ey to march before giving up\n */\nfloat shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end) {\n    float depth = start;\n    float eps = EPSILON;\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++) {\n        float dist = sceneSDF(eye + depth * marchingDirection);\n        if (dist < eps*(1.0+depth*.1)*image_scale) {\n\t\t\treturn depth-dist;\n        }\n        depth += dist;\n        //eps *= 1.0+.001*(depth+1.0);\n        if (depth >= end) {\n            return end;\n        }\n    }\n    return end;\n}\n            \n\n/**\n * Return the normalized direction to march in from the eye point for a single pixel.\n * \n * fieldOfView: vertical field of view in degrees\n * size: resolution of the output image\n * fragCoord: the x,y coordinate of the pixel in the output image\n */\nvec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord) {\n    vec2 xy = fragCoord - size / 2.0;\n    float z = size.y / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\n/**\n * Using the gradient of the SDF, estimate the normal on the surface at point p.\n */\nvec3 estimateNormal(vec3 p) {\n    //surface color for bump mapping\n    return normalize(vec3(\n        sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),\n        sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),\n        sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\n/**\n * Lighting contribution of a single point light source via Phong illumination.\n * \n * The vec3 returned is the RGB color of the light's contribution.\n *\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n * lightPos: the position of the light\n * lightIntensity: color/intensity of the light\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye,\n                          vec3 lightPos, vec3 lightIntensity) {\n    lightPos = eye;\n    vec3 N = estimateNormal(p);\n    vec3 L = normalize(lightPos - p);\n    vec3 V = normalize(eye - p);\n    vec3 R = normalize(reflect(-L, N));\n    \n    float dotLN = dot(L, N);\n    float dotRV = dot(R, V);\n    \n    if (dotLN < 0.0) {\n        // Light not visible from this point on the surface\n        return vec3(0.0, 0.0, 0.0);\n    } \n    \n    if (dotRV < 0.0) {\n        // Light reflection in opposite direction as viewer, apply only diffuse\n        // component\n        return lightIntensity * (k_d * dotLN);\n    }\n    return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));\n}\n\n/**\n * Lighting via Phong illumination.\n * \n * The vec3 returned is the RGB color of that point after lighting is applied.\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye) {\n    const vec3 ambientLight = 0.5 * vec3(1.0, 1.0, 1.0);\n    vec3 color = ambientLight * k_a;\n    \n    vec3 light1Pos = vec3(4.0,\n                          2.0,\n                          4.0);\n    vec3 light1Intensity = vec3(0.8);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light1Pos,\n                                  light1Intensity);   \n    return color;\n}\n\n/**\n * Return a transform matrix that will transform a ray from view space\n * to world coordinates, given the eye point, the camera target, and an up vector.\n *\n * This assumes that the center of the camera is aligned with the negative z axis in\n * view space when calculating the ray marching direction. See rayDirection.\n */\nmat3 viewMatrix(vec3 eye, vec3 center, vec3 up) {\n    // Based on gluLookAt man page\n    vec3 f = normalize(center - eye);\n    vec3 s = normalize(cross(f, up));\n    vec3 u = cross(s, f);\n    return mat3(s, u, -f);\n}\n\nvec3 depth_map(vec2 coord){\n    return texture(iChannel0, coord/iResolution.xy).xyz;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec3 dmap = depth_map(fragCoord);\n    if (fragCoord.x*image_scale<iResolution.x && fragCoord.y*image_scale<iResolution.y){\n    fragCoord *= image_scale;\n    fragCoord += vec2(image_scale/2.0);\n    float speed = 10.0;\n\tvec3 eye = vec3(iTime,0,.5);\n    eye = warp(eye);\n    vec3 viewDir = rayDirection(45.0, iResolution.xy, fragCoord);\n    viewDir.y += (cos(iTime/5.0)/5.0);\n    viewDir.x += (sin(iTime/5.0)/5.0);\n    if (length(iMouse.xy) > 40.0) {\n        viewDir.yz *= rot(3.14*0.5-iMouse.y/iResolution.y*3.14);\n        viewDir.xz *= rot(3.14-iMouse.x/iResolution.x*3.14*2.0);\n    }\n    mat3 viewToWorld = -viewMatrix(eye, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0));\n    \n    vec3 worldDir = viewToWorld * viewDir;\n    \n    \n    float l0 = log(length(eye-dmap)+1.0)*2.0;\n    if(l0 < 20.0) l0 = 0.0;\n\n    \n    \n    float dist = shortestDistanceToSurface(eye, worldDir, MIN_DIST+l0, MAX_DIST);\n    \n    // The closest point on the surface to the eyepoint along the view ray\n    vec3 p = eye + dist * worldDir;\n    fragColor = vec4(p, min(0.0,abs(l0-dist)*.9));\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "#define image_scale 8.0",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}