{
    "Shader": {
        "info": {
            "date": "1614516996",
            "description": "Initial toy by @NuSan: \"The vanishing of Ashlar by NuSan, PC 4k intro made for Outline Online 2020\"\n\nAdded 2 serial EMA IIR filters with Variance Clipping (filtered temporal integration) to slightly denoise the output. It's smudgy, but less noisy.",
            "flags": 96,
            "hasliked": 0,
            "id": "ttKfDm",
            "likes": 10,
            "name": "The vanishing of Ashlar Denoise",
            "published": 3,
            "tags": [
                "intro",
                "4k",
                "outline",
                "denoise",
                "taa"
            ],
            "usePreview": 0,
            "username": "spawner64",
            "viewed": 747
        },
        "renderpass": [
            {
                "code": "// The vanishing of Ashlar by NuSan\n// PC 4k intro made for Outline Online 2020\n\n// Unfortunately, the GPU Synthesizer I made cannot be ported on shadertoy, as it uses a second audio pass to compute reverbs\n// So only soundcloud for now ...\n\n// Original Tools: Leviathan, custom GPU synth based on Oidos, Shader Minifier, Crinkler\n// https://www.pouet.net/prod.php?which=85684\n// https://youtu.be/lAvug7LKiIE\n\n// if sound doesn't start or seems desynchronised:\n// try clicking pause/start button in the \"soundcloud\" square in the bottom right\n// then press rewind just under the shader picture on the left\n\n///////////////////////\n// POST PROCESS PASS //\n///////////////////////\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    vec3 col = texture(iChannel0, uv).xyz;\n\n    float time = iTime - .9;\n    \n    // Bloom computation\n    vec3 cumul = vec3(0);\n\tfor(float i=-2.; i<=2.5; ++i) {\n\t\tfor(float j=-2.; j<=2.5; ++j) {\n\t\t\tvec4 cur = textureLod(iChannel1, uv + (vec2(i,j))*36./vec2(1920.,1080.), iResolution.y>720. ? 6. : 4.);\n\t\t\tcumul += cur.xyz;\n\t\t}\n\t}\n    // use more bloom for brighter values\n\tcol += cumul * clamp(dot(cumul.xyz,vec3(.01))-.2,0.,1.)*0.1;\n    \n    // 'tone mapping'\n    col = smoothstep(0.,1.,col);\n    col = pow(col,vec3(.6));\n    \n    // fade in / fade out\n    col *= sat(time*2.) * sat(127.-time);\n    \n    // grain\n    vec3 grain = textureLod(iChannel1, uv, 0.0).rgb;\n    col = mix(col, grain, 0.125);\n    \n    fragColor = vec4(col, 1);\n    \n    float phase = sin(iTime * SPLIT_SCREEN_SWEEP_SPEED) * 0.5 + 0.5;\n    fragColor = renderVSplitLine(fragColor, vec3(0), 1.0, fragCoord.xy, phase * iResolution.x);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "musicstream",
                        "id": 22886,
                        "published": 0,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "https://soundcloud.com/antoine-zanuttini/the-vanishing-of-ashlar"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "#define EMA_IIR_INVERSE_CUTOFF_FREQUENCY        (0.785)      // 0.0 - 0.999\n#define VARIANCE_CLIPPING_COLOR_BOX_SIGMA       (0.975)      // 0.5 - 1.0\n#define SPLIT_SCREEN_SWEEP_SPEED                (1.5)\n\n#define SAMPLE_RGBA(sampler, coord) (texture((sampler), (coord)))\n#define SAMPLE_RGB(sampler, coord) (SAMPLE_RGBA((sampler), (coord)).rgb)\n\nfloat pi=acos(-1.);\n\nfloat sat(float t) { return clamp(t, 0.,1.); }\n\n//DAVE HOSKINS' HASH FUNCTIONS\n// we use them mainly because they don't contain any sin/cos and so should be more consistent accross hardware\n//https://www.shadertoy.com/view/4djSRW\nfloat rnd(float p)\n{\n    p = fract(p * 0.1031);\n    p *= p + 33.33;\n    return fract(2.*p*p);\n}\n\nvec3 rnd23(vec2 p)\n{\n\tvec3 p3 = fract(p.xyx * vec3(.1031, .1030, .0973));\n    p3 += dot(p3, p3.yxz+33.33);\n    return fract((p3.xxy+p3.yzz)*p3.zyx);\n}\n\nfloat rnd31(vec3 p3)\n{\n\tp3  = fract(p3 * .1031);\n    p3 += dot(p3, p3.yzx + 33.33);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\nvec3 rnd33(vec3 p3)\n{\n\tp3 = fract(p3 * vec3(.1031, .1030, .0973));\n    p3 += dot(p3, p3.yxz+33.33);\n    return fract((p3.xxy + p3.yxx)*p3.zyx);\n}\n\n// https://www.shadertoy.com/view/4dSBDt\nvec3 RGBToYCoCg(vec3 RGB) {\n    float cTerm = 0.5 * 256.0 / 255.0;\n\tfloat Y  = dot(RGB, vec3( 1, 2,  1)) * 0.25;\n\tfloat Co = dot(RGB, vec3( 2, 0, -2)) * 0.25 + cTerm;\n\tfloat Cg = dot(RGB, vec3(-1, 2, -1)) * 0.25 + cTerm;\n\treturn vec3(Y, Co, Cg);\n}\n\n// https://www.shadertoy.com/view/4dSBDt\nvec3 YCoCgToRGB(vec3 YCoCg) {\n\tfloat cTerm = 0.5 * 256.0 / 255.0;\n\tfloat Y  = YCoCg.x;\n\tfloat Co = YCoCg.y - cTerm;\n\tfloat Cg = YCoCg.z - cTerm;\n\tfloat R  = Y + Co - Cg;\n\tfloat G  = Y + Cg;\n\tfloat B  = Y - Co - Cg;\n\treturn vec3(R, G, B);\n}\n\n// based on https://www.shadertoy.com/view/4dSBDt\nvoid getVarianceClippingBounds(vec3 color, sampler2D colorSampler, ivec2 screenSpaceUV, float colorBoxSigma, out vec3 colorMin, out vec3 colorMax) {\n    vec3 colorAvg = color;\n    vec3 colorVar = color * color;\n\n    // Marco Salvi's Implementation (by Chris Wyman)\n    // unrolled loop version\n    \n    vec3 fetch = vec3(0);\n\n    // unwinded the for loop\n    {\n        // top\n        {\n            // left / top\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2(-1, -1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // center / top\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 0, -1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // right / top\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 1, -1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n        }\n\n        // center\n        {\n            // left / center\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2(-1,  0), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            \n            // center / center is intentionally skipped\n            \n\n            // right / center\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 1,  0), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n        }\n\n        // bottom\n        {\n            // left / bottom\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2(-1,  1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // center / bottom\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 0,  1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n\n            // right / bottom\n            fetch = texelFetch(colorSampler, screenSpaceUV + ivec2( 1,  1), 0).rgb;\n            fetch = RGBToYCoCg(fetch);\n            colorAvg += fetch;\n            colorVar += fetch * fetch;\n        }\n    }\n\n    colorAvg *= 0.111111111;\n    colorVar *= 0.111111111;\n\n    vec3 sigma = sqrt(max(vec3(0.0), colorVar - colorAvg * colorAvg));\n\tcolorMin = colorAvg - colorBoxSigma * sigma;\n\tcolorMax = colorAvg + colorBoxSigma * sigma;\n}\n\nvec4 renderVSplitLine(vec4 fragColor, vec3 lineColor, float lineThickness, vec2 screenSpaceUV, float splitScreenSpaceX) {\n    if (abs(screenSpaceUV.x - splitScreenSpaceX) < lineThickness) {\n        fragColor.rgb = lineColor;\n\t}\n\n    return fragColor;\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "\n// Lower that value if it's too slow\n#define SAMPLE_COUNT 30.\n\n#define res iResolution\n\n//////////////////////\n// PATHTRACING PASS //\n//////////////////////\n\n// we use globals for most parameters, it save space\n// s is starting position, r is ray direction\n// n is normal at intersection point and d is distance to the intersection\nvec3 s,r,n=vec3(0);\nfloat d=10000.;\nvec3 boxid=vec3(0);\n\nmat2 rot(float a) {return mat2(cos(a),sin(a),-sin(a),cos(a));}\n\n// Compute octahedron distance from center, os is the size of each of the 4 'axis'\nfloat octaedge(vec3 p, vec4 os) {\n    \n    vec4 vv=vec4(1.4142,-1.4142,1,-1); // 1.4142 = cos(45)/cos(60)\n    vec4 popo = p.xxyy*vv.xyww + p.yyzz*vv.zzxy;\n    popo=abs(popo)-os;\n          \n    float d = max(max(popo.x,popo.y),max(popo.z,popo.w));\n\n    return d;\n}\n\nvec4 osize1 = vec4(10);\nvec4 osize2 = vec4(2);\nvec3 boxrepeat = vec3(1,8,8);\nvec3 centerrepeat = vec3(.4,2,2);\nfloat boxanim = 0.;\nfloat centeranim = 0.;\nfloat boxtime = 0.;\nfloat insidedist(vec3 p) {\n\treturn max(octaedge(p, osize1), -octaedge(p, osize2));\n}\n\n// analytical box intersection\nvoid box(vec3 basepos, int side) {\n\t\n    // are we on the outside octahedron or the center one\n\tbool iscenter = octaedge(basepos,osize2)<.1;\n\tvec3 rep = iscenter ? centerrepeat : boxrepeat;\n\t\n    // main repetition is based on the x axis\n\tvec3 id2 = floor(basepos.x/rep.x)+vec3(1.7,3,7);\n\t\n    // then we can have integer multiplier subdivision without breaking the illusion\n\trep = (rep/(floor(rnd33(id2)*vec3(6))+1.));\n\t\n\tvec3 pos=vec3(0);\t\n    \n    // offset on yz axis, box animation\n\tvec2 ooo = fract(rnd(floor(basepos.x/rep.x)+.7)*vec2(1,3.7))*8.*7.;\n    ooo*=boxtime*vec2(1,1.3)*(iscenter?centeranim:boxanim)*rep.yz*0.03;\n    basepos.yz += ooo;\n\tpos.yz += ooo;\n  \n    // here we are applying the box repetition\n\tboxid = (floor(basepos/rep)+0.5)*rep;\n\n\tvec3 size = rep*0.4;\n  \n\tvec3 vr = r;\n\tpos=s+pos-boxid;\n  \n\tvec3 box=max((size-pos)/vr,(-size-pos)/vr);\n\tfloat bd = min(min(box.x,box.y),box.z);\n\tif(bd>0. && bd>d*float(side)) {\n\t\tvec3 cur = step(abs(pos+vr*d),size);\n\t\tif(side>0 ? (min(cur.x,min(cur.y,cur.z))>0.) : insidedist(s+r*bd)>0.) {\n\t\t\td=bd;\n\t\t\tn=-step(box-bd,vec3(0))*sign(pos+vr*d);\n\t\t}\n\t}\n}\n\n\n// analytical octrahedron intersection, with customisable size for each of the 4 'axis'\nvoid frontocta(vec4 size, int side) {\n    \n  \tvec4 vv=vec4(1.4142,-1.4142,1,-1); // 1.4142 = cos(45)/cos(60)\n    vec4 invd = 1. / (r.xxyy*vv.xyww + r.yyzz*vv.zzxy);\n  \tvec4 popo = -s.xxyy*vv.xyww - s.yyzz*vv.zzxy;\n    \n    vec4 t0 = (popo - size) * invd;\n    vec4 t1 = (popo + size) * invd;\n    vec4 mi = min(t0, t1);\n    vec4 ma = max(t0, t1);\n\n    float front = min(min(ma.x,ma.y),min(ma.z,ma.w));\n    float back = max(max(mi.x,mi.y),max(mi.z,mi.w));\n    if(back>front) return;\n\n    if(side==0) {\n        back=front;\n    }\n\n    if(back<d && back > 0.) {\n        d = back;\n        vec4 vo = sign(t0-t1) * (side==0 ? step(-back,-ma) : step(back,mi));\n\n        n = vo.xxz - vo.yzw;\n        n.y += vo.y-vo.w;\n        n*=-sign(float(side)-.5)*vec3(0.817,0.5777,0.817); // = vec3(1,0.5 * 1.4142,1)/1.224 = 1.224 = cos(45) * tan(60)\n    }\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 frag = fragCoord.xy;\n\tvec2 uv = (frag-res.xy*0.5)/res.y;\n\t\t\n\tvec3 col = vec3(0);\n\t\t\n\tfloat time =iTime-.9;\n\tboxtime = time;\n\n    // Main way to control the intro (camera, DOF focus, shape)\n    // Each vec3 is a section of the intro\n    // first value is the seed of the camera motionpath/speed/FOV, fractionnal part is a time offset, negative values subdivide the section in two parts\n    // second value is the focus distance for the DOF, negative value makes the DOF bigger\n    // third value is the shape seed, integer value is the background shape, fractionnal part is the center shape\n\tvec3 mot[16] = vec3[16]( \n\t\t\t\t\t\t vec3(12,2,14.19)\n\t\t\t\t\t\t,vec3(-4.7,11,29)\n\t\t\t\t\t\t,vec3(7,10,7.2)\n\t\t\t\t\t\t,vec3(11,-5,5.63)\n\t\t\t\t\t\t// --------------\n\t\t\t\t\t\t,vec3(16.45,5,17.4)\n\t\t\t\t\t\t,vec3(-12,5,12.2)\n\t\t\t\t\t\t,vec3(2,5,12.2)\n\t\t\t\t\t\t,vec3(0.4,9,10)\n\t\t\t\t\t\t// --------------\n\t\t\t\t\t\t,vec3(17.8,7,11.1)\n\t\t\t\t\t\t,vec3(-7.6,-20,15)\n\t\t\t\t\t\t,vec3(-13,-30,2.2)\n\t\t\t\t\t\t,vec3(7,40,3)\n\t\t\t\t\t\t// --------------\n\t\t\t\t\t\t,vec3(17,20,6)\n\t\t\t\t\t\t,vec3(-5.4,50,15.4)\n\t\t\t\t\t\t,vec3(16,30,13)\n\t\t\t\t\t\t,vec3(12,10,7)\n\t\t\t\t\t\t);\n\n\n\tfloat light = 0.;\n\tint section = int(min(16.,time/8.));\n\tfloat rest = mod(time,8.);\n\n\tvec3 mval = mot[section];\n\tif(section>5 && section<9) mval.z+=floor(rest)*2.2;\n\n\tvec3 pcam = rnd23(vec2(round(abs(mval.x)),0));\n\t\t\n\t//////// SIZES ////////\n\tif(section==0) osize2 = vec4(6);\n\t\n    // extruding the shapes\n\tfloat push2 = max(0.,time-48.)*1.5;\n\tif(section>7) push2 = 10000.;\n\tfloat push = 2.+max(0.,time-40.)*.5+push2;\n\tfloat decol=max(0.,time-70.);\n\tif(section>14) {\n\t\tdecol=0.;\n\t\tpush=0.;\n\t\tpush2=0.;\n\t}\n\n\tif(section>4)osize2 = vec4(2,push,push,2);\n\tif(section>6)osize1 = vec4(10,10.+push2,10.+push2,10);\n\t\n\t//////// REPEATS ////////\n\tboxrepeat = rnd23(vec2(floor(mval.z),0))*50.;\n\tcenterrepeat = pow(rnd23(vec2(0,fract(mval.z)*31.5+28.)),vec3(2))*10.+.2;\n\n\tif(section==3) osize1=vec4(20);\n\t\t\n\t//////// NIGHT ////////\n\tfloat skydist = 1.;\n\tfloat bright=0.;\n\tif(section>8 && section<15) {\n\t\tboxanim = .3;\n\t\tboxrepeat *= 2.;\n\t\tcenterrepeat *= 10.;\n\t\tif(section>11) {\n            // transition to night section, with light appearing\n\t\t\tlight = sat((time/8.-12.));\n\t\t\tskydist = section>12?200.:20.*light;\n\t\t\tosize1 = vec4(20,push2,push2,20);\n\t\t\tboxanim=0.;\n\t\t\tif(section==14) {\n                // center brightening and vanishing\n\t\t\t\tcenterrepeat.xy*=1.1;\n\t\t\t\tbright=pow(sat(time/8.-14.07),2.);\n\t\t\t\tosize2.xw = vec2(2.-sqrt(bright+.01-uv.y*.02+uv.x*.001)*2.3,17.*bright+2.);\n\t\t\t}\n\t\t}\n\t}\n\tcenteranim = section>2?(section>7?0.3:0.3):0.;\n\n\t//////// CAMERA ANIMATION ////////\n    // array value is a seed to an offset on lissajous curves, with various speed factor\n\tfloat avance = pcam.x*200. + (rest+(fract(mval.x+.5)-.5)*8.) * (pcam.y-0.2);\n\tif(mval.x<0.) avance += floor(rest/4.)*3.;\n\t\n\tfloat focusdist = abs(mval.y);\n\tfloat dofamount = mval.y>0. ? .05 : .15;\n    // extrapush is used to put the camera outside the room without colliding, so we can zoom more\n\tfloat extrapush = max(fract(pcam.z*17.23)-.5,0.)*15.;\n\tfloat fov = pcam.z*1.5+.5 + extrapush/2.;\n\tvec3 bs=vec3(0,-1.5 + sin(avance*.2)*1.,0);\n\tvec3 t = vec3(0,-1.5 + sin(avance*.3)*3.,0);\n\n    // lissajous curve to makes interesting camera motion\n\tbs.x += 5.*sin(avance*.4 + 0.7);\n\tbs.z += 5.*sin(avance*.9);\n\n    // camera target is following the same curve in front of the camera but with a random factor to focus more on the center\n\tfloat dt=max(0.,fract(pcam.z*24.81)-.2)*6.;\n\tt.x += dt*sin(avance*.4 + 0.7 + 1.);\n\tt.z += dt*sin(avance*.9 + 1.);\n\t\n\t//////// SKYDIVING ////////\n\tvec3 govec = vec3(-1,1.41,-1);\n\tvec3 poff = govec*decol*min(2.,decol)*2.5;\n\tt -= poff + govec*10.*(step(2.,decol)-bright);\n\tbs -= poff;\n    \n\t//////// CAMERA COMPUTE ////////\n\tvec3 cz=normalize(t-bs);\n\tvec3 cx=normalize(cross(cz,vec3(0,1,0)));\n\tvec3 cy=cross(cz,cx);\n\n\t// Main path tracing loop, do many samples to reduce the noise\n    float ZERO=min(0.,iTime); // this is a trick to force the GPU to keep the loop\n    // instead of trying to compile a giant shader by duplicating what's inside\n\tfor(float i=ZERO; i<SAMPLE_COUNT; ++i) {\n    \t\t\n\t\ts=bs;\t\n\t\tvec2 h = rnd23(frag-13.6-i*184.7).xy;\n\t\t// DOF\n\t\tvec3 voff = sqrt(h.x)*(cx*sin(h.y*6.283)+cy*cos(h.y*6.283))*dofamount;\n\t\ts-=voff;\n\t\tr=normalize(uv.x*cx+uv.y*cy+fov*cz + voff*fov/(focusdist+extrapush));\n\n\t\ts += (r-cz) * extrapush;\n\t\t\n        // number of bounces is 3\n\t\tfor(float j=0.; j<3.; ++j) {\n\t\t\t////////// TRACE //////////\n\t\t\td=100000.;\n  \n            // find instersection with geometry\n            \n            // first test if we started inside a repeating box\n\t\t\tbox(s,-1);\n  \n            // then intersect with the background octahedron\n\t\t\tfrontocta(osize1, 0);\n  \n            // save that intersection for latter\n\t\t\tfloat d2=d;\n\t\t\tvec3 s2=s;\n\t\t\tvec3 n2=n;\n\n            // intersect with the center shape\n\t\t\tfrontocta(osize2, 1);\n  \n            // now use that position to carve the repeating box\n\t\t\tbox(s+r*d,1);\n\n            // if intersection position is outside the center octahedron, it means that we went trough the shape\n            // so we back to the background intersection\n\t\t\tif(octaedge(s+r*d,osize2)>0.01) {\n\t\t\t\td=d2;\n\t\t\t\tn=n2;\n                // last possible repeating box intersection on the background octahedron\n\t\t\t\tbox(s+r*d,1);\n\t\t\t}\n    \n            // and finally the ground plane intersection\n\t\t\tfloat curplane=(1.1-s.y)/r.y;\n\t\t\tif(curplane>0. && curplane<d) {\n\t\t\t\td=curplane;\n\t\t\t\tn=sign(s.y)*vec3(0,1,0);\n\t\t\t}\n    \t\t\t\n\t\t\tif(d>10000.) break;\n\t\t\t\n\t\t\t// go to the intersection point\n\t\t\ts = s + r * d;\n\t\t\n            // test if we are outside the 'sky distance'\n\t\t\tfloat edge1 = octaedge(s,osize1);\t\t\t\t\t\t\n\t\t\tif(edge1>skydist) {\n                // if so, we just push the sky color and early out\n\t\t\t\tcol += mix(vec3(0.6,0.8,1)*0.8, vec3(1,0.7,0.5) * 2., max(r.x+r.z*.3-r.y*.7,0.)*.7);\n\t\t\t\tbreak;\n\t\t\t}\n\n            // if we are in the light section\n\t\t\tif(light>0.) {\n\t\t\t\tfloat middle = step(7.,edge1);\n\n                // center burning\n\t\t\t\tcol += bright * step(1.,-edge1) * vec3(.5,.7,1)*3.;\n\t\t\t\t\n                // side lights in two colors\n\t\t\t\tcol += middle * vec3(0.4,0.5,0.8) * 1.2 * step(0.7,rnd(dot(boxid,vec3(1,4,7))+floor(time)*0.1));\n\t\t\t\tcol += middle * vec3(0.2,0.5,0.9) * 1.2 * step(0.1,fract(.2+boxid.z*0.01 + floor(time)*13.2)*3.-1.5);\t\t\t\n\t\t\t}\n\n            // slight increase in perf, get out before computing rebound direction in the last rebound\n\t\t\tif(j==2.) break;\n\n            // roughness computing, depending on if we are on the center shape or not\n\t\t\tvec3 grid = step(fract(s*4.-.1),vec3(.8));\n\t\t\tfloat rough = octaedge(s,osize2)<.1 ? .5 : mix(1.,0.45*rnd31(floor(s*4.-.1)*27.33),min(grid.x,min(grid.y,grid.z)));\n            // slight offset so we get out of the surface before rebound\n\t\t\ts-=r*0.01;\n            // random rebound direction according to roughness parameter\n\t\t\tr=normalize(reflect(r,n) + normalize(rnd23(frag+vec2(i*277.,j*375.)+fract(time))-.5)*rough);\n\t\t}\n\t}\n\tcol *= .6/SAMPLE_COUNT;\n\t\n\tfragColor = vec4(col, 1);\n}",
                "description": "",
                "inputs": [],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "void mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 new = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    float phase = sin(iTime * SPLIT_SCREEN_SWEEP_SPEED) * 0.5 + 0.5;\n    if (normalizedSpaceUV.x < phase) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    new = RGBToYCoCg(new);\n\n    vec3 colorMin = vec3(0);\n\tvec3 colorMax = vec3(0);\n    getVarianceClippingBounds(new, iChannel0, ivec2(screenSpaceUV), VARIANCE_CLIPPING_COLOR_BOX_SIGMA, colorMin, colorMax);\n\n    vec3 history = SAMPLE_RGB(iChannel1, normalizedSpaceUV);\n    history = RGBToYCoCg(history);\n\n    vec3 filtered = vec3(0);\n    history = clamp(history, colorMin, colorMax);\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n    filtered = YCoCgToRGB(filtered);\n\n    fragColor = vec4(filtered, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "void mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 screenSpaceUV = fragCoord.xy;\n    vec2 normalizedSpaceUV = screenSpaceUV / iResolution.xy;\n    vec3 new = SAMPLE_RGB(iChannel0, normalizedSpaceUV);\n\n    float phase = sin(iTime * SPLIT_SCREEN_SWEEP_SPEED) * 0.5 + 0.5;\n    if (normalizedSpaceUV.x < phase) {\n        fragColor = vec4(new, 1.0);\n        return;\n    }\n\n    new = RGBToYCoCg(new);\n\n    vec3 colorMin = vec3(0);\n\tvec3 colorMax = vec3(0);\n    getVarianceClippingBounds(new, iChannel0, ivec2(screenSpaceUV), VARIANCE_CLIPPING_COLOR_BOX_SIGMA, colorMin, colorMax);\n\n    vec3 history = SAMPLE_RGB(iChannel1, normalizedSpaceUV);\n    history = RGBToYCoCg(history);\n\n    vec3 filtered = vec3(0);\n    history = clamp(history, colorMin, colorMax);\n    filtered = mix(new, history, EMA_IIR_INVERSE_CUTOFF_FREQUENCY);\n    filtered = YCoCgToRGB(filtered);\n\n    fragColor = vec4(filtered, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}