{
    "Shader": {
        "info": {
            "date": "1607176045",
            "description": "First raymarching test project with post-processing Sobel filter for shiny outline.",
            "flags": 32,
            "hasliked": 0,
            "id": "WdGfWD",
            "likes": 8,
            "name": "Messing with Phong",
            "published": 3,
            "tags": [
                "3d",
                "raymarching",
                "sobel"
            ],
            "usePreview": 0,
            "username": "PlathC",
            "viewed": 470
        },
        "renderpass": [
            {
                "code": "void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Sobel filter\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    mat3 kernelX = mat3(-1, 0, 1,\n                        -2, 0, 2,\n                        -1, 0, 1);\n    \n    mat3 kernelY = mat3(-1, -2, -1,\n                         0,  0,  0,\n                         1,  2,  1);\n    \n    float wStep = 3.f / iResolution.x;\n    float hStep = 3.f / iResolution.y;\n    \n    float tempFragXValue = 0.f;\n    float tempFragYValue = 0.f;\n    for(float i = -1.f; i <= 1.f; i++)\n    {\n     \tfor(float j = -1.f; j <= 1.f; j++)\n        {\n            vec2 newTextureCoordinates = vec2(uv.x + (i * wStep), uv.y + (j * hStep));\n            vec4 pixel = vec4(texture(iChannel0, newTextureCoordinates).xyz, 1.0);\n            float gray = (pixel.x + pixel.y + pixel.z) / 3.f;\n        \ttempFragXValue += kernelX[int(i)+1][int(j)+1] * gray;\n            tempFragYValue += kernelY[int(i)+1][int(j)+1] * gray;\n        }\n    }\n\t\n    float resultFrag = length(vec2(tempFragXValue, tempFragYValue));\n\t\n    // Mix sobel color with base image color and show the mean of both in order to create shiny outline.\n    fragColor = vec4(resultFrag, resultFrag, resultFrag, 1.0) * vec4(texture(iChannel0, uv).xyz, 1.0) + 0.5 * vec4(texture(iChannel0, uv).xyz, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "mat3 xRotationMatrix(float radAngle)\n{\n    return mat3(1., 0.,            0.,\n                0., cos(radAngle), -sin(radAngle),\n                0., sin(radAngle), cos(radAngle));\n}\n\nmat3 yRotationMatrix(float radAngle)\n{\n    return mat3(cos(radAngle),  0., sin(radAngle),\n                0.,             1., 0.,\n                -sin(radAngle), 0., cos(radAngle));\n}\n\nmat3 zRotationMatrix(float radAngle)\n{\n    return mat3(cos(radAngle), -sin(radAngle), 0.,\n                sin(radAngle),  cos(radAngle), 0.,\n                0., 0., 1.);\n}\n\nmat4 transformationMatrix(vec3 translation, vec3 radAngles)\n{\n    mat3 xMatrix = xRotationMatrix(radAngles.x);\n    mat3 yMatrix = yRotationMatrix(radAngles.y);\n    mat3 zMatrix = zRotationMatrix(radAngles.z);\n    \n    mat3 rotationMatrix = zMatrix * yMatrix * xMatrix;\n    mat4 result = mat4(rotationMatrix[0].x, rotationMatrix[1].x, rotationMatrix[2].x, translation.x,\n                       rotationMatrix[0].y, rotationMatrix[1].y, rotationMatrix[2].y, translation.y,\n                       rotationMatrix[0].z, rotationMatrix[1].z, rotationMatrix[2].z, translation.z,\n                       0.,\t\t\t\t    0., \t\t\t     0.,                  1.);\n    return result;\n}\n\nmat4 transformationMatrix(vec3 translation, vec3 radAngles, float scale)\n{\n    mat3 xMatrix = xRotationMatrix(radAngles.x);\n    mat3 yMatrix = yRotationMatrix(radAngles.y);\n    mat3 zMatrix = zRotationMatrix(radAngles.z);\n    \n    mat3 rotationMatrix = zMatrix * yMatrix * xMatrix;\n    mat4 result = mat4(rotationMatrix[0].x, rotationMatrix[1].x, rotationMatrix[2].x, translation.x,\n                       rotationMatrix[0].y, rotationMatrix[1].y, rotationMatrix[2].y, translation.y,\n                       rotationMatrix[0].z, rotationMatrix[1].z, rotationMatrix[2].z, translation.z,\n                       0.,\t\t\t\t    0., \t\t\t     0.,                  scale);\n    return result;\n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "#define PI 3.1415926538\n#define DEG2RAD(deg) deg * PI / 180.\n\n#define MAX_STEPS 800\n#define STEP_SIZE 0.01\n#define MAX_DIST 10.\n#define EPSILON 0.00001\n\n// Camera strongly based on https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-generating-camera-rays/generating-camera-rays\n// and http://viclw17.github.io/2018/11/29/raymarching-algorithm/\nstruct Camera \n{\n    vec3 origin;\n    vec3 rayDirection;\n};\n    \nCamera buildCamera(vec2 uv, float imageRatio, float radFieldOfView, vec3 eyePosition, vec3 translation, vec3 rotation)\n{\n    vec2 screenPixel = vec2(uv) * 2. - vec2(1.);\n    screenPixel *= tan(radFieldOfView / 2.);\n    screenPixel.x *= imageRatio;\n    \n    mat4 worldToCamMatrix = transformationMatrix(translation, rotation);\n    \n    vec3 pixelPosition = (vec4(vec3(screenPixel, 1), 1.)* worldToCamMatrix).xyz;\n    \n    vec3 rayDirection = (vec4(normalize(pixelPosition - eyePosition), 1.) * worldToCamMatrix).xyz;\n    \n    return Camera(pixelPosition, rayDirection);\n}    \n\n\nfloat sdfTorus(vec3 point, vec2 size)\n{\n  \tvec2 q = vec2(length(point.xz)- size.x, point.y);\n\treturn length(q) - size.y;\n}\n\n\nvec4 skyShading(vec3 direction)\n{\n\treturn vec4(vec3(abs(sin(direction) * cos(direction))), 1.);\n}\n\n// https://iquilezles.org/articles/distfunctions\nfloat displacement(vec3 p)\n{\n\treturn sin((1.25 * sin(iTime)) * p.x) * sin((1.25 * cos(iTime)) * p.y) * sin((1.25 * sin(iTime)) * p.z);\n}\n\nfloat opDisplace(vec3 p)\n{\n    float d1 = sdfTorus(p, vec2(2., 0.5));\n    float d2 = displacement(p);\n    return d1 + d2;\n}\n\n//http://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/#surface-normals-and-lighting\nvec3 estimateNormal(vec3 p) {\n    return normalize(vec3(\n        opDisplace(vec3(p.x + EPSILON, p.y, p.z)) - opDisplace(vec3(p.x - EPSILON, p.y, p.z)),\n        opDisplace(vec3(p.x, p.y + EPSILON, p.z)) - opDisplace(vec3(p.x, p.y - EPSILON, p.z)),\n        opDisplace(vec3(p.x, p.y, p.z  + EPSILON)) - opDisplace(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\n//https://en.wikipedia.org/wiki/Phong_reflection_model\nvec4 phong(vec3 point, Camera camera)\n{\n\tvec3 normal = estimateNormal(point);\n    const vec3 specular = vec3(1., 1., 1.);\n    const vec3 diffuse = vec3(1., 1., 1.);\n    const float ambient = 0.5;\n    const float shininess = 10.;\n    \n    const vec3 light = vec3(1., 1., 2.);\n    vec3 directionLightVector = normalize(light - point);\n    vec3 perfectRay = 2. * (directionLightVector * normal) * normal - directionLightVector;\n    vec3 directionToViewer = normalize(camera.origin - point);\n    \n    // The actual phong formula \"messing\"\n    vec3 color = ambient + (diffuse * (directionLightVector * normal) + specular * pow(abs(perfectRay * directionToViewer), vec3(shininess)));\n\n    return vec4(color, 1.);\n}\n\nvec4 rayMarch(Camera cam)\n{\n    mat4 transform = transformationMatrix(vec3(0., 0., 0.), \n                                          vec3(DEG2RAD(180. * sin(iTime)), DEG2RAD(180. * sin(iTime)), DEG2RAD(180. * sin(iTime))), \n                                          1.);\n   \tfloat fullDistance = 0.;\n    vec3 position = vec3(0., 0., -5);\n    for (int i = 0; i < MAX_STEPS; i++)\n    {\n        vec3 currentPoint = cam.origin + fullDistance * cam.rayDirection;\n        \n        bool hit = false;\n        float accumulation = 0.;\n        float currentDistance = opDisplace((transform * vec4(currentPoint + position, 1.)).xyz);\n        if(currentDistance < EPSILON)\n        {\n            return phong((transform * vec4(currentPoint + position, 1.)).xyz, cam);\n        }\n                \n        fullDistance += STEP_SIZE;\n        if(fullDistance > MAX_DIST)\n            return skyShading(cam.rayDirection);    \t\n    }\n    \n    return skyShading(cam.rayDirection);\n}\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{    \n    const float fieldOfView = 90.;\n    vec2 uv = fragCoord / iResolution.xy;\n    float imageRatio = iResolution.x / iResolution.y;\n    Camera camera = buildCamera(uv, imageRatio, DEG2RAD(fieldOfView), vec3(0., 0., -2.), \n                                vec3(0., 0., 0.), vec3(0., 0., DEG2RAD(90. * cos(iTime))));\n\n    \n    fragColor = rayMarch(camera);\n}",
                "description": "",
                "inputs": [],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}