{
    "Shader": {
        "info": {
            "date": "1476804624",
            "description": "Part 09: Basic 3D --- raycasting and simple lighting\nIntro to democoding using ShaderToy\nBy cxw/Incline - Demosplash 2016",
            "flags": 0,
            "hasliked": 0,
            "id": "MtyGDV",
            "likes": 2,
            "name": "demosplash2016-cxw-09",
            "published": 3,
            "tags": [
                "phong",
                "raycasting",
                "tutorial",
                "lighting",
                "shading",
                "demoparty"
            ],
            "usePreview": 0,
            "username": "cxw",
            "viewed": 704
        },
        "renderpass": [
            {
                "code": "precision highp int; precision highp float;\n\n// Parameters for your demo.\n\n//Geometry\n#define QUAD_SIDE_LEN (2.0)\n#define TWOSIDED\n#define SHADING_RULE (3)\n    // 0=>none, 1=>flat, 2=>Lambertian, 3=>Phong\n\n//View\n#define ORBIT_RADIUS (6.0)\n#define FOVY_DEG (20.0)\n    // Sort of like the zoom on a camera --- smaller is closer\n\n// Material\n#define SHININESS (256.0)\n\n// Display physics\n#define GAMMA (2.2)\n#define ONE_OVER_GAMMA (0.45454545454545454545454545454545)\n\n// Routines /////////////////////////////////////////////////////////////\n\n// BASIC 3D ///////////////////////////////////////////\n\nvoid lookat(in vec3 in_eye, in vec3 in_ctr, in vec3 in_up,\n            out mat4 view, out mat4 view_inv)\n{\n    // From Mesa glu.  Thanks to\n    // http://learnopengl.com/#!Getting-started/Camera\n    // and https://www.opengl.org/wiki/GluLookAt_code\n\n    vec3 forward, side, up;\n\n    forward=normalize(in_ctr-in_eye);\n    up = in_up;\n    side = normalize(cross(forward,up));\n    up = cross(side,forward);   // already normalized since both inputs are\n        //now side, up, and forward are orthonormal\n\n    mat4 orient, where;\n\n    // Note: in Mesa gluLookAt, a C matrix is used, so the indices\n    // have to be swapped compared to that code.\n    vec4 x4, y4, z4, w4;\n    x4 = vec4(side,0);\n    y4 = vec4(up,0);\n    z4 = vec4(-forward,0);\n    w4 = vec4(0,0,0,1);\n    orient = transpose(mat4(x4, y4, z4, w4));\n\n    where = mat4(1.0); //identity (1.0 diagonal matrix)\n    where[3] = vec4(-in_eye, 1);\n\n    view = (orient * where);\n\n    // Compute the inverse for later\n    view_inv = mat4(x4, y4, z4, -where[3]);\n    view_inv[3][3] = 1.0;   // since -where[3].w == -1, not what we want\n        // Per https://en.wikibooks.org/wiki/GLSL_Programming/Vertex_Transformations ,\n        // M_{view->world}\n} //lookat\n\nvoid gluPerspective(in float fovy_deg, in float aspect,\n                    in float near, in float far,\n                    out mat4 proj, out mat4 proj_inv)\n{   // from mesa glu-9.0.0/src/libutil/project.c.\n    // Thanks to https://unspecified.wordpress.com/2012/06/21/calculating-the-gluperspective-matrix-and-other-opengl-matrix-maths/\n\n    float fovy_rad = radians(fovy_deg);\n    float dz = far-near;\n    float sin_fovy = sin(fovy_rad);\n    float cot_fovy = cos(fovy_rad) / sin_fovy;\n\n    proj=mat4(0);\n    //[col][row]\n    proj[0][0] = cot_fovy / aspect;\n    proj[1][1] = cot_fovy;\n\n    proj[2][2] = -(far+near)/dz;\n    proj[2][3] = -1.0;\n\n    proj[3][2] = -2.0*near*far/dz;\n\n    // Compute the inverse matrix.\n    // http://bookofhook.com/mousepick.pdf\n    float a = proj[0][0];\n    float b = proj[1][1];\n    float c = proj[2][2];\n    float d = proj[3][2];\n    float e = proj[2][3];\n\n    proj_inv = mat4(0);\n    proj_inv[0][0] = 1.0/a;\n    proj_inv[1][1] = 1.0/b;\n    proj_inv[3][2] = 1.0/e;\n    proj_inv[2][3] = 1.0/d;\n    proj_inv[3][3] = -c/(d*e);\n} //gluPerspective\n\nvoid compute_viewport(in float x, in float y, in float w, in float h,\n                        out mat4 viewp, out mat4 viewp_inv)\n{\n    // See https://en.wikibooks.org/wiki/GLSL_Programming/Vertex_Transformations#Viewport_Transformation\n    // Also mesa src/mesa/main/viewport.c:_mesa_get_viewport_xform()\n\n    viewp = mat4(0);\n    // Reminder: indexing is [col][row]\n    viewp[0][0] = w/2.0;\n    viewp[3][0] = x+w/2.0;\n\n    viewp[1][1] = h/2.0;\n    viewp[3][1] = y+h/2.0;\n\n    // assumes n=0 and f=1,\n    // which are the default for glDepthRange.\n    viewp[2][2] = 0.5;  // actually 0.5 * (f-n);\n    viewp[3][2] = 0.5;  // actually 0.5 * (n+f);\n\n    viewp[3][3] = 1.0;\n\n    //Invert.  Done by hand.\n    viewp_inv = mat4(1.0);\n    viewp_inv[0][0] = 2.0/w;    // x->x\n    viewp_inv[3][0] = -1.0 - (2.0*x/w);\n\n    viewp_inv[1][1] = 2.0/h;    // y->y\n    viewp_inv[3][1] = -1.0 - (2.0*y/h);\n\n    viewp_inv[2][2] = 2.0;      // z->z\n    viewp_inv[3][2] = -1.0;\n\n}  //compute_viewport\n\n// RAYCASTING /////////////////////////////////////////\n\nvec4 wts(in mat4 modelviewproj, in mat4 viewport,\n                in vec3 pos)\n{   // world to screen coordinates\n    vec4 clipvertex = modelviewproj * vec4(pos,1.0);\n    vec4 ndc = clipvertex/clipvertex.w;\n    vec4 transformed = viewport * ndc;\n    return transformed;\n} //wts\n\n// screen to world: http://bookofhook.com/mousepick.pdf\nvec4 WorldRayFromScreenPoint(in vec2 scr_pt,\n    in mat4 view_inv,\n    in mat4 proj_inv,\n    in mat4 viewp_inv)\n{   // Returns world coords of a point on a ray passing through\n    // the camera position and scr_pt.\n\n    vec4 ndc = viewp_inv * vec4(scr_pt,0.0,1.0);\n        // z=0.0 => it's a ray.  0 is an arbitrary choice in the\n        // view volume.\n        // w=1.0 => we don't need to undo the perspective divide.\n        //      So clip coords == NDC\n\n    vec4 view_coords = proj_inv * ndc;\n        // At this point, z=0 will have become something in the\n        // middle of the projection volume, somewhere between\n        // near and far.\n    view_coords = view_coords / view_coords.w;\n        // Keepin' it real?  Not sure what happens if you skip this.\n    //view_coords.w = 0.0;\n        // Remove translation components.  Note that we\n        // don't use this trick.\n    vec4 world_ray_point = view_inv * view_coords;\n        // Now scr_pt is on the ray through camera_pos and world_ray_point\n    return world_ray_point;\n} //WorldRayFromScreenPoint\n\n// HIT-TESTING ////////////////////////////////////////\n\nvec3 HitZZero(vec3 camera_pos, vec3 rayend)\n{   // Find where the ray meets the z=0 plane.  The ray is\n    // camera_pos + t*(rayend - camera_pos) per Hook.\n    float hit_t = -camera_pos.z / (rayend.z - camera_pos.z);\n    return (camera_pos + hit_t * (rayend-camera_pos));\n} //HitZZero\n\n// --- IsPointInRectXY ---\n// All polys will be quads in the X-Y plane, Z=0.\n// All quad edges are parallel to the X or Y axis.\n// These quads are encoded in a vec4: (.x,.y) is the LL corner and\n// (.z,.w) is the UR corner (coords (x,y)).\n\nbool IsPointInRectXY(in vec4 poly_coords, in vec2 world_xy_of_point)\n{\n    // return true if world_xy_of_point is within the poly defined by\n    // poly_coords in the Z=0 plane.\n    // I can test in 2D rather than 3D because all the geometry\n    // has z=0 and all the quads are planar.\n\n    float x_test, y_test;\n    x_test = step(poly_coords.x, world_xy_of_point.x) *\n            (1.0 - step(poly_coords.z, world_xy_of_point.x));\n        // step() is 1.0 if world.x >= poly_coords.x\n        // 1-step() is 1.0 if world.x < poly_coords.z\n    y_test = step(poly_coords.y, world_xy_of_point.y) *\n            (1.0 - step(poly_coords.w, world_xy_of_point.y));\n\n    return ( (x_test>=0.9) && (y_test >= 0.9) );\n        // Not ==1.0 because these are floats!\n\n} //IsPointInRectXY\n\n// CAMERA AND LIGHT ///////////////////////////////////\n\nhighp vec3 pos_clelies(in float time, in float radius)\n{   //Clelies curve\n    //thanks to http://wiki.roblox.com/index.php?title=Parametric_equations\n    vec3 pos; float m = 0.8;\n    highp float smt = sin(m*time);\n    pos.x = radius * smt*cos(time);\n    pos.y = radius * smt*sin(time);\n    pos.z = radius * cos(m*time);\n    return pos;\n} //camerapos\n\nvoid get_cam_and_light(\n    in float time,\n    out vec3 camera_pos, out vec3 camera_look_at, out vec3 camera_up,\n    out float fovy_deg, out vec3 light_pos)\n{\n    camera_pos = pos_clelies(time, ORBIT_RADIUS);\n    camera_look_at = vec3(0.0);\n    camera_up = vec3(0.0, 1.0, 0.0);\n    fovy_deg = FOVY_DEG;\n    light_pos = camera_pos;\n} //get_cam_and_light\n\n// SHADING ////////////////////////////////////////////\n\nfloat lambertian_shade(in vec3 pixel_pos, in vec3 normal,\n                    in vec3 light_pos, in vec3 camera_pos)\n{ //Lambertian shading.  Returns the reflectance visible at camera_pos as a\n  //result of lighting pixel_pos (having normal) from light_pos.  \n  //One-sided object.\n\n    vec3 light_dir = normalize(light_pos - pixel_pos);\n    vec3 eye_dir = normalize(camera_pos - pixel_pos);\n    if(dot(light_dir, eye_dir) < 0.0) {\n        return 0.0;     // Camera behind the object => no reflectance\n    } else {\n        return max(0.0, dot(light_dir, normal));\n            // ^^^^^^^^ light behind the object => no reflectance\n    }\n} //lambertian_shade\n\nvec3 phong_color(\n    in vec3 pixel_pos, in vec3 normal, in vec3 camera_pos,      // Scene\n    in vec3 light_pos, in vec3 ambient_color,                   // Lights\n    in vec3 diffuse_color, in vec3 specular_color,              // Lights\n    in float shininess)                                         // Material\n{   // Compute pixel color using Phong shading.  Modified from\n    // https://en.wikipedia.org/wiki/Blinn%E2%80%93Phong_shading_model\n    // normal must be normalized on input.  All inputs are world coords.\n    // Set shininess <=0 to turn off specular highlights.\n    // Objects are one-sided.\n\n    vec3 light_dir = normalize(light_pos - pixel_pos);\n    vec3 eye_dir = normalize(camera_pos - pixel_pos);\n\n    if(dot(light_dir, eye_dir) < 0.0) {\n        return ambient_color;       // Camera behind the object\n    }\n\n    float lambertian = max(0.0, dot(light_dir, normal));        // Diffuse\n\n    float specular = 0.0;\n    if((lambertian > 0.0) && (shininess > 0.0)) {               // Specular\n        vec3 reflectDir = reflect(-light_dir, normal);\n        float specAngle = max(dot(reflectDir, eye_dir), 0.0);\n        specular = pow(specAngle, shininess);\n    }\n    /*\n    return pow(ambient_color + lambertian*diffuse_color + specular*vec3(1.0),\n                vec3(ONE_OVER_GAMMA));\n        // TODO Do I need this?\n    */\n    lambertian = pow(lambertian, ONE_OVER_GAMMA);\n    specular = pow(specular, ONE_OVER_GAMMA);\n\n    vec3 retval = ambient_color + lambertian*diffuse_color + \n        specular*specular_color;\n\n    return clamp(retval, 0.0, 1.0);     // no out-of-range values, please!\n\n} //phong_color\n\n// mainImage() //////////////////////////////////////////////////////////\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float time = iTime;\n    vec2 pixel_coord_01 = fragCoord.xy / iResolution.xy;\n\n    // --- Camera and light ---\n    vec3 camera_pos, camera_look_at, camera_up, light_pos;\n    float fovy_deg;\n\n    get_cam_and_light(time,\n        camera_pos, camera_look_at, camera_up, fovy_deg, light_pos);\n\n    // Camera processing\n\n    mat4 view, view_inv;\n    lookat(camera_pos, camera_look_at, camera_up,\n            view, view_inv);\n\n    mat4 proj, proj_inv;            // VVVVVVVVV squares are square! :)\n    gluPerspective(fovy_deg, iResolution.x/iResolution.y, 1.0, 10.0,\n                    proj, proj_inv);\n\n    mat4 viewport, viewport_inv;    // VVVVVVVVV squares are square! :)\n    compute_viewport(0.0, 0.0, iResolution.x, iResolution.y,\n                        viewport, viewport_inv);\n\n    vec3 material_color = vec3(0.0);    //Color of the quad before shading\n\n    // Raycasting\n\n    vec3 rayend = WorldRayFromScreenPoint(fragCoord,\n                                    view_inv, proj_inv, viewport_inv).xyz;\n        // rayend-camera_pos is the direction of the ray\n    vec3 world_xyz0_of_point = HitZZero(camera_pos, rayend);\n        // Where the ray hits z=0\n    vec3 normal = vec3(0.0,0.0,-1.0 + 2.0*step(0.0, camera_pos.z));\n        // normal Z is -1 if camera_pos.z<0.0, and +1 otherwise.\n\n    // Hit-testing\n    float qh = QUAD_SIDE_LEN*0.5;\n    vec4 theshape = vec4(-qh,-qh,qh,qh);\n\n    if(IsPointInRectXY(theshape, world_xyz0_of_point.xy)) {\n\n#ifndef TWOSIDED\n        material_color = vec3(1.0);\n#else\n        float front_view = step(0.0, camera_pos.z);\n        material_color = vec3(front_view, 0.0, 1.0-front_view);\n#endif\n\n    } else {    //we didn't hit\n        fragColor = vec4(0.0,0.0,0.0,1.0);  //black\n        return; // *** EXIT POINT ***\n            // comment out the \"return\" for a chuckle\n    }\n\n    // Shading (it's a shader, after all!)\n\n#if SHADING_RULE == 0\n    fragColor = vec4(material_color, 1.0);                  //No shading\n\n#elif SHADING_RULE == 1\n    // Flat shading - per-poly\n    float reflectance = // VVVVVVV per-poly, lighting as a the poly's center.\n        lambertian_shade(vec3(0.0), normal, light_pos, camera_pos);\n\n    float reflectance_gc = pow(reflectance, ONE_OVER_GAMMA);\n        // Gamma-correct luminous-intensity reflectance into monitor space.\n        // Hey, it's just math, right?  I did this because the quad was too\n        // dark otherwise.\n\n    // White light for simplicity\n    fragColor = vec4(reflectance_gc * material_color, 1.0);\n\n#elif SHADING_RULE == 2\n    //Lambertian shading\n    float reflectance = //     VVV Lambertian is per-point, not per-poly\n        lambertian_shade(world_xyz0_of_point, normal, light_pos, camera_pos);\n\n    float reflectance_gc = pow(reflectance, ONE_OVER_GAMMA);\n    fragColor = vec4(reflectance_gc * material_color, 1.0);\n\n#else\n    // Phong shading\n    vec3 ambient_color = vec3(0.1);\n    vec3 specular_color = vec3(1.0);\n    vec3 color = phong_color(\n        world_xyz0_of_point, normal, camera_pos, light_pos, \n        ambient_color, material_color, specular_color,  // Light colors\n        SHININESS);\n\n    fragColor = vec4(color, 1.0);\n#endif\n} //mainImage\n\n// vi: set ts=4 sts=4 sw=4 et ai: //\n\n",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}