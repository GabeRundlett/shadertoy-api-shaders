{
    "Shader": {
        "info": {
            "date": "1536012316",
            "description": "These shaders are my implementation of the ray/path tracer described in the book \"Raytracing in one weekend\" by Peter Shirley. I have tried to follow the code from his book as much as possible.",
            "flags": 32,
            "hasliked": 0,
            "id": "llVcDz",
            "likes": 17,
            "name": "RIOW 1.07: Diffuse",
            "published": 3,
            "tags": [
                "raytracing",
                "ray",
                "tracer",
                "one",
                "in",
                "path",
                "7",
                "weekend",
                "chapter"
            ],
            "usePreview": 0,
            "username": "reinder",
            "viewed": 5118
        },
        "renderpass": [
            {
                "code": "// Raytracing in one weekend, chapter 7: Diffuse. Created by Reinder Nijhoff 2018\n// Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n// @reindernijhoff\n//\n// https://www.shadertoy.com/view/llVcDz\n//\n// These shaders are my implementation of the raytracer described in the (excellent) \n// book \"Raytracing in one weekend\" [1] by Peter Shirley (@Peter_shirley). I have tried \n// to follow the code from his book as much as possible, but I had to make some changes \n// to get it running in a fragment shader:\n//\n// - There are no classes (and methods) in glsl so I use structs and functions instead. \n//   Inheritance is implemented by adding a type variable to the struct and adding ugly \n//   if/else statements to the (not so overloaded) functions.\n// - The scene description is procedurally implemented in the world_hit function to save\n//   memory.\n// - The color function is implemented using a loop because it is not possible to have a \n//   recursive function call in glsl.\n// - Only one sample per pixel per frame is calculated. Samples of all frames are added \n//   in Buffer A and averaged in the Image tab.\n//\n// You can find the raytracer / pathtracer in Buffer A.\n//\n// = Ray tracing in one week =\n// Chapter  7: Diffuse                           https://www.shadertoy.com/view/llVcDz\n// Chapter  9: Dielectrics                       https://www.shadertoy.com/view/MlVcDz\n// Chapter 11: Defocus blur                      https://www.shadertoy.com/view/XlGcWh\n// Chapter 12: Where next?                       https://www.shadertoy.com/view/XlycWh\n//\n// = Ray tracing: the next week =\n// Chapter  6: Rectangles and lights             https://www.shadertoy.com/view/4tGcWD\n// Chapter  7: Instances                         https://www.shadertoy.com/view/XlGcWD\n// Chapter  8: Volumes                           https://www.shadertoy.com/view/XtyyDD\n// Chapter  9: A Scene Testing All New Features  https://www.shadertoy.com/view/MtycDD\n//\n// [1] http://in1weekend.blogspot.com/2016/01/ray-tracing-in-one-weekend.html\n//\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    vec4 data = texelFetch(iChannel0, ivec2(fragCoord),0);\n    fragColor = vec4(sqrt(data.rgb/data.w),1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// Raytracing in one weekend, chapter 7: Diffuse. Created by Reinder Nijhoff 2018\n// @reindernijhoff\n//\n// https://www.shadertoy.com/view/llVcDz\n//\n// These shaders are my implementation of the raytracer described in the (excellent) \n// book \"Raytracing in one weekend\" [1] by Peter Shirley (@Peter_shirley). I have tried \n// to follow the code from his book as much as possible.\n//\n// [1] http://in1weekend.blogspot.com/2016/01/ray-tracing-in-one-weekend.html\n//\n\n#define MAX_FLOAT 1e5\n#define MAX_RECURSION 5\n\n//\n// Hash functions by Nimitz:\n// https://www.shadertoy.com/view/Xt3cDn\n//\n\nuint base_hash(uvec2 p) {\n    p = 1103515245U*((p >> 1U)^(p.yx));\n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    return h32^(h32 >> 16);\n}\n\nfloat g_seed = 0.;\n\nvec2 hash2(inout float seed) {\n    uint n = base_hash(floatBitsToUint(vec2(seed+=.1,seed+=.1)));\n    uvec2 rz = uvec2(n, n*48271U);\n    return vec2(rz.xy & uvec2(0x7fffffffU))/float(0x7fffffff);\n}\n\nvec3 hash3(inout float seed) {\n    uint n = base_hash(floatBitsToUint(vec2(seed+=.1,seed+=.1)));\n    uvec3 rz = uvec3(n, n*16807U, n*48271U);\n    return vec3(rz & uvec3(0x7fffffffU))/float(0x7fffffff);\n}\n\n//\n// Ray trace helper functions\n//\n\nfloat schlick(float cosine, float ior) {\n    float r0 = (1.-ior)/(1.+ior);\n    r0 = r0*r0;\n    return r0 + (1.-r0)*pow((1.-cosine),5.);\n}\n\nvec3 random_in_unit_sphere(inout float seed) {\n    vec3 h = hash3(seed) * vec3(2.,6.28318530718,1.)-vec3(1,0,0);\n    float phi = h.y;\n    float r = pow(h.z, 1./3.);\n\treturn r * vec3(sqrt(1.-h.x*h.x)*vec2(sin(phi),cos(phi)),h.x);\n}\n\n//\n// Ray\n//\n\nstruct ray {\n    vec3 origin, direction;\n};\n    \n//\n// Hit record\n//\n\nstruct hit_record {\n    float t;\n    vec3 p, normal;\n};\n\n//\n// Hitable, for now this is always a sphere\n//\n\nstruct hitable {\n    vec3 center;\n    float radius;\n};\n\nbool hitable_hit(const in hitable hb, const in ray r, const in float t_min, \n                 const in float t_max, inout hit_record rec) {\n    // always a sphere\n    vec3 oc = r.origin - hb.center;\n    float b = dot(oc, r.direction);\n    float c = dot(oc, oc) - hb.radius * hb.radius;\n    float discriminant = b * b - c;\n    if (discriminant < 0.0) return false;\n\n\tfloat s = sqrt(discriminant);\n\tfloat t1 = -b - s;\n\tfloat t2 = -b + s;\n\t\n\tfloat t = t1 < t_min ? t2 : t1;\n    if (t < t_max && t > t_min) {\n        rec.t = t;\n        rec.p = r.origin + t*r.direction;\n        rec.normal = (rec.p - hb.center) / hb.radius;\n\t    return true;\n    } else {\n        return false;\n    }\n}\n\n//\n// Camera\n//\n\nstruct camera {\n    vec3 origin, lower_left_corner, horizontal, vertical;\n};\n\nray camera_get_ray(camera c, vec2 uv) {\n    return ray(c.origin, \n               normalize(c.lower_left_corner + uv.x*c.horizontal + uv.y*c.vertical - c.origin));\n}\n\n//\n// Color & Scene\n//\n\nbool world_hit(const in ray r, const in float t_min, const in float t_max, out hit_record rec) {\n    rec.t = t_max;\n    bool hit = false;\n    \n\thit = hitable_hit(hitable(vec3(0,0,-1), .5), r, t_min, rec.t, rec) || hit;\n\thit = hitable_hit(hitable(vec3(0,-100.5,-1),100.), r, t_min, rec.t, rec) || hit;\n    \n    return hit;\n}\n\nvec3 color(in ray r) {\n    vec3 col = vec3(1);  \n\thit_record rec;\n    \n    for (int i=0; i<MAX_RECURSION; i++) {\n    \tif (world_hit(r, 0.001, MAX_FLOAT, rec)) {\n        \tvec3 rd = normalize(rec.normal + random_in_unit_sphere(g_seed));\n            col *= .5;\n\n            r.origin = rec.p;\n            r.direction = rd;\n\t    } else {\n            float t = .5*r.direction.y + .5;\n            col *= mix(vec3(1),vec3(.5,.7,1), t);\n            return col;\n    \t}\n    }\n    return col;\n}\n\n//\n// Main\n//\n\nvoid mainImage( out vec4 frag_color, in vec2 frag_coord ) {\n    if (ivec2(frag_coord) == ivec2(0)) {\n        frag_color = iResolution.xyxy;\n    } else {\n        g_seed = float(base_hash(floatBitsToUint(frag_coord)))/float(0xffffffffU)+iTime;\n\n        vec2 uv = (frag_coord + hash2(g_seed))/iResolution.xy;\n        float aspect = iResolution.x/iResolution.y;\n\n        ray r = camera_get_ray(camera(vec3(0), vec3(-2,-1,-1), vec3(4,0,0), vec3(0,4./aspect,0)), uv);\n        vec3 col = color(r);\n        \n        if (texelFetch(iChannel0, ivec2(0),0).xy == iResolution.xy) {        \n\t        frag_color = vec4(col,1) + texelFetch(iChannel0, ivec2(frag_coord), 0);\n        } else {        \n\t        frag_color = vec4(col,1);\n        }\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}