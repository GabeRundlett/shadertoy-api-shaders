{
    "Shader": {
        "info": {
            "date": "1533761201",
            "description": "End of time by Alcatraz & Altair - grid scene.\nFull intro: http://www.pouet.net/prod.php?which=77102\nintroducing Madtracer [tm]\n\n",
            "flags": 96,
            "hasliked": 0,
            "id": "Xt3cWS",
            "likes": 52,
            "name": "EOT - Grid scene",
            "published": 3,
            "tags": [
                "demoscene",
                "pathtracing",
                "pathtracing",
                "4kintro",
                "madtracer"
            ],
            "usePreview": 0,
            "username": "Virgill",
            "viewed": 1679
        },
        "renderpass": [
            {
                "code": "//------------------------------------------------------------------------\n//  End of time.  A 4k intro by Virgill/Alcatraz & KK/Altair\n//\n//  Full intro: http://www.pouet.net/prod.php?which=77102\n//  Youtube: https://youtu.be/5lR76o9lWB0\n//\n//  Thanks to these ppl for help + inspiration: Slerpy, LJ, Xtr1m, Gopher\n//------------------------------------------------------------------------\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = (fragCoord.xy/iResolution.xy);\n    fragColor = texture(iChannel0, uv);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "musicstream",
                        "id": 15671,
                        "published": 0,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "https://soundcloud.com/virgill/4klang-end-of-time"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "//------------------------------------------------------------------------\n//  End of time.  A 4k intro by Virgill/Alcatraz & KK/Altair\n//\n//  Full intro: http://www.pouet.net/prod.php?which=77102\n//  Youtube: https://youtu.be/5lR76o9lWB0\n//\n//  Thanks to these ppl for help + inspiration: Slerpy, LJ, Xtr1m, Gopher\n//------------------------------------------------------------------------\n\n\n/*\nBasically it traces primary ray normally, averaging samples on the way plus one more or less random sample \nin the reflection direction at every step. This effectively produces volumetric lighting \nwith directional glow (thanks to secondary samples) and once the primary ray hits surface the \nremaining iterations (there's no early exit in the tracing loop) result in DOF/antialiasing \n(primary ray is randomized per step and still converging and averaging) and \"pathtraced\" surface (secondary samples).\n\nSecondary \"rays\" particularly hacky. The direction is computed normally as view direction reflected by the normal, \nrandomized according to roughness, but there's only one sample taken at the \"best known\" secondary ray distance \n(which is updated after the sample). In effect, on low roughness this approach usually finds the proximity \nof the reflected surface and on high roughness samples randomly around the shaded point (but then, nobody really cares).\nIn the end, averaging everything hides most artifacts. :)\n*/\n\n\nvec3 scol;\n\nvoid dmin(inout vec3 d, float x, float y, float z)\n{\n\tif(x<d.x) d=vec3(x,y,z);\n}\n\n// 3D noise function (IQ, Shane)\nfloat noise(vec3 p)\n{\n\tvec3 ip=floor(p);\n\tp-=ip;\n\tvec3 s=vec3(7, 157, 113);\n\tvec4 h=vec4(0., s.yz, s.y+s.z)+dot(ip, s);\n\tp=p*p*(3.-2.*p);\n\th=mix(fract(sin(h)*43758.5), fract(sin(h+s.x)*43758.5), p.x);\n\th.xy=mix(h.xz, h.yw, p.y);\n\treturn mix(h.x, h.y, p.z);\n}\n\n// hemisphere hash function based on a hash by Slerpy\nvec3 hashHs(vec3 n, float seed)\n{\n\tfloat a = fract(sin(seed)*43758.5)*2.-1.;\n\tfloat b = 6.283*fract(sin(seed)*41758.5)*2.-1.;\n\tfloat c=sqrt(1.-a*a);\n\tvec3 r=vec3(c*cos(b), a, c*sin(b));\n\treturn r;\n}\n\nfloat box(vec2 p)\n{\n\tp=abs(p); return max(p.x, p.y);\n}\n\nvoid pR(inout vec2 p, float a)\n{\n\tp = cos(a)*p+sin(a)*vec2(p.y, -p.x);\n}\n\n\nvec3 map(vec3 p)\n{\n\n\tvec3 q;\n\tvec3 d = vec2(0, 1.).yxx;\n\tfloat floornoise = .8*noise(3.*p+2.3*iTime)+0.1*noise(20.*p+2.2*iTime);\n\tdmin(d, min(5.-p.z, 1.5+p.y), 0.1+0.3*step(mod(4.*p.z, 1.), .5), .0); \n\tdmin(d, length(p+vec3(0., 0., 1.9+sin(iTime)))-.500, .99, 1.); \t\t  \n\tq=p; pR(q.xy, 0.6*iTime);\n\n\tdmin(d, length(q+vec3(0, 0., 1.9+sin(iTime)))-.445-0.09*sin(43.*q.x-q.y+10.*iTime), 1., 0.1);\n\tif( iTime>24. )p.y-=0.1*iTime-2.4; \n\tq = abs(p-round(p-.5)-.5);\n\tif( iTime>24. )p.y+=0.1*iTime-2.4;\n\tfloat g = min(min(box(q.xy), box(q.xz)), box(q.yz))-.05;\n\tfloat c = min(.6-abs(p.x+p.z), .45-abs(p.y));\n\tif (iTime>12.) dmin(d, max(g, c), .1, 0.5); //lattice (by Slerpy)\n\n\tif( iTime>18. )dmin(d, box(p.zx+vec2(2, 2))-.5, 1., .4); \n\tif( iTime>17.3)dmin(d, box(p.zx+vec2(2,-2))-.5, 1.,-.4); \n\treturn d;\n\n}\n\n\nvec3 normal(vec3 p)\n{\n\tfloat m = map(p).x;\n\tvec2 e = vec2(0,.05);\n\treturn normalize(m-vec3(map(p - e.yxx).x, map(p - e.xyx).x, map(p - e.xxy).x));\n}\n\n\nvoid madtracer(in vec3 ro1, in vec3 rd1, in float seed)\n{\n\tscol = vec3(0);\t\n\tfloat t = 0., t2 = 0.;\n\tvec3 m1, m2, rd2, ro2, nor2;\n\tvec3 roold=ro1;\n\tvec3 rdold=rd1;\n\tm1.x=0.;\n\tfor( int i = 0; i < 140; i++ )\n\t{\n\n\t\tseed = fract(seed+iTime*float(i+1)+.1);\n\t\tro1=mix(roold, hashHs(ro1, seed), 0.002);\t\t\t\t// antialiasing\n\t\trd1=mix(rdold, hashHs(rdold, seed), 0.06*m1.x);\t\t\t// antialiasing\n\t\tm1 = map(ro1+rd1*t);\n\t\tt+=m1.z!=0. ? 0.25*abs(m1.x)+0.0008 : 0.25*m1.x;\n\t\tro2 = ro1 + rd1*t;\n\t\tnor2 = normal(ro2); \t\t\t\t\t\t\t\t\t// normal of new origin\n\t\tseed = fract(seed+iTime*float(i+2)+.1);\n        rd2 = mix(reflect(rd1, nor2), hashHs(nor2, seed), m1.y);// reflect depending on material\n\t\tm2 = map(ro2+rd2*t2);\n\t\tt2+=m2.z!=0. ? 0.25*abs(m2.x) : 0.25*m2.x;\n\t\tscol+=.007*(vec3(1.+m2.z, 1., 1.-m2.z)*step(1., m2.y)+vec3(1.+m1.z, 1., 1.-m1.z)*step(1., m1.y));\n\t}\n}\n\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord)\n{\n\n\n\tvec2 uv = fragCoord.xy / iResolution.xy;\n    fragColor=vec4(0.0);\n\t// borders\n\tif( uv.y>.1&&uv.y<0.9 )\n\t{\n\t\tfloat seed = sin(fragCoord.x + fragCoord.y)*sin(fragCoord.x - fragCoord.y);\n\t\tvec3 bufa= texture(iChannel0, uv).xyz;\n\n\t\t// camera\n\t\tvec3 ro, rd;\n\t\tvec2 uv2 = (2.*fragCoord.xy-iResolution.xy)/iResolution.x;\n\t\tro = vec3(0, 0,-5);\n\t\trd = normalize(vec3(uv2, 1));\n\t\t// rotate scene\n        if (iTime>12.)\n        {\n\t\t\tpR(rd.xz, .5*-sin(.17*iTime));\n\t\t\tpR(rd.yz, .5*sin(.19*iTime));\n\t\t\tpR(rd.xy, .4*-cos(.15*iTime));\n        }\n\t\t// render    \n\t\tmadtracer(ro, rd, seed);\n\n\t\tfloat fade =min(3.*abs(sin((3.1415*(iTime-12.)/24.))), 1.);\n\t\tfragColor =clamp(vec4(0.7*scol+0.7*bufa, 0.)*fade, 0., 1.); // with blur\n\t}\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}