{
    "Shader": {
        "info": {
            "date": "1703403732",
            "description": "Just having fun shading fb39ca4's voxel scene.",
            "flags": 32,
            "hasliked": 0,
            "id": "mtyfRV",
            "likes": 11,
            "name": "GGX Voxel Raytracing",
            "published": 3,
            "tags": [
                "idk"
            ],
            "usePreview": 0,
            "username": "KylBlz",
            "viewed": 549
        },
        "renderpass": [
            {
                "code": "\n// GGX BRDF - thanks XT95 - https://www.shadertoy.com/view/Dtl3WS\n// ACES fitted - thanks Paniq - https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\n// Voxel Raymarch - thanks fb39ca4 - https://www.shadertoy.com/view/4dX3zl\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec4 channel0 = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    fragColor.rgb = linear_srgb(ACESFitted(\n        channel0.rgb / floor(channel0.a)\n    ));\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "#define SHADOWS\n//#define USE_DFD_COARSE\n//#define USE_DFD_SMOOTH\n\n// camera properties\nconst float\tznear = 0.1, zfar = 64.0, FOV = 69.0;\nconst int MAX_RAY_STEPS = 64;\nconst int MAX_REFLECTION_STEPS = 64;\nconst int MAX_SHADOW_STEPS = 64;\nconst int TEMPORALSMOOTHING = 6;\n\n// math constants\nconst highp float\tSQRT2 = 1.4142136, SC45 = 0.7071068, D2R = 0.0174533,\n            eps = 0.001, ieps = 0.999, epsCol = 0.0039062,\n            QTRPI = 0.7853981, HPI = 1.5707963, PI = 3.1415926, TWOPI = 6.2831853,\n            iQTRPI = 1.2732396, iHPI = 0.6366197, iPI = 0.3183098, iTWOPI = 0.1591549;\n\n// average of px considering coarse dfd_ group of 3 pixels per quad\nfloat dfCoarse(in vec2 fc, in float v) {\n    vec2 f = vec2(uvec2(fc.xy) & uvec2(1)),\n         d = vec2(dFdx(v), dFdy(v)),\n         q = d * (0.0 - f),\n         i = d * (1.0 - f);\n    vec3 vals = q.xyx + vec3(q.y, i.xy) + v;\n    return dot(vals, vec3(0.3333333));\n}\n\n// thanks iradicator, this is less sensitive to nonlinear local neighborhood (with respect to fragcoord)\nfloat dfSmooth(in vec2 fc, in float v) { \n    vec2 q = vec2(uvec2(fc.xy) & uvec2(1));\n    q = q * 2.0 - 1.0;    \n    v -= 0.5 * dFdx(v) * q.x;\n    v -= 0.5 * dFdy(v) * q.y;\n    return v;\n}\n\n// generate a unique value for each pixel/frame\nint genSeed(in int f, in ivec2 c) {\n    return (c.x + c.y*2 + f*11) + (c.x*1155 ^ c.y*2244);\n}\n\n// low discrepancy sequence - https://www.shadertoy.com/view/7dByR1\nfloat weyl1(in int v) {\n    return fract(float(v*40503) * exp2(-16.0));\n}\n\nvec2 weyl2(in int v) {\n    return fract(vec2(v*ivec2(49471, 37345)) * exp2(-16.0));\n}\n\nvec3 weyl3(in int v) {\n    return fract(vec3(v*ivec3(53685, 43977, 36025)) * exp2(-16.0));\n}\n\nfloat linearAngle(float d, float r) {\n    return asin(clamp(r/d, eps, ieps));\n}\n\n// orthonormal basis assuming up is +y\nmat3 basisUp(in vec3 forward) {\n    vec3 down = vec3(0.0, -1.0, 0.0);\n    vec3 right = normalize(cross(forward, down));\n    return mat3(right, normalize(cross(forward, right)), forward);\n}\n\n// orthonormal basis at normal\nvoid basis(in vec3 n, out vec3 f, out vec3 r) {\n    float s = (n.z >= 0.0)? 1.0: -1.0;\n    float a = 1.0 / (s + n.z);\n    float b = -n.x*n.y*a;\n    f = vec3(1.0 - n.x*n.x*a*s, b*s, -n.x*s);\n    r = vec3(b, s - n.y*n.y*a, -n.y);\n}\n\n// concentric mapping square [0,1] to circle [-1,1]\nvec2 concentric(in vec2 v) {\n    vec2 w = v * 2.0 - 1.0;\n    float thta, rad;\n    if (abs(w.x) > abs(w.y)) {\n        rad = w.x;\n        thta = QTRPI * (w.y/w.x);\n    } else {\n        rad = w.y;\n        thta = HPI - QTRPI * (w.x/w.y);\n    }\n    return rad * vec2(cos(thta), sin(thta));\n}\n\n// uniform sample cone\nvec3 uniformConeDir(vec3 lv, float lr, in vec2 rng) {\n    // cone section\n    float sa = tan(linearAngle(length(lv), lr));\n    vec3 u, r, nlv = normalize(lv);\n    basis(nlv, r, u);\n    return normalize(nlv + sa * (r * rng.x + u * rng.y));\n}\n\nvec2 rotate2d(in vec2 v, in float a) {\n    float sinA = sin(a);\n    float cosA = cos(a);\n    return vec2(v.x * cosA - v.y * sinA, v.y * cosA + v.x * sinA);\t\n}\n\n// thanks XT95 https://www.shadertoy.com/view/Dtl3WS\nfloat F_Schlick(float f0, float f90, float theta) {\n    return f0 + (f90 - f0) * pow(1.0 - theta, 5.0);\n}\n\nfloat D_GTR(float roughness, float NoH, float k) {\n    float a2 = roughness*roughness;\n    return a2 / (PI * pow(NoH*NoH * (a2*a2 - 1.0) + 1.0, k));\n}\n\nfloat G_Smith(float NoV, float roughness2) {\n    float b = NoV*NoV;\n    float a = roughness2*roughness2;\n    return 2.0 * NoV / (NoV + sqrt(a+b - a*b));\n}\n\nfloat GeometryTerm(float NoL, float NoV, float roughness) {\n    float a2 = roughness*roughness;\n    float G1 = G_Smith(NoV, a2);\n    float G2 = G_Smith(NoL, a2);\n    return G1*G2;\n}\n\nfloat ggxDiffuse(float NoL, float NoV, float LoH, float roughness) {\n    float FD90 = 0.5 + 2.0 * roughness * LoH*LoH;\n    float a = F_Schlick(1.0, FD90, NoL);\n    float b = F_Schlick(1.0, FD90, NoV);\n    return a * b / PI;\n}\n\nfloat ggxSpecular(float roughness, float NoH, float NoV, float NoL) {\n    float alpha = roughness*roughness;\n    float D = D_GTR(alpha, NoH, 2.0);\n    float beta = 0.5 + roughness * 0.5;\n    float G = GeometryTerm(NoL, NoV, beta*beta);\n    return D * G / (4.0 * NoL * NoV);\n}\n\n// fast orthogonal matrix inverse\nmat4 orthoInverse(in mat4 m) {\n    mat3 r = transpose(mat3(m));\n    return mat4(\n        vec4(r[0], 0.0),\n        vec4(r[1], 0.0),\n        vec4(r[2], 0.0),\n        vec4(r * vec3(-m[3]), 1.0)\n    );\n}\n\n// construct 4x4 view mat from camera origin, forward direction, time\nmat4 viewMat(in vec3 origin, in vec3 direction, in float time) {\n    // update camera here\n    origin.xz = rotate2d(origin.xz, time * 0.5 - HPI);\n    direction.xz = rotate2d(direction.xz, time * 0.5 - HPI);\n    // construct view mat\n    mat3 bas = basisUp(direction);\n    return mat4(\n        vec4(bas[0], 0.0),\n        vec4(bas[1], 0.0),\n        vec4(bas[2], 0.0),\n        vec4(origin, 1.0)\n    );\n}\n \n// construct 4x4 projection mat using offaxis parameters, aspect ratio, global FOV\nmat4 projectionMat(in vec2 offaxis, in float aspect) {\n    // proj parameters\n    float f = zfar;\n    float n = znear;\n    float fovrad = FOV * D2R;\n    float r =  n * aspect * tan(0.5 * (fovrad - offaxis.x));\n    float l = -n * aspect * tan(0.5 * (fovrad + offaxis.x));\n    float t =  n          * tan(0.5 * (fovrad - offaxis.y));\n    float b = -n          * tan(0.5 * (fovrad + offaxis.y));\n    // construct proj mat\n    return mat4(\n        vec4(2.0*n/(r-l),         0.0, (r+l)/(r-l),           0.0),\n        vec4(        0.0, 2.0*n/(t-b), (t+b)/(t-b),           0.0),\n        vec4(        0.0,         0.0, (f+n)/(f-n), 2.0*f*n/(f-n)),\n        vec4(        0.0,         0.0,         1.0,           0.0)\n    );\n}\n\n// project the pixel at ndc into a worldspace ray\nvoid getCameraRay(in mat4 view, in mat4 proj, in vec2 ndc, out vec3 ro, out vec3 rd) {\n    ro = view[3].xyz;\n    // inverse projection\n    vec4 ndch = transpose(inverse(proj)) * vec4(ndc, 1.0, 1.0);\n    // apply view matrix\n    rd = normalize(mat3(view) * vec3(ndch.xy, 1.0));\n}\n\n// project a worldspace location hl into camera NDC using its view projection\nvec3 reprojCoordsNDC(in mat4 view, in mat4 proj, in vec3 hl) {\n    // inverse view to camera space\n    vec4 camspace = orthoInverse(view) * vec4(hl, 1.0);\n    // homogenous projection\n    vec4 ndch = camspace * proj;\n    // perspective divide xy, path length in z for depth filtering\n    return vec3(ndch.xy / ndch.w, length(camspace));\n}\n\n// 3D reproject given image, distance, pixel location (see reprojCoordsNDC)\nvec4 reprojectBuffer(in sampler2D iChannel, in float dist, in vec2 fc) {\n    ivec2 ifc = ivec2(fc);\n    // get the 4 neighboring pixel values\n    vec4 b   = texelFetch(iChannel, ifc,               0);\n    vec4 bx  = texelFetch(iChannel, ifc + ivec2(1, 0), 0);\n    vec4 by  = texelFetch(iChannel, ifc + ivec2(0, 1), 0);\n    vec4 bxy = texelFetch(iChannel, ifc + ivec2(1, 1), 0);\n    // depth match filter\n    float has   = step(abs(fract(b.a) - dist), exp2(-8.0));\n    float hasx  = step(abs(fract(bx.a) - dist), exp2(-8.0));\n    float hasy  = step(abs(fract(by.a) - dist), exp2(-8.0));\n    float hasxy = step(abs(fract(bxy.a) - dist), exp2(-8.0));\n    float ttl = has + hasx + hasy + hasxy;\n    if (ttl < 1.0)\n        return vec4(0.0);\n    if (ttl > 3.0) {\n        // fancy bilinear interpolation\n        vec2 a = clamp(fc - floor(fc), vec2(0.0), vec2(1.0));\n        return max(vec4(0.0), mix(mix(b, bx, a.x), mix(by, bxy, a.x), a.y));\n    }\n    // last resort interp\n    return (b*has + bx*hasx + by*hasy + bxy*hasxy) / ttl;\n}\n\n// Thanks Paniq\nvec3 linear_srgb(in vec3 x) {\n    return mix(1.055*pow(x, vec3(1./2.4)) - 0.055, 12.92*x, step(x, vec3(0.0031308)));\n}\n\nvec3 srgb_linear(in vec3 x) {\n    return mix(pow((x + 0.055)/1.055,vec3(2.4)), x / 12.92, step(x, vec3(0.04045)));\n}\n\n// Paniq's ACES fitted from https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 ACESFitted(in vec3 color) {\n    // ODT_SAT => XYZ => D60_2_D65 => sRGB\n    color = color * mat3(\n        0.59719, 0.35458, 0.04823,\n        0.07600, 0.90834, 0.01566,\n        0.02840, 0.13383, 0.83777\n    );\n    // Apply RRT and ODT\n    vec3 a = color * (color + 0.0245786) - 0.000090537;\n    vec3 b = color * (0.983729 * color + 0.4329510) + 0.238081;\n    color = a / b;\n    // Back to color space\n    color = color * mat3(\n         1.60475, -0.53108, -0.07367,\n        -0.10208,  1.10813, -0.00605,\n        -0.00327, -0.07276,  1.07602\n    );\n    // Clamp to [0, 1]\n    return clamp(color, 0.0, 1.0);\n}\n\nfloat sdSphere(vec3 p, float d) {\n    return length(p) - d;\n}\n\nfloat sdBox(vec3 p, vec3 b) {\n    vec3 d = abs(p) - b;\n    return min(max(d.x,max(d.y,d.z)),0.0) + length(max(d,0.0));\n}\n\nbool getVoxel(ivec3 c) {\n    vec3 p = vec3(c) + vec3(0.5);\n    float d = min(max(-sdSphere(p, 7.5), sdBox(p, vec3(6.0))), -sdSphere(p, 20.0));\n    return d < 0.0;\n}\n\n// thanks fb39ca4 https://www.shadertoy.com/view/4dX3zl\nvoid voxelRaymarch(in vec3 rayPos, in vec3 rayDir, in int MAX_STEPS, out float t, out vec3 normal, out ivec3 mapPos, out vec3 hitloc) {\n    mapPos = ivec3(floor(rayPos));\n    ivec3 rayStep = ivec3(sign(rayDir));\n    vec3 deltaDist = abs(vec3(length(rayDir)) / rayDir);\n    vec3 sideDist = (sign(rayDir) * (vec3(mapPos) - rayPos) + (sign(rayDir) * 0.5) + 0.5) * deltaDist; \n    vec3 mask;\n    bool hitvoxel = false;\n    for (int i = 0; i < MAX_STEPS; i++) {\n        if (getVoxel(mapPos)) {\n            hitvoxel = true;\n            break;\n        }\n        // Thanks kzy for the suggestion!\n        mask = vec3(lessThanEqual(sideDist.xyz, min(sideDist.yzx, sideDist.zxy)));\n        // All components of mask are false except for the corresponding largest component of sideDist, which is the axis along which the ray should be incremented.\t\t\t\n        sideDist += mask * deltaDist;\n        mapPos += ivec3(mask) * rayStep;\n    }\n    if (hitvoxel) {\n        // there's probably a better way\n        normal = sign(-rayDir) * mask;\n        t = dot(normal, vec3(mapPos) + max(vec3(0.0), normal) - rayPos) / dot(normal, rayDir);\n        hitloc = rayPos + rayDir * t;\n        return;\n    }\n    t = zfar;\n    normal = vec3(0.0);\n    hitloc = rayPos + rayDir * t;\n    mapPos = ivec3(hitloc);\n}\n\nfloat getAO(in vec3 hitPos, in ivec3 mapPos, in vec3 normal) {\n    vec3 basis = 1.0 - abs(normal);\n    vec3 mapos = vec3(mapPos) + 0.5;\n    vec3 diff = (hitPos - mapos) * basis;\n    vec3 absdiff = abs(diff);\n    // two potential closest walls\n    vec3 maxcomp = vec3(greaterThanEqual(absdiff.xyz, max(absdiff.yzx, absdiff.zxy)));\n    vec3 diff1stmax = diff * maxcomp;\n    vec3 diff2ndmax = diff * (1.0 - maxcomp);\n    // sample 3 voxels\n    vec3 nd1m = normalize(diff1stmax);\n    vec3 nd2m = normalize(diff2ndmax);\n    vec3 nd3m = nd1m + nd2m;\n    bool occupied0 = getVoxel(ivec3( floor(mapos + normal + nd1m) ));\n    bool occupied1 = getVoxel(ivec3( floor(mapos + normal + nd2m) ));\n    bool occupied2 = getVoxel(ivec3( floor(mapos + normal + nd3m) ));\n    // distance functions of occupied voxels\n    diff1stmax = abs(diff1stmax);\n    diff2ndmax = abs(diff2ndmax);\n    float occlu0 = float(occupied0) * max(diff1stmax.x, max(diff1stmax.y, diff1stmax.z));\n    float occlu1 = float(occupied1) * max(diff2ndmax.x, max(diff2ndmax.y, diff2ndmax.z));\n    float occlu2 = float(occupied2 && !occupied0 && !occupied1) * (0.5 - distance(hitPos * basis, (mapos + nd3m * 0.5) * basis));\n    // occlude up to 3/4 hemisphere\n    return 1.0 - min(ieps, (occlu0 + occlu1 + occlu2) * 0.5);\n}\n\nvec4 sampleLight(in vec3 hitloc, in vec3 lv, in ivec3 light) {\n\n#ifdef SHADOWS\n    float t;\n    vec3 normal, hitloc2;\n    ivec3 mapPos;\n    voxelRaymarch(hitloc, lv, MAX_SHADOW_STEPS, t, normal, mapPos, hitloc2);\n#else\n    ivec3 mapPos = light;\n    float t = distance(hitloc, vec3(light));\n#endif\n    return vec4(vec3(mapPos), t);\n}\n\nvec3 shade_ggx(in vec2 fc, in vec3 diffCol, in vec3 spec8, in vec3 specCol, in vec3 rayPos, in vec3 rayDir, in vec3 hitloc, in float t, inout vec3 normal, in ivec3 mapPos, in ivec3 light, in vec3 litCol, in vec3 rflcol, in vec3 rng) {\n    // really sampling a sphere inside the voxel\n    vec3 ll = vec3(light) + 0.5;\n    vec3 lv = ll - hitloc;\n    lv = uniformConeDir(lv, 0.5, rng.xy);\n    // light stuff\n    vec3 hv = normalize(lv - rayDir);\n    float dnl = dot(normal, lv);\n    float dnh = dot(normal, hv);\n    float dnv = dot(normal, -rayDir);\n    float dlh = dot(lv, hv);\n    // sample light\n    vec4 smp = sampleLight(hitloc + normal * eps, lv, light);\n    // decide to shade\n    float diff = 0.0;\n    float spec = 0.0;\n    if (step(0.0, dnl) > 0.5) {\n        float invsquare = TWOPI / (1.0 + smp.w*smp.w);\n        float hitlit = invsquare * float(ivec3(smp.xyz) == light);\n        // value sharing\n#ifdef USE_DFD_COARSE\n        hitlit = (hitlit + dfCoarse(fc, hitlit)) * 0.5;\n#endif\n#ifdef USE_DFD_SMOOTH\n        hitlit = (hitlit + dfSmooth(fc, hitlit)) * 0.5;\n#endif\n        // ggx\n        float rough = 1.0 - specCol.b * 0.5;\n        diff = ggxDiffuse(dnl, dnv, dlh, rough) * hitlit;\n        spec = ggxSpecular(rough, dnh, dnv, dnl) * hitlit;\n    }\n    // base ambient\n    float amb = 0.02 * max(0.5, dot(normal, normalize(ll + vec3(0.0, 5.0, 0.0))));\n    // ambient occlusion\n    float ao = getAO(hitloc, mapPos, normal);\n    // reflection\n    float refl = F_Schlick(0.1, 0.5, dnv);\n    // emissive\n    float emiss = float(mapPos == light);\n    // bloom\n    vec3 rll = ll - rayPos;\n    float srl = sqrt(dot(rll, rll));\n    float drd = dot(rll / srl, rayDir);\n    float bloom = 0.2 * clamp(t - srl + 0.5, 0.0, 1.0) * pow(max(0.0, drd), 1024.0);\n    // integrate, clamping spec is biased\n    \n    vec3 color = (amb + diff) * diffCol;\n    color += clamp(spec * specCol * specCol, 0.0, 1.0);\n    color *= litCol;\n    color += rflcol * refl;\n    color *= ao;\n    color += litCol * emiss;\n    color.rgb += bloom * litCol;\n    return max(vec3(0.0), color);\n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// https://media.disneyanimation.com/uploads/production/publication_asset/48/asset/s2012_pbs_disney_brdf_notes_v3.pdf\n\nvoid textureMap(in ivec3 mapPos, in vec3 hitloc, sampler2D channel, inout vec3 normal, out vec3 diffCol, out vec3 spec8, out vec3 specCol) {\n    // mapping\n    vec2 mirror = vec2((mapPos.x ^ mapPos.z) & 1, (mapPos.y ^ mapPos.z) & 1);\n    mat3 rot = mat3(normal.yzx, normal.xyz, normal.zxy);\n    vec2 plnpos = fract(rotate2d(fract((hitloc - vec3(mapPos)) * rot).xz, HPI*mirror.x + PI*mirror.y));\n    // textures\n    diffCol = texture(channel, plnpos).rgb;\n    spec8 = textureLod(channel, vec2(0.5), 7.0).grb;\n    specCol = diffCol;\n    // normals\n    normal = normalize(normal * PI + (spec8 - specCol));\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n\n    // get current camera\n    float time = float(iFrame)*0.01 - 0.001;\n    vec3 camOrigin = vec3(0.0, 0.0, -15.0);\n    vec3 camDirection = vec3(0.0, 0.0, 1.0);\n    float aspect = iResolution.x / iResolution.y;\n    mat4 view = viewMat(camOrigin, camDirection, time);\n    mat4 proj = projectionMat(vec2(0.0), aspect);\n\n    // get last camera\n    float lastTime = float(iFrame-1)*0.01 - 0.001;\n    mat4 lastView = viewMat(camOrigin, camDirection, lastTime);\n    mat4 lastProj = proj;\n    \n    // get pixel ray to trace\n    vec2 uv = fragCoord.xy / iResolution.xy;\n    vec2 ndc = uv * 2.0 - 1.0;\n    vec3 ro, rd;\n    getCameraRay(view, proj, ndc, ro, rd);\n\n    // main voxel ray march\n    float t;\n    vec3 normal, hitloc;\n    ivec3 mapPos;\n    voxelRaymarch(ro, rd, MAX_RAY_STEPS, t, normal, mapPos, hitloc);\n\n    // last frame reprojection in NDC\n    vec3 lastNDC = reprojCoordsNDC(lastView, lastProj, hitloc);\n    vec2 lastPx = (lastNDC.xy * 0.5 + 0.5) * iChannelResolution[0].xy;\n    vec4 lastFrame = reprojectBuffer(iChannel0, lastNDC.z/zfar, lastPx - 0.5);\n\n    // main material properties\n    vec3 diffCol = vec3(1.0);\n    vec3 spec8 = vec3(1.0);\n    vec3 specCol = vec3(1.0);\n    textureMap(mapPos, hitloc, iChannel1, normal, diffCol, spec8, specCol);\n\n    // reflection sharpness based on roughness and Schlick\n    float rough = (1.0 / specCol.b) - 1.0;\n    float dnv = dot(normal, -rd);\n    float nrmPwr = TWOPI * rough / (1.0 - F_Schlick(0.1, 0.5, dnv));\n\n    // reflected ray march\n    float t2;\n    vec3 normal2, hitloc2;\n    ivec3 mapPos2;\n    int seed = genSeed(iFrame, ivec2(fragCoord));\n    vec3 rng = vec4(concentric(weyl2(seed)), concentric(weyl2(~seed))).xyz;\n    vec3 rfldir = reflect(rd, normalize(normal * nrmPwr + rng));\n    voxelRaymarch(hitloc + normal * eps, rfldir, MAX_REFLECTION_STEPS, t2, normal2, mapPos2, hitloc2);\n\n    // reflected material properties\n    vec3 diffCol2 = vec3(1.0);\n    vec3 spec82 = vec3(1.0);\n    vec3 specCol2 = vec3(1.0);\n    textureMap(mapPos2, hitloc2, iChannel1, normal2, diffCol2, spec82, specCol2);\n\n    // lights\n    const int NLIGHTS = 4;\n    ivec3 lights[NLIGHTS] = ivec3[](ivec3(5, 4, -3), ivec3(-6, 4, 2), ivec3(-3, 4, -6), ivec3(2, 4, 5));\n    vec3 litCols[NLIGHTS] = vec3[](vec3(3.0, 0.3, 0.3), vec3(0.3, 3.0, 0.3), vec3(0.3, 0.3, 3.0), vec3(5.0, 4.5, 4.0));\n\n    // shade reflections\n    vec3 col2 = vec3(0.0);\n    for (int i = 0; i < NLIGHTS; i++) {\n        col2 += shade_ggx(fragCoord, diffCol2, spec82, specCol2, hitloc, rfldir, hitloc2, t2, normal2, mapPos2, lights[i], litCols[i], vec3(0.0), rng);\n    }\n\n    // reflections decay to prevent fireflies \n    col2 *= 1.0 / (1.0 + t2*t2*0.1);\n\n    // shade main ray\n    vec3 col = vec3(0.0);\n    for (int i = 0; i < NLIGHTS; i++) {\n        col += shade_ggx(fragCoord, diffCol, spec8, specCol, ro, rd, hitloc, t, normal, mapPos, lights[i], litCols[i], col2, rng);\n    }\n\n    // temporal smoothing, moving average\n    int lastFrameN = int(floor(lastFrame.a));\n    if (lastFrameN > TEMPORALSMOOTHING) {\n        float s = float(TEMPORALSMOOTHING) / float(lastFrameN);\n        lastFrame.a = float(TEMPORALSMOOTHING);\n        lastFrame.rgb *= s;\n    }\n\n    // encode sample number in integer componenet and distance in fractional componenet of .a\n    fragColor = vec4(lastFrame.rgb + col, floor(lastFrame.a) + 1.0 + (t/zfar) );\n    \n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 46,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/79520a3d3a0f4d3caa440802ef4362e99d54e12b1392973e4ea321840970a88a.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}