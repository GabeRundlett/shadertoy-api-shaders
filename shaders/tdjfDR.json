{
    "Shader": {
        "info": {
            "date": "1589901012",
            "description": "A multipass reflective box tunnel with some random reflective ray scattering thrown in. Basically, it's just a remake of W23's \"Path Racer\" and NuSan's \"Corridor Travel\" examples.",
            "flags": 0,
            "hasliked": 0,
            "id": "tdjfDR",
            "likes": 154,
            "name": "Traced Tunnel",
            "published": 3,
            "tags": [
                "tunnel",
                "blur",
                "dof",
                "raytrace",
                "pathtrace",
                "square",
                "motion"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 3665
        },
        "renderpass": [
            {
                "code": "/*\n\n\tTraced Tunnel\n\t-------------\n\n\tThis initially started as a simple textured square tube, but then I took\n\ta look at W23's \"Past Racer\" example and wanted to emulate the awesome\n\treflective... pseudo-pathtraced style of that. NuSan also has a really\n\tnice example on here, based on the same, that provided inspiration as well --\n    That one is well worth a look as the coloring is beautiful.\n\n\tI wrote this from scratch, but have used elements from the aforementioned\n    examples. I love the camera \"tick\" function in Nusan's example, so stuck \n    with that, and I like the way W23 gave certain random tiles more of an \n    opaque factor than others, so continued with that theme.\n\n\tIn regard to my own elements, I abandoned the box formula for four simple\n\tplane traces, since I needed a bit more control. I've also put in squarish \n    polar mapped textures to give more of a wrapped feel. Other than that, I \n    haven't brought anything particularly new to the table.\n\n\tI initially went to the trouble to raytrace octagonal walls, only to \n    discover that light bounces off rectangular walls in a cleaner -- and more \n    interesting -- way, so reverted back to the original arrangement.\n\n    This contains elements of path tracing, but I won't go as far as to call it\n\tthat, so I'll simply call it a reflective ray scattering demonstration. I've \n    basically patched in code here and there, but here's a quick explanation as \n    to what's happening:\n\n    I think most know how to raytrace a square tunnel with a single pass or \n    more -- Raytrace, retrieve the hit point, then use that to color the pixel.\n    With extra reflective passes, you calculate the reflected unit direction \n    ray at the hit point (ref = relflect(r, n)), raytrace to the surface again \n    from there, retrieve the color at the new hit point, then combine it with \n    the previous color -- How you do that is up to you; addition, mixing, or \n    whatever you choose. If you want more bounces, continue the process. Simple.\n    \n    However, pure reflections don't really reflect (no pun intended) the way real \n    surfaces behave. As you could imagine, they're rough at a microscopic level,\n\tso don't perfectly reflect rays in one direction; There's some randomness\n\tto it. Essentially, rough surfaces scatter the reflective rays in a way that \n    give the appearance of graded opaqueness, and smoother polished surfaces look \n    more reflective. There's more to it, but that's the gist of it.\n\n    To put this into practice, you simply add some randomness to the reflected \n    ray, which is based on the roughness of the surface. In a similar way to W23 \n    and NuSan's examples, I've textured square grids to the walls of the tunnel, \n    then randomly assigned roughness levels to each. This causes each grid cell \n    to look opaque, completely reflective, or somewhere in-between. The\n    reflected rays on the right-angled geometry gives a see-through impression, \n    but that's not the case.\n\t\n\n\tInspired largely by the following:\n\n    // The simple renderer is great, but it's the camera work that I love most.\n    past racer by jetlag - w23\n\thttps://www.shadertoy.com/view/Wts3W7\n\n    // Simple, but georgeous lighting and colors.\n\tCorridor Travel - NuSan\n    https://www.shadertoy.com/view/3sXyRN\n\n*/\n\n\n// Pure reflections looks pretty cool, and clean, but lack the subtlety of a\n// randomly reflected ray.\n//#define PURE_REFLECTION\n\n// Full rotational movement.\n//#define CAM_ROTATION\n\n// Camera swing.\n#define CAM_SWING\n\n// Depth of field.\n#define DEPTH_OF_FIELD\n\n// Motion blur: Temporal blending of samples.\n//#define MOTION_BLUR\n\n\n\n// Sample number: Higher is better, but slower. Eight is enough. :)\nconst int sampleNum = 8;\n\n\n// 2D rotation.\nmat2 r2(float a){ return mat2(cos(a), sin(a), -sin(a), cos(a)); }\n\n// Random functions: All based on IQ's originals.\n\n// vec2 to float hash.\nfloat hash21(vec2 p) {\n  return fract(sin(dot(p, vec2(425.215, 714.388)))*45758.5453);\n}\n\n// vec2 to vec2 hash.\nvec2 hash22(vec2 p) {\n  return fract(sin(vec2(dot(p, vec2(72.927, 98.283)), dot(p, vec2(41.295, 57.263))))\n                  *vec2(43758.5453, 23421.6361));\n}\n\n// vec2 to vec3 hash.\nvec3 hash23(vec2 p){\n    return fract(sin(vec3(dot(p, vec2(12.989, 78.233)), dot(p, vec2(51.898, 56.273)),\n                      dot(p, vec2(41.898, 57.263)))) *vec3(43758.5453, 23421.6361, 65426.6357));\n}\n\n// Also from NuSan's example. I tried other variations, but\n// this just seems to work better.\nfloat tick(float t, float d) {\n  \n  float m = fract(t/d);\n  m = smoothstep(0., 1., m);\n  m = smoothstep(0., 1., m);\n  return (floor(t/d) + m)*d;\n}\n\n// NuSan's cool camera tick function.\nfloat tickTime(float t){ return t*2. + tick(t, 4.)*.75; }\n\n\n// Camera movement. Adapted from NuSan's example.\nvoid cam(inout vec3 p, float tm, float tTime) {\n  \n    #ifdef CAM_ROTATION\n    p.xy *= r2(tm/4.);\n    p.xz *= r2(tm/2.);\n    #endif\n    \n    #ifdef CAM_SWING\n  \tp.xz *= r2(sin(tTime*.3)*.4);\n  \tp.xy *= r2(sin(tTime*.1)*2.);\n    #endif\n    \n}\n\n// Plane intersection: Old formula, and could do with some tidying up.\n// The tiny \"9e-7\" figure is something I hacked in to stop near plane \n// artifacts from appearing. I don't like it at all, but not a single \n// formula I found deals with the problem. There definitely has to be\n// a better way, so if someone knows of a more robust formula, I'd \n// love to use it.\nfloat rayPlane(vec3 ro, vec3 rd, vec3 n, float d){\n\n\n    float t = 1e8;\n    //float retval = 0.; // Inside or outside the object. Not used here.\n\n\tfloat ndotdir = dot(rd, n);\n     \n\tif (ndotdir < 0.){\n\t\n\t\tfloat dist = (-d - dot(ro, n) + 9e-7)/ndotdir;\t// + 9e-7\n   \t\t\n\t\tif (dist>0. && dist<t){ \n            t = dist; \n            //retval = 1.;\n\t\t}\n\t}\n    \n    return t;\n\n}\n\nfloat udBox(in vec2 p, in vec2 b){\n\treturn length(max(abs(p) - b + .1, 0.)) - .1;\n}\n\n// Used for polar mapping various shapes.\nfloat uvShape(vec2 p){\n    // Polar mapping a square wall.\n    p = abs(p);\n    return max(p.x, p.y);\n    \n    // Mapping hexagon walls.\n    //p *= r2(-3.14159/12.);\n    //p = abs(p);\n    //return max(p.x*.8660254 + p.y*.5, p.y);\n    \n    \n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n  \n    // Aspect correct screen coordinates.\n    vec2 uv = (fragCoord - iResolution.xy*.5)/iResolution.y;\n    \n\n    // Depth of field (DOF) amount, and the DOF distance. In this\n    // case, a figure of 3 will bring everything into focus three units \n    // down the tunnel, but camera blur things around it.\n    const float DOF = .05, DOFDist = 3.;\n    \n    // Global time, and tick time, which in this case is regular time, with\n    // a lurching tick on it. I think it's great, but it might not be for\n    // those who are prone to motion sickness.\n    float tm = iTime;\n    float tickTm = tickTime(tm);\n    \n    // Initial camera position. The tick time variable gives the camera a\n    // slight lurching motion along Z.\n    vec3 ca = vec3(0, 0, tickTm);\n    \n    \n    // Initialize the scene color to zero.\n     vec3 col = vec3(0);\n\n\n    // Taking a few samples, which is not much different to standard antialiasing. The main \n    // difference is that you set up your unit direction ray with UV coordinates randomly \n    // sampled around the pixel area. The average of all returned colors gives you a nice \n    // antialiased look... provided you take enough costly samples, of course. In this case, \n    // we're taking just 8 -- Not ideal, but good enough for the purpose of this example.\n    for(int j = 0; j<sampleNum; j++) {\n\n        // Pixel offset.\n        vec2 offs = hash22(uv + float(j)*74.542 + 35.877) - .5;\n\n        #ifdef MOTION_BLUR\n        // Motion blur: Just a simple temporal blending of samples. In case it isn't\n        // obvious, you're advancing global time a little with each sample, which results \n        // in frames further in time being blended with the present. You could go \n        // backwards instead, if the idea of looking into the future bothers you. :D\n        tm = iTime + float(j)*.05/float(sampleNum);\n        tickTm = tickTime(tm);\n        #endif\n \n        vec3 ro = vec3(0);\n        #ifdef DEPTH_OF_FIELD\n        // Depth of field. Spreading out the sample, according to screen depth.\n        ro.xy += offs*DOF;\n        vec3 r = normalize(vec3(uv - offs*DOF/DOFDist, 1));\n        #else\n        vec3 r = normalize(vec3(uv - offs/iResolution.y, 1));\n        #endif\n\n        // Camera movement. Rotation, swivle, etc.\n        cam(ro, tm, tickTm);\n        cam(r, tm, tickTm);\n        \n        \n        ro.z += ca.z;\n\n        // Alpha, for blending layers.\n        float alpha = 1.;\n\n        // Fog distance.\n        float fogD = 1e5;\n\n\n        // Reflective bounces. Just three here.\n        for(int i = 0; i<3; i++) {\n\n\n            // Tracing the four planes, then determining the closet.\n            // I'll tidy this up later.; \n            //\n            vec4 pl; // Vector storage for the four planes.\n            pl.x = rayPlane(ro, r, vec3(0, 1, 0), 1.); // Bottom.\n            pl.y = rayPlane(ro, r, vec3(0, -1, 0), 1.); // Top.\n            pl.z = rayPlane(ro, r, vec3(1, 0, 0), 1.); // Left.\n            pl.w = rayPlane(ro, r, vec3(-1, 0, 0), 1.); // Right.\n           \n            // Minimum plane distance.\n            float d = min(min(pl.x, pl.y), min(pl.z, pl.w));\n    \n            // Set the fog distance on the first pass.\n            if(i==0) fogD = d;\n\n            // Hit position.\n            vec3 p = ro + r*d;\n            // Determine the UV coordinates for texturing, and the normal,\n            // for lighting and other things.\n            //\n            // Set the normal and UVs to the bottom or top planes.\n            vec3 n = vec3(0,  pl.x<pl.y? 1 : -1, 0);\n            vec2 tuv = p.xz + vec2(0, n.y);\n\n            // If we've hit the side walls instead, change the normal and \n            // UVs accordingly.\n            if(min(pl.z, pl.w)<min(pl.x, pl.y)) {\n             \n                n = vec3(pl.z<pl.w? 1 : -1, 0, 0);\n                \n                tuv = p.yz + vec2(n.x, 0); // Left walls.\n            }\n\n            // Texture scaling for texturing.\n            const float sc = 12.;\n            tuv *= sc;\n            \n            \n            // Sample color.\n            vec3 sampleCol = vec3(1);\n            \n            // Grid square ID and local coordinates.\n            vec2 id = floor(tuv);\n            tuv -= id + .5;\n            \n   \n             /////\n            // Use the UV coordinates to create a whitish colored rounded box grid.\n            float patDist = udBox(tuv, vec2(.4));\n            // Use the square grid shape for shading.\n            float sh = clamp(.5 - patDist/.2, 0., 1.);\n       \n            // Subtle coloring.\n            vec3 sqCol = .85 + .3*cos((hash21(id + .2)*2.)*6.2831 + vec3(0, 1, 2));\n            sampleCol = mix(vec3(0), sqCol*sh, (1. - smoothstep(0., .005, patDist)));\n \n            ////\n            // Perform a squarish polar mapping (of sorts), read in to some textures, then\n            // color them up, etc.\n            //\n            // Quantized squarish polar mapping.\n            const vec2 txSc = vec2(2, 1./2.); // Texture scale.\n            vec3 ip3 = (floor(p*sc) + .0)/sc; // Quantizing... as opposed to continuous values.\n            float ang = atan(ip3.x, ip3.y)/6.2831; // Angle of grid cell from the tube center.\n            vec2 tnuv = vec2(uvShape(ip3.xy)*ang*txSc.x, ip3.z*txSc.y); // Square polar UVs.\n            //\n            // Smooth squarish polar mapping.\n            const vec2 txSc2 = vec2(1, 1./4.); // Texture scale.\n    \t\tvec3 p3 = mix(p, (floor(p*sc) + .0)/sc, .8); // Slightly smooth quantized values.\n            float ang2 = atan(p3.x, p3.y)/6.2831; // Angle of grid cell from the tube center.\n            vec2 tnuv2 = vec2(uvShape(p3.xy)*ang2*txSc2.x + p3.z*.075, p3.z*txSc2.y);  // Square polar UVs.\n\n            // Reading the texel values, and manipulating a bit. Note the squaring of the value,\n            // (tx *= tx) which is a rough sRGB to linear conversion.\n            vec3 tx = texture(iChannel0, fract(tnuv - .5 - vec2(iTime/(sc)/2., 0))).xyz; tx *= tx;\n            tx = mix(tx, vec3(dot(tx, vec3(.299, .587, .114))), .75);\n            tx = smoothstep(.1, .55, tx);\n\n            vec3 tx2 = texture(iChannel1, fract(tnuv2 - .5 - vec2(iTime/(sc)/2., 0))).xyz; tx2 *= tx2;\n            tx2 = smoothstep(.18, .5, tx2);//*vec3(1.1, 1, .9); \n            \n            // Apply the textures to the sample color. \n            sampleCol *= tx*tx2*4.; \n            \n            // Some fakish point lighting. \n            // Light direction vector. The light is 3 units up from the camera, which\n            // coincides with the depth of field distance.\n            vec3 ld = normalize(ca + vec3(0, 0, 3) - p);\n            float dif = max(dot(ld, n), 0.); // Diffuse.\n            float spe = pow(max(dot(reflect(ld, -n), -r), 0.), 8.); // Specular.\n            float fre = pow(max(1. - abs(dot(r, n))*.5, 0.), 1.); // Fresnel.\n            \n            sampleCol *= (dif + vec3(1, .9, .7)*spe*4. + vec3(.5, .7, 1)*fre);\n                \n            /*\n            // W23's chromatic effect. It looks good in his artsy black and white\n            // example, but there's too much color here for it to be effective.\n            \n            float patDistL = udBox(tuv - vec2(.05, 0), vec2(.4));\n            float patDistR = udBox(tuv - vec2(0, .05), vec2(.4));\n            sampleCol *= step(0., -vec3(patDistL, patDist, patDistR) - .025);\n            */\n            \n            // Applying some fog.\n            sampleCol *= 1.35/(1. + fogD*fogD*.05);\n         \n\n            \n            // Add the sample color to overall accumulated scene color.\n            //col += sampleCol*alpha*fre*exp(-fogD*.2);\n            col += sampleCol*alpha*fre;\n            \n            // Reduce the alpha factor by a bit and mix in the Fresnel factor as well.\n            alpha *= 0.9;\n\n   \n            // Calculate the reflection vector for the next pass.\n            \n            #ifdef PURE_REFLECTION\n            \n            // Pure reflection overide. It's definitely cleaner, but less interesting.\n            r = reflect(r,n);\n            \n            #else\n            \n            // Just some randomized reflection, based on certain heuristics. There are\n            // various ways to create a randomized relective vector, but it's mainly\n            // common sense. \n            float h = hash21(id)*smoothstep(0., .005, -patDist + .15);\n          \n            // Purely reflected vector.\n            vec3 ref = reflect(r,n);\n            // Random vector.\n            r = normalize(hash23(uv + float(j)*74.524 + float(i)*35.712) - .5);\n            // Mixing the purely reflected vector with the random vector according\n            // to some heuristics. In this case, a random opaque factor for the \n            // tile, the tile shade, pattern border, fog... I made it up as I \n            // went along. :)\n            r = normalize(mix(ref, r, (hash21(tuv)*.0 + h*.1*sh)*exp(-fogD*.05)));\n            \n            // Ensuring random reflection. I normally use other logic, but it works\n            // well enough in W23 and Nusan's examples, so it'll do. :)\n            r = dot(r, n)<0.? -r : r;\n            #endif\n\n            // Advance the position to the new hit point. Also be sure to bump\n            // the ray off the surface to avoid self collision... If I had a\n            // dollar for every time I've forgotten to do this... :)\n            ro = p + n*.0011;\n        }\n\n    }\n    \n    // Divide by the total number of samples.\n    col /= float(sampleNum);\n    \n\n    // Use this to tone down highlight extrema... However, if you like to live on\n    // the edge and burn your eyes, then leave it as is. :D\n    //col = 1. - exp(-col);\n    \n    \n    // Gamma correction and screen presentation.\n    fragColor = vec4(pow(max(col, 0.), vec3(0.4545)), 1);\n    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "texture",
                        "id": 3,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/95b90082f799f48677b4f206d856ad572f1d178c676269eac6347631d4447258.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "texture",
                        "id": 48,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/8979352a182bde7c3c651ba2b2f4e0615de819585cc37b7175bcefbca15a6683.jpg"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}