{
    "Shader": {
        "info": {
            "date": "1616067306",
            "description": "Storing a 2D distance field in a texture for much faster 2D realtime path tracing. Temporal camera reprojection is also utilized to generate the appearance of a much higher sampled image.",
            "flags": 32,
            "hasliked": 0,
            "id": "ssfGWM",
            "likes": 49,
            "name": "2D Path Tracer",
            "published": 3,
            "tags": [
                "2d",
                "global",
                "illumination",
                "truchet",
                "tracing",
                "trace",
                "path",
                "path",
                "denoise",
                "reprojection",
                "radiosity"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 1541
        },
        "renderpass": [
            {
                "code": "/*\n\n\t2D Path Tracer\n\t--------------\n    \n    A while ago, I posted what appeared to be a high sampled 2D path traced scene \n    running in realtime. With that particular example, I was more concerned with the \n    2D camera reprojection and the realtime field itself, so I put the lighting in as \n    an afterthought. Anyway, this is another version that uses a static field and a \n    more traditional path traced coloring procedure (emitters, throughput, etc) in \n    order to better display the results.\n\n\tTechnically speaking, this is a low-sample path traced rendering of a 2D distance \n    field that has been stored in the channels of a screen buffer, then camera \n    reprojected a few times to give the impression of a much higher sampling. The 2D \n    distance field itself has been encoded into one of the faces of the cube map.    \n    \n    Just for the record, I prefer the aesthetic of noisy, single pass, low sampled 2D \n    path traced imagery, which require far less work to produce. Unfortunately, very\n    few people feel the same way, which means I've had to code up this multitab mess \n    in order to avoid hurting people's eyes. :D\n    \n    Additionally, there are a few compiler directives in the \"Common\" tab to try that \n    might help.\n\n    By the way, this can be extended to 3D situations as well, and I have an example \n    ready to go. In the meantime, IQ has an awesome 3D gloabally illuminated example, \n\tcomplete with denoising camera reprojection on Shadertoy that's well worth the \n    look, especially since examples like that are thin on the ground.\n\n\n    Useful links:\n\n\t// 3D temporal reprojection: IQ puts up a lot of difficult to find code with\n    // very little fanfare. This is one example.\n    Some boxes - iq\n    https://www.shadertoy.com/view/Xd2fzR\n\n\n*/\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    // Retrieving the stored color.\n    vec4 col = texture(iChannel0, fragCoord/iResolution.xy);\n    \n    // This particular function is a modified version of Narkowicz's\n    // HDR to LDR function. There's more to it, but for me, it tones down \n    // heavy lighting. In this case, however, I prefer the HDR look on this\n    // particular 2D scene, so I'm leaving it out by default. In general\n    // though, you should be using it.\n    //col.xyz = ACESFilm(col.xyz);\n\n    // Gamma correction and screen presentation.\n    fragColor = pow(col, vec4(.4545));\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// Show the outline of the 2D field. I like it, but I think it spoils the\n// illusion a little. By the way, changing this requires a time reset, or\n// pressing the back button.\n// Default - Truchet: 0, Repeat circles: 1.\n#define SCENE 0\n\n// Color scheme: Red\\Blue: 0, Multicolor: 1\n#define COLORSCHEME 0\n\n// Display the inside field color. I'm not sure if it strictly adheres\n// to the rules, but I like it. If you turn it off, try it with the\n// outline (directive below) showing.\n#define SHOWINSIDE\n\n// Show the outline of the 2D field. I like it, but I think it spoils the\n// illusion a little.\n//#define OUTLINE\n\n// Show the background tile grid.\n#define GRID\n\n// Use camera reprojection. It's worth turning this off to see what you\n// end up with without it... I happen to like the noise aesthetic, but\n// not too many people do, which is why you don't see a lot of 2D\n// path tracing examples.\n#define REPROJECTION\n\n// Distance field object ID.\nvec2 gIP;\n\n// Object ID.\nfloat gObjID;\n\n// Grid pattern repeat scale. Baking wrapped distance fields into textures can be \n// a little fiddly. Basically, the pattern is wrapped on a 32 by 32 unit basis.\nfloat repSc = 16.; \n\n\n\n// Standard 2D rotation formula.\nmat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n\n\n// IQ's vec2 to float hash.\nfloat hash21(vec2 p){ p = mod(p, 1024.); \n                      return fract(sin(dot(p, vec2(27.619, 57.583)))*43758.5453); }\n\nvec2 hash22(vec2 p) {\n    //return vec2(0);\n    p = mod(p, 1024.);\n    return fract(sin(vec2(dot(p, vec2(12.989, 78.233)), dot(p, vec2(41.898, 57.263))))\n                      *vec2(43758.5453, 23421.6361));\n}\n\n// IQ's vec2 to float hash, but with a repeat factor. If you repeat random\n// textures to wrap, then you need to wrap the random functions.\nfloat hash21Rep(vec2 p){ \n    p = mod(p, repSc); \n    return fract(sin(dot(p, vec2(27.619, 57.583)))*43758.5453); \n}\n\nvec2 hash22Rep(vec2 p) {\n    //return vec2(0);\n    p = mod(p, repSc);\n    return fract(sin(vec2(dot(p, vec2(12.989, 78.233)), dot(p, vec2(41.898, 57.263))))\n                      *vec2(43758.5453, 23421.6361));\n}\n\n// Believe it or not, the simple one-line function below took me ages to figure out. The \n// only refrences to it seem to be from some Microsoft documentation somewhere, because it's \n// all written in some obscure way that involves the term, \"fract(p)*2. - 1.,\" etc.\n//\n// Anyway, the following should have been obvious to me, but it wasn't: A unit cube centered \n// on a grid has six faces with a center at vec3(0), and 8 vertices at coordinates, \n// vec3(-.5, -.5, -.5), vec3(-.5, -.5, .5), etc. Therefore, using very basic UV mapping logic, \n// the faces will be the following:\n//\n// Left face: \n// // Wrapping and centering coordinates on the YZ plain: \n// p.yz = fract(p.yz) - .5;\n// // The X coordinate is at \"-.5\".\n// p.x = -.5;\n// // Texture coordinate. \n// vec4 tx = texture(texChannel, vec3(-.5, fract(p.yz) - .5));\n//\n// All faces follow the same logic, with a bit of UV flipping to get things facing the right \n// way, etc. Using uv = fract(uv) - .5:\n//\n// The four cube sides - Left, back, right, front.\n// NEGATIVE_X, POSITIVE_Z, POSITIVE_X, NEGATIVE_Z\n// vec3(-.5, uv.yx), vec3(uv, .5), vec3(.5, uv.y, -uv.x), vec3(-uv.x, uv.y, -.5).\n//\n// Bottom and top.\n// NEGATIVE_Y, POSITIVE_Y\n// vec3(uv.x, -.5, uv.y), vec3(uv.x, .5, -uv.y).\n//\n//\n// From what I've noticed, the size of the cube you use doesn't seem to matter -- I'm \n// assuming this is due to an internal normalization process. Therefore, to save extra \n// calculations (which matter when doing 3D stuff), you may as well use the unit cube \n// figures above -- instead of vec3(fract(p)*2. - 1., 1), vec3(fract(p) - .5)*n, n), etc.\n \n\n// Reading in the texture from the right face of the cube: I chose this because it \n// writes more easily, but you can read from any, or as many, faces you'd like. I'm\n// assuming that all sides index into memory at the same rate, otherwise you'd have to\n// take that into consideration when favoring one side or the other.\n//\n// By the way, \"p\" is simply your \"uv\" coordinates, which are usually: \n// uv = fragCoord/iResolution.y, but could represent cube sides, like p.xz, etc.\nvec4 tx(samplerCube tx, vec2 p){    \n\n    return texture(tx, vec3(fract(p) - .5, .5));\n}\n\n// IQ's box function, with modified smoothing element.\nfloat sBoxS(in vec2 p, in vec2 b, in float rf){\n  \n  vec2 d = abs(p) - b + rf;\n  return min(max(d.x, d.y), 0.) + length(max(d, 0.)) - rf;\n    \n}\n\n// Krzysztof Narkowicz's HDR color to LDR space using the ACES operator.\n// https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve\n//\n// I could be wrong, but I found this to be twice as strong as the original,\n// so needed to compensate. However, it's not my area, so if Knarkowicz sees\n// this at some stage, hopefully, he might shed some light. On a side note,\n// Knarkowicz (user name) has some awesome examples on Shadertoy, if you feel \n// like looking them up. :)\n \nvec3 ACESFilm(in vec3 x){\n    // Different numbers to the original: They work here, but might not\n    // be suitable for other examples. Having said that, these numbers\n    // match more closely to Stephen Hill's original.\n    float tA = .6275, tB = .015, tC = .6075, tD = .295, tE = .14;\n    return clamp((x*(tA*x + tB))/(x*(tC*x + tD) + tE), 0., 1.);\n}\n\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "\n#if SCENE == 0\n// Default scene, which is just a basic Truchet decoration.\nvec4 dfGridObjects(vec2 p, vec2 ip, float sc){\n    \n    // Cell ID -- We're rendering to a texture, so there's\n    // wrapping involved.\n    ip = mod(ip, repSc);\n    \n    // Float and vec2 random samples.\n    float rnd = hash21Rep(ip + .11);\n    vec2 rnd2 = hash22Rep(ip + .21);\n    \n    // Used to move the arcs in and out.   \n    float flip = 1.;\n    if(mod(ip.x + ip.y, 2.)<.5) flip = -flip;\n    if(rnd<.5) flip = -flip;\n \n    // Cell border.\n    float bord = sBoxS(p, vec2(.5*sc), 0.);\n\n    // Random tile flip.\n    if(rnd<.5) p.y = -p.y;\n\n    // Arc on opposite diagonals.\n    float d = min(length(p - .5*sc), length(p + .5*sc)) - (.5 - .05*flip)*sc;\n    d = abs(d) - .07*sc;\n    \n    // Clip to the cell borders, and chop a bit off while we're at it.\n    d = max(d, bord + .125*sc);\n    \n    // Metallic circles.\n    float rnd3 = hash21Rep(ip + .54)*.1 + .1;\n    float bl =  min(length(p - .5*sc), length(p + .5*sc)) - rnd3*sc;\n    \n    // Take out some of the circles in a checkered fashion\n    if(flip>0.) bl = 1e5; // bl += rnd3*sc/2.;\n    \n    // Add the circles to the arcs.\n    d = min(d, bl);\n\n    // Add some lights, then randomly shift them out along the \n    // diagonal. The idea is to produce some random light play.\n    float rnd4 = hash21Rep(ip + .67);\n    p -= rot2(3.14159/2.)*vec2(rnd4 - .5)*.75*sc;\n\n    // Circular light objects at random sizes. By the way, these are\n    // just regular objects, but the main renderer will read their\n    // object ID, then flag them as emitters.\n    float d2 = length(p - .0*sc) - .05*sc;\n    if(mod(ip.x + ip.y, 2.)<.5) d2 += .03*sc;  //1e5;\n      \n    // Object ID. The circles will be the emitters.\n    float objID = d<d2? 0. : 1.;\n    \n    // Cell ID.\n    gIP = ip;\n    \n    // Minimum object, cell ID and object ID.\n    return vec4(min(d, d2), ip, objID);\n}\n\n#else\n// Alternate repeat circles.\nvec4 dfGridObjects(vec2 p, vec2 ip, float sc){\n    \n    // Cell ID -- We're rendering to a texture, so there's\n    // wrapping involved.\n    ip = mod(ip, repSc);\n  \n    // Float and vec2 random samples.\n    float rnd = hash21Rep(ip + .11);\n    vec2 rnd2 = hash22Rep(ip + .21);\n    \n    // Offset circles in each cell. \n    float sz = (.1 + rnd*.3)*sc;\n    float mx = max(.48 - sz/sc, 0.)*2.;\n    float d  = length(p - (rnd2 - .5)*mx*sc) - sz;\n    /*\n    // Rotated capsules... Needs work, so circles it is. :)\n    float sz = sc/2.5;\n    float mx = max(.48 - sz/sc, 0.)*2.;\n    p *= rot2((rnd - .5)*6.2831); //rot2(floor(rnd3*16.)/16.*6.2831);\n    float d = sBoxS(p - (rnd2 - .5)*mx*sc, vec2(sc/2.5, sc/6.), .15*sc);\n    */\n    \n    // Setting some for the cell objects as emitters.\n    float hOffs = mod(floor((ip.y - .5)/2.), 2.)*2.;\n    bool light = (mod((ip.x - .5) + hOffs, 4.)<.5 && mod((ip.y - .5), 2.)<.5)? true : false;\n    \n    // Object ID. The circles will be the emitters.\n    float objID = light? 1. : 0.;\n    \n    // Cell ID.\n    gIP = ip;\n    \n    // Return the scene distance, cell ID and object ID.\n    return vec4(d, ip, objID);\n}\n\n#endif\n\n\n// Iterating through grid neighbors at a particular scale. Fiddly coding, but necessary.\nvec4 dfNeighbors(vec2 q){\n\n    \n    // Scale, ID, and distance field storage.\n    float sc = 1./repSc;\n    float d = 1e5;\n    float oID = 0.;\n    vec2 id = vec2(0);\n    \n    \n    // This is a rendering of a repeat grid of object. Sometimes, you need to consider\n    // immdiate neighbors, which is fine.\n    //\n    // However, if you wish to bounce light around, things can be affected by objects that \n    // are several cells away. In this case, several on either side. This means checking\n    // a crazy number of cells -- The kind of numbers that would fry your GPU. Thankfully,\n    // we can do this once at runtime, and store the overall distance field in a texture,\n    // or one of the cube map faces, which is what we're doing here.\n    \n    int iters = min(0, iFrame) + 8;\n    for(int j = 0; j<=iters; j++){\n        for(int i = 0; i<=iters; i++){\n\n            vec2 p = q;\n            vec2 ip = floor(p/sc + (vec2(i, j) - float(iters)/2.)*sc) + .5;\n            \n        \tp -= ip*sc;\n            \n            vec4 dij = dfGridObjects(p, ip, sc);\n          \n            if(dij.x<d) {\n                d = dij.x;\n                id = dij.yz;//gIP;\n                oID = dij.w;//objID;\n            }\n \n        }\n    }\n    \n    return vec4(d, id, oID);\n    \n}\n\n\n\n\nvoid mainCubemap(out vec4 fragColor, in vec2 fragCoord, in vec3 rayOri, in vec3 rayDir){\n    \n    \n    // UV coordinates.\n    //\n    // For whatever reason (which I'd love expained), the Y coordinates flip each\n    // frame if I don't negate the coordinates here -- I'm assuming this is internal, \n    // a VFlip thing, or there's something I'm missing. If there are experts out there, \n    // any feedback would be welcome. :)\n    vec2 uv = fract(fragCoord/iResolution.y*vec2(1, -1));\n  \n    // Pixel storage.\n    vec4 col;\n   \n    // Initial conditions -- Performed just the once upon initialization.\n    //if(abs(tx(iChannel0, uv).w - iResolution.y)>.001){\n    //\n    // IQ gave me the following tip, which saved me a heap of trouble and an extra channel. \n    // I'm not sure how he figured this out, but he pretty much knows everything. :D\n    //\n    // If the texture hasn't loaded, or if we're on the first frame, initialize whatever \n    // you wish to initialize. In this case, I'm precalculating an expensive distance\n    // field and storing it in one of the cube map faces.\n    if(textureSize(iChannel0, 0).x<2 || iFrame<1){\n        \n        // INITIAL CONDITIONS.\n       \n        // Construct a distance field whilst seting the wrapping value, then store it.\n        //repSc = 16.;\n        col = dfNeighbors(uv); // Distance field in X, and object IDs in YZ.\n\n        \n    }\n    else col = tx(iChannel0, uv);\n\n\n    // Store in the cube map.\n    fragColor = vec4(col);\n    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    }
                ],
                "name": "Cube A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 41
                    }
                ],
                "type": "cubemap"
            },
            {
                "code": "\n\n// Reading the distance field from the texture map.\nfloat map(vec2 p){\n\t// Reading distance fields from a texture means taking scaling into\n    // consideration. If you zoom coordinates by a scalar (4, in this case), \n    // you need to scale the return distance value accordingly... Why does \n    // everything have to be so difficult? :D\n    const float sc = 4.;\n    vec4 tex = tx(iChannel0, p/sc);\n    gIP = tex.yz; // The object ID is stored in the YZ channels..\n    gObjID = tex.w;\n    return tex.x*sc;\n}\n\n\n\n// Tracing variables.\n#define FAR 8.\n#define DELTA .001\n#define RSF 1.\n\nfloat trace(vec2 o, vec2 r){\n    \n    // Raymarching.\n    float d, t = 0.;\n    \n    \n    // Just 16 iterations here, but I'd preffer more: If speed and complilation time is \n    // a concern, choose the smallest number you can get away with. Apparently, swapping \n    // the zero for min(0, iFrame) can force the compliler to not unroll the loop, so \n    // that can help sometimes too.\n    for(int i = min(0, iFrame); i<16; i++){\n        \n        // Surface distance.\n        d = map(o + r*t);\n        \n        // In most cases, the \"abs\" call can reduce artifacts by forcing the ray to\n        // close in on the surface by the set distance from either side. Because this is\n        // two dimensional, it appears to be necessary -- rather than an option -- to avoid \n        // negative values... I haven't thought it through enough, but basically, 2D \n        // raymarching, or whatever you wish to call the process, works differently.\n        //\n        // Displaying the inside 2D filed colors. I probably doesn't strictly adhere to\n        // 2D path tracing rules, but I like it visually.\n        #ifdef SHOWINSIDE\n        if((d<0. && abs(d)<DELTA) || t>FAR) break;\n        #else\n        if(d<0. || t>FAR) break;\n        #endif\n        \n        // No ray shortening is needed here, and in an ideal world, you'd never need it, but \n        // sometimes, something like \"t += d*.7\" will be the only easy way to reduce artifacts.\n        t += d*RSF;\n    }\n    \n    t = min(t, FAR); // Clipping to the far distance, which helps avoid artifacts.\n    \n    return t;\n    \n}\n\n\n// Square grid.\nfloat gridField(vec2 p){\n    \n    p = abs(p - floor(p) - .5);\n    return abs(max(p.x, p.y) - .5);\n}\n\n\n// Standard 2D normal function.\nvec2 nr(in vec2 p){\n    \n\tconst vec2 e = vec2(.001, 0);\n    // Four taps.\n\t//return normalize(vec2(map(p + e.xy) - map(p - e.xy), \n    //                      map(p + e.yx) - map(p - e.yx)));\n    // Three taps... I tend to prefer extra samples for normal\n    // calculations, but this should be fine for this example.\n    float m = map(p);                    \n    return normalize(vec2(map(p + e.xy) - m, map(p + e.yx) - m));\n}\n\n// Translating the camera.\nvec2 getCamTrans(float t){ return vec2(sin(t/32.)/8., -t/24.); }\n\n// Rotating the camera.\nmat2 getCamRot(float t){\n     \n    //return rot2(0.);\n    return rot2(cos(t/12.)/8.);\n}\n\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    // Aspect correct screen coordinates.\n\tvec2 uv = (fragCoord - iResolution.xy*.5)/iResolution.y;\n    \n    \n    \n    // The overall scene color.\n    vec3 col = vec3(0);\n    \n   \n    vec2 cam = getCamTrans(iTime);\n    mat2 camRot = getCamRot(iTime);\n    \n\n    vec2 rd;\n    \n \n    // Rotating and moving the canvas. A 2D \"to\" and \"from\" setup would be better, but this\n    // will do for the purpose of the demonstration.\n    uv = uv*camRot - cam;\n    \n    // Making a copy of the rotated coordinates for later use.\n    vec2 rUV = uv;\n    \n    float sf = 4./iResolution.y;\n    float grid = gridField(uv*repSc/4.);\n    \n    \n \n \n    // Number of samples and the number of reflective bounces: Without camera\n    // reprojection techniques, you'd need about 64 samples at least, which\n    // would bring even the best machine to a crawl.\n    const int SAMPLES = 8;\n    #if SCENE == 0\n    const int BOUNCES = 3;\n    #else\n    const int BOUNCES = 2;\n    #endif\n    \n    \n    //vec3 accum = vec3(0);\n    \n    // Sample loop.\n    for (int i =0; i < SAMPLES; i++){\n        \n        // Sample number in float form.\n        float fi = float(i);\n        \n        // Random time.\n        float fTm = fract(iTime*.92397 + float(iFrame + 1));\n        \n        // The initial jittered ray origin or camera point for this sample.\n        vec2 ro = uv + (hash22(uv + fi + fTm + .35) - .5)/iResolution.y*1.;\n        \n        \n        // The initial random unit direction ray for this sample.\n        float ti = (fi + hash21(uv + fi + fTm))*6.2831/float(SAMPLES);\n        rd = vec2(cos(ti), sin(ti));\n        \n        // The sample color.\n        vec3 sCol = vec3(0);\n        // Emissive color: I'm calulating this on the fly, but it can be\n        // set before entering the loop.\n        vec3 emissive = vec3(0);\n        // Throughput, which is analogous to a record of the scene's \n        // accumulative transferred color history. A lot of people use\n        // Demofox's path tracing code, and he uses this variable name, \n        // so if it's good enough for him... :) By the way, his path\n        // tracing articles are worth the read, for anyone interested.\n        vec3 throughput = vec3(1);\n        // Surface roughness.\n        float roughness = 0.;\n        // Transfer power: It's kind of redundant here, since I'm not\n        // reducing it after each bounce, but it's here for completeness.\n        float ePower = 1.;\n        \n        // 2D distance field outline variable.\n        float outline = 1e5;\n        \n        \n        // Distance field copy.\n        float mp = map(ro);\n        \n        // Grid line distance.\n        float gridL = max(grid, -mp);\n        \n        // Bounce loop.\n        for(int j = 0; j<BOUNCES; j++){\n            \n            // Bounce trace.\n            float t = trace(ro, rd);\n            vec2 svID = gIP; // Saving the ID here.\n   \n            float objID = gObjID;\n            \n            // Bounce number in float form.\n            float fj = float(j);\n            \n            // Color for this bounce.\n            vec3 bCol = vec3(0);\n            vec2 sp = ro + rd*t;\n            \n            if(t<FAR){\n                \n                // The randomly distributed unit direction vector: For 2D stuff, this seems \n                // to be the accepted way to go about it. Basically it's just a normalized\n                // vector in a random circular direction, which makes sense on a 2D plane.\n                float fij = fi*float(BOUNCES) + fj;\n                float tij = (fij + hash21(uv + fij + fTm))*6.2831/float(SAMPLES*BOUNCES);\n                vec2 rndRD = vec2(cos(tij), sin(tij));\n                \n                // 2D surface normal... In this case, numerically calculated, but analytical\n                // calculations are possible as well.\n                vec2 sn = nr(sp); // Normal.\n                 \n            \n                bool light = objID == 1.? true : false;\n                \n                // Set the object color.\n                #if COLORSCHEME == 0\n                vec3 oCol = hash21(svID + .25) < .5? vec3(.6, .8, 1) : vec3(1, .8, .6);\n                if(hash21(svID + .34)<.2 && !light) oCol = vec3(1.5, .75, .5);\n                #else\n                float rndC = hash21(svID + .18);\n                vec3 oCol = (.65 + .35*cos(rndC*6.2831/2.1 + vec3(0, 1, 2) - 2.1));\n                #endif\n       \n                \n                // Set the emissive color.\n                emissive = light? vec3(3)*oCol : vec3(0);\n                //if(hash21(svID + .34)<.5) emissive = emissive.zyx;\n                \n                // Dropping the emissive power with each pass.\n                //emissive *= ePower;\n                //ePower *= .75;\n                \n                // Object roughness. As you'd imagine, smoother objects have less roughness.\n                roughness = light? .1 : .02;\n \n                // Not normally necessary, but keeps a copy of the field values.\n                if(j==0){\n                 \n                    \n                    \n                    #ifdef OUTLINE\n                    if(!light) outline = mp;\n                    #endif\n   \n                }\n           \n                // Color for this particular bounce.\n                bCol = oCol; \n                \n               \n            \n                vec2 refl = reflect(rd, sn);\n                //if(dot(rndRD, sn)>0.) rndRD = -rndRD;\n                // Mostly reflective, but adding in a little roughness.\n                //rd = normalize(mix(reflect(rd, sn), rndRD, roughness)); \n                rd = mix(rndRD, refl, step(0., hash21(uv + vec2(fi*53.87, fj*137.65)) - roughness)); \n\n                // Updating the ray origin to the hit point, then bumping the ray\n                // off the surface to avoid self collisions.\n                ro = sp + sn*DELTA*1.1;\n\n            } \n            \n             \n            // Adding the bounce color using standard path tracing rules... I'm\n            // not sure how well it translate to the 2D form, but it looks \n            // interesting, so it'll do. :)\n            //\n            // Adding the light and surface color history... You could get more \n            // technical than that, but that's basically what you're doing. :)\n            sCol += emissive*throughput;\n            // Applying the currect bounce color to the path throughput weighting.\n            throughput *= bCol;\n            \n        }\n        \n        #ifdef GRID\n        // Grid lines -- Needs to be applied in overlay form.\n        sCol = mix(sCol, sCol*1.25, 1. - smoothstep(0., sf*3., gridL - .015));\n        sCol = mix(sCol, sCol/2.5, 1. - smoothstep(0., sf, gridL - .005)*.7);\n        #endif \n        \n        #ifdef OUTLINE\n        // Display the 2D field outline. It needs to be applied to each sample\n        // in overlay form. Applying a dark border inside the path tracing loop\n        // effects the overall color.\n        \n            #ifdef SHOWINSIDE\n            const float outer = 1.6;\n            const float inner = .1;\n            #else\n            const float outer = .5;\n            const float inner = 5.;\n            #endif\n        \n        sCol = mix(sCol, sCol*outer, 1. - step(0., abs(outline - .003) - .006));\n        sCol = mix(sCol, sCol*inner, 1. - step(0., abs(outline - .00125) - .0025));\n        \n        /*\n        // Flat color... Not for me. :)\n        sCol = mix(sCol, vec3(0), 1. - step(0., outline - .006));\n        sCol = mix(sCol, vec3(1, .8, .6), 1. - step(0.,outline));\n        */\n        #endif \n        \n        \n        // Add the sample color.\n        col += sCol;\n        \n    }\n    \n    \n    // Divide by the sample number.\n    col /= float(SAMPLES); \n    \n    //col = min(col, 1.);\n    \n    \n    \n    #ifdef REPROJECTION\n\n    // Camera reprojection. This is basically the crux of the example, and as you \n    // can see, it's not that involved. In essence, we're calculating where we \n    // believe the previous frame should be placed on the sceen in relation to the\n    // new one -- Effectively, we'd like to place it directly under the new one. \n    // To do that, we index into the stored buffer at the current position minus \n    // the frame to frame camera difference.\n    //\n    // On a side note, I think the calculations are correct, but it's been a while \n    // since I've done this, so if there's something that doesn't look quite right,\n    // it probably isn't... And feel free to let me know that. It's the only way\n    // I'll learn not to be stupid. :D\n    \n    // Recalculating the UV coordinates.\n    uv = (fragCoord - iResolution.xy*.5)/iResolution.y;\n   \n    // Frame to frame camera translation difference.\n    vec2 camDelta = getCamTrans(iTime - iTimeDelta);\n    vec2 camOffs = -(camDelta - cam);\n    \n    // Frame to frame camera rotation difference.\n    mat2 rotDelta = getCamRot(iTime - iTimeDelta);\n    vec2 rotOffs = -(rotDelta*uv - camRot*uv);\n    \n    \n    // Offsetting the UV coordinates accordingly, then projecting to the current\n    // screen coordinates, which have to range from zero to one along X and Y.\n    vec2 cuv = (uv - rotOffs - camOffs)*vec2(iResolution.y/iResolution.x, 1)  + .5;\n    \n    // Two differently rotated-translated rectangles are more than likely not going\n    // to line up, so you need to check boundaries. You might note a bit of smudging\n    // on the screen borders. Usually, your offscreen buffer would be larger, or the\n    // onscreen buffer will be smaller. Basically, I could put a screen border around\n    // everything, but I don't think it's that noticeable.\n    if(cuv.x<0. || cuv.x>1.) cuv.x = uv.x*iResolution.y/iResolution.x + .5;\n    if(cuv.y<0. || cuv.y>1.) cuv.y = uv.y + .5;\n    vec3 tCol = texture(iChannel1, cuv).xyz;\n    \n    \n    // Mixing in the new frmae with the previous one. In fact, we're cycling about\n    // 8 screens. This effectively gives you 8 times the sampling. So, if your \n    // original sample count is just 8, this would boost it to 64. The reason you\n    // don't go too high is that temporal reprojection is just an estimation, so\n    // eventually, temporal screen lag will catch up with you.\n    const float totTimeFrames = 12.;\n    col = mix(tCol, col, 1./totTimeFrames);\n    \n    #endif\n    \n    // Output to the buffer.\n    fragColor = vec4((max(col, 0.)), 1);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "cubemap",
                        "id": 41,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/a//media/previz/cubemap00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}