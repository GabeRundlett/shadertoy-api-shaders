{
    "Shader": {
        "info": {
            "date": "1719237253",
            "description": "A small demo illustrating an approximation of goniochromatic Fresnel reflectance in iridescent car paint materials. Drag the mouse to look around. Refer to Buffer B for details. Bonus: Enable \"RAINBOW_VOMIT\" in Buffer B for more aggressive iridescence. :D",
            "flags": 32,
            "hasliked": 0,
            "id": "mdSyWd",
            "likes": 71,
            "name": "Iridescent Car Paint",
            "published": 3,
            "tags": [
                "sdf",
                "paint",
                "pbr",
                "iridescence",
                "car",
                "iridescent",
                "clearcoat",
                "goniochromism"
            ],
            "usePreview": 1,
            "username": "piyushslayer",
            "viewed": 1801
        },
        "renderpass": [
            {
                "code": "/**\n    A small demo illustrating an approximation of goniochromatic fresnel reflectance in \n    iridescent car paint materials based on the paper: \"A Practical Extension to Microfacet \n    Theory for the Modeling of Varying Iridescence\" by Laurent Belcour (Unity Technologies)\n    & Pascal Barla (Inria). Drag the mouse to look around. For more details, look in Buffer B.\n*/\n\n#define TONEMAP 1\n#define GAMMA_CORRECT 1\n#define EXPOSURE_SCALE 0.75\n\nconst float GAMMA = 2.2;\n\n/**----------------------------------------------------------------\n\n        *** ACES tonemap ***\n   \n-------------------------------------------------------------------*/\n\n// From: https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/\nvec3 ACESFilmicCurve(vec3 x)\n{\n    float a = 2.51f;\n    float b = 0.03f;\n    float c = 2.43f;\n    float d = 0.59f;\n    float e = 0.14f;\n    return clamp((x * (a * x + b)) / (x * (c * x + d) + e), 0.0f, 1.0f);\n}\n\n/**----------------------------------------------------------------\n\n        *** Lens Flare (from shadertoy.com/view/XdfXRX) ***\n   \n-------------------------------------------------------------------*/\n\n#define ORB_FLARE_COUNT\t8\n#define DISTORTION_BARREL 1.3\n\nvec2 GetDistOffset(vec2 uv, vec2 pxoffset)\n{\n    vec2 tocenter = uv.xy;\n    vec3 prep = normalize(vec3(tocenter.y, -tocenter.x, 0.0));\n    \n    float angle = length(tocenter.xy) * 2.221 * DISTORTION_BARREL;\n    vec3 oldoffset = vec3(pxoffset, 0.);\n    \n    vec3 rotated = oldoffset * cos(angle) + cross(prep, oldoffset)\n        * sin(angle) + prep * dot(prep, oldoffset) * (1. - cos(angle));\n    \n    return rotated.xy;\n}\n\nvec3 Flare(vec2 uv, vec2 pos, float dist, float size)\n{\n    pos = GetDistOffset(uv, pos);\n    \n    float r = max(0.01 - pow(length(uv + (dist - 0.05) * pos), 2.4) * (1.0 / (size * 2.0)), 0.0) * 6.0;\n\tfloat g = max(0.01 - pow(length(uv +  dist         * pos), 2.4) * (1.0 / (size * 2.0)), 0.0) * 6.0;\n\tfloat b = max(0.01 - pow(length(uv + (dist + 0.05) * pos), 2.4) * (1.0 / (size * 2.0)), 0.0) * 6.0;\n    \n    return vec3(r, g, b);\n}\n\nvec3 Ring(vec2 uv, vec2 pos, float dist)\n{\n    vec2 uvd = uv * (length(uv));\n    \n    float r = max(1.0 / (1.0 + 32.0 * pow(length(uvd + (dist - 0.05) * pos), 2.0)), 0.0) * 0.25;\n\tfloat g = max(1.0 / (1.0 + 32.0 * pow(length(uvd +  dist         * pos), 2.0)), 0.0) * 0.23;\n\tfloat b = max(1.0 / (1.0 + 32.0 * pow(length(uvd + (dist + 0.05) * pos), 2.0)), 0.0) * 0.21;\n    \n    return vec3(r, g, b);\n}\n\nvec3 LensFlare(vec2 uv, vec2 pos, float brightness, float size)\n{\n\t\n    vec3 c = Flare(uv, pos, -1.0,       size) * 3.0;\n    c +=     Flare(uv, pos,  0.5, 0.8 * size) * 2.0;\n    c +=     Flare(uv, pos, -0.4, 0.8 * size);\n    \n    c +=     Ring(uv, pos, -1.0) * 0.5 * size;\n    c +=     Ring(uv, pos,  1.0) * 0.5 * size;\n    \n    return c * brightness;\n}\n\nvec2 GetLightPositionNDC(in vec2 fragCoord, in vec4 cachedCameraAngles)\n{\n    mat4 worldToViewMatrix = GetCameraWorldToView(cachedCameraAngles.zw);\n                        \n    vec3 lightPositionVS = (LIGHT_POSITION * worldToViewMatrix).xyz;\n    vec2 lightPositionNDC = CAMERA_ZOOM * lightPositionVS.xy / lightPositionVS.z;\n    lightPositionNDC = lightPositionNDC * vec2(iResolution.y / iResolution.x, 1.0);\n    return lightPositionNDC;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy;\n    vec2 halfNdc = (fragCoord - 0.5 * iResolution.xy) / iResolution.y;\n    // Normalized camera angles in range [0.0, 1.0], xy - history, zw - current frame.\n    vec4 cachedCameraAngles = texelFetch(iChannel1, ivec2(0), 0);\n    \n    vec3 linearColor = texelFetch(iChannel0, ivec2(fragCoord), 0).xyz;\n    \n    vec2 lightPositionNDC = GetLightPositionNDC(fragCoord, cachedCameraAngles);\n    \n    if (lightPositionNDC.y > 0.0)\n    {\n        linearColor += LensFlare(halfNdc * 4.0, lightPositionNDC, 0.64, 8.0);\n    }\n    \n    fragColor = vec4(\n\n#if GAMMA_CORRECT\n    pow(\n#endif\n\n#if TONEMAP\n    ACESFilmicCurve(\n#endif\n\n     linearColor\n    \n#if TONEMAP\n    * EXPOSURE_SCALE)\n#endif\n\n#if GAMMA_CORRECT\n    , vec3(1.0 / GAMMA)), 1.0);\n#endif    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/**\n*  Common Stuff\n*/\n\n#define PI                            3.1415926535\n#define TWO_PI                        6.2831853071\n#define HALF_PI                       1.5707963267\n#define QUARTER_PI                    0.7853981633\n#define PI_INV                        0.3183098861\n#define SMOL_EPS                      0.0005\n#define EPS                           0.005\n#define BIG_EPS                       0.05\n#define FLT_MAX                       3.402823466e+38\n\n#define Square(x)                     (x*x)\n#define Saturate(x)                   clamp(x, 0.0, 1.0)\n#define Min3(x, y, z)                 min(x, min(y, z))\n#define Max3(x, y, z)                 max(x, max(y, z))\n#define RemapTo01(x)                  (x * 0.5 + 0.5)\n#define SmoothAbs(x, k, offset)       (sqrt(x * x + k * k) - offset)\n#define ToRadian(value)               (value / 180.0 * PI)\n\n#define TAA_ENABLED 1\n\n#if TAA_ENABLED\n    #define CAS_FILTER\n#endif\n\n// Camera constants\nconst float CAMERA_FAR            = 20.0;\nconst float CAMERA_RADIUS         = 5.0;\nconst float CAMERA_ZOOM           = tan(ToRadian(52.5)); // zoom = tan(fov * 0.5), where fov is in degrees\nconst vec3  CAMERA_UP             = vec3(0.0, 1.0, 0.0);\nconst vec3  CAMERA_TARGET         = vec3(0.0);\nconst vec4  LIGHT_POSITION        = vec4(-25.0, 75.0, -15.0, 1.0);\n\n// Halton (2, 3) sequence generate offline for camera jitter.\nconst vec2 HaltonSequence[16u] = vec2[](\n    vec2( 0.269531, -0.158436),\n    vec2(-0.355469,  0.174897),\n    vec2( 0.144531, -0.380658),\n    vec2(-0.105469, -0.047325),\n    vec2( 0.394531,  0.286008),\n    vec2(-0.417969, -0.269547),\n    vec2( 0.082031,  0.063786),\n    vec2(-0.167969,  0.397119),\n    vec2( 0.332031, -0.454733),\n    vec2(-0.292969, -0.121399),\n    vec2( 0.207031,  0.211934),\n    vec2(-0.042969, -0.343621),\n    vec2( 0.457031, -0.010288),\n    vec2(-0.449219,  0.323045),\n    vec2( 0.050781, -0.232510),\n    vec2(-0.199219,  0.100823)\n);\n\n/**\n*  Helper data structures\n*/\nstruct Ray\n{\n    vec3 origin, direction;\n};\n\nstruct Material\n{\n    // alpha channel - unused\n    vec4 albedo;\n    /**\n        red channel - roughness\n        green channel - metalness\n        blue channel - clearcoat\n        alpha channel - material ID\n    */\n    vec4 pbrParams;\n    vec4 iridescenceParams;\n};\n\nstruct PixelContext\n{\n    vec3 hitPosition;\n    float shadow;\n    vec3 normal;\n    vec3 clearcoatNormal;\n    vec3 lightDirection;\n    vec3 viewDirection;\n    vec3 halfVector;\n    vec3 f0;\n    \n    Ray reflectionRay;\n    \n    Material material;\n};\n\nstruct SHCoefficients\n{\n\tvec3 l00, l1m1, l10, l11, l2m2, l2m1, l20, l21, l22;\n};\n\n/**\n*  Helper Utility Functions\n*/\n\nfloat pow5(const float x) \n{\n    float x2 = x * x;\n    return x2 * x2 * x;\n}\n\nmat2 Rotate2D(float theta)\n{\n    float s = sin(theta);\n    float c = cos(theta);\n    return mat2(c, -s, s, c);\n}\n\nmat3 RotateX(float theta) \n{\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(1, 0, 0),\n        vec3(0, c, -s),\n        vec3(0, s,  c)\n    );\n}\n\nmat3 RotateY(float theta)\n{\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3( c, 0, s),\n        vec3( 0, 1, 0),\n        vec3(-s, 0, c)\n    );\n}\n\nmat3 RotateZ(float theta)\n{\n    float c = cos(theta);\n    float s = sin(theta);\n    return mat3(\n        vec3(c, -s, 0),\n        vec3(s,  c, 0),\n        vec3(0,  0, 1)\n    );\n}\n\n/**\n*  Quality hashes collection by nimitz https://www.shadertoy.com/view/Xt3cDn\n*/\nuint BaseHash1D(uint p)\n{\n    p = 1103515245U*((p >> 1U)^(p));\n    uint h32 = 1103515245U*((p)^(p>>3U));\n    return h32^(h32 >> 16);\n}\n\nvec2 Hash21(in uint x)\n{\n    uint n = BaseHash1D(x);\n    uvec2 rz = uvec2(n, n*48271U); //see: http://random.mat.sbg.ac.at/results/karl/server/node4.html\n    return vec2((rz.xy >> 1) & uvec2(0x7fffffffU))/float(0x7fffffff);\n}\n\nuint BaseHash2D(uvec2 p)\n{\n    p = 1103515245U*((p >> 1U)^(p.yx));\n    uint h32 = 1103515245U*((p.x)^(p.y>>3U));\n    return h32^(h32 >> 16);\n}\n\nfloat Hash12(uvec2 x)\n{\n    uint n = BaseHash2D(x);\n    return float(n)*(1.0/float(0xffffffffU));\n}\n\nvec3 Hash13(inout float seed) {\n    uint n = BaseHash2D(floatBitsToUint(vec2(seed += 0.1, seed += 0.1)));\n    uvec3 rz = uvec3(n, n * 16807U, n * 48271U);\n    return vec3(rz & uvec3(0x7fffffffU)) / float(0x7fffffff);\n}\n\nuint BaseHash3D(uvec3 p)\n{\n    p = 1103515245U*((p.xyz >> 1U)^(p.yzx));\n    uint h32 = 1103515245U*((p.x^p.z)^(p.y>>3U));\n    return h32^(h32 >> 16);\n}\n\nvec3 Hash33(uvec3 x)\n{\n    uint n = BaseHash3D(x);\n    uvec3 rz = uvec3(n, n*16807U, n*48271U); //see: http://random.mat.sbg.ac.at/results/karl/server/node4.html\n    return vec3((rz >> 1) & uvec3(0x7fffffffU))/float(0x7fffffff);\n}\n\n/**\n*  Source: Karthik Karanth's blog: \n*  https://karthikkaranth.me/blog/generating-random-points-in-a-sphere/#better-choice-of-spherical-coordinates\n*/\nvec3 RandomPointInUnitSphere(inout float seed) {\n    vec3 h = Hash13(seed) * vec3(TWO_PI, 2.0, 1.0) - vec3(0.0, 1.0, 0.0);\n    float theta = h.x;\n    float sinPhi = sqrt(1.0 - h.y * h.y);\n    float r = pow(h.z, 0.3333333334);\n    \n    return r * vec3(cos(theta) * sinPhi, sin(theta) * sinPhi, h.y);\n}\n\nvec3 RandomPointInUnitHemisphere(inout float seed) {\n    vec3 h = Hash13(seed) * vec3(TWO_PI, 1.0, 1.0);// - vec3(0.0, 1.0, 0.0);\n    float theta = h.x;\n    float sinPhi = sqrt(1.0 - h.y * h.y);\n    float r = pow(h.z, 0.3333333334);\n    \n    return r * vec3(cos(theta) * sinPhi, h.y, sin(theta) * sinPhi);\n}\n\n/**\n*  Camera Matrix Orientation: \n*\n*\n*             Up\n*   -lookAt    ^\n*       ↖      |\n*         ↖    |\n*           ↖  |\n*             ↖.------> Right\n*/\nmat3 GetCameraBasis(in vec3 origin, in vec3 target)\n{\n    vec3 lookAt = normalize(origin - target); // Towards camera\n    vec3 right = normalize(cross(CAMERA_UP, lookAt)); \n    vec3 up = normalize(cross(lookAt, right));\n    return mat3(right, up, -lookAt);\n}\n\nvec3 GetCameraPosition(in vec2 cameraAngles)\n{\n    // Make the camera arcball-ish using spherical coordinates\n    vec2 theta = vec2(cameraAngles.x * PI * 4.0, mix(PI * 0.1, PI * 0.499, cameraAngles.y));\n\n    return vec3(\n        sin(theta.x) * sin(theta.y),\n        cos(theta.y),\n        cos(theta.x) * sin(theta.y)\n    ) * CAMERA_RADIUS;\n}\n\nmat4 GetCameraWorldToView(in vec2 cameraAngles)\n{\n    vec3 camPosition = GetCameraPosition(cameraAngles);\n    \n    mat4 result = mat4(GetCameraBasis(camPosition, CAMERA_TARGET));\n    result[0].w = -dot(result[0].xyz, camPosition);\n    result[1].w = -dot(result[1].xyz, camPosition);\n    result[2].w = -dot(result[2].xyz, camPosition);\n    result[3] = vec4(0.0, 0.0, 0.0, 1.0);\n    \n    return result;\n}\n\nRay GetCameraRay(in vec2 pixelCoord, in vec2 cameraAngles)\n{\n    // Generate camera ray through a camera view matrix\n    vec3 origin = GetCameraPosition(cameraAngles);\n    mat3 cameraWorld = GetCameraBasis(origin, CAMERA_TARGET);\n    vec3 direction = normalize(cameraWorld * vec3(pixelCoord, CAMERA_ZOOM));\n    return Ray(origin, direction);\n}\n\n/**\n*  Box Mapping by iq - https://www.shadertoy.com/view/MtsGWH\n*/\nvec4 TextureMapTriplanar(in sampler2D texMap, in vec3 position, in vec3 normal, in float sharpnessFactor)\n{\n    // project + fetch\n\tvec4 x = textureLod(texMap, position.yz, 0.0);\n\tvec4 y = textureLod(texMap, position.zx, 0.0);\n\tvec4 z = textureLod(texMap, position.xy, 0.0);\n    \n    // blend the maps along the 3 orthogonal axes\n    vec3 m = pow(abs(normal), vec3(sharpnessFactor));\n\treturn (x * m.x + y * m.y + z * m.z) / (m.x + m.y + m.z);\n}\n\n/**\n*  Yusuke Tokuyoshi and Anton S. Kaplanyan. 2019. Improved Geometric Specular Antialiasing.\n*  https://www.jp.square-enix.com/tech/library/pdf/ImprovedGeometricSpecularAA.pdf\n*/\nfloat GetFilteredRoughness(float roughness, vec3 normal)\n{\n    float linearRoughness = roughness * roughness;\n    \n    vec3 ddu = dFdx(normal);\n    vec3 ddv = dFdy(normal);\n\n    float variance = 0.16 * (dot(ddu, ddu) + dot(ddv, ddv)); // sigma = 0.4\n\n    float kernelRoughness = min(2.0 * variance, 0.18); // kappa = 0.18\n    float squareRoughness = Saturate(linearRoughness * linearRoughness + kernelRoughness);\n\n    return sqrt(squareRoughness);\n}\n\n/**\n*  Tom Duff, James Burgess, Per Christensen, Christophe Hery, Andrew Kensler, Max Liani, and Ryusuke Villemin, Building an Orthonormal Basis, Revisited\n*  https://graphics.pixar.com/library/OrthonormalB/paper.pdf\n*/\nvoid OrthonormalBasis(in vec3 n, out vec3 b1, out vec3 b2) \n{ \n    float signum = float(n.z > SMOL_EPS) * 2.0 - 1.0;\n    float a = -1.0 / (signum + n.z);\n    float b = n.x * n.y * a;\n    b1 = vec3(1.0 + signum * n.x * n.x * a, signum * b, -signum * n.x);\n    b2 = vec3(b, signum + n.y * n.y * a, -n.y);\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "/**\n    A quasi-realistic looking carbon fiber texture pattern based on overlapping two different sets of uv maps\n    mixed using a zigzag checkered pattern. The checkered pattern is stored in x channel of the carbon fiber\n    map. The anisotropic brushed \"metal\" look is generated by stretching two sets of perlin fbm noise along the\n    x and y axis and then mixing them using the same zigzag checkered pattern. A second map is also generated\n    that stores the heightmap for each \"weave\" in the mesh. Finally everything is mixed together using these \n    two masks with 2 distinct colors to differentiate between the horizontal and vertical weaves. Some fake lighting\n    is also added to enhance the effect of the heightmap & the anisotropic brushes on each weave of the mesh. Try playing\n    around with different settings below to customize the look of the texture. \n*/\n\n#define WEAVE_SCALE 80.0\n#define HORIZONTAL_WEAVE_COLOR vec3(0.003)\n#define VERTICAL_WEAVE_COLOR   vec3(0.01)\n\n#define ANISOTROPIC_MASK 1\n#define ANISOTROPIC_ANIMATION 0\n#define ANISOTROPIC_THRESHOLD 0.3\n#define ANISOTROPIC_ANIMATION_SPEED 0.02\n\n#define DIFFUSE_SCALE 2.0\n#define SPECULAR_SCALE 0.5\n\nfloat PerlinNoise(vec2 x, float freq) \n{\n    x *= freq; // tile\n    \n    vec2 f = fract(x);\n    x = floor(x);\n\n\tfloat a = Hash12(uvec2(abs(mod(x, freq))));\n    float b = Hash12(uvec2(abs(mod(x + vec2(1.0, 0.0), freq))));\n    float c = Hash12(uvec2(abs(mod(x + vec2(0.0, 1.0), freq))));\n    float d = Hash12(uvec2(abs(mod(x + vec2(1.0, 1.0), freq))));\n\n    vec2 u = f * f * (3.0 - 2.0 * f);\n\treturn mix(a, b, u.x) + (c - a) * u.y * (1.0 - u.x) + (d - b) * u.x * u.y;\n}\n\n\n\nfloat PerlinFbm (vec2 uv, float freq, int octaves)\n{\n    float amp = .5;\n    float noise = 0.;\n    \n    for (int i = 0; i < octaves; ++i)\n    {\n        noise += amp * PerlinNoise(uv, freq);\n        amp *= .5;\n        freq *= 2.;\n    }\n    return noise;\n}\n\nvec2 GenerateCarbonFiberMap(in vec2 uv)\n{\n    vec2 gridUv = uv * WEAVE_SCALE;// * vec2(1.0, iResolution.y / iResolution.x); // Scale grid row size based on aspect ratio.\n    vec2 gridId = floor(gridUv);\n    float maskScaleInverse = 0.5;\n    vec2 maskOffset = (gridUv + gridId.yx) * maskScaleInverse;\n    \n    float patternMask = mod(floor(maskOffset.x), 2.0); // zigzag pattern\n    vec2 gradients = 1.0 - abs(fract(maskOffset) - 0.5); // horizontal and vertical gradient patterns\n    gradients -= 0.5;\n    gradients = Saturate(pow(gradients, vec2(0.25)));\n    float heightMap = mix(gradients.y, gradients.x, patternMask); // mix both gradients based on the zigzag pattern\n    \n#if ANISOTROPIC_MASK\n    float anisotropicBrush = mix(PerlinFbm(uv * vec2(50.0, 0.1) + vec2(0.0, uv.x * 8.0) \n#if ANISOTROPIC_ANIMATION\n                                           + iTime * ANISOTROPIC_ANIMATION_SPEED\n#endif\n                                           , 32.0, 8), // vertical anisotropic\n                                 PerlinFbm(uv * vec2(0.1, 50.0) + vec2(uv.y * 8.0, 0.0)\n#if ANISOTROPIC_ANIMATION\n                                           + iTime * ANISOTROPIC_ANIMATION_SPEED\n#endif\n                                           , 32.0, 8), // horizontal anisotropic\n                                 patternMask);\n    heightMap = mix(heightMap, anisotropicBrush, ANISOTROPIC_THRESHOLD);\n#endif\n    return vec2(patternMask, heightMap * heightMap);\n\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{  \n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    float lastFrameWidth = texelFetch(iChannel1, ivec2(2, 0), 0).x;\n    \n    if (iFrame == 0 || floor(lastFrameWidth) != iResolution.x)\n    {\n        vec2 uv = fragCoord / iResolution.xy;\n        vec2 carbonFiber = GenerateCarbonFiberMap(uv);\n        vec3 outColor = vec3(1.0);\n        outColor *= carbonFiber.y * mix(VERTICAL_WEAVE_COLOR, HORIZONTAL_WEAVE_COLOR, carbonFiber.x);\n        fragColor = vec4(outColor, carbonFiber.y);\n    }    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "/**\n    Scene Pass which does most of the heavylifting. The iridescent car paint is based on the paper\n    \"A Practical Extension to Microfacet Theory for the Modeling of Varying Iridescence\" by \n    Laurent Belcour (Unity Technologies) & Pascal Barla (Inria). The logic from the original paper is \n    simplified a bit here to make it run faster but as a result it only does fresnel interference calculations\n    for dielectric-dielectric interfaces. In this case even though the underlying car material is metal, \n    it still works out fairly well. \n    \n    The basic idea is to add a dielectric thin-film layer of varying thickness on top of the metallic layer\n    with an arbitrary roughness value, and then performing analytical spectral integration based on Airy Summation\n    in fourier domain, which then is converted back to rgb resulting in a new iridescent term trplacing the usual fresnel\n    term used in pbr rendering.\n    \n    A clearcoat layer is then also added on top of the iridescent thin-film paint layer \n    to make it look more reflective like car paints irl.\n    \n    Try playing with the debug flags to see different layers of rendering or try turning on the RAINBOW_VOMIT\n    flag to see a more pronounced version of the iridescence car paint. Iridescence can also be switched off,\n    in which case it will just render a fully carbon fiber car material. \n*/\n\n// #define DEBUG\n// #define DEBUG_SPHERE\n\n#define IRIDESCENT_CAR 1\n#if IRIDESCENT_CAR\n    #define RAINBOW_VOMIT 0\n#endif\n\n#define DEBUG_MODE_ALBEDO                         0\n#define DEBUG_MODE_NORMAL                         1\n#define DEBUG_MODE_CLEARCOAT_NORMAL               2\n#define DEBUG_MODE_DIRECT_DIFFUSE                 3\n#define DEBUG_MODE_DIRECT_SPECULAR                4\n#define DEBUG_MODE_CLEARCOAT_DIRECT_SPECULAR      5\n#define DEBUG_MODE_DIFFUSE_AMBIENT_OCCLUSION      6\n#define DEBUG_MODE_INDIRECT_DIFFUSE               7\n#define DEBUG_MODE_CLEARCOAT_REFLECTION_COLOR     8\n#define DEBUG_MODE_CLEARCOAT_INDIRECT_SPECULAR    9\n#define DEBUG_MODE_SCENE_REFLECTION_COLOR         10\n#define DEBUG_MODE_SCENE_INDIRECT_SPECULAR        11\n#define DEBUG_MODE_INDIRECT_SPECULAR_COMBINED     12\n\n#define DEBUG_MODE DEBUG_MODE_DIFFUSE_AMBIENT_OCCLUSION\n\n#ifdef DEBUG\n\n    bool debugValueActivated = false;\n    vec3 debugValue = vec3(0.0);\n    \n    #define DEBUG_SET_MODE(option, value)         \\\n        if (option == DEBUG_MODE)                 \\\n        {                                         \\\n            debugValueActivated = true;           \\\n            debugValue = value;                   \\\n        }                                    \n        \n    #define DEBUG_SET_OUTPUT(option)              \\\n        if (debugValueActivated)                  \\\n        {                                         \\\n            option = debugValue;                  \\\n        }\n        \n#else\n\n    #define DEBUG_SET_MODE(option, value)\n    #define DEBUG_SET_OUTPUT(option)\n    \n#endif\n\n#define CalculateDinc(d, eta2)         (2.0 * d * eta2)\n\nconst float LIGHT_INTENSITY          = 24.0;\nconst vec3  LIGHT_COLOR              = vec3(1.0, 0.91, 0.78);\nconst float LIGHT_SIZE               = 8.0;\nconst float INDIRECT_LIGHT_INTENSITY = 0.78;\n\n/**\n*  HDRI Cubemap used for generating SH coefficients: https://polyhaven.com/a/kloofendal_misty_morning_puresky\n*  Tool used for generating SH Coefficients: https://github.com/google/filament/tree/main/tools/cmgen\n*/\nconst SHCoefficients shCoeffs = SHCoefficients(\n    vec3( 0.793924391269684,  0.837475955486298,  0.940771281719208), // L00, irradiance, pre-scaled base\n    vec3( 0.327819824218750,  0.359646946191788,  0.423689544200897), // L1-1, irradiance, pre-scaled base\n    vec3( 0.125889003276825,  0.114405624568462,  0.089422538876534), // L10, irradiance, pre-scaled base\n    vec3(-0.005460172425956, -0.013677077367902, -0.021917015314102), // L11, irradiance, pre-scaled base\n    vec3( 0.003116087289527, -0.000884470762685, -0.005603316240013), // L2-2, irradiance, pre-scaled base\n    vec3( 0.041825212538242,  0.037392575293779,  0.028037762269378), // L2-1, irradiance, pre-scaled base\n    vec3( 0.004975790623575,  0.001385384355672, -0.004225638695061), // L20, irradiance, pre-scaled base\n    vec3(-0.019441796466708, -0.018265457823873, -0.017435092478991), // L21, irradiance, pre-scaled base\n    vec3( 0.008399057202041, -0.004809430800378, -0.024586766958237)  // L22, irradiance, pre-scaled base\n);\n\n/**----------------------------------------------------------------\n\n        *** Signed Distance Functions ***\n   \n-------------------------------------------------------------------*/\n\nvec2 SignedDistanceUnion(in vec2 a, in vec2 b)\n{\n    return a.x < b.x ? a : b;\n}\n\nfloat SignedDistanceSmoothUnion(in float a, in float b, in float k)\n{\n    float h = clamp(0.5 + 0.5 * (b - a) / k, 0.0, 1.0);\n    return mix(b, a, h) - k * h * (1.0 - h);\n}\n\nvec4 SignedDistanceSmoothUnionWithAlbedo(in vec4 a, in vec4 b, in float k)\n{\n    float s = SignedDistanceSmoothUnion(a.x, b.x, k);\n    float sA = s - a.x;\n    float sB = s - b.x;\n    float r = sA / (sA + sB);\n    return vec4(s, mix(b.yzw, a.yzw, r));\n}\n\nfloat SignedDistanceSmoothSubtraction(in float d1, in float d2, in float k)\n{\n    float h = clamp(0.5 - 0.5 * (d2 + d1) / k, 0.0, 1.0);\n    return mix(d2, -d1, h) + k * h * (1.0 - h); \n}\n\n\nvec3 SignedDistanceCheapBendXY(in vec3 p, in float k)\n{\n    mat2  m = Rotate2D(k * p.x);\n    vec3  q = vec3(m * p.xy, p.z);\n    return q;\n}\n\nvec3 SignedDistanceCheapBendXZ(in vec3 p, in float k)\n{\n    mat2  m = Rotate2D(k * p.x);\n    vec2  r = m * p.xz;\n    vec3  q = vec3(r.x, p.y, r.y);\n    return q;\n}\n\nvec3 SignedDistanceCheapBendZY(in vec3 p, in float k)\n{\n    mat2  m = Rotate2D(k * p.z);\n    vec3  q = vec3(p.x, m * p.yz);\n    return q;\n}\n\n// From IQ's video: https://www.youtube.com/watch?v=sl9x19EnKng&t=1892s\nvoid RepeatRadial(inout vec3 position, in float radius, in float sectors)\n{\n    float angle = TWO_PI * 1.0 / sectors;\n    float sector = round(atan(position.z, position.x) / angle);\n    position = RotateY(-angle * sector) * position;\n    position.x -= radius;\n}\n\nfloat SignedDistanceRoundBox(in vec3 position, in vec3 center, in vec3 bounds, in float radius)\n{\n  vec3 q = abs(position - center) - bounds;\n  return length(max(q, 0.0)) + min(max(q.x, max(q.y, q.z)), 0.0) - radius;\n}\n\nfloat SignedDistanceSphere(in vec3 position, in vec3 center, in float radius)\n{\n    return length(position - center) - radius;\n}\n\nfloat SignedDistanceEllipsoid(in vec3 position, in vec3 radius) \n{\n    float k0 = length(position / radius);\n    float k1 = length(position / (radius * radius));\n    return k0 * (k0 - 1.0) / k1;\n}\n\nfloat SignedDistanceCylinder(in vec3 position, in float height, in float radius)\n{\n    vec2 d = abs(vec2(length(position.xz), position.y)) - vec2(radius, height);\n    return min(max(d.x, d.y), 0.0) + length(max(d, 0.0));\n}\n\nfloat SignedDistancePlaneY(in vec3 position, in float height)\n{\n    return position.y + height;\n}\n\nfloat SignedDistancePlaneZ(in vec3 position, in float depth)\n{\n    return position.z + depth;\n}\n\nvoid SignedDistanceCarBody(in vec3 position, inout vec2 result)\n{    \n#if IRIDESCENT_CAR\n    result.y = 0.0;\n#else\n    result.y = 1.0;\n#endif\n    \n    // Main body\n#if 1\n    result.x = SignedDistanceRoundBox(RotateY(QUARTER_PI) * vec3(position.xy, SmoothAbs(position.z, 0.42, 0.06)), vec3(-0.5, 0.0, 0.5), vec3(0.2, 0.02, 0.2) + \\\n        /** skew */ vec3(position.y, 0.0, position.y) * 0.4, 0.6);\n#else\n    result.x = SignedDistanceSkewedRoundBox(rotateY(QUARTER_PI) * position, vec3(-0.5, 0.0, 0.5), vec3(position.y, 0.0, position.y), 0.4, vec3(0.2, 0.02, 0.2), 0.6);\n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceSkewedRoundBox(rotateY(QUARTER_PI) * position, vec3(0.5, 0.0, -0.5), vec3(position.y, 0.0, position.y), 0.4, \\\n        vec3(0.2, 0.02, 0.2), 0.6), 1.0);\n#endif\n   \n    // Rounded front\n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceEllipsoid(position - vec3(0.0, 0.5, 1.5), vec3(0.9, 0.3, 0.6)), 0.4);\n    \n    // Rounded back \n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceRoundBox(position, vec3(0.0, 0.0, -0.8), vec3(0.35, 0.5, 0.35) + /** skew */ vec3(position.y, 0.0, position.y) * 0.4, 0.2), 0.6);\n    \n    // Flatten the body top\n    result.x = SignedDistanceSmoothSubtraction(-result.x, SignedDistancePlaneY(SignedDistanceCheapBendZY(position + vec3(0., 0., 0.6), 0.04), -0.4), 0.03);    \n\n    vec3 tempPosition = vec3(SmoothAbs(position.x, 0.04, 0.0), position.yz);\n    \n    // Front headlights\n#if 0\n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceEllipsoid(RotateZ(-0.6283185307) * RotateY(-0.6283185307) * (tempPosition -vec3(0.6, 0.15, 1.15)), vec3(0.15, 0.2, 0.42)), 0.225);\n#else\n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceEllipsoid(RotateY(-0.6283185307) * (tempPosition - vec3(0.575, 0.15, 1.16)), vec3(0.175, 0.2, 0.45)), 0.225);\n#endif\n    \n    // Rear engine exhausts\n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceEllipsoid(RotateX(-0.1570796326) * (tempPosition - vec3(0.45, 0.25, -0.8)), vec3(0.25, 0.3, 0.7)), 0.25);\n    \n    // Roof dome\n    result.x = SignedDistanceSmoothUnion(result.x, SignedDistanceEllipsoid(SignedDistanceCheapBendZY(position - vec3(0.0, 0.42, 0.0), 0.25), vec3(0.6, 0.3, 0.85)), 0.4);\n    \n    // Cutoff dome with a skewed plane to make the back look more aerodynamic\n    result.x = SignedDistanceSmoothSubtraction(-result.x, SignedDistancePlaneY(SignedDistanceCheapBendZY(position - vec3(0.0, 0.0, 0.8), 0.08), -0.725), 0.15);\n    \n    // Flatten underneath the body\n    result.x = SignedDistanceSmoothSubtraction(-result.x, -SignedDistancePlaneY(position, 0.1), 0.1);\n}\n\nvoid SignedDistanceCarSpoiler(in vec3 position, inout vec2 result)\n{\n    // Spoiler support beams\n    float distanceToSpoiler = SignedDistanceSmoothSubtraction(-SignedDistancePlaneY(RotateX(0.1570796326) * position, -0.3), \n        SignedDistanceRoundBox((RotateX(-0.6283185307) * vec3(abs(position.x), position.yz)) - vec3(0.3, 1.25, -0.95), vec3(0.0, 0.0, 0.0), vec3(0.001, 0.25, 0.05), 0.001), 0.01);\n    \n    // Spoiler Wing\n    distanceToSpoiler = SignedDistanceSmoothUnion(distanceToSpoiler, SignedDistanceSmoothSubtraction(SignedDistancePlaneZ(SignedDistanceCheapBendXZ(position, 0.5), 1.75),\n        SignedDistanceRoundBox(SignedDistanceCheapBendXY(RotateX(0.1570796326) * position, -0.125), vec3(0.0, 0.335, -1.75), vec3(0.9, 0.0, 0.2), 0.01), 0.04), 0.025);\n        \n    result = SignedDistanceUnion(vec2(distanceToSpoiler, 1.0), result);\n}\n\nvoid SignedDistanceTorii(in vec3 position, inout vec2 result)\n{\n    vec4 torii = vec4(0.0, 0.0, 3.0, 4.0);\n    RepeatRadial(position, 6.0, 8.0);\n    position = RotateY(HALF_PI) * position;\n    vec3 mirrorXPosition = vec3(abs(position.x), position.yz);\n    \n    \n    // Red Parts\n    // Hashira (Pillars)\n    torii.x = SignedDistanceCylinder(RotateZ(0.15) * mirrorXPosition - vec3(1.0, 0.0, 0.0), 2.5, 0.16 - mirrorXPosition.y * 0.0125);\n    \n    // Nuki (lower joint bar)\n    torii.x = SignedDistanceSmoothUnion(torii.x, SignedDistanceRoundBox(position, vec3(0.0, 1.965, 0.0), vec3(1.06, 0.08, 0.05), 0.01), 0.02);\n    \n    // Kusabi (Wedges)\n    torii.x = SignedDistanceSmoothUnion(torii.x, SignedDistanceSmoothSubtraction(\n                                         -SignedDistanceRoundBox(mirrorXPosition - vec3(0.7, 0.0, 0.0), vec3(0.0, 2.075, 0.0), vec3(0.23, 0.03, 0.04), 0.01),\n                                         -SignedDistanceCylinder(RotateX(HALF_PI) * mirrorXPosition - vec3(0.7, 0.0, -2.825), 0.25, 0.75),\n                                     0.01),\n                                  0.02);\n    \n    // Daiwa (Decorative Rings)\n    torii.x = SignedDistanceSmoothUnion(torii.x, SignedDistanceCylinder(RotateZ(0.05) * (mirrorXPosition - vec3(0.64, 2.55, 0.0)), 0.02, 0.2) - 0.02, 0.01);\n    \n    // Gakuzuka (Supporting center strut)\n    torii.x = SignedDistanceSmoothUnion(torii.x, SignedDistanceRoundBox(position, vec3(0.0, 2.25, 0.0), vec3(0.14, 0.32, 0.02), 0.01), 0.01);\n    \n    // Shimaki (Bent reinforcing lintel for the kasagi) \n    position = SignedDistanceCheapBendXY(position, 0.05);\n    torii.x = SignedDistanceSmoothUnion(torii.x, SignedDistanceRoundBox(position, vec3(0.0, 2.645, 0.0), vec3(0.5, 0.06, -0.9) + vec3(position.y, 0.0, position.y) * 0.4, 0.01), 0.01);\n    \n    \n    // Black parts\n    // Nemaki (Pillar Sleeves)\n    torii.y = SignedDistanceCylinder(RotateZ(0.15) * (mirrorXPosition - vec3(1.024, -0.1, 0.0)), 0.4, 0.18) - 0.015;\n    // Kasagi (Top bent horizontal lintel)\n    torii.y = SignedDistanceSmoothUnion(torii.y, SignedDistanceRoundBox(position, vec3(0.0, 2.8, 0.0), vec3(-1.75, 0.08, -0.48) + vec3(position.y * 1.25, 0.0, position.y * 0.25), 0.01), 0.01);\n    \n    result = SignedDistanceUnion(SignedDistanceUnion(torii.xz, torii.yw), result);\n}\n\nvec2 SignedDistanceScene(in vec3 position)\n{\n    vec2 result = vec2(0.0);\n    \n#if defined(DEBUG_SPHERE)\n    result.x = SignedDistanceSphere(position, vec3(0.0, 0.65, 0.0), 0.9);\n#if IRIDESCENT_CAR\n    result.y = 0.0;\n#else\n    result.y = 1.0;\n#endif\n#else\n    SignedDistanceCarBody(position, result);\n    SignedDistanceCarSpoiler(position, result);\n#endif\n    SignedDistanceTorii(position, result);\n    result = SignedDistanceUnion(result, vec2(SignedDistancePlaneY(position, 0.25), 2.0));\n\n    return result;\n}\n\nvec3 CalculateNormal(vec3 position)\n{\n\tvec2 eps = vec2(SMOL_EPS, 0.);\n    return normalize(vec3(SignedDistanceScene(position + eps.xyy).x, \n                          SignedDistanceScene(position + eps.yxy).x,\n                          SignedDistanceScene(position + eps.yyx).x) \n                     - SignedDistanceScene(position).x);\n}\n\n/**----------------------------------------------------------------\n\n        *** Sphere Tracing Functions ***\n   \n-------------------------------------------------------------------*/\n\nbool SphereTrace(in Ray ray, inout vec2 result)\n{\n    float totalMarchedDistance = 0.0;\n    result = vec2(-1.0);\n    vec2 currentMarched = vec2(SMOL_EPS, 0.0);\n    \n    for(uint i = 0u; i < 200u && totalMarchedDistance < CAMERA_FAR; ++i)\n    {\n        currentMarched = SignedDistanceScene(ray.origin.xyz + ray.direction.xyz * totalMarchedDistance);\n        if (currentMarched.x <= totalMarchedDistance * SMOL_EPS)\n        {\n            result.x = totalMarchedDistance;\n            result.y = currentMarched.y;\n            return true;\n        }\n        totalMarchedDistance += currentMarched.x * 0.9;\n    }\n    \n    result.x = CAMERA_FAR;\n    return false;\n}\n\nfloat SoftShadowSphereTrace(in Ray ray)\n{\n    float totalMarched = SMOL_EPS;\n    float currentMarched = 0.0;\n    float shadow = 1.0;\n    for(uint i = 0u; i < 100u && totalMarched < CAMERA_FAR; ++i)\n    {\n        currentMarched = SignedDistanceScene(ray.origin.xyz + ray.direction.xyz * totalMarched).x;\n        if (currentMarched <= totalMarched * SMOL_EPS)\n        {\n            return 0.0;\n        }\n        \n        shadow = min(shadow, LIGHT_SIZE * currentMarched / totalMarched);\n        totalMarched += currentMarched * 0.8;\n    }\n    \n    return shadow;\n}\n\n/**----------------------------------------------------------------\n\n        *** Material Functions ***\n   \n-------------------------------------------------------------------*/\n\nvec3 GetFogColor(in float height, in float hdrMultiplier)\n{\n    return mix(vec3(0.75, 0.85, 1.0), vec3(0.05, 0.125, 0.4), height) * hdrMultiplier;\n}\n\nvec4 GetFloorAlbedoWithCheckeredMask(in vec3 position)\n{\n    float checkerboard = mod(floor(position.x * 2.0) + floor(position.z * 2.0), 2.0); // checkered pattern\n    return vec4(0.25 + checkerboard * vec3(0.25), checkerboard);\n}\n\nvoid SetupFloorMaterial(inout PixelContext pixel)\n{\n    pixel.material.albedo = GetFloorAlbedoWithCheckeredMask(pixel.hitPosition);\n    pixel.material.pbrParams.x = mix(0.25, 0.95, pixel.material.albedo.w);\n    pixel.material.pbrParams.y = mix(0.75, 0.05, pixel.material.albedo.w);\n    pixel.material.pbrParams.z = 0.0;\n}\n\nvoid SetupToriiGateMaterial(inout Material material, in bool isRed)\n{\n    material.albedo = isRed ? vec4(0.8, 0.01, 0.01, 0.0) : vec4(vec3(0.01), 0.0);\n    material.pbrParams = vec4(0.8, 0.05, 0.0, 0.0);\n}\n\nvec4 GetCarbonFiberTexture(in sampler2D texMap, in vec3 P, in vec3 N, in float sharpnessFactor)\n{\n    return TextureMapTriplanar(texMap, P, N, sharpnessFactor);\n}\n\nvoid SetupCarbonFiberMaterial(inout PixelContext pixel, in sampler2D texMap, in bool modifyNormal)\n{\n    pixel.material.albedo = TextureMapTriplanar(texMap, pixel.hitPosition, pixel.normal, 8.0);\n    pixel.material.pbrParams.x = Saturate((pixel.material.albedo.y + 0.5) * 1.25);\n    pixel.material.pbrParams.y = 0.5;\n    pixel.material.pbrParams.z = 0.5;\n    \n    if (modifyNormal)\n    {\n        pixel.normal = normalize(pixel.normal - vec3(dFdx(pixel.material.albedo.w), dFdy(pixel.material.albedo.w), pixel.material.albedo.w) * vec3(0.5, 0.5, 2.5));\n    }\n}\n\nvec4 GetCarPaintAlbedoWithStripeMask(in vec3 position)\n{\n    vec4 result;\n    result.w = smoothstep(0.0725, 0.0675, abs(abs(position.x) - 0.12)); // ~0.6 width per stripe\n    // result.xyz = mix(vec3(0.02, 0.125, 0.25), vec3(1.0), result.w);\n    result.xyz = mix(vec3(0.05), vec3(0.15), result.w);\n    return result;\n}\n\nvoid SetupCarPaintMaterial(inout PixelContext pixel, bool modifyNormal)\n{   \n#if IRIDESCENT_CAR\n    pixel.material.albedo = GetCarPaintAlbedoWithStripeMask(pixel.hitPosition);\n    pixel.material.pbrParams.x = mix(0.45, 0.15, pixel.material.albedo.w);\n    pixel.material.pbrParams.y = 0.95;//mix(0.9, 0.3,  pixel.material.albedo.w);\n    pixel.material.pbrParams.z = 0.75;\n#if RAINBOW_VOMIT\n    pixel.material.iridescenceParams.x = 1.39; // eta2\n    pixel.material.iridescenceParams.y = 1.55; // eta3\n    pixel.material.iridescenceParams.z = mix(CalculateDinc(0.57, pixel.material.iridescenceParams.x), CalculateDinc(0.51, pixel.material.iridescenceParams.x), pixel.material.albedo.w);\n#else\n    pixel.material.iridescenceParams.x = 1.33; // eta2\n    pixel.material.iridescenceParams.y = 1.12; // eta3\n    pixel.material.iridescenceParams.z = mix(CalculateDinc(mix(0.35, 0.65, pow(dot(abs(pixel.normal), vec3(1.0)) * 0.33334, 0.75)), pixel.material.iridescenceParams.x), \n                                                           CalculateDinc(0.425, pixel.material.iridescenceParams.x), pixel.material.albedo.w);\n#endif\n    pixel.material.iridescenceParams.w = 0.0; // kappa3 (unused for now since we only do the dielectric/dielectric fresnel interference in this demo)\n    \n    if (modifyNormal)\n    {\n        vec3 normalOffset = sqrt(Hash33(uvec3(abs(pixel.hitPosition * min(iResolution.x, iResolution.y)))) * 0.064);\n        pixel.normal = mix(pixel.normal - normalOffset, pixel.normal, pixel.material.albedo.w); // subtle flakes\n        pixel.material.pbrParams.x += mix(Min3(normalOffset.x, normalOffset.y, normalOffset.z), 0.0, pixel.material.albedo.w);\n        pixel.normal = normalize(pixel.normal);\n    }\n#endif\n}\n\nvoid SetupShadingMaterial(inout PixelContext pixel, in float materialID, in bool modifyNormal)\n{\n    if (materialID < 4.5)\n    {\n        SetupToriiGateMaterial(pixel.material, false);\n    }\n    \n    if (materialID < 3.5)\n    {\n        SetupToriiGateMaterial(pixel.material, true);\n    }\n    \n    if (materialID < 2.5)\n    {\n        SetupFloorMaterial(pixel);\n    }\n    \n    if (materialID < 1.5\n#if IRIDESCENT_CAR\n    && materialID > 0.5\n#endif\n    )\n    {\n        SetupCarbonFiberMaterial(pixel, iChannel1, modifyNormal);\n    }\n\n    if (materialID < 0.5)\n    {\n        SetupCarPaintMaterial(pixel, modifyNormal);\n    }\n \n    pixel.material.pbrParams.w = materialID;\n}\n\n/**----------------------------------------------------------------\n\n        *** BRDF Functions ***\n   \n-------------------------------------------------------------------*/\n\nfloat NormalDistributionGGX(float linearRoughness, float NdotH)\n{\n    // Walter et al. 2007, \"Microfacet Models for Refraction through Rough Surfaces\"\n    float oneMinusNdotHSquared = 1.0 - NdotH * NdotH;\n    float a = NdotH * linearRoughness;\n    float k = linearRoughness / (oneMinusNdotHSquared + a * a);\n    float d = k * k * (1.0 / PI);\n    return d;\n}\n\nfloat VisibilitySmithGGX(float linearRoughness, float NdotV, float NdotL) \n{\n    // Heitz 2014, \"Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs\"\n    float a2 = linearRoughness * linearRoughness;\n    float GGXV = NdotL * sqrt((NdotV - a2 * NdotV) * NdotV + a2);\n    float GGXL = NdotV * sqrt((NdotL - a2 * NdotL) * NdotL + a2);\n    // This also compensates for the division by the denominator of 4.0 * NoV * NoL. \n    return 0.5 / max(GGXV + GGXL, SMOL_EPS);\n}\n\nvec3 FresnelSchlickApprox(const vec3 f0, float VoH) \n{\n    // Schlick 1994, \"An Inexpensive BRDF Model for Physically-Based Rendering\"\n    return f0 + (vec3(1.0) - f0) * pow5(1.0 - VoH);\n}\n\nfloat FresnelSchlickApproxF90(float f0, float f90, float VoH) {\n    return f0 + (f90 - f0) * pow5(1.0 - VoH);\n}\n\nfloat VisibilityKelemen(float LoH) {\n    // Kelemen 2001, \"A Microfacet Based Coupled Specular-Matte BRDF Model with Importance Sampling\"\n    return Saturate(0.25 / max((LoH * LoH), SMOL_EPS));\n}\n\n// Depolarization functions for natural light\nfloat Depolarize(vec2 polV)\n{ \n    return 0.5 * (polV.x + polV.y);\n}\n\nvec3 DepolarizeColor(vec3 colS, vec3 colP)\n{\n    return 0.5 * (colS + colP);\n}\n\n// Fresnel equations for dielectric/dielectric interfaces.\nvoid FresnelDielectric(in float cosTheta1, in float eta1, in float eta2, out vec2 R, out vec2 phi)\n{\n    // Sinus theta1 'squared'\n    float sinTheta1 = (1.0 - cosTheta1 * cosTheta1);\n    float eta12  = eta1 / eta2;\n\n    // Total Internal Reflection\n    if(Square(eta12) * sinTheta1 > 1.0)\n    {\n        vec2 R = vec2(1.0);\n        phi = 2.0 * atan(vec2(-Square(eta12) * sqrt(sinTheta1 - 1.0/Square(eta12)) / cosTheta1, \n                        -sqrt(sinTheta1 - 1.0 / Square(eta12)) / cosTheta1));\n        return;\n    }\n    \n    // Transmission & Reflection\n    float cosTheta2 = sqrt(1.0 - Square(eta12) * sinTheta1);\n    vec2 r = vec2((eta2 * cosTheta1 - eta1 * cosTheta2) / (eta2 * cosTheta1 + eta1 * cosTheta2),\n                  (eta1 * cosTheta1 - eta2 * cosTheta2) / (eta1 * cosTheta1 + eta2 * cosTheta2));\n    phi.x = (r.x < 0.0) ? PI : 0.0;\n    phi.y = (r.y < 0.0) ? PI : 0.0;\n    R = Square(r);\n}\n\n// Evaluation XYZ sensitivity curves in Fourier space\nvec3 EvalSensitivity(float OPD, float shift)\n{\n\t// Use Gaussian fits, given by 3 parameters: val, pos and var\n\tfloat phase = TWO_PI * OPD * 1.0e-6;\n\tvec3 val = vec3(5.4856e-13, 4.4201e-13, 5.2481e-13);\n\tvec3 pos = vec3(1.6810e+06, 1.7953e+06, 2.2084e+06);\n\tvec3 var = vec3(4.3278e+09, 9.3046e+09, 6.6121e+09);\n\tvec3 xyz = val * sqrt(TWO_PI * var) * cos(pos * phase + shift) * exp(-var * phase*phase);\n\txyz.x   += 9.7470e-14 * sqrt(TWO_PI * 4.5282e+09) * cos(2.2399e+06 * phase + shift) * exp(-4.5282e+09 * phase * phase);\n\treturn xyz / 1.0685e-7;\n}\n\n// L. Belcour and P. Barla : “A Practical Extension to Microfacet Theory for the Modeling of Varying Iridescence”, \n// ACM Transactions on Graphics, 36, 4, pp. 65:1-65:14 (Jul. 2017)\n// https://hal.science/hal-01518344/document\nvec3 GetIridescentFresnel(in Material material, in float LoH, in float eta1)\n{   \n    // XYZ to CIE 1931 RGB color space (using neutral E illuminant)\n    const mat3 XYZ_TO_RGB = mat3(\n                                    2.3706743, -0.5138850,  0.0052982, \n                                   -0.9000405,  1.4253036, -0.0146949,\n                                   -0.4706338,  0.0885814,  1.0093968\n                                );\n    \n    // Force eta2 -> 1.0 when Dinc -> 0.0\n\tmaterial.iridescenceParams.x = mix(1.0, material.iridescenceParams.x, smoothstep(0.0, 0.03, material.iridescenceParams.z));\n    \n    float cosTheta1 = LoH;\n\tfloat cosTheta2 = sqrt(1.0 - Square(eta1 / material.iridescenceParams.x) * (1.0 - Square(cosTheta1)));\n\n    // First interface\n\tvec2 R12, phi12;\n\tFresnelDielectric(cosTheta1, eta1, material.iridescenceParams.x, R12, phi12);\n\tvec2 R21  = R12;\n\tvec2 T121 = vec2(1.0) - R12;\n\tvec2 phi21 = vec2(PI) - phi12;\n    \n    // Second interface\n\tvec2 R23, phi23;\n\tFresnelDielectric(cosTheta2, material.iridescenceParams.x, material.iridescenceParams.y, R23, phi23);\n\n\t// Phase shift\n\tfloat OPD = material.iridescenceParams.z * cosTheta2;\n\tvec2 phi2 = phi21 + phi23;\n    \n    // Compound terms\n\tvec3 I = vec3(0.0);\n    \n\tvec2 R123 = R12 * R23;\n\tvec2 r123 = sqrt(R123);\n\tvec2 Rs   = Square(T121) * R23 / (1.0 - R123);\n\n\t// Reflectance term for m = 0 (DC term amplitude)\n\tvec2 C0 = R12 + Rs;\n\tvec3 S0 = EvalSensitivity(0.0, 0.0);\n\tI += (Depolarize(C0) * S0);\n    \n    // Reflectance term for m > 0 (pairs of diracs)\n\tvec2 Cm = Rs - T121;\n\tfor(float m = 1.0; m < 4.0; ++m)\n    {\n\t\tCm *= r123;\n\t\tvec3 SmS = 2.0 * EvalSensitivity(m * OPD, m * phi2.x);\n\t\tvec3 SmP = 2.0 * EvalSensitivity(m * OPD, m * phi2.y);\n\t\tI += DepolarizeColor(Cm.x * SmS, Cm.y * SmP);\n\t}\n    \n    I = Saturate(XYZ_TO_RGB * I);\n    \n    return I;\n}\n\nvec3 SHIrradiance(vec3 nrm)\n{\n\tconst SHCoefficients c = shCoeffs;\n\tconst float c1 = 0.429043;\n\tconst float c2 = 0.511664;\n\tconst float c3 = 0.743125;\n\tconst float c4 = 0.886227;\n\tconst float c5 = 0.247708;\n\treturn (\n                c1 * c.l22 * (nrm.x * nrm.x - nrm.y * nrm.y) +\n                c3 * c.l20 * nrm.z * nrm.z +\n                c4 * c.l00 -\n                c5 * c.l20 +\n                2.0 * c1 * c.l2m2 * nrm.x * nrm.y +\n                2.0 * c1 * c.l21  * nrm.x * nrm.z +\n                2.0 * c1 * c.l2m1 * nrm.y * nrm.z +\n                2.0 * c2 * c.l11  * nrm.x +\n                2.0 * c2 * c.l1m1 * nrm.y +\n                2.0 * c2 * c.l10  * nrm.z\n\t\t    );\n}\n\n// Karis 2014, \"Physically Based Material on Mobile\"\n// https://www.unrealengine.com/en-US/blog/physically-based-shading-on-mobile\nvec2 EnvBRDFApproxLazarov(float roughness, float NoV)\n{\n    const vec4 c0 = vec4(-1.0, -0.0275, -0.572,  0.022);\n    const vec4 c1 = vec4( 1.0,  0.0425,  1.040, -0.040);\n\n    vec4 r = roughness * c0 + c1;\n    float a004 = min(r.x * r.x, exp2(-9.28 * NoV)) * r.x + r.y;\n\n    return vec2(-1.04, 1.04) * a004 + r.zw;\n}\n\nfloat EnvBRDFApproxNonmetal( float Roughness, float NoV )\n{\n\t// Same as EnvBRDFApprox( 0.04, Roughness, NoV )\n\tconst vec2 c0 = vec2( -1.0, -0.0275 );\n\tconst vec2 c1 = vec2( 1.0, 0.0425 );\n\tvec2 r = Roughness * c0 + c1;\n\treturn min( r.x * r.x, exp2( -9.28 * NoV ) ) * r.x + r.y;\n}\n\nvec3 IorToF0(in float transmittedIor, in float incidentIor)\n{\n    return vec3(Square((transmittedIor - incidentIor) / (transmittedIor + incidentIor)));\n}\n\nvec3 F0ToIor(in vec3 f0)\n{\n    vec3 r = sqrt(f0);\n    return (1.0 + r) / (1.0 - r);\n}\n\nvoid AdjustNormalAngleReflectance(inout PixelContext pixel)\n{\n    if (pixel.material.pbrParams.z > BIG_EPS)\n    {\n        //vec3 clearcoatf0 = IorToF0(F0ToIor(pixel.f0).x, 1.2);\n        vec3 clearcoatf0 = Saturate(pixel.f0 * (pixel.f0 * (0.941892 - 0.263008 * pixel.f0) + 0.346479) - 0.0285998);\n        pixel.f0 = mix(pixel.f0, clearcoatf0, pixel.material.pbrParams.z);\n    }\n    \n    pixel.f0 = mix(pixel.f0, pixel.material.albedo.xyz, pixel.material.pbrParams.y);\n}\n\nvec3 GetDiffuseColor(Material material)\n{\n    return material.albedo.xyz * (1.0 - material.pbrParams.y);\n}\n\nfloat GetDiffuseLambert()\n{\n    return PI_INV;\n}\n\nfloat GetDiffuseBurley(float linearRoughness, float NoV, float NoL, float LoH) {\n    // Burley 2012, \"Physically-Based Shading at Disney\"\n    float f90 = 0.5 + 2.0 * linearRoughness * LoH * LoH;\n    float lightScatter = FresnelSchlickApproxF90(1.0, f90, NoL);\n    float viewScatter  = FresnelSchlickApproxF90(1.0, f90, NoV);\n    return lightScatter * viewScatter * PI_INV;\n}\n\n// Lagarde and de Rousiers 2014, \"Moving Frostbite to PBR\"\nfloat SpecularOcclusionLagarde(float NoV, float visibility, float roughness)\n{\n    return Saturate(pow(NoV + visibility, exp2(-16.0 * roughness - 1.0)) - 1.0 + visibility);\n}\n\nfloat CalculateAmbientOcclusion(inout PixelContext pixel)\n{\n    float ambientOcclusion = 0.0;\n    pixel.hitPosition += pixel.clearcoatNormal * SMOL_EPS;\n    \n    // 4spp seemed like a good balance between minimal noise vs decent AO,\n    // but feel free to increase this to suppress noise artifacts and fireflies.\n    // (If your GPU is up for it that is)\n    const float AO_SAMPLES = 4.0;\n    const float INV_AO_SAMPLES = 1.0 / float(AO_SAMPLES);\n    const float DISTANCE_FACTOR = 0.9;\n    \n    vec3 tangent, binormal;\n    OrthonormalBasis(pixel.clearcoatNormal, tangent, binormal);\n    \n    // float seed = max(iResolution.x, iResolution.y) * INV_AO_SAMPLES;\n    float seed = pixel.hitPosition.z * max(iResolution.x, iResolution.y) + pixel.hitPosition.x + iTime;\n    \n    for(float i = 0.0; i < AO_SAMPLES; ++i)\n    {\n        vec3 sampleDirection = RandomPointInUnitHemisphere(seed);\n        //vec3 sampleDirection = RandomPointInUnitSphere(seed);\n        \n        sampleDirection = normalize(sampleDirection.x * tangent + sampleDirection.y * pixel.clearcoatNormal + sampleDirection.z * binormal);\n        \n        float totalMarched = 0.025, currentMarched;\n        for (uint j = 0u; j < 8u; ++j)\n        {\n            currentMarched = SignedDistanceScene(pixel.hitPosition + sampleDirection * totalMarched).x; \n            totalMarched += currentMarched;\n            if(abs(currentMarched) < totalMarched * EPS) break;\n        }\n        \n        ambientOcclusion += totalMarched * DISTANCE_FACTOR; //1.0 - exp(-visibility);\n    }\n    \n    return Saturate(ambientOcclusion * INV_AO_SAMPLES);\n}\n\nvec3 BRDF(in PixelContext pixel)\n{\n    vec3 result = vec3(0.0);\n    \n    float NoV = abs(dot(pixel.normal, pixel.viewDirection)) + 1e-5;\n    float NoL = Saturate(dot(pixel.normal, pixel.lightDirection));\n    float NoH = Saturate(dot(pixel.normal, pixel.halfVector));\n    float LoH = Saturate(dot(pixel.lightDirection, pixel.halfVector));\n    //float VoH = Saturate(dot(V, H));\n    \n    float clearcoatNoL = Saturate(dot(pixel.clearcoatNormal, pixel.lightDirection));\n    float clearcoatNoH = Saturate(dot(pixel.clearcoatNormal, pixel.halfVector));\n    float clearcoatNoV = max(SMOL_EPS, dot(pixel.clearcoatNormal, pixel.viewDirection));\n    \n    float linearRoughness = clamp(pixel.material.pbrParams.x * pixel.material.pbrParams.x, 1e-5, 1.0);\n    float clearcoatLinearRoughness = 0.015625; //clamp(clearcoatRoughness, 0.015625 /** 0.045 */, 1.0);\n    clearcoatLinearRoughness = GetFilteredRoughness(clearcoatLinearRoughness, pixel.clearcoatNormal);\n    \n    AdjustNormalAngleReflectance(pixel);\n    \n    // specular brdf\n    float D = NormalDistributionGGX(linearRoughness, NoH);\n    float V = VisibilitySmithGGX(linearRoughness, NoV, NoL);\n    vec3  F = FresnelSchlickApprox(pixel.f0, LoH);\n\n#if IRIDESCENT_CAR\n#if RAINBOW_VOMIT\n    if (pixel.material.pbrParams.w < 0.5) F = GetIridescentFresnel(pixel.material, NoV, 1.2);\n#else\n    if (pixel.material.pbrParams.w < 0.5) F = GetIridescentFresnel(pixel.material, LoH, 1.2);\n#endif\n#endif\n    vec3  Fs = D * V * F;\n    \n    DEBUG_SET_MODE(DEBUG_MODE_DIRECT_SPECULAR, Fs);\n    \n    // diffuse brdf\n    vec3 diffuseColor = GetDiffuseColor(pixel.material);\n    vec3 Fd = diffuseColor * GetDiffuseBurley(linearRoughness, NoV, NoL, LoH);\n    Fd *= (1.0 - F);\n\n    DEBUG_SET_MODE(DEBUG_MODE_DIRECT_DIFFUSE, Fd * NoL);\n    \n    // clearcoat specular\n    float clearCoatD = NormalDistributionGGX(clearcoatLinearRoughness, clearcoatNoH);\n    float clearcoatV = VisibilityKelemen(LoH);\n    vec3  clearcoatF = vec3(FresnelSchlickApproxF90(0.04, 1.0, LoH));\n#if IRIDESCENT_CAR\n#if RAINBOW_VOMIT\n    if (pixel.material.pbrParams.w < 0.5) clearcoatF = GetIridescentFresnel(pixel.material, clearcoatNoV, 1.0);   \n#else\n    if (pixel.material.pbrParams.w < 0.5) clearcoatF = GetIridescentFresnel(pixel.material, NoH, 1.0);   \n#endif\n#endif\n\n    clearcoatF *= pixel.material.pbrParams.z;\n    \n    vec3 clearcoatFs = clearCoatD * clearcoatV * clearcoatF;\n    //vec3 attenuation = 1.0 - clearcoatF;\n    // attenuation *= pixel.shadow;\n    \n    DEBUG_SET_MODE(DEBUG_MODE_CLEARCOAT_DIRECT_SPECULAR, clearcoatFs);\n    \n    result  = Fd + Fs;\n    result *= NoL * (1.0 - clearcoatF); // attenuation\n    result += clearcoatFs * clearcoatNoL;\n    result *= LIGHT_INTENSITY * LIGHT_COLOR * pixel.shadow;\n    \n    // indirect diffuse\n    float diffuseAO = CalculateAmbientOcclusion(pixel);\n    DEBUG_SET_MODE(DEBUG_MODE_DIFFUSE_AMBIENT_OCCLUSION, vec3(diffuseAO));\n    \n    vec3 indirectDiffuse = SHIrradiance(pixel.normal) * GetDiffuseLambert() * sqrt(diffuseColor) * (1.0 - clearcoatF) * diffuseAO * LIGHT_COLOR;\n    DEBUG_SET_MODE(DEBUG_MODE_INDIRECT_DIFFUSE, indirectDiffuse);\n    \n    //result += indirectDiffuse;\n\n#if 1\n    vec2 reflectionHitResult;\n    Material sceneMaterial = pixel.material;\n    \n    float specularAO = SpecularOcclusionLagarde(clearcoatNoV, diffuseAO, clearcoatLinearRoughness);\n    \n    // Default scene indirect specular to indirect diffuse for surfaces that are too rough (hacky). \n    vec3 sceneIndirectSpecular = indirectDiffuse * 0.2, clearcoatIndirectSpecular = vec3(0.0);\n    vec2 envBrdfMetal = EnvBRDFApproxLazarov(sceneMaterial.pbrParams.x, NoV);\n    // Energy isn't strictly conserved here, but this looks slightly better at near zero angles.\n    float envBrdfNonMetal = EnvBRDFApproxNonmetal(0.015625 /**clearcoatRoughness*/, clearcoatNoV);\n    envBrdfNonMetal *= sceneMaterial.pbrParams.z * specularAO;\n    \n    if (sceneMaterial.pbrParams.z > BIG_EPS)\n    {\n        clearcoatIndirectSpecular = GetFogColor(Saturate(pixel.reflectionRay.direction.y), LIGHT_INTENSITY * 0.5);\n        if (SphereTrace(pixel.reflectionRay, reflectionHitResult))\n        {\n            // BEWARE: Reusing hitposition & material here for reflections!\n            pixel.hitPosition = pixel.reflectionRay.origin + pixel.reflectionRay.direction * reflectionHitResult.x;\n            SetupShadingMaterial(pixel, reflectionHitResult.y, false); \n            clearcoatIndirectSpecular = GetDiffuseColor(pixel.material) * 2.5;\n        }\n        \n        //clearcoatIndirectSpecular *= envBrdfNonMetal * clearcoatF;\n    }\n    \n    DEBUG_SET_MODE(DEBUG_MODE_CLEARCOAT_REFLECTION_COLOR, clearcoatIndirectSpecular);\n    // Again, doesn't conserve energy completely but this (instead of just clearcoatF) looks nicer.\n    // clearcoatIndirectSpecular *= envBrdfNonMetal * mix(vec3(0.1), vec3(1.0), sqrt(clearcoatF));\n    clearcoatIndirectSpecular *= envBrdfNonMetal * (clearcoatF * 0.9 + 0.1);\n    DEBUG_SET_MODE(DEBUG_MODE_CLEARCOAT_INDIRECT_SPECULAR, clearcoatIndirectSpecular);\n    \n    // Only do the expensive reflection ray march if the material roughness falls below a certain threshold. \n    if (sceneMaterial.pbrParams.x < 0.5)\n    {\n        float seed = pixel.hitPosition.x * iResolution.y + pixel.hitPosition.z * iResolution.x * mod(iTime, 256.0);\n        vec3 randomHemisphereSample = RandomPointInUnitHemisphere(seed);\n        pixel.reflectionRay.direction = normalize(pixel.reflectionRay.direction + randomHemisphereSample * linearRoughness);\n        sceneIndirectSpecular = GetFogColor(Saturate(pixel.reflectionRay.direction.y), 2.0);\n\n\n        if (SphereTrace(pixel.reflectionRay, reflectionHitResult))\n        {\n            // BEWARE: Reusing hitposition & material here for reflections!\n            pixel.hitPosition = pixel.reflectionRay.origin + pixel.reflectionRay.direction * reflectionHitResult.x;\n            SetupShadingMaterial(pixel, reflectionHitResult.y, false); \n            sceneIndirectSpecular = GetDiffuseColor(pixel.material);\n        }\n\n        DEBUG_SET_MODE(DEBUG_MODE_SCENE_REFLECTION_COLOR, sceneIndirectSpecular);\n\n        sceneIndirectSpecular *= pixel.f0 * envBrdfMetal.x + envBrdfMetal.y;\n        sceneIndirectSpecular *= specularAO;\n        // sceneIndirectSpecular *= smoothstep(0.0, 0.9, specularAO) + 0.1; // hacky af but looks nice.\n        if (sceneMaterial.pbrParams.z > BIG_EPS)\n        {\n            sceneIndirectSpecular *= (1.0 - clearcoatF) * (1.0 - sceneMaterial.pbrParams.z) * (1.0 - envBrdfNonMetal);\n        }\n    }\n    \n    DEBUG_SET_MODE(DEBUG_MODE_SCENE_INDIRECT_SPECULAR, sceneIndirectSpecular);\n    DEBUG_SET_MODE(DEBUG_MODE_INDIRECT_SPECULAR_COMBINED, clearcoatIndirectSpecular + sceneIndirectSpecular);\n    \n    result += (indirectDiffuse + (clearcoatIndirectSpecular + sceneIndirectSpecular) * LIGHT_COLOR) * INDIRECT_LIGHT_INTENSITY;\n#endif\n    \n    return result;\n}\n\nvoid ShadePixel(in Ray sceneRay, in vec2 hitResult, inout vec3 result)\n{    \n    PixelContext pixel;\n    \n    pixel.hitPosition = sceneRay.origin + sceneRay.direction * hitResult.x;\n    pixel.viewDirection = -sceneRay.direction;\n    \n    pixel.clearcoatNormal = pixel.normal = CalculateNormal(pixel.hitPosition); \n    DEBUG_SET_MODE(DEBUG_MODE_NORMAL, pixel.normal * 0.5 + 0.5);\n    DEBUG_SET_MODE(DEBUG_MODE_CLEARCOAT_NORMAL, pixel.clearcoatNormal * 0.5 + 0.5);\n    \n    pixel.lightDirection = normalize(LIGHT_POSITION.xyz - pixel.hitPosition);\n    pixel.halfVector = normalize(pixel.viewDirection + pixel.lightDirection);\n    \n    pixel.shadow = SoftShadowSphereTrace(Ray(pixel.hitPosition + pixel.normal * SMOL_EPS, pixel.lightDirection));\n    \n    SetupShadingMaterial(pixel, hitResult.y, true); \n    DEBUG_SET_MODE(DEBUG_MODE_ALBEDO, pixel.material.albedo.xyz);\n    \n    pixel.f0 = vec3(0.04);\n    \n    pixel.reflectionRay = Ray(pixel.hitPosition + pixel.clearcoatNormal * SMOL_EPS, normalize(reflect(sceneRay.direction, pixel.clearcoatNormal)));\n    \n    // Mix shading result with fog\n    result = mix(BRDF(pixel), result, Saturate(1.0 - exp(-pow(hitResult.x * 0.06, 8.0))));\n}\n\n/**----------------------------------------------------------------\n\n        *** Main Image ***\n   \n-------------------------------------------------------------------*/\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = vec4(0.0);\n    \n    // Halton sequence generated offline within range [-0.5, 0.5]\n    vec2 offset = HaltonSequence[uint(iFrame) % 16u];\n    \n    // Pixel coordinates [-0.5, 0.5]\n    vec2 halfNdc = (fragCoord + offset - 0.5 * iResolution.xy) / iResolution.y;\n    // Cached polar and azimuthal angles(normalized) for the arcball camera from the previous frame. [0.0, 1.0]\n    vec4 cachedCameraAngles = texelFetch(iChannel0, ivec2(0), 0);\n    cachedCameraAngles.xy = cachedCameraAngles.zw;\n    // Current frame mouse position [0.0, 1.0]\n    vec4 currentMouse = iMouse / iResolution.xyxy;\n    // Previous frame mouse position [0.0, 1.0]\n    vec4 previousMouse = texelFetch(iChannel0, ivec2(1, 0), 0);\n\n    // Add mouse drag velocity to camera angles so it only moves from its current position\n    if (currentMouse.z > 0.0 && previousMouse.z > 0.0)\n    {\n        cachedCameraAngles.zw += currentMouse.xy - previousMouse.xy;\n        cachedCameraAngles.w = Saturate(cachedCameraAngles.w); // confine polar angle to [0.0, 1.0] domain, it becomes [0.0, PI] after de-normalization. \n    }\n#if 1\n    else\n    {\n        float cameraSpeed = iTime * 0.015;\n        cachedCameraAngles.z = cameraSpeed;\n        cachedCameraAngles.w = mix(0.9, 0.45, RemapTo01(sin(cameraSpeed * 3.0)));\n    }\n#endif\n\n    if (iFrame == 0) // Initial camera angles (normalized).\n    {\n        cachedCameraAngles = vec2(0., 0.85).xyxy;\n    }\n\n    vec4 outColor = vec4(0.0);\n    outColor.xyz = GetFogColor(pow(halfNdc.y * cachedCameraAngles.w + 0.5, 2.0), 2.0);\n    \n\n    Ray sceneRay = GetCameraRay(halfNdc, cachedCameraAngles.zw);\n    vec2 hitResult;\n    \n    // Sun haze\n    float sunDot = Saturate(dot(sceneRay.direction, normalize(LIGHT_POSITION.xyz)));\n    outColor.xyz += pow(sunDot, 8.0) * 4.0;\n    outColor.xyz += pow(sunDot, 6.0) * 3.0;\n    outColor.xyz += pow(sunDot, 4.0) * 2.0;\n    outColor.xyz += pow(sunDot, 3.0);\n\n    if (SphereTrace(sceneRay, hitResult))\n    {\n        ShadePixel(sceneRay, hitResult, outColor.xyz);\n        DEBUG_SET_OUTPUT(outColor.xyz);\n    }\n    \n    outColor.w = hitResult.x;\n\n    if (fragCoord.y < 1.0)\n    {\n        if (fragCoord.x < 3.0) outColor.xyz = iResolution;\n        if (fragCoord.x < 2.0) outColor     = currentMouse;\n        if (fragCoord.x < 1.0) outColor     = cachedCameraAngles;\n    }\n\n    fragColor = outColor;\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "/**\n    TAA pass for anti-aliasing, and getting rid of some of that nasty noise. Enable or disable TAA in the common tab.\n*/\n\n#if TAA_ENABLED\n\n#define TAA_USE_NEAREST_DEPTH 1\n\n#define TAA_PERFORM_TONEMAP 1\n#define TAA_CONVERT_TO_YCOCG 1\n\n#define TAA_FILTERED_INPUT 1\n#if TAA_FILTERED_INPUT\n    #define TAA_FILTERED_PLUS_WEIGHTS 1\n#endif\n\n#define TAA_ANTI_GHOSTING 1\n\nconst ivec2 NeighborhoodOffsets[9] = ivec2[](\n    ivec2(-1,  0),\n    ivec2( 1,  0),\n    ivec2( 0,  1),\n    ivec2( 0, -1),\n    ivec2( 0,  0),\n    ivec2(-1, -1),\n    ivec2( 1, -1),\n    ivec2(-1,  1),\n    ivec2( 1,  1)\n);\n\nconst float GaussianWeights[3] = float[](0.25, 0.125, 0.0625);\n\nfloat GetLuma(in vec3 color)\n{\n    // ITU-R BT.2020 color space\n    // return dot(color, vec3(0.2627, 0.6780, 0.0593);\n\n    // ITU-R BT.709 color space\n    // return dot(color, vec3(0.2126, 0.7152, 0.0722));\n    \n    // ITU-R BT.601 color space\n    return dot(color, vec3(0.299, 0.587, 0.114));\n}\n\nfloat HDRTonemap(in float luma)\n{\n    return 1.0 / (1.0 + luma);\n}\n\nfloat HDRTonemapInverse(in float luma)\n{\n    return 1.0 / (1.0 - luma);\n}\n\nvec3 RGBToYCoCg(in vec3 RGB)\n{\n    return vec3(dot(RGB, vec3(0.25f, 0.5f, 0.25f)),\n                dot(RGB, vec3(0.5f, 0.0f, -0.5f)),\n                dot(RGB, vec3(-0.25f, 0.5f, -0.25f)));\n}\n\n\nvec3 YCoCgToRGB(in vec3 YCoCg)\n{\n    return vec3(YCoCg.x + YCoCg.y - YCoCg.z,\n                YCoCg.x + YCoCg.z,\n                YCoCg.x - YCoCg.y - YCoCg.z);\n}\n\nvec4 FromRGB(in vec4 color)\n{\n    color.xyz = max(color.xyz, vec3(SMOL_EPS));\n    \n#if TAA_PERFORM_TONEMAP\n    color.xyz *= HDRTonemap(GetLuma(color.xyz));\n#endif\n\n#if TAA_CONVERT_TO_YCOCG \n    color.xyz = RGBToYCoCg(color.xyz);\n#endif\n\n    return color;\n}\n\nvec3 ToRGB(in vec3 color)\n{\n#if TAA_CONVERT_TO_YCOCG\n    vec3 result = YCoCgToRGB(color);\n#endif\n\n#if TAA_PERFORM_TONEMAP\n    result *= HDRTonemapInverse(GetLuma(result));\n#endif\n    \n    return max(result, vec3(SMOL_EPS));\n}\n\nfloat FindNearestDepth(in vec4 neighborhoodSamples[9u])\n{\n    float nearestDepth = neighborhoodSamples[4u].w;\n    \n#if TAA_USE_NEAREST_DEPTH\n    vec4 diagonalNeighbors = vec4(neighborhoodSamples[5u].w, neighborhoodSamples[6u].w,\n                                  neighborhoodSamples[7u].w, neighborhoodSamples[8u].w);\n                                  \n    float nearestBottom    = min(diagonalNeighbors.x, diagonalNeighbors.y);\n    float nearestTop       = min(diagonalNeighbors.z, diagonalNeighbors.w);\n    float nearestDiagonal  = min(nearestBottom, nearestTop);\n    \n    nearestDepth = min(nearestDepth, nearestDiagonal);\n#endif\n\n    return nearestDepth;\n}\n\nvec2 CalculateHistoryUV(in vec4 worldPosition, in vec2 historyCameraAngles, in vec2 haltonOffset)\n{\n    mat4 historyWorldToView = GetCameraWorldToView(historyCameraAngles);\n                        \n    vec3 viewPosition = (worldPosition * historyWorldToView).xyz; // Note: view matrix is stored in row major, hence the inverse multiply.\n    vec2 uvHistory = CAMERA_ZOOM * viewPosition.xy / viewPosition.z;\n    uvHistory = 0.5 + uvHistory * vec2(iResolution.y / iResolution.x, 1.0);\n    uvHistory -= haltonOffset / iResolution.xy; // remove jitter\n    return uvHistory;\n}\n\nvoid FetchNeighborhoodSamples(in sampler2D inputColor, in ivec2 texCoord, out vec4 neighborhoodSamples[9u])\n{\n    for (uint i = 0u; i < 9u; ++i)\n    {\n        neighborhoodSamples[i] = FromRGB(texelFetch(inputColor, texCoord + NeighborhoodOffsets[i], 0));\n    }\n}\n\nvec4 FilterInput(in vec4 neighborhoodSamples[9u], in vec2 jitter)\n{\n#if TAA_FILTERED_INPUT\n    float totalWeight = 0.0;\n    vec2 pixelOffset = vec2(0.0);\n    \n#if TAA_FILTERED_PLUS_WEIGHTS\n    float plusWeights[5u];\n    for (uint i = 0u; i < 5u; ++i)\n    {\n        pixelOffset = vec2(NeighborhoodOffsets[i]) - jitter * 1.0;\n        plusWeights[i] = exp(-2.29f * dot(pixelOffset, pixelOffset));\n        totalWeight += plusWeights[i];\n    }\n    \n    for (uint i = 0u; i < 5u; ++i)\n    {\n        plusWeights[i] *= 1.0 / totalWeight;\n    }\n    \n    return neighborhoodSamples[0u] * plusWeights[0u] + neighborhoodSamples[1u] * plusWeights[1u]\n         + neighborhoodSamples[2u] * plusWeights[2u] + neighborhoodSamples[3u] * plusWeights[3u]\n         + neighborhoodSamples[4u] * plusWeights[4u];\n#else\n    float gaussianWeights[9u];\n    for (uint i = 0u; i < 9u; ++i)\n    {\n        pixelOffset = vec2(NeighborhoodOffsets[i]) - jitter * 1.0;\n        gaussianWeights[i] = exp(-2.29f * dot(pixelOffset, pixelOffset));\n        totalWeight += gaussianWeights[i];\n    }\n    \n    for (uint i = 0u; i < 9u; ++i)\n    {\n        gaussianWeights[i] *= 1.0 / totalWeight;\n    }\n    \n    return neighborhoodSamples[0u] * gaussianWeights[0u] + neighborhoodSamples[1u] * gaussianWeights[1u]\n         + neighborhoodSamples[2u] * gaussianWeights[2u] + neighborhoodSamples[3u] * gaussianWeights[3u]\n         + neighborhoodSamples[4u] * gaussianWeights[4u] + neighborhoodSamples[5u] * gaussianWeights[5u]\n         + neighborhoodSamples[6u] * gaussianWeights[6u] + neighborhoodSamples[7u] * gaussianWeights[7u]\n         + neighborhoodSamples[8u] * gaussianWeights[8u];\n#endif\n#else\n    return neighborhoodSamples[4u];\n#endif\n}\n\n// Courtesy of TheRealMJP: https://gist.github.com/TheRealMJP/c83b8c0f46b63f3a88a5986f4fa982b1\nvec4 SampleHistoryCatmullRom(in sampler2D history, in vec2 uv, in vec2 texSize)\n{\n    // We're going to sample a a 4x4 grid of texels surrounding the target UV coordinate. We'll do this by rounding\n    // down the sample location to get the exact center of our \"starting\" texel. The starting texel will be at\n    // location [1, 1] in the grid, where [0, 0] is the top left corner.\n    vec2 samplePos = uv * texSize;\n    vec2 texPos1 = floor(samplePos - 0.5) + 0.5;\n\n    // Compute the fractional offset from our starting texel to our original sample location, which we'll\n    // feed into the Catmull-Rom spline function to get our filter weights.\n    vec2 f = samplePos - texPos1;\n\n    // Compute the Catmull-Rom weights using the fractional offset that we calculated earlier.\n    // These equations are pre-expanded based on our knowledge of where the texels will be located,\n    // which lets us avoid having to evaluate a piece-wise function.\n    vec2 w0 = f * (-0.5 + f * (1.0 - 0.5 * f));\n    vec2 w1 = 1.0 + f * f * (-2.5 + 1.5 * f);\n    vec2 w2 = f * (0.5 + f * (2.0 - 1.5 * f));\n    vec2 w3 = f * f * (-0.5 + 0.5 * f);\n\n    // Work out weighting factors and sampling offsets that will let us use bilinear filtering to\n    // simultaneously evaluate the middle 2 samples from the 4x4 grid.\n    vec2 w12 = w1 + w2;\n    vec2 offset12 = w2 / (w1 + w2);\n\n    // Compute the final UV coordinates we'll use for sampling the texture\n    vec2 texPos0 = texPos1 - 1.0;\n    vec2 texPos3 = texPos1 + 2.0;\n    vec2 texPos12 = texPos1 + offset12;\n\n    texPos0 /= texSize;\n    texPos3 /= texSize;\n    texPos12 /= texSize;\n\n    vec4 result = vec4(0.0);\n    result += textureLod(history, vec2(texPos0.x, texPos0.y), 0.0) * w0.x * w0.y;\n    result += textureLod(history, vec2(texPos12.x, texPos0.y), 0.0) * w12.x * w0.y;\n    result += textureLod(history, vec2(texPos3.x, texPos0.y), 0.0) * w3.x * w0.y;\n\n    result += textureLod(history, vec2(texPos0.x, texPos12.y), 0.0) * w0.x * w12.y;\n    result += textureLod(history, vec2(texPos12.x, texPos12.y), 0.0) * w12.x * w12.y;\n    result += textureLod(history, vec2(texPos3.x, texPos12.y), 0.0) * w3.x * w12.y;\n\n    result += textureLod(history, vec2(texPos0.x, texPos3.y), 0.0f) * w0.x * w3.y;\n    result += textureLod(history, vec2(texPos12.x, texPos3.y), 0.0) * w12.x * w3.y;\n    result += textureLod(history, vec2(texPos3.x, texPos3.y), 0.0f) * w3.x * w3.y;\n\n    return result;\n}\n\nvoid ComputeMeanVariance(in vec4 neighborhoodSamples[9u], out vec3 mean, out vec3 variance)\n{\n    const float totalNeighborhoodSamplesInv = 1.0 / 9.0;\n    vec3 m1  = neighborhoodSamples[0u].xyz + neighborhoodSamples[1u].xyz + neighborhoodSamples[2u].xyz + neighborhoodSamples[3u].xyz \n             + neighborhoodSamples[4u].xyz + neighborhoodSamples[5u].xyz + neighborhoodSamples[6u].xyz + neighborhoodSamples[7u].xyz\n             + neighborhoodSamples[8u].xyz;\n    vec3 m2  = neighborhoodSamples[0u].xyz * neighborhoodSamples[0u].xyz + neighborhoodSamples[1u].xyz * neighborhoodSamples[1u].xyz \n             + neighborhoodSamples[2u].xyz * neighborhoodSamples[2u].xyz + neighborhoodSamples[3u].xyz * neighborhoodSamples[3u].xyz \n             + neighborhoodSamples[4u].xyz * neighborhoodSamples[4u].xyz + neighborhoodSamples[5u].xyz * neighborhoodSamples[5u].xyz\n\t\t\t + neighborhoodSamples[6u].xyz * neighborhoodSamples[6u].xyz + neighborhoodSamples[7u].xyz * neighborhoodSamples[7u].xyz\n             + neighborhoodSamples[8u].xyz * neighborhoodSamples[8u].xyz;\n    mean     = m1 * totalNeighborhoodSamplesInv;\n    variance = sqrt(abs(m2 * totalNeighborhoodSamplesInv - mean * mean));\n}\n\nfloat DisocclusionAntiGhosting(in float nearestDepth, in vec2 uvHistory, in sampler2D inputBuffer)\n{\n#if TAA_ANTI_GHOSTING\n    const ivec2 offset = ivec2(-1, 1);\n    \n    ivec2 historyCoord = ivec2(uvHistory * iResolution.xy);\n    float nearestHistoryDepth = texelFetch(inputBuffer, historyCoord, 0).w; \n    \n    vec4 historyDepthCorners = vec4(texelFetch(inputBuffer, historyCoord + offset.xx, 0).w,\n                                    texelFetch(inputBuffer, historyCoord + offset.yx, 0).w,\n                                    texelFetch(inputBuffer, historyCoord + offset.xy, 0).w,\n                                    texelFetch(inputBuffer, historyCoord + offset.yy, 0).w);\n                                    \n    float nearestHistoryDepthCorner = min(min(historyDepthCorners.x, historyDepthCorners.y), min(historyDepthCorners.z, historyDepthCorners.w));\n    nearestHistoryDepth = min(nearestHistoryDepthCorner, nearestHistoryDepth);\n    \n    return Saturate((abs(nearestDepth - nearestHistoryDepth) - 0.001) * 10.0);\n#else\n    return 0.0;\n#endif\n}\n\nvec4 ClipHistoryColor(in vec4 historyColor, in vec4 neighborhoodSamples[9u], float disocclusionFactor)\n{\n    vec3 mean, variance;\n    ComputeMeanVariance(neighborhoodSamples, mean, variance);\n    \n    float varianceScale = 1.25;\n    varianceScale *= max(0.25, 1.0 - disocclusionFactor);\n    variance *= varianceScale;\n    \n    vec3 historyMin = mean - variance;\n    vec3 historyMax = mean + variance;\n    historyColor.xyz = clamp(historyColor.xyz, historyMin, historyMax);\n    return historyColor;\n}\n\n#endif\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n#if TAA_ENABLED\n    // Halton sequence generated offline within range [-0.5, 0.5]\n    vec2 offset = HaltonSequence[uint(iFrame) % 16u];\n    // Pixel coordinates [-0.5, 0.5]\n    vec2 halfNdc = (fragCoord + offset - 0.5 * iResolution.xy) / iResolution.y;\n    // Normalized camera angles in range [0.0, 1.0], xy - history, zw - current frame.\n    vec4 cachedCameraAngles = texelFetch(iChannel1, ivec2(0), 0);\n    \n    vec4 neighborhoodSamples[9u];\n    FetchNeighborhoodSamples(iChannel1, ivec2(fragCoord), neighborhoodSamples);\n    \n    // Current frame data, xyz - color, w - ray hit distance    \n    vec4 currentColor = FilterInput(neighborhoodSamples, offset);\n    float nearestDepth = FindNearestDepth(neighborhoodSamples);\n    \n    Ray sceneRay = GetCameraRay(halfNdc, cachedCameraAngles.zw);\n    vec2 uvHistory = CalculateHistoryUV(vec4(sceneRay.origin + sceneRay.direction * nearestDepth, 1.0), cachedCameraAngles.xy, offset);\n    \n    float velocityMagnitude = length(fragCoord / iResolution.xy - uvHistory);\n    \n    float disocclusionFactor = DisocclusionAntiGhosting(nearestDepth, uvHistory, iChannel1);\n    vec4 historyColor = FromRGB(min(max(SampleHistoryCatmullRom(iChannel0, uvHistory, iResolution.xy), vec4(1e-6)), FLT_MAX));\n    historyColor = ClipHistoryColor(historyColor, neighborhoodSamples, disocclusionFactor);\n    \n    float blendWeight = mix(0.05, 0.3, Saturate(velocityMagnitude * 2.5));\n    blendWeight = mix(blendWeight, 1.0, disocclusionFactor);\n    \n    if (any(lessThan(uvHistory, vec2(0.0))) || any(greaterThanEqual(uvHistory, vec2(1.0))) || any(isnan(uvHistory)) || any(isinf(uvHistory)))\n    {\n        blendWeight = 1.0;\n    }\n    \n    currentColor.xyz = mix(historyColor.xyz, currentColor.xyz, blendWeight);\n    \n    fragColor = vec4(ToRGB(currentColor.xyz), nearestDepth);    \n#else\n    fragColor = texelFetch(iChannel1, ivec2(fragCoord), 0);\n#endif\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "/**\n    Contrast Adaptive Sharpening pass based on AMD's FidelityFx library to recover some\n    of the car paint microdetails after TAA (only if TAA is enabled).  \n*/\n\n#ifdef CAS_FILTER\n    #define CAS_BETTER_DIAGONALS\n    #define FSR_CAS_DENOISE\n    #define CAS_GO_SLOWER\n    #define CAS_SLOW\n#endif\n\nconst float SHARPNESS = 0.8;\n\nfloat APrxLoRcpF1(in float a)\n{\n    return uintBitsToFloat(uint(0x7ef07ebb) - floatBitsToUint(a));\n}\n\nfloat APrxLoSqrtF1(in float a)\n{\n    return uintBitsToFloat((floatBitsToUint(a) >> 1u) + uint(0x1fbc4639));\n}\n\nfloat APrxMedRcpF1(in float a)\n{\n    float b = uintBitsToFloat(uint(0x7ef19fff) - floatBitsToUint(a));\n    return b * ( -b * a + 2.0);\n}\n\nvec3 CasLoad(in ivec2 pixelCoord)\n{\n    return texelFetch(iChannel0, pixelCoord, 0).xyz;\n}\n\nuvec4 CasSetup(in float sharpness)\n{\n    uvec4 result;\n    float sharp = -1.0 / mix(8.0, 5.0, Saturate(sharpness));\n    vec2 hSharp = vec2(sharp);\n    result.x = floatBitsToUint(sharp);\n    result.y = packHalf2x16(hSharp);\n    result.z = floatBitsToUint(8.0);\n    result.w = 0u;\n    \n    return result;\n}\n\nvoid CasFilter(inout vec3 color, in ivec2 pixelCoord, in uvec4 casParams)\n{\n    vec3 a = CasLoad(pixelCoord + ivec2(-1,-1));\n    vec3 b = CasLoad(pixelCoord + ivec2( 0,-1));\n    vec3 c = CasLoad(pixelCoord + ivec2( 1,-1));\n    vec3 d = CasLoad(pixelCoord + ivec2(-1, 0));\n    vec3 e = CasLoad(pixelCoord);\n    vec3 f = CasLoad(pixelCoord + ivec2( 1, 0));\n    vec3 g = CasLoad(pixelCoord + ivec2(-1, 1));\n    vec3 h = CasLoad(pixelCoord + ivec2( 0, 1));\n    vec3 i = CasLoad(pixelCoord + ivec2( 1, 1));\n    \n    // Soft min and max.\n    //  a b c             b\n    //  d e f * 0.5  +  d e f * 0.5\n    //  g h i             h\n    float mnR = Min3(Min3(d.r, e.r, f.r), b.r, h.r);\n    float mnG = Min3(Min3(d.g, e.g, f.g), b.g, h.g);\n    float mnB = Min3(Min3(d.b, e.b, f.b), b.b, h.b);\n    \n#ifdef CAS_BETTER_DIAGONALS\n    float mnR2 = Min3(Min3(mnR, a.r, c.r), g.r, i.r);\n    float mnG2 = Min3(Min3(mnG, a.g, c.g), g.g, i.g);\n    float mnB2 = Min3(Min3(mnB, a.b, c.b), g.b, i.b);\n    mnR = mnR + mnR2;\n    mnG = mnG + mnG2;\n    mnB = mnB + mnB2;\n#endif\n\n    float mxR = Saturate(Max3(Max3(d.r, e.r, f.r), b.r, h.r));\n    float mxG = Saturate(Max3(Max3(d.g, e.g, f.g), b.g, h.g));\n    float mxB = Saturate(Max3(Max3(d.b, e.b, f.b), b.b, h.b));\n    \n#ifdef CAS_BETTER_DIAGONALS\n    float mxR2 = Saturate(Max3(Max3(mxR, a.r, c.r), g.r, i.r));\n    float mxG2 = Saturate(Max3(Max3(mxG, a.g, c.g), g.g, i.g));\n    float mxB2 = Saturate(Max3(Max3(mxB, a.b, c.b), g.b, i.b));\n    mxR = mxR + mxR2;\n    mxG = mxG + mxG2;\n    mxB = mxB + mxB2;\n#endif\n\n// Smooth minimum distance to signal limit divided by smooth max.\n#ifdef CAS_GO_SLOWER\n    float rcpMR = 1.0 / mxR;\n    float rcpMG = 1.0 / mxG;\n    float rcpMB = 1.0 / mxB;\n#else\n    float rcpMR = APrxLoRcpF1(mxR);\n    float rcpMG = APrxLoRcpF1(mxG);\n    float rcpMB = APrxLoRcpF1(mxB);\n#endif\n#ifdef CAS_BETTER_DIAGONALS\n    float ampR = Saturate(min(mnR, 2.0 - mxR) * rcpMR);\n    float ampG = Saturate(min(mnG, 2.0 - mxG) * rcpMG);\n    float ampB = Saturate(min(mnB, 2.0 - mxB) * rcpMB);\n#else\n    float ampR = Saturate(min(mnR, 1.0 - mxR) * rcpMR);\n    float ampG = Saturate(min(mnG, 1.0 - mxG) * rcpMG);\n    float ampB = Saturate(min(mnB, 1.0 - mxB) * rcpMB);\n#endif\n\n// Shaping amount of sharpening.\n#ifdef CAS_GO_SLOWER\n    ampR = sqrt(ampR);\n    ampG = sqrt(ampG);\n    ampB = sqrt(ampB);\n#else\n    ampR = APrxLoSqrtF1(ampR);\n    ampG = APrxLoSqrtF1(ampG);\n    ampB = APrxLoSqrtF1(ampB);\n#endif\n\n    // Filter shape.\n    //  0 w 0\n    //  w 1 w\n    //  0 w 0\n    float peak = uintBitsToFloat(casParams.x);\n\n#ifdef FSR_CAS_DENOISE\n    // Luma times 2.\n    float bL = b.b * 0.5 + (b.r * 0.5 + b.g);\n    float dL = d.b * 0.5 + (d.r * 0.5 + d.g);\n    float eL = e.b * 0.5 + (e.r * 0.5 + e.g);\n    float fL = f.b * 0.5 + (f.r * 0.5 + f.g);\n    float hL = h.b * 0.5 + (h.r * 0.5 + h.g);\n    \n    // Noise detection.\n    float nz = 0.25 * bL + 0.25 * dL + 0.25 * fL + 0.25 * hL - eL;\n    nz = Saturate(abs(nz) * APrxMedRcpF1(Max3(Max3(bL, dL, eL), fL, hL) - Min3(Min3(bL, dL, eL), fL, hL)));\n    nz = 1.0 - 0.5 * nz;\n    peak *= nz;\n#endif\n\n    float wR = ampR * peak;\n    float wG = ampG * peak;\n    float wB = ampB * peak;\n    \n    // Filter.\n#ifndef CAS_SLOW\n    // Using green coef only, depending on dead code removal to strip out the extra overhead.\n#ifdef CAS_GO_SLOWER\n    float rcpWeight = 1.0 / (1.0 + 4.0 * wG);\n#else\n    float rcpWeight = APrxMedRcpF1(1.0 + 4.0 * wG);\n#endif\n    color.r = (b.r * wG + d.r * wG + f.r * wG + h.r * wG + e.r) * rcpWeight;\n    color.g = (b.g * wG + d.g * wG + f.g * wG + h.g * wG + e.g) * rcpWeight;\n    color.b = (b.b * wG + d.b * wG + f.b * wG + h.b * wG + e.b) * rcpWeight;\n#else\n#ifdef CAS_GO_SLOWER\n    float rcpWeightR = 1.0 / (1.0 + 4.0 * wR);\n    float rcpWeightG = 1.0 / (1.0 + 4.0 * wG);\n    float rcpWeightB = 1.0 / (1.0 + 4.0 * wB);\n#else\n    float rcpWeightR = APrxMedRcpF1(1.0 + 4.0 * wR);\n    float rcpWeightG = APrxMedRcpF1(1.0 + 4.0 * wG);\n    float rcpWeightB = APrxMedRcpF1(1.0 + 4.0 * wB);\n#endif\n    color.r = (b.r * wR + d.r * wR + f.r * wR + h.r * wR + e.r) * rcpWeightR;\n    color.g = (b.g * wG + d.g * wG + f.g * wG + h.g * wG + e.g) * rcpWeightG;\n    color.b = (b.b * wB + d.b * wB + f.b * wB + h.b * wB + e.b) * rcpWeightB;\n#endif\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    ivec2 pixelCoord = ivec2(fragCoord);\n    vec4 outColor = texelFetch(iChannel0, pixelCoord, 0);\n\n#ifdef CAS_FILTER\n    uvec4 casParams = CasSetup(SHARPNESS);\n    CasFilter(outColor.xyz, pixelCoord, casParams);\n#endif\n\n    fragColor = outColor;\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    }
                ],
                "name": "Buffer D",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 260
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}