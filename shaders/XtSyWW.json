{
    "Shader": {
        "info": {
            "date": "1508481976",
            "description": "fork of\nhttps://www.shadertoy.com/view/ldBSDt\nlets see how much i can work on this\nnot much so far. saving a few multiplications only.",
            "flags": 0,
            "hasliked": 0,
            "id": "XtSyWW",
            "likes": 13,
            "name": "Relativistic 2",
            "published": 3,
            "tags": [
                "relativistic",
                "brdf",
                "transformation",
                "fresnel",
                "relativity",
                "lorenz"
            ],
            "usePreview": 0,
            "username": "ollj",
            "viewed": 1235
        },
        "renderpass": [
            {
                "code": "/*\nThinking in terms of speed instead of positions (over time)\n is the first step of understanding relativity. Basic calculus stuff.\n\nYou and the scene arpound move at the SAME speed that is shown on top\n,as a fraction of the speed of light.\n\nAt first glance you appear to stand still in a set that stands still\n,but this is newtonian physics of a static point of reference\n,but this is an overly simplified model that only works well for small speeds.\n\nDepending on your relative speed, similarly to running trough rain\n, more rain hits you from the front and at an angle\n, depending on your relative speed.\nThe difference is that speed of rain is variable, mutable;\n There is terminal velocity of water and air pressure stuff.\nBUT light always moves at a constant speed.\n\nBarely noticable below 5% of the speed of light; the faster you move;\n- The more your view turns into a fisheye-lens\n- The more photons reach you from your movement direction\n- The more your movement direction gets blue shifted, seing ultraviolet, x-ray, gamma\n- The more your negative movement direction gets redshifted, seing infrared\n\n\nIn reality everything is relative, there is no static reference point\n, or, any arbitiaryly chosen referene point is equaly valid\nand can be transformed into another one with coordinate transformations.\nIn rality, the speed of light is likely the only static refference.\nAsserting that the speed of light is the fastest possible speed\n and a universal constant (if not the only one).\n the [speed of time] and [scales of space] are mutable\n (as well as positions in time and space (position can hange over time, duh!)).\nThe speed and scale of spacetime depend on:\n- ... an observers relative movement to observed things.\n- ... deformation of spacetime due to mass.\n[Lorenz Transformation] warps spacetime and can transform one observation into another.\n\nAnything with a non-zero-resting-mass can never reach the speed of light\n, only approach it.\nAnything with a     zero-restimg-mass always moves at the speed of light\n, possibly not the shortest distance, trough warked space, with reflections.\nWhile moving at the speed of light, your time stands still.\nThe closer your speed is to the speed of light\n, the more spacetime warps into a singularity.\nThe speed of time always has a >=0 magnitude, like a length(spacetime).\n*/\n\n// Created by Sebastien Durand - 2014\n// License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n// Adaptation from article\n// http://www.anu.edu.au/physics/Searle/Obsolete/Seminar.html (link broken today!)\n// An explanation on phenomenon involved: \n// http://people.physics.anu.edu.au/~cms130/TEE/site/tee/learning/formulas/formulas.html\n// http://people.physics.anu.edu.au/~cms130/TEE/site/tee/learning/cd/cd.html\n// http://vimeo.com/76102645\n\n// model constrains: \n// is bufferless, no free moving camera.\n// Only valid for static objects \n// == no relative movement between camera and set\n// TODO: if(objects have (large) speed) calculate 4d intersection trough spacetime.\n// == (apply lorenz transformation)\n// TODO: if(objects have (large) speed) calculate differential for doppler effect.\n// TODO: if(objects have (large) speed) calculate shadows at good time \n\n//ollj feels confident enough to add some movement to this.\n//but also too tired to do it now.\n\n#define zFar 300.\n#define iterRm 60\n#define iterShadow 30\n#define eps .001\n\n#define tim iTime*.06\n\n#define doGrid\n\n//Doppler Effect intensity\n#define gDoppler 1.\n//Fisheye Effect intensity\n#define gFisheye 1.\n//this line makes (next to) no difference, disabled is faster.\n//#define doFisheyePlusPartial\n\n// Wavelengths in NanoMeter\n#define lU 340.\n#define lB 460.\n#define lG 520.\n#define lR 700.\n#define lI 1000.\n\n#define sat(a) clamp(a,.0,1.)\n\n//Newtonian RayMarching\nfloat sdBox(vec3 p, vec3 b){vec3 d = abs(p)-b\n;return min(max(d.x,max(d.y,d.z)),.0)+length(max(d,.0));} \n\n//all materialIDs.y should be negative\n//, this way they never conflict with positive zFar          \nvec2 gd(vec3 p){\n//;p.xy*=mat2(cos(-.091),sin(-.091),-sin(-.091),cos(-.091))\n;float d1=abs(dot(p,-vec3(0,1,0))-.15)\n;p+=vec3(.2,.52,-.4)\n;p=mod(p,1.6)-.8\n;float d2=sdBox(p,vec3(.15))\n#ifdef doGrid\n;float d3=length(p.xy)-.02;\n;d3=min(d3,length(p.yz)-.02);\n;d3=min(d3,length(p.zx)-.02);\n ;return (d3<d2&&d3<d1)?vec2(d3, mod(length(p),.15)<.1?30:80)\n :(d1<d2)?vec2(d1,1):vec2(d2,41) \n#endif\n;return(d1<d2)?vec2(d1,1):vec2(d2,41) \n;}\n\nfloat softshadow(vec3 u,vec3 t,float n,float m,float k)\n{float h,a=1.\n;for(int i=0;i<iterShadow;i++\n){if(n>m)break\n ;h=gd(u+t*n).x;a=min(a,7.*h/n);n+=.028\n;}return sat(a-.6);}\n\n#define iterAO 5.\nfloat calcAO(vec3 u,vec3 n){float a=0.,s=1.\n;for(float i=.0;i<iterAO;i++\n){float h=.01+.05*float(i);a+=-(gd(n*h+u).x-h)*s;s*=.75\n;}return sat(1.-4.*a);} \n\nvec2 castRay(vec3 u,vec3 t,float z)//origin,direction,zFar\n{float a=.0,h=eps*2.0;vec2 d\n;for(int i=0;i<iterRm;i++\n){if(abs(h)<eps||a>z)break\n ;a+=h;d=gd(u+t*a);h=d.x\n;}return vec2(a,d.y);}\n\nvec3 calcNormal(in vec3 p){vec2 e=vec2(eps,0);return normalize(vec3\n(gd(p+e.xyy).x-gd(p-e.xyy).x\n,gd(p+e.yxy).x-gd(p-e.yxy).x\n,gd(p+e.yyx).x-gd(p-e.yyx).x));}\n\n#define u5(a) ((a)*.5+.5)\n\nvec3 render( in vec3 u, in vec3 t,float z )\n{vec3 c=vec3(0)\n;vec2 d=castRay(u,t,20.)\n;if(d.y!=z//if(near surface)\n){u+=d.x*t\n //material color aborbtion spectrum:\n ;if(d.y==1.)c=.4+.1*vec3(1)*mod(floor(5.*u.z)+floor(5.*u.x),2.)\n ;else       c=vec3(.6)+.4*sin(vec3(.05,.08,.1)*(d.y-1.))\n //brdf,normal,lightDir //shade,ao,diffuse \n ;vec3 b=vec3(0),n=calcNormal(u),l=normalize(vec3(-.6,.7,-.5))\n ;float s=1.,a=calcAO(u,n),g=sat(dot(n,l))\n //shade \n ;if(g>.02){s=softshadow(u,l,.025, 10.,7.);g*=s;}\n ;b+=1.2*g*vec3(1,.9,.7)//diffuse\n ;b+=.2*sat(u5(n.y))*vec3(.1,.11,.13)*a;//ambiance\n ;b+=.2*sat(dot(n,normalize(-vec3(l.x,0,l.z))))*sat(1.-u.y)*vec3(.15)*a;//bac\n ;s*=pow(sat(dot(reflect(t,n),l)),16.)//specular\n ;a*=.5*.7*pow(sat(1.+dot(n,t)),2.) //diffuse.fresnel\n ;c=c*(b+s+a)+a//bdrf+specular\n ;c*=exp(-.01*d.x*d.x)//fog\n ;c=sat(c);\n;}return c;}\n\n//Relativistic Kit:\n\n//direction,velocity,ray,intensity\nfloat initRayForSpeed(vec3 t,vec3 v,out vec3 r,out float i\n){float b=length(v) // = (velocity of observer) / (speed of light)\n ;if(b==0.){r=t;i=1.;return 1.;}//no (fast) movement, newtonian.\n ;v=normalize(v)\n ;float a=dot(t,v)\n ,g=inversesqrt(1.-b*b)\n ,c=(a-b)/(1.-a*b)\n ;r=c*v+sqrt(1.-c*c)*normalize(t-a*v); //*Perpendicular component \n ;b=1.-b*c;i=g*b*b//Fisheye Effect:\n#ifdef doFisheyePlusPartial\n ;i=1.+(i-1.)*gFisheye;//Partial Fisheye for clarity\n#endif\n ;return mix(1.,g*b,gDoppler);}\n// http://en.wikipedia.org/wiki/Relativistic_aberration  \n\nfloat cShift(float s,vec3 c,float v,float i)\n{if(s<lU)return v*s/lU\n;if(s<lB)return(c.b-v  )*(s-lU)/(lB-lU)+v\n;if(s<lG)return(c.g-c.b)*(s-lB)/(lG-lB)+c.b\n;if(s<lR)return(c.r-c.g)*(s-lG)/(lR-lG)+c.g\n;if(s<lI)return(i  -c.r)*(s-lR)/(lI-lR)+c.r\n;return (lI/s)*i;}\n//origin,direction,velosity\nvec3 RelativisticRayTracing(in vec3 u, in vec3 t, in vec3 v)\n{vec3 r \n;float i\n,d=initRayForSpeed(t,v,r,i)\n;vec3 c = render(u,r,zFar)\n;if(gFisheye!=0.)c/= i\n;if(gDoppler!= 0.\n){d=1.+(d-1.)*gDoppler\n//ideally a texture stores some UV and IR (absorbtion spectrum) \n// that also gets shifted!\n//To save memory, we instead extrapolate into uv and ir,\n//An alternative could to define a texture as its hsr peak\n// and to extend the hsr range into uv and ir wavelengths.\n//  This would define a \"invisiblepink\" that is \"uv, mixed with ir\"\n \n ;float uv=.5*c.b+.25*c.g+.125*c.r //predict ultraviolet\n       ,ir=.5*c.r+.25*c.g+.125*c.b //predict infrared\n\n;return vec3(cShift(lR/d,c,uv,ir) //Shift to .rgb range\n        \t,cShift(lG/d,c,uv,ir)\n            ,cShift(lB/d,c,uv,ir));}return c;}\n\n//camera\nmat3 LookAt(vec3 u,vec3 t){vec3 f=normalize(u)//origin,up\n,r=normalize(cross(f,t));return mat3(r, cross(r,f),f);}\nvec3 RD(vec3 u,vec3 t,vec2 f){return LookAt(t-u,vec3(0,1,0))\n*normalize(vec3((2.*f-iResolution.xy)/iResolution.y,2.6));} \n\nvoid mainImage(out vec4 o,in vec2 v\n){o=vec4(0);//essential init for compatibility\n ;float b=sat(mix //fraction of light_speed [0..1]\n  (mod(tim,1.1)-.04      //change over Time\n ,iMouse.y/iResolution.y//change UI Mouse\n ,u5(sign(iMouse.z))))\n ;vec3 t,u=vec3(0,1.2,-20)\n ,look=u+vec3(cos(9.32*iMouse.x/iResolution.x),-.02,sin(9.32*iMouse.x/iResolution.x))\n ;for(int i=0;i<2;i++\n ){for(int j=0;j<2;j++\n  ){v=v.xy+.5*vec2(i,j)\n   ;t=RD(u,look,v)\n   ;if(v.y/iResolution.y>.96//splitscreen visualizes rpeed.\n   ){vec3 m=mix(vec3(0,1,0),vec3(1,0,0),b)\n    ;o.xyz+=mix(vec3(0),m,step(v.x/iResolution.x,b))         \n   ;}else{\n    ;o.xyz+=RelativisticRayTracing(u,t,b*vec3(1,0,0))\n   ;}   \n  ;}\n ;}\n ;o.xyz*=.25;}\n\n",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}