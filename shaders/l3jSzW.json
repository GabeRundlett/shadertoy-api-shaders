{
    "Shader": {
        "info": {
            "date": "1710344228",
            "description": "Attempting to replicate old school analog video feedback. Will add more realistic effects in a later fork.",
            "flags": 32,
            "hasliked": 0,
            "id": "l3jSzW",
            "likes": 4,
            "name": "Interactive Video Feedback #2",
            "published": 3,
            "tags": [
                "feedback",
                "analog"
            ],
            "usePreview": 0,
            "username": "jcarrano",
            "viewed": 154
        },
        "renderpass": [
            {
                "code": "void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = texelFetch(iChannel0, ivec2(fragCoord), 0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "\n#define AGC_TARGET 0.5\n#define AWB_STRENGTH 0.9\n\n#define AWB_FACTOR (1.0 - AWB_STRENGTH)\n\nmat3 rz(float theta)\n{\n    return mat3(vec3(cos(theta), sin(theta), .0),\n             \tvec3(-sin(theta), cos(theta), .0),\n                vec3(.0, .0, 1.));\n}\n\nmat3 ry(float theta)\n{\n    return mat3(vec3(cos(theta), .0, -sin(theta)),\n             \tvec3(.0, 1., .0),\n                vec3(sin(theta), .0, cos(theta)));\n}\n\nmat3 rx(float theta)\n{\n    return mat3(vec3(1., .0, .0),\n             \tvec3(.0, cos(theta), sin(theta)),\n                vec3(.0, -sin(theta), cos(theta)));\n}\n\n\nfloat mouserot()\n{\n    return (iMouse.z > 0.0)? (iMouse.x-iMouse.z)/4000. : 0.;\n}\n\nfloat mousezoom()\n{\n    return (iMouse.z > 0.0)? 1.0 + (iMouse.y-iResolution.y/2.0)/4000. : 1.0;\n}\n\nmat3 proj()\n{\n    float g = 0.001 * cos(iTime/1.2);\n    float h = 0.001 * sin(iTime/1.0);\n    \n    return rx(g) * ry(h) * rz(mouserot());\n}\n\n// https://www.pcg-random.org/\nvoid pcg4d(inout uvec4 v)\n{\n\tv = v * 1664525u + 1013904223u;\n    v.x += v.y*v.w; v.y += v.z*v.x; v.z += v.x*v.y; v.w += v.y*v.z;\n    v = v ^ (v>>16u);\n    v.x += v.y*v.w; v.y += v.z*v.x; v.z += v.x*v.y; v.w += v.y*v.z;\n}\n\n// https://www.cs.sfu.ca/mmbook/programming_assignments/additional_notes/rgb_yuv_note/RGB-YUV.pdf\n\nconst mat3 yuv2rgb = mat3(vec3(1., 1., 1.),\n                          vec3(0., -0.39465, 2.03211),\n                          vec3(1.13983, -0.58060,  0.));\n\nconst mat3 rgb2yuv = mat3(vec3(0.299, -0.14713, 0.615),\n                          vec3(0.587, -0.28886,  -0.51499),\n                          vec3(0.114, 0.436,  -0.10001));\n\n\nconst mat2 uvbleed = mat2(vec2(0.99, 0.01),\n                          vec2(0.03, 0.99));\n\n\nvec3 analog_video_response(vec3 camera_pix)\n{\n    // Component bleed\n    vec3 yuv = rgb2yuv*camera_pix;\n    //yuv.yz = trunc(uvbleed*yuv.yz*512.)/512.;\n    yuv.yz = uvbleed*yuv.yz;\n    yuv += dFdx(yuv)*vec3(.3, -.2, -.2);;\n    yuv += dFdy(yuv)*vec3(.3, -.2, -.2);\n\n    return yuv2rgb*yuv;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord/iResolution.xy - 0.5;\n    vec3 pqr = proj()*vec3(uv, mousezoom()) + mousezoom()*vec3(0.50, 0.50, 0.);\n\n    vec4 avgValue = textureLod(iChannel0, vec2(0.5), 10.0);\n    \n    // Automatic Gain Control\n    float avg_lumi = (avgValue.r + avgValue.g + avgValue.b)/3.0;\n    float agc0 = avg_lumi-AGC_TARGET;\n    float agc= 1.0 - agc0*agc0*agc0*10.0;\n    \n    // Automatic White Balance\n    vec3 wb0 = (avgValue.rgb + AWB_FACTOR) / (max(avgValue.r, max(avgValue.g, avgValue.b)) + AWB_FACTOR);\n    vec3 wb1 = (2.0 - sqrt(wb0)) * agc;\n    \n    \n    vec4 screen = textureProj(iChannel0, pqr, -1.0);\n    screen.yz = textureProj(iChannel0, pqr, 1.0).yz;\n    \n    uvec4 seed0 = uvec4(fragCoord.x, screen.w, uint(iFrame), (agc0+0.5)*512.0);\n    pcg4d(seed0);\n    vec3 noise = vec3(seed0.rgb%256u)/5000.;\n    \n    vec3 as_seen = clamp(wb1*screen.rgb*0.98 + noise, 0.0, 1.0);\n    fragColor.rgb = pow(clamp(analog_video_response(as_seen), 0., 1.), vec3(1.15));\n    fragColor.a = float(seed0.w);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}