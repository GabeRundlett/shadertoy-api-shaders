{
    "Shader": {
        "info": {
            "date": "1679440463",
            "description": "An attempt to visualize music of my friend and collaborator.",
            "flags": 96,
            "hasliked": 0,
            "id": "md3Sz4",
            "likes": 10,
            "name": "Julie's Dunes study + noise",
            "published": 3,
            "tags": [
                "fft",
                "audio",
                "piano",
                "audioreactive"
            ],
            "usePreview": 0,
            "username": "morisil",
            "viewed": 990
        },
        "renderpass": [
            {
                "code": "// Fork of \"Julie's Dunes study\" by morisil. https://shadertoy.com/view/dllSWj\n// 2023-03-21 23:14:02\n\n// NOTE: audio on shadertoy works only if you interact ith the\n// webpage while AudioContext is being created and then SoundCloud\n// track is autoplayed. This visual does not exist without sound,\n// pleese keep it in mind if you see a black screen. In such a case\n// you can reload the page while interacting with it.\n\n// Copyright Kazimierz Pogoda, 2023 - https://xemantic.com/\n// I am the sole copyright owner of this Work.\n// You cannot host, display, distribute or share this Work in any form,\n// including physical and digital. You cannot use this Work in any\n// commercial or non-commercial product, website or project. You cannot\n// sell this Work and you cannot mint an NFTs of it.\n// I share this Work for educational purposes, and you can link to it,\n// through an URL, proper attribution and unmodified screenshot, as part\n// of your educational material. If these conditions are too restrictive\n// please contact me and we'll definitely work it out.\n\n// copyright statement borrowed from Inigo Quilez\n\n// Music by Julie Amouzegar Kim:\n// https://soundcloud.com/julie-amouzegar/dunes-piano-version\n\n// The music was composed by Julie, my dearest collaborator and\n// cerebral sibling. This sequence of progressions appeared in\n// Julieâ€™s dream, and I was there as well. So even though I heard\n// it already in her dream conceptually, I had to wait until she\n// expressed it so I could perceive it. And I like it a lot,\n// especially while listening to it on loop, while working on\n// visuals driven by this music.\n\n// See also Dunes - piano, study:\n// https://www.shadertoy.com/view/cllSWM\n\n// See also Generative Art Deco 4:\n// https://www.shadertoy.com/view/mds3DX\n\nconst float SHAPE_SIZE = .618;\nconst float CHROMATIC_ABBERATION = .02;\nconst float ITERATIONS = 7.;\nconst float INITIAL_LUMA = .6;\n\n\nfloat getColorComponent(in vec2 st, in float modScale, in float blur) {\n    vec2 modSt = mod(st, 1. / modScale) * modScale * 2. - 1.;\n    float dist = length(modSt);\n    float angle = atan(modSt.x, modSt.y) + sin(iTime * .08) * 9.0;\n    float shapeMap = smoothstep(SHAPE_SIZE + blur, SHAPE_SIZE - blur, sin(dist * 3.0) * .5 + .5);\n    return shapeMap;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy;\n    vec4 feedback = texture(iChannel0, uv);\n    float blur = .4 + sin(iTime * .52) * .2;\n\n    vec2 st =\n        (2.* fragCoord - iResolution.xy)\n        / min(iResolution.x, iResolution.y);\n    vec2 origSt = st;\n\n    st -= (feedback.r + feedback.g + feedback.b) * st * .3;\n\n    st *= rotate2d(sin(iTime * .14) * .3);\n    st *= (sin(iTime * .15) + 2.) * .3;\n    \n    st *= log(length(st * .428)) * 1.3;\n\n\n    float modScale = 1.;\n\n    vec3 color = vec3(0);\n    float luma = INITIAL_LUMA;\n    for (float i = 0.; i < ITERATIONS; i++) {\n        vec2 center = st + vec2(sin(iTime * .12), cos(iTime * .13)) * 1.5;\n        float fft = texture(iChannel0, vec2(length(center), .25)).r;\n        \n        vec3 shapeColor = vec3(\n            getColorComponent(center - st * CHROMATIC_ABBERATION, modScale, blur),\n            getColorComponent(center, modScale, blur),\n            getColorComponent(center + st * CHROMATIC_ABBERATION, modScale, blur)        \n        ) * luma;\n        st *= 1.1 + getColorComponent(center, modScale, .04) * 1.2;\n        st *= rotate2d(sin(iTime  * .05) * 1.33);\n        color += shapeColor;\n        color = clamp(color, 0., 1.);\n        luma *= .6;\n        blur *= .63;\n    }\n\n    float origDist = length(origSt);\n    float zucconiDomain = ZUCCONI_OFFSET - origDist;\n    vec3 audioColor = spectral_zucconi6(zucconiDomain) * feedback.a * .4;\n    color *= feedback.rgb;\n    color += audioColor;\n    fragColor = vec4(color, 1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "float spatializeAudio(in float dist) {\n    float fftDomain = pow(dist, 2.0);\n    float fft = texture(iChannel1, vec2(fftDomain * .09, .25)).r;\n    fft = pow(fft, 4.0);\n    return fft;\n}\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord) {\n    vec2 uv = fragCoord / iResolution.xy;\n    vec2 st =\n        (2. * fragCoord - iResolution.xy)\n        / min(iResolution.x, iResolution.y);\n    float dist = length(st);\n    \n    float audioSignal = spatializeAudio(dist);\n    float zucconiDomain = ZUCCONI_OFFSET - dist;    \n    vec3 color = spectral_zucconi6(zucconiDomain) * audioSignal * .2;\n    //float rotationDomain = (color.r + color.g + color.b) * 1.0;\n    //vec2 stShift = vec2(color.r - .005, color.g - .005) * vec2(sin(rotationDomain), cos(rotationDomain));\n    //stShift *= st * .5;\n    \n    vec3 mixedColor = texture(iChannel0, fragCoord / iResolution.xy - st * 0.09\n                             * iResolution.y / iResolution.xy\n                              //,.99\n                             ).rgb;\n    float angle = atan(st.x, st.y);\n\n    float noiseScale = 1.0;\n\n    vec2 offset = uv //+ vec2((mixedColor.g - .5) * 0.01, (mixedColor.r - .5) * 0.01) \n    \n    + (vec2(\n        snoise(vec3(st * noiseScale, iTime * .3)),\n        snoise(vec3(st * noiseScale+ vec2(1000.0), iTime * .3))\n     ) - .5) * .04;\n    //* vec2(sin(angle * 1.0 + iTime * .5), cos(angle * 1.0 + iTime * .7));\n\n    //vec3 prevColor = texture(iChannel0, uv - stShift).rgb;\n    vec3 prevColor = texture(iChannel0, offset).rgb;\n    color += prevColor * 0.95;\n    //vec3 color = prevColor * 0. + spectral_zucconi6(dist * 1.3 - .3) * audioSignal * 2.0;\n\n    fragColor = vec4(color, audioSignal);\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "musicstream",
                        "id": 32182,
                        "published": 0,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "https://soundcloud.com/julie-amouzegar/dunes-electro-version"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "const float ZUCCONI_OFFSET = 1.05;\n\n// Spectral Colour Schemes\n// By Alan Zucconi\n// Website: www.alanzucconi.com\n// Twitter: @AlanZucconi\n\n// Example of different spectral colour schemes\n// to convert visible wavelengths of light (400-700 nm) to RGB colours.\n\n// The function \"spectral_zucconi6\" provides the best approximation\n// without including any branching.\n// Its faster version, \"spectral_zucconi\", is advised for mobile applications.\n\n\n// Read \"Improving the Rainbow\" for more information\n// http://www.alanzucconi.com/?p=6703\n\n\n\nfloat saturate (in float x)\n{\n    return min(1.0, max(0.0,x));\n}\nvec3 saturate (in vec3 x)\n{\n    return min(vec3(1.,1.,1.), max(vec3(0.,0.,0.),x));\n}\n\n// --- Spectral Zucconi --------------------------------------------\n// By Alan Zucconi\n// Based on GPU Gems: https://developer.nvidia.com/sites/all/modules/custom/gpugems/books/GPUGems/gpugems_ch08.html\n// But with values optimised to match as close as possible the visible spectrum\n// Fits this: https://commons.wikimedia.org/wiki/File:Linear_visible_spectrum.svg\n// With weighter MSE (RGB weights: 0.3, 0.59, 0.11)\nvec3 bump3y (in vec3 x, in vec3 yoffset)\n{\n\tvec3 y = vec3(1.,1.,1.) - x * x;\n\ty = saturate(y-yoffset);\n\treturn y;\n}\nvec3 spectral_zucconi (in float w)\n{\n    // w: [400, 700]\n\t// x: [0,   1]\n\tfloat x = saturate((w - 400.0)/ 300.0);\n\n\tconst vec3 cs = vec3(3.54541723, 2.86670055, 2.29421995);\n\tconst vec3 xs = vec3(0.69548916, 0.49416934, 0.28269708);\n\tconst vec3 ys = vec3(0.02320775, 0.15936245, 0.53520021);\n\n\treturn bump3y (\tcs * (x - xs), ys);\n}\n\n// --- Spectral Zucconi 6 --------------------------------------------\n\n// Based on GPU Gems\n// Optimised by Alan Zucconi\nvec3 spectral_zucconi6 (in float x)\n{\n\n\tconst vec3 c1 = vec3(3.54585104, 2.93225262, 2.41593945);\n\tconst vec3 x1 = vec3(0.69549072, 0.49228336, 0.27699880);\n\tconst vec3 y1 = vec3(0.02312639, 0.15225084, 0.52607955);\n\n\tconst vec3 c2 = vec3(3.90307140, 3.21182957, 3.96587128);\n\tconst vec3 x2 = vec3(0.11748627, 0.86755042, 0.66077860);\n\tconst vec3 y2 = vec3(0.84897130, 0.88445281, 0.73949448);\n\n\treturn\n\t\tbump3y(c1 * (x - x1), y1) +\n\t\tbump3y(c2 * (x - x2), y2) ;\n}\n\nmat2 rotate2d(float _angle){\n    return mat2(cos(_angle),-sin(_angle),\n                sin(_angle),cos(_angle));\n}\n\n\n// Optimized AshimaSimplexNoise by @makio64 https://www.shadertoy.com/view/Xd3GRf\n// Original : https://github.com/ashima/webgl-noise/blob/master/src/noise3D.glsl\n// 2D Version: https://www.shadertoy.com/view/4sdGD8\nlowp vec4 permute(in lowp vec4 x){return mod(x*x*34.+x,289.);}\nlowp float snoise(in mediump vec3 v){\n  const lowp vec2 C = vec2(0.16666666666,0.33333333333);\n  const lowp vec4 D = vec4(0,.5,1,2);\n  lowp vec3 i  = floor(C.y*(v.x+v.y+v.z) + v);\n  lowp vec3 x0 = C.x*(i.x+i.y+i.z) + (v - i);\n  lowp vec3 g = step(x0.yzx, x0);\n  lowp vec3 l = (1. - g).zxy;\n  lowp vec3 i1 = min( g, l );\n  lowp vec3 i2 = max( g, l );\n  lowp vec3 x1 = x0 - i1 + C.x;\n  lowp vec3 x2 = x0 - i2 + C.y;\n  lowp vec3 x3 = x0 - D.yyy;\n  i = mod(i,289.);\n  lowp vec4 p = permute( permute( permute(\n\t  i.z + vec4(0., i1.z, i2.z, 1.))\n\t+ i.y + vec4(0., i1.y, i2.y, 1.))\n\t+ i.x + vec4(0., i1.x, i2.x, 1.));\n  lowp vec3 ns = .142857142857 * D.wyz - D.xzx;\n  lowp vec4 j = -49. * floor(p * ns.z * ns.z) + p;\n  lowp vec4 x_ = floor(j * ns.z);\n  lowp vec4 x = x_ * ns.x + ns.yyyy;\n  lowp vec4 y = floor(j - 7. * x_ ) * ns.x + ns.yyyy;\n  lowp vec4 h = 1. - abs(x) - abs(y);\n  lowp vec4 b0 = vec4( x.xy, y.xy );\n  lowp vec4 b1 = vec4( x.zw, y.zw );\n  lowp vec4 sh = -step(h, vec4(0));\n  lowp vec4 a0 = b0.xzyw + (floor(b0)*2.+ 1.).xzyw*sh.xxyy;\n  lowp vec4 a1 = b1.xzyw + (floor(b1)*2.+ 1.).xzyw*sh.zzww;\n  lowp vec3 p0 = vec3(a0.xy,h.x);\n  lowp vec3 p1 = vec3(a0.zw,h.y);\n  lowp vec3 p2 = vec3(a1.xy,h.z);\n  lowp vec3 p3 = vec3(a1.zw,h.w);\n  lowp vec4 norm = inversesqrt(vec4(dot(p0,p0), dot(p1,p1), dot(p2, p2), dot(p3,p3)));\n  p0 *= norm.x;\n  p1 *= norm.y;\n  p2 *= norm.z;\n  p3 *= norm.w;\n  lowp vec4 m = max(.6 - vec4(dot(x0,x0), dot(x1,x1), dot(x2,x2), dot(x3,x3)), 0.);\n  return .5 + 12. * dot( m * m * m, vec4( dot(p0,x0), dot(p1,x1),dot(p2,x2), dot(p3,x3) ) );\n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            }
        ],
        "ver": "0.1"
    }
}