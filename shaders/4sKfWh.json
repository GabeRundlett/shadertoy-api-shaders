{
    "Shader": {
        "info": {
            "date": "1528638373",
            "description": "Using rounded Voronoi diffusion masks to create a pattern with a bio organic flavor resembling connected cellular nodes... or to put it another way, it's a variation on Aeikick's \"Trabeculum Reaction Diffusion\" example. :) Allow about 60 seconds.",
            "flags": 32,
            "hasliked": 0,
            "id": "4sKfWh",
            "likes": 20,
            "name": "Connected Cellular Nodes",
            "published": 3,
            "tags": [
                "diffusion",
                "pattern",
                "cell",
                "reaction",
                "node"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 1118
        },
        "renderpass": [
            {
                "code": "/*\n\n\tConnected Cellular Nodes\n\t------------------------\n\n\tUsing rounded Voronoi diffusion masks to create a pattern with a bio organic flavor \n\tresembling connected cellular nodes... or to put it another way, it's a variation on \n\tAeikick's \"Trabeculum Reaction Diffusion\" example. :) The pattern is legible in \n\tunder ten seconds and reaches a relative state of equilibrium in under 60 seconds.\n\n\tThe basic idea behind Aiekick's example was to produce masks to control the way in which\n\treactancts A and B interact with the system. Visually speaking, it's a way of \n\tinfluencing the dark and bright sections of the resultant reaction diffusion pattern.\n\n\tFor the masks, instead of Fabrice's tri-nodal distance formula (which happens to resemble \n\tbone trabeculae, hence the name, trabeculum), I've used some rounded Voronoi that is \n\tbased on Tomkh's rounded Voronoi border refinements. I've also applied separate masks\n\tto the feed and kill variables.\n\t\n\tCellular lines were used for the kill mask to force some cellular borders and a similar \n\tfeed mask created a clear section just inside the cells. The rest was just a regular \n\tGray-Scott diffusion pattern. Combined with a little color and shading, the result is a \n\tkind of randomly connected amoeba party. :)\n \n\tI finally got in amongst it and coded a fixed sized texture. I occasionally play around \n\twith 3D arrays packed into 2D textures, so it was just a case of repurposing code from  \n    that. It mightn't seem like much, but having a procedurally generated texture that \n\tbehaves in the same way as a regular in-house Shadertoy texture makes life so much \n\teasier. For one, switching canvas size results in the same pattern creation. Plus\n\trepeat textures can be applied to surfaces without any hassle. Also, aspect correct\n\tcoordinates produce an apect correct texture.\n\n\tBy the way, I've produced a 3D reaction diffusion example that I'll release shortly.\n\n\t\n\tInspired by:\n\n\t// I get a lot of inspiration from the French coders on here. :)\n\tTrabeculum Reaction Diffusion - aiekick\n\thttps://www.shadertoy.com/view/MsKfDR\n\n*/\n\n// Texture maping function. This one is arranged to wrap according to the specified\n// texture size, which can be set in the \"Common\" code tab. It differs ever so slightly\n// to the same function in \"BufA\" tab in that it's scaled by the texture size as well.\nvec4 texMap(sampler2D tx, vec2 p) { \n    \n    // The newer \"texelFetch\" function. I had it in my head that the old way would be \n    // more compatible, compile faster, and \"might\" render faster inside a raymarching\n    // equation, but I honestly wouldn't know. If anyone does, feel free to let me know. :)\n    //return texelFetch(tx, ivec2(mod(p*dSize, dSize)), 0);\n    \n    // Returning the correct pixel... using the usual unwieldly mess. :) Normally, I'd \n    // have to use \"floor(p*dSize),\" but things seem to working without it.\n    return texture(tx, (mod(p*dSize, dSize) + .5)/iChannelResolution[0].xy); \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Aspect correct screen coordinates.\n    vec2 uv = (fragCoord - iResolution.xy*.5)/iResolution.y;\n    \n    // Normalized screen coordinates, used for vignettes, \n    // color gradient overlays, etc.\n    vec2 uv0 = fragCoord/iResolution.xy;\n    \n    // Scrolling.\n    uv -= vec2(1, .5)*iTime/8.;\n    \n    // Rotation, to give the pattern a slightly more random look.\n    mat2 rot = r2(3.14159/6.);\n    uv *= rot;\n    \n    // Hassle free changes in texture size. :)\n    //uv /= 1.5;\n\n    // Three diffusion texture samples. The regular one, and one offset slightly\n    // to creat the drop shadow, and a higher frequency sample for a light\n    // background pattern.\n    vec4 tx = texMap(iChannel0, uv);\n    vec4 tx2 = texMap(iChannel0, uv - vec2(3., -2)*rot/iResolution.y);\n    vec4 tx3 = texMap(iChannel0, uv*3.);\n    \n    // Create a very simple color gradient background with an overlay.\n    vec3 bg = mix(vec3(1, .6, .3), vec3(1, .8, .2), uv0.y); // Vertical color gradient.\n    bg = mix(bg, vec3(0), (1. - smoothstep(0., .1, tx3.x - .5))*.2); // Fine pattern overlay.\n    bg = mix(bg, bg.yxz, uv0.x - .25); // Horizontal color gradient mixing.\n    bg *= tx2.x*1.1; // Applying the drop shadow to the background.\n    \n    // Initiate the scene color to the background.\n    vec3 col = bg.zyx;\n    \n    \n    // Apply the main diffusion pattern.\n    col = mix(col, vec3(0), 1. - smoothstep(0., .1, tx.x - .45));\n    \n\n    // Coloring in the cells. It's a very basic white with a drop shadow, overlayed with \n    // black black, which is almost redundant, but if you wanted different colors,\n    // etc, this would be neccessary.\n    vec3 cellCol = mix(vec3(1)*tx2.x, vec3(0), 1. - smoothstep(0., .1, tx.x - .5));\n    \n    // The mask used in the diffusion process is stored in the \"Z\" channel.\n    // It's just some rounded Voronoi, but it saves a extra function call, \n    // plus changes only need to be applied in the \"Buf A\" tab.\n    //vec2 v = Voronoi(uv, vec2(6));\n    float mask = tx.z;\n    // Applying the cell contents to the scene.\n    col = mix(col, cellCol, (1. - smoothstep(0., .1, -mask + .1))*(1. - tx.y));\n\n    \n    // Square vignette -- I was too lazy to write my own square vignette code, so I \n    // \"borrowed\" and adapted a segment from Flockaroo's amazing \"when voxels wed pixels\"\n    // example, which you can find here: https://www.shadertoy.com/view/MsKfRw\n    //\n    // On a side note, I'm going to put together an example that applies his cross\n    // hatching formula. I just need to find the right scene to do it justice. \n    vec2 scc=(fragCoord-.5*iResolution.xy)/iResolution.x;\n    float vign = 1.1 - .3*dot(scc, scc);\n    vign*= 1. - .75*exp(-sin(uv0.x*3.14159)*20.*iResolution.x/iResolution.y);\n    vign*= 1. - .75*exp(-sin(uv0.y*3.14159)*20.);\n    col *= vign;\n\n    // Rough gamma correction.\n    fragColor = vec4(sqrt(max(col, 0.)), 1);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// The texture size. Because there are no fixed size buffers, we have to be careful with \n// size. Obviously, if using a canvas with smaller dimensions, this would break, but who'd\n// be viewing things in a window that small. :) Jokes aside, if someone could give me a\n// compelling reason, I could put some resize code in for times when the resolution falls\n// below this threshold.\n//\n// By the way, I was using these weird dimensions to test that the wrapping and mapping \n// routines work. Plus, I was using something that wrapped by a factor of six, so the\n// following numbers tie in with that.\nconst vec2 dSize = vec2(240, 180);\n\n// Standard 2D rotation formula.\nmat2 r2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }\n\n// vec2 to float.\nfloat hash21(vec2 p, vec2 dim) { \n\n    p = mod(p, dim);\n    return fract(sin(dot(p, vec2(1.27, 113.93)))*43758.5453);\n}\n\n// 2x2 hash algorithm.\nvec2 hash22(vec2 p, vec2 dim) { \n\n    p = mod(p, dim);\n    // More concise, but wouldn't disperse things as nicely as the block below.\n    float n = sin(dot(p,vec2(113, 1))); \n    return fract(vec2(2097152, 262144)*n);\n    \n    // Animation.\n    //p = fract(vec2(2097152, 262144)*n);\n    //return sin(p*6.2831853 + iTime)*0.5 + 0.5;\n}\n\n// 2x2 hash algorithm.\nvec2 hash22B(vec2 p, vec2 dim) { \n\n    p = mod(p, dim);\n    // More concise, but wouldn't disperse things as nicely as the block below.\n    float n = sin(dot(p,vec2(113, 1))); \n    return fract(vec2(2097152, 262144)*n)*.7;\n    \n    // Animation.\n    //p = fract(vec2(2097152, 262144)*n);\n    //return sin(p*6.2831853 + iTime)*0.35 + 0.35;\n}\n\n// IQ's exponential-based smooth minimum function. Unlike the polynomial-based\n// smooth minimum, this one is associative and commutative.\nfloat sminExp(float a, float b, float k){\n\n    float res = exp(-k*a) + exp(-k*b);\n    return -log(res)/k;\n}\n\n// With variable distance smoothing, it's probably not technically correct, but\n// you can't tell the difference. :)\n#define FAST_EXP\n\n// Exponential smoothing.\nfloat sExp(float a, float k){\n\n    return exp(-k*a);\n}\n\n// Commutative smooth minimum function. Provided by Tomkh and taken from \n// Alex Evans's (aka Statix) talk: \n// http://media.lolrus.mediamolecule.com/AlexEvans_SIGGRAPH-2015.pdf\n// Credited to Dave Smith @media molecule.\nfloat smin(float a, float b, float r){\n\n   float f = max(0., 1. - abs(b - a)/r);\n   return min(a, b) - r*.25*f*f;\n}\n\nvec2 cellID; // Individual Voronoi cell IDs.\n\n\n// 2D 2nd-order Voronoi: Obviously, this is just a rehash of IQ's original. I've tidied\n// The is a variation on a regular 2-pass Voronoi traversal that produces a Voronoi\n// pattern based on the interior cell point to the nearest cell edge (as opposed\n// to the nearest offset point). It's a slight reworking of Tomkh's example, which\n// in turn, is based on IQ's original example. The links are below:\n//\n// On a side note, I have no idea whether a faster solution is possible, but when I\n// have time, I'm going to try to find one anyway.\n//\n// Voronoi distances - iq\n// https://www.shadertoy.com/view/ldl3W8\n//\n// Here's IQ's well written article that describes the process in more detail.\n// https://iquilezles.org/articles/voronoilines\n//\n// Faster Voronoi Edge Distance - tomkh\n// https://www.shadertoy.com/view/llG3zy\nvec2 Voronoi(in vec2 p, in vec2 dim){\n    \n    p *= dim;\n    \n    // One of Tomkh's snippets that includes a wrap to deal with\n    // larger numbers, which is pretty cool.\n\n#if 1\n    // Slower, but handles big numbers better.\n    vec2 n = floor(p);\n    p -= n;\n    vec2 h = step(.5, p) - 1.5;\n    n += h; p -= h;\n#else\n    vec2 n = floor(p - 1.);\n    p -= n;\n#endif\n    \n    // Storage for all sixteen hash values. The same set of hash values are\n    // reused in the second pass, and since they're reasonably expensive to\n    // calculate, I figured I'd save them from resuse. However, I could be\n    // violating some kind of GPU architecture rule, so I might be making \n    // things worse... If anyone knows for sure, feel free to let me know.\n    //\n    // I've been informed that saving to an array of vectors is worse.\n    //vec2 svO[3];\n    \n    // Individual Voronoi cell ID. Used for coloring, materials, etc.\n    cellID = vec2(0); // Redundant initialization, but I've done it anyway.\n\n    // As IQ has commented, this is a regular Voronoi pass, so it should be\n    // pretty self explanatory.\n    //\n    // First pass: Regular Voronoi.\n\tvec2 mo, o;\n    \n    // Minimum distance, \"smooth\" distance to the nearest cell edge, regular\n    // distance to the nearest cell edge, and a line distance place holder.\n    float md = 8., lMd = 8., lMd2 = 8., lnDist, d;\n    \n    for( int j=0; j<3; j++ )\n    for( int i=0; i<3; i++ ){\n    \n        o = vec2(i, j);\n        o += hash22B(n + o, dim) - p;\n        // Saving the hash values for reuse in the next pass. I don't know for sure,\n        // but I've been informed that it's faster to recalculate the had values in\n        // the following pass.\n        //svO[j*3 + i] = o; \n  \n        // Regular squared cell point to nearest node point.\n        d = dot(o, o); \n\n        if( d<md ){\n            \n            md = d;  // Update the minimum distance.\n            // Keep note of the position of the nearest cell point - with respect\n            // to \"p,\" of course. It will be used in the second pass.\n            mo = o; \n            cellID = vec2(i, j) + n; // Record the cell ID also.\n        }\n       \n    }\n    \n    #ifdef FAST_EXP\n    lMd = 0.;\n    #endif\n\n    // Second pass: Distance to closest border edge. The closest edge will be one of the edges of\n    // the cell containing the closest cell point, so you need to check all surrounding edges of \n    // that cell, hence the second pass... It'd be nice if there were a faster way.\n    for( int j=0; j<3; j++ )\n    for( int i=0; i<3; i++ ){\n        \n        // I've been informed that it's faster to recalculate the hash values, rather than \n        // access an array of saved values.\n        o = vec2(i, j);\n        o += hash22B(n + o, dim) - p;\n        // I went through the trouble to save all sixteen expensive hash values in the first \n        // pass in the hope that it'd speed thing up, but due to the evolving nature of \n        // modern architecture that likes everything to be declared locally, I might be making \n        // things worse. Who knows? I miss the times when lookup tables were a good thing. :)\n        // \n        //o = svO[j*3 + i];\n        \n        // Skip the same cell... I found that out the hard way. :D\n        if( dot(o-mo, o-mo)>.00001 ){ \n            \n            // This tiny line is the crux of the whole example, believe it or not. Basically, it's\n            // a bit of simple trigonometry to determine the distance from the cell point to the\n            // cell border line. See IQ's article for a visual representation.\n            lnDist = dot( 0.5*(o+mo), normalize(o-mo));\n            \n            // Abje's addition. Border distance using a smooth minimum. Insightful, and simple.\n            //\n            // On a side note, IQ reminded me that the order in which the polynomial-based smooth\n            // minimum is applied effects the result. However, the exponentional-based smooth\n            // minimum is associative and commutative, so is more correct. In this particular case, \n            // the effects appear to be negligible, so I'm sticking with the cheaper polynomial-based \n            // smooth minimum, but it's something you should keep in mind. By the way, feel free to \n            // uncomment the exponential one and try it out to see if you notice a difference.\n            //\n            // // Polynomial-based smooth minimum.\n            //lMd = smin(lMd, lnDist, lnDist*.5); \n            //\n            // Exponential-based smooth minimum. By the way, this is here to provide a visual reference \n            // only, and is definitely not the most efficient way to apply it. To see the minor\n            // adjustments necessary, refer to Tomkh's example here: Rounded Voronoi Edges Analysis - \n            // https://www.shadertoy.com/view/MdSfzD\n            \n            #ifdef FAST_EXP\n            lMd += sExp(lnDist, (lnDist)*30.);\n            #else\n            lMd = sminExp(lMd, lnDist, (lnDist)*30.); \n            #endif\n            \n            // Minimum regular straight-edged border distance. If you only used this distance,\n            // the web lattice would have sharp edges.\n            lMd2 = min(lMd2, lnDist);\n        }\n\n    }\n    \n    #ifdef FAST_EXP\n    lMd = -log(lMd)/((lMd)*30.);\n    #endif\n\n    // Return the smoothed and unsmoothed distance. I think they need capping at zero... but \n    // I'm not positive.\n    return max(vec2(lMd, lMd2), 0.);\n}\n\n/*\n// IQ's value noise formula.\nfloat noise( in vec2 p ){\n   \n    vec2 i = floor(p); p -= i; \n    p *= p*p*(p*(p*6. - 15.) + 10.);\n    //p *= p*(3. - p*2.);  \n\n    return mix( mix( hash21(i + vec2(0, 0)), \n                     hash21(i + vec2(1, 0)), p.x),\n                mix( hash21(i + vec2(0, 1)), \n                     hash21(i + vec2(1, 1)), p.x), p.y);\n}\n*/",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "/*\n\tConnected Cellular Nodes\n\t------------------------\n\n    Diffusion reaction: The process is simple enough to understand, but whenever I'm \n    working through it, I often wonder which brainiac nerd poured a solution from one \n    beaker into another, then thought to themselves, \"That'd be a great way to make \n    procedural giraffe textures.\" :) ... Actually, I think the initial idea came from\n\tthe famous Engima code breaking guy, Alan Turing, but don't quote me on that. :)\n       \n    At its very core, diffusion textures are just a visual representation over time of \n    a particular kind of partial differential equation, nothing more, so in essence, you \n    could ignore all explanations and simply apply it. However, if you're like me and \n    you require a better understanding, refer to the articles below. If you're after a \n\tdecent summary, refer to the following article: \n     \n    http://www.karlsims.com/rd.html\n\n\tAnyway A lot of the code here is just some standard noise routines for anyone who\n\twants to experiment with different intial conditions. The actual code to produce the \n\tdiffusion texture is contained in the \"mainImage\" function and there isn't much of \n\tthat at all.\n\n\n\t// Articles that may be helpful:\n\n\tReaction Diffusion: The Gray-Scott Algorithm\n \thttp://www.algosome.com/articles/reaction-diffusion-gray-scott.html\n\t\n\tGray Scott Model of Reaction Diffusion\n\thttps://groups.csail.mit.edu/mac/projects/amorphous/GrayScott/\n    \n    Karl Sims - http://www.karlsims.com/rd.html\n\t\n\tRobert Munafo - http://mrob.com/pub/comp/xmorphia/\n\n\tReaction–Diffusion System\n\thttps://en.wikipedia.org/wiki/Reaction%E2%80%93diffusion_system\n\n*/\n\n// Texture maping function. This one is arranged to wrap according to the specified\n// texture size, which can be set in the \"Common\" code tab.\nvec4 texMap(sampler2D tx, vec2 p) { \n    \n    // The newer \"texelFetch\" function. I had it in my head that the old way would be \n    // more compatible, compile faster, and \"might\" render faster inside a raymarching\n    // equation, but I honestly wouldn't know. If anyone does, feel free to let me know. :)\n    //return texelFetch(tx, ivec2(mod(p.xy, dSize)), 0);\n    \n    return texture(tx, (mod(p.xy, dSize) + .5)/iChannelResolution[0].xy); \n}\n\n\n/*\n\n// 25 (or 9) tap Laplacian -- Gaussian Laplacian, to be more precise. I think of it as taking\n// the sum of the partial second derivatives of a blurry 2D height map... in each channel...\n// I think I'm making things more confusing, but it works anyway. :D Seriously, just look\n// up the Laplacian operator of a 2D function.\nvec4 Laplacian(sampler2D tx, vec2 p) {\n    \n\n\t// Kernel matrix dimension, and a half dimension calculation.\n    const int mDim = 5, halfDim = (mDim - 1)/2;\n\n    // You can experiment with different Laplacian related setups here. Obviously, when \n    // using the 3x3, you have to change \"mDim\" above to \"3.\" There are widely varying \n    // numerical variances as well, so that has to be considered also.\n    float kernel[mDim*mDim] = float[mDim*mDim](\n    \n \t\t//The Laplacian-Gaussian... I can't remember where I found this,\n        // but I've seen it in more than one place, and it seems about right.\n\t\t0.,  0., .25,  0.,  0.,\n        0., .25,  .5, .25,  0.,\n        .25, .5,  -4., .5, .25,\n        0., .25,  .5, .25,  0.,\n        0.,  0., .25,  0.,  0.);\n      \n        // Another variation -- Might need scaling first.\n        //1., 1., 1., 1., 1.,\n        //1., 1., 1., 1., 1.,\n        //1., 1.,-24.,1., 1.,\n        //1., 1., 1., 1., 1.,\n        //1., 1., 1., 1., 1.);\n\n\t\t// 3x3 variation.\n        //1., 2., 1.,\n        //2., -12., 2.,\n        //1., 2., 1.);\n     \n\t\t// 3x3 variation. Slightly different to above, and scaled differently,\n\t\t// so that has to be taken into account.\n        //.05, .2, .05,\n        //.2,  -1., .2,\n        //.05, .2, .05);\n\n    \n    // Initiate the color. In this example, we only want the XY values, but just\n    // in case you'd like to apply this elsewhere, I've included all four texture\n    // channnels.\n    vec4 col = vec4(0);\n    \n    // \n    // We're indexing neighboring pixels, so this value tends to be in the order of a\n    // pixel width. However, with up to a 5x5 area span, a factor of one tends to be\n    // too blurry. The \".5\" to \".25\" range tends to give smooth but concise results.\n    float pixBlur = 1./3.; // Range [1, 0]... 1./2. tends to give average blur.\n    \n    // The relates but to the size of the array we're indexing into. It's also\n    // necessary to index the precise pixel we wish to filter. Hence, the \"floor.\"\n    p = floor(p*dSize);\n\n    \n    // There's a million boring ways to apply a kernal matrix to a pixel, and this \n    // is one of them. :)\n    for (int j=0; j<mDim; j++){\n        for (int i=0; i<mDim; i++){ \n            \n            col += kernel[j*mDim + i]*texMap(tx, p + vec2(i - halfDim, j - halfDim)*pixBlur);\n        }\n    }\n\n\n    return col;\n}\n*/\n\n// Nine tap Laplacian.\nvec4 Laplacian9(sampler2D tx, vec2 p) {\n    \n    // Note the divide \"2.\" on the end. A factor of one tends to be too blurry. Fractional pixel\n    // spans are possible due to the linear texel indexing. Dividing by \"3.\" and \"4.\" work too. \n    // Higher than that, however, tends to pixelize things.\n\tconst vec3 e = vec3(-1, 0, 1)/4.;\n    \n    // The relates but to the size of the array we're indexing into. It's also\n    // necessary to index the precise pixel we wish to filter. Hence, the \"floor.\"\n    p = floor(p*dSize);\n \n    // Laplacian with some Gaussian smoothing applied... I'm guessing, so I probably wouldn't\n    // quote me on it. :)\n    return (texMap(tx, p + e.xx)*.5 +  texMap(tx, p + e.xy ) + texMap(tx, p + e.xz)*.5 + // First row.\n\t\t\ttexMap(tx, p + e.yx) - texMap(tx, p)*6. + texMap(tx, p + e.yz) + \t\t     // Seond row.\n\t\t\ttexMap(tx, p + e.zx)*.5 + texMap(tx, p + e.zy) +  texMap(tx, p + e.zz)*.5);  // Third row\n  \n    \n    // Laplacian with no Gaussian component... I think.\n    //return (texMap(tx, p + e.xx) +  texMap(tx, p + e.xy ) + texMap(tx, p + e.xz) + // First row.\n\t//\t\ttexMap(tx, p + e.yx) - texMap(tx, p)*8. + texMap(tx, p + e.yz) + \t\t     // Seond row.\n\t//\t\ttexMap(tx, p + e.zx) + texMap(tx, p + e.zy) +  texMap(tx, p + e.zz));  // Third row\n\n \n}\n\n/*\n// Five tap Laplacian -- The simplest Laplacian filter... unless there's a more minimalistic one.\nvec4 Laplacian5(sampler2D tx, vec2 p) {\n    \n    // Note the divide \"2.\" on the end. A factor of one tends to be too blurry. Fractional pixel\n    // spans are possible due to the linear texel indexing. Dividing by \"3.\" works too. Higher \n    // than that, however, tends to pixelize things.\n\tconst vec3 e = vec3(-1, 0, 1)/2.;\n    \n    // The relates but to the size of the array we're indexing into. It's also\n    // necessary to index the precise pixel we wish to filter. Hence, the \"floor.\"\n    p = floor(p*dSize);\n\n\treturn texMap(tx, p - e.xy) + texMap(tx, p - e.yx) - texMap(tx, p)*4. + texMap(tx, p + e.xy) + texMap(tx, p +  e.yx);\n}\n*/\n\n\n\n/*\n// Analytic Laplacian of sorts.\nvec4 grad(sampler2D tx, in vec2 uv) {\n    \n    // Note the divide \"2.\" on the end. A factor of one tends to be too blurry. Fractional pixel\n    // spans are possible due to the linear texel indexing. Dividing by \"3.\" works too. Higher \n    // than that, however, tends to pixelize things.\n    vec2 e = vec2(.5, 0)/2.;\n\tvec2 dfdx = texMap(tx, uv + e).xy - texMap(tx, uv - e).xy;\n    vec2 dfdy = texMap(tx, uv + e.yx).xy - texMap(tx, uv - e.yx).xy;\n    return vec4(dfdx, dfdy);\n}\n\n// Divergence of gradient.\nvec2 LaplacianA(sampler2D tx, in vec2 p) {\n    \n    // The relates but to the size of the array we're indexing into. It's also\n    // necessary to index the precise pixel we wish to filter. Hence, the \"floor.\"\n    p = floor(p*dSize);\n \n    vec2 e = vec2(.5, 0)/2.;\n    vec2 dgdx = grad(tx, p + e).xy - grad(tx, p - e).xy;\n    vec2 dgdy = grad(tx, p + e.yx).zw - grad(tx, p - e.yx).zw;\n    vec2 lap = (dgdx + dgdy);\n    \n    return lap;\n}\n*/\n\n\n// Converting the fragment coordinates to coincide with the mapping function. I'm not sure\n// about everyone else, but arranging for non aspect correct coordinates to coincide with\n// aspect correct wrappable arrays and back does my head in. :) Not so much here, but\n// packing 3D arrays into a 2D textures is a confusing process.\nvec2 convertCoord(vec2 p){ return mod(p.xy, dSize)/dSize; }\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    \n    \n    // Fragment coordinate conversion.\n    vec2 p = convertCoord(fragCoord);\n    \n\n    // Grab the reaction diffusion values from the previous frame. These values are\n    // are representative of concentrations of hypothetical liquid, gas, etc, solutions,\n    // which are denoted by A and B. A is stored in the X channel, and B is stored in \n    // the Y channel.\n\tvec4 rdVal = texture(iChannel0, fragCoord/iResolution.xy);\n    // Equivalent function, but the one above does the same thing with less effort.\n\t//vec4 rdVal = texMap(iChannel0, floor(p*dSize));\n    \n    // The concentrations of elements A and B will tend to spread out in a smoother -- and\n    // sometimes, faster -- way if we smooth out the underlying values. Making that happen \n    // is as simple as blurring the A and B concoction (the X and Y texture values) every \n    // pass. The wider the blur, the better. You could achieve that by by adding \n    // an extra buffer and performing the blur in conjunction with the reaction \n    // diffusion calculations performed here, or you could combine a blur matrix with \n    // the Lapacian matrix all in one step, which is what we're doing here. In other \n    // words we're combining a 5x5 Gaussian matrix with a Laplacian matrix and \n    // using the resultant matrix in the Laplacian step.\n    //\n    // And yes, more buffers could be added to decrease equilibrium time, but I \n    // wanted to keep things simple.\n      \n    \n    // In regard to the form of the reaction-diffusion equation we're using, there's some \n\t// kind of physical flow involved, which tends to require second derivative measurements.\n\t// To get those from an underlying pixelated map, pixel samples from a spread of neighbors \n\t// will be required, so it's not a stretch to imagine that some kind of pixel matrix will \n\t// be involved. Hence, the Laplacian step below:\n    //\n    // 25 tap Laplacian to really smoothen things out.\n    //vec2 lap = Laplacian(iChannel0, p).xy;\n    //vec2 lap = Laplacian2D(iChannel0, p).xy;\n    // Other Laplacian functions to experiment with. The different pixels arrangements\n    // produce subtle differences. Each function would need to be uncommented above.\n    vec2 lap = Laplacian9(iChannel0, p).xy;\n    //vec2 lap = LaplacianA(iChannel0, p);\n    //vec2 lap = Laplacian5(iChannel0, p).xy;\n    \n    // Feed and kill rates. These are close to standard values that you see everywhere.\n    // You can change them, but they're sensitive.\n    float feed = 0.0545, kill = 0.062;\n    // More constants to try. A lot of them are presets that I found using a handy pattern\n    // generator at this link: http://mrob.com/pub/comp/xmorphia/ogl/index.html\n    //float feed = 0.058, kill = 0.065; // Lines and dots.\n    //float feed = 0.046, kill = 0.063; // Lines and dots.\n    //float feed = 0.098, kill = 0.057; // Solid cells.\n    //float feed = 0.037, kill = 0.06; // Random joined lines.\n    //float feed = 0.0353, kill = 0.06; // Random joined lines.\n    //float feed = 0.03, kill = 0.063; // Self replicating spots.\n    //float feed = 0.03, kill = 0.0565; // Maze.\n    \n    // Applying the feed and kill masks... I wonder who the bio masochist was that came up with\n    // those terms? Create and destroy seem a little less personal to me... :) Anyway, the kill\n    // mask is a ring around cell edges, and the feed mask is an inner ring just inside the\n    // cell edges. I put that one there to keep the inner part of the cell clear -- I thought\n    // it looked neater.\n    vec2 fv = Voronoi(p, vec2(6)); // \"6\" factors into the \"dSize\" dimensions.\n    float mask = fv.x;\n    // Feed mask.\n    float fm = smoothstep(0., .1,  abs(mask - .1) + .007);//*.1 + .9;\n    // Kill mask.\n    float km = smoothstep(0., .1,  abs(mask - .05) + .055);//*.1 + .9;\n    \n    // Mixing Laplacians depending on circumstances is possible too, but I've left that alone.\n    //lap = mix(lap, lap2,  smoothstep(0., .1, mask - .25));\n    //lap = mix(lap, lap2,  .5);\n    \n    // Apply the feed and kill masks. By the way, you don't have to apply both, or any for \n    // that matter.\n    feed *= fm;\n    kill *= km;\n    \n    \n    // Diffusion rates for concentrations A and B. The first component needs to be higher\n    // than the second. The amplitude depends on the size of the Laplacian. I've noticed \n    // that if \"dAB.x\" is exactly twice \"dAB.y,\" the pattern will form quicker, but won't\n    // vary greatly. Tiny changes in these values will widely change the pattern, but can\n    // also bring about a blank screen. I guess that's one of the downsides of diffusion \n    // patterns.\n\tvec2 dAB = vec2(.2, .106);\n    //vec2 dAB = vec2(.2, .1);\n    \n    // Time component. Kind of redundant here, but it can be used to control reaction rate.\n    // Unfortunately, like all the figures used here, just a tiny change can ruin the \n    // reaction, which results in no pattern at all. Either way, you should try to set \n    // this number as high as you can without trashing the pattern.\n    const float t = 1.; \n    \n    // The diffusion term: Just the constant diffusion rates multiplied by the Laplacian\n    // for each concentration.\n    vec2 diffusion = dAB*lap;\n    // The reaction term: The \"rdVal.x*rdVal.y*rdVal.y\" value is representative of the\n    // chance that a particle from concentration A will react with two particles from\n    // concentration B, which from probability theory is: A*B*B. This results in a decrease\n    // of concentration A and an increase in concentration B by that particular amount.\n    // Hence, the negative and positive vector terms on the end.\n    vec2 reaction = vec2(rdVal.x*rdVal.y*rdVal.y)*vec2(-1, 1);\n    \n    // Feed and kill rates. Substance A is added at a feed rate, and substance B is taken\n    // away at a kill rate. Hence, the positive and negative vector terms on the end.\n    // It took me a while to figure out why the \"1. - rdVal.x\" term was necessary. It's \n    // necessary to reduce the amount that is fed into the system as the concentration of\n    // A \"rdVal.x\" builds up, otherwise, we'd never reach equilibrium.\n    vec2 feedKill = vec2(feed*(1. - rdVal.x), (kill + feed)*rdVal.y)*vec2(1, -1);\n    // Try the following with just the \"rdVal.x\" and the initial condition:\n    // fragColor.xy = vec2(1, 0) + (hash22(p*64.).xy - .5)*.75;\n    //\n    // Interesting, but equilibrium is never attained.\n    //vec2 feedKill = vec2(feed*rdVal.x, (kill + feed)*rdVal.y)*vec2(1, -1);\n\n    // Calculating the change in concentration of A and B. This calculation the crux of the\n    // whole thing. It's just an applied partial differential equation... which is a little \n    // difficult to write in ASCII form, but easy to apply. To see the actual equations in\n    // mathematical or physical form, you can read about it in the sources I've provided above.\n    \n    // New u value: du\\dt = rU*LapU - u*v*v + f*(1. - u);\n    // New v value: dv\\dt = rV*LapV + u*v*v + (f + k)*v;  \n\tvec2 delta = diffusion + reaction + feedKill;\n    \n    // Updating the old A and B concentrations by adding the change in concentration\n    // over time.\n    fragColor.xy = clamp(rdVal.xy + delta*t, 0., 1.);\n    \n    // Debug, to bypass the diffusion process.\n    //fragColor.xy = rdVal.xy;\n    \n    // The mask will be used in the \"Image\" tab, so rather than recalculating it, we may\n    // as well store it in the \"Z\" channel.\n    fragColor.z = mask;\n    \n    // Cute trick to allow reinitialization whenever the user switches between window\n    // sizes. However, if all four channels were needed, you'd have to load in another\n    // buffer and store it there.\n    fragColor.w = iResolution.y; \n    \n    \n    // Initializing the substances A and B: It requires a little finesse.\n    //\n    // You could literally spend weeks playing around with concentration initialization and \n    // never quite understand what works and what doesn't... OK, maybe that's just me, but\n    // I've never been able to determine a general routine that enables a pattern to form.\n    // Either way, here are a bunch of different initial conditions that do produce patterns.\n    //\n    // Sometimes, the application won't recognize the first frame -- or something, so it's \n    // necessary to initialize for the first few frames to give it a chance to catch on.\n    // Also, check for changes in canvas size.\n    if(iFrame<10 || abs(rdVal.w - iResolution.y)>.001) {\n        \n        // Alternative. Basic hash noise.\n        //fragColor.xy =  vec2(1, 0) + (hash22(p, dSize).xy*.9 - .5);\n\n        // Repeat rounded Voronoi. It seems to fill things in quickly. \"18\" factors into\n        // the repeat texture dimensions (dSize).\n        vec2 v = Voronoi(p, vec2(18));\n        fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(vec2(v.x, v.x)*1.3 - .5);\n        \n        //fragColor.xy = vec2(1)*v.x;\n        \n        //v = Voronoi(p, vec2(6));\n        //fragColor.xy *= smoothstep(0., .1,  v.x);\n        \n        //vec2 v = Voronoi(p*16., vec2(16));\n        //float mask = 1. - smoothstep(0., .1, v.y - v.x - .2);\n        //fragColor.xy = vec2(1, 0) +  vec2(1, -1)*vec2(mask);\n\n        // Required multi-channel noise texture in \"iChannel1.\"\n        //fragColor.xy =  vec2(1, 0) +  texture(iChannel1, fragCoord.xy/iResolution.y).xy -.5;   \n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(Voronoi(p*64.)*1.3 - .5);\n        // Some of these require functions above which need to be uncommented first.\n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(sTexture(iChannel1, p).xy - .5);\n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(noise(p*64.) - .5);\n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(abs(noise(p*64.) - .5)*2. - .5);\n        //fragColor.xy =  vec2(1, 0) + (hash22(p*64.).xy - .5); //(hash22(p*64.).xy - .5)*1.1, etc.\n        //fragColor.xy =  vec2(.5, -.5)*.75 + vec2(Voronoi(p*64.), Voronoi(p*64. + vec2(3, 7))); \n        //fragColor.xy =  vec2(.45, -.53) + dot(sin(p*9.*6.283 - cos(p.yx*7.*6.283 + 1.15)*3.14159), vec2(.25)) + .5;\n        \n    }\n    \n    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}