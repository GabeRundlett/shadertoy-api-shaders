{
    "Shader": {
        "info": {
            "date": "1456152648",
            "description": "Seeing what happens if you interpolate between gbuffers over time, to try to get away with doing fewer frames of \"full work\"",
            "flags": 32,
            "hasliked": 0,
            "id": "XdGGDy",
            "likes": 5,
            "name": "G-Buffer Temporal Interpolation",
            "published": 3,
            "tags": [
                "3d",
                "interpolation",
                "temporal"
            ],
            "usePreview": 0,
            "username": "demofox",
            "viewed": 1150
        },
        "renderpass": [
            {
                "code": "/*============================================================\n\nThis shader uses the interpolation settings to blend between\nthe gbuffer data in buffers A,B,C,D to get the current gbuffer\ndata and then renders a final output pixel.\n\n============================================================*/\n\n#define DEBUG_SHOW_NORMALS 0\n\nconst float c_gamma = 2.2;\n\n//============================================================\n// SHARED CODE BEGIN\n//============================================================\n\nconst float c_pi = 3.14159265359;\n\n// Distance from the camera to the near plane\nconst float c_cameraDistance = 2.0; \n\n// The vertical field of view of the camera in radians\n// Horizontal is defined by accounting for aspect ratio\nconst float c_camera_FOV = c_pi / 2.0;  \n\n// camera orientation\nvec3 c_cameraPos   = vec3(0.0);\nvec3 c_cameraRight = vec3(1.0, 0.0, 0.0);    \nvec3 c_cameraUp    = vec3(0.0, 1.0, 0.0);\nvec3 c_cameraFwd   = vec3(0.0, 0.0, 1.0); \n\nconst vec2 txState = vec2(0.0,0.0);\n// x = interpolation mode: 0,1,2 = nearest, linear, cubic\n// y = time between frames\n// zw = unused\n\n//============================================================\nvoid GetRayInfo (in vec2 adjustedFragCoord, out vec3 rayOrigin, out vec3 rayDirection)\n{\n    // calculate a uv of the pixel such that:\n    // * the top of the screen is y = 0.5, \n    // * the bottom of the screen in y = -0.5\n    // * the left and right sides of the screen are extended based on aspect ratio.\n    // * left is -x, right is +x\n    float aspectRatio = iResolution.x / iResolution.y;\n    vec2 uv = (adjustedFragCoord / iResolution.xy) - vec2(0.5);\n    uv.x *= aspectRatio;\n    \n    // set up the ray for this pixel.\n    // It starts from the near plane, going in the direction from the camera to the spot on the near plane.\n    vec3 rayLocalDir = vec3(uv * sin(c_camera_FOV), c_cameraDistance);\n    rayOrigin =\n        c_cameraPos +\n        rayLocalDir.x * c_cameraRight * c_cameraDistance +\n        rayLocalDir.y * c_cameraUp * c_cameraDistance +\n        rayLocalDir.z * c_cameraFwd * c_cameraDistance;\n    rayDirection = normalize(rayOrigin - c_cameraPos);      \n}\n\n//============================================================\n// SHARED CODE END\n//============================================================\n\n//============================================================\n// save/load code from IQ's shader: https://www.shadertoy.com/view/MddGzf\nvec4 loadValue( in vec2 re )\n{\n    return texture( iChannel0, (0.5+re) / iChannelResolution[1].xy, -100.0 );\n}\n\n//============================================================\nvoid DecodeData (in vec4 encodedData, out vec3 normal, out vec2 uv)\n{      \n    normal.xy = encodedData.xy;\n    normal.z = -sqrt(1.0 - (normal.x*normal.x + normal.y*normal.y));\n    \n    uv = abs(encodedData.zw);\n}\n\n//=======================================================================================\nvec2 CubicHermite (vec2 A, vec2 B, vec2 C, vec2 D, float t)\n{\n\tfloat t2 = t*t;\n    float t3 = t*t*t;\n    vec2 a = -A/2.0 + (3.0*B)/2.0 - (3.0*C)/2.0 + D/2.0;\n    vec2 b = A - (5.0*B)/2.0 + 2.0*C - D / 2.0;\n    vec2 c = -A/2.0 + C/2.0;\n   \tvec2 d = B;\n    \n    return a*t3 + b*t2 + c*t + d;\n}\n\n//=======================================================================================\nvec3 CubicHermite (vec3 A, vec3 B, vec3 C, vec3 D, float t)\n{\n\tfloat t2 = t*t;\n    float t3 = t*t*t;\n    vec3 a = -A/2.0 + (3.0*B)/2.0 - (3.0*C)/2.0 + D/2.0;\n    vec3 b = A - (5.0*B)/2.0 + 2.0*C - D / 2.0;\n    vec3 c = -A/2.0 + C/2.0;\n   \tvec3 d = B;\n    \n    return a*t3 + b*t2 + c*t + d;\n}\n\n//============================================================\nvoid GetInterpolatedData (in vec2 fragCoord, in int interpolationMode, float frameLength, out vec3 normal, out vec2 uv)\n{\n    float t = mod(iTime, frameLength) / frameLength;\n    \n    // linear interpolate data\n    if (interpolationMode == 0)\n    {\n        vec3 normal1;\n        vec2 uv1;\n        DecodeData(texture(iChannel1, fragCoord.xy / iResolution.xy), normal1, uv1);   \n\n        vec3 normal2;\n        vec2 uv2;\n        DecodeData(texture(iChannel2, fragCoord.xy / iResolution.xy), normal2, uv2);    \n\n        normal = mix(normal1, normal2, t);\n        normal = normalize(normal);\n        uv = mix(uv1, uv2, t);\n    }\n    // cubic interpolation\n    else\n    {\n        vec3 normal0;\n        vec2 uv0;\n        DecodeData(texture(iChannel0, fragCoord.xy / iResolution.xy), normal0, uv0);  \n        \n        vec3 normal1;\n        vec2 uv1;\n        DecodeData(texture(iChannel1, fragCoord.xy / iResolution.xy), normal1, uv1);   \n\n        vec3 normal2;\n        vec2 uv2;\n        DecodeData(texture(iChannel2, fragCoord.xy / iResolution.xy), normal2, uv2);  \n        \n        vec3 normal3;\n        vec2 uv3;\n        DecodeData(texture(iChannel3, fragCoord.xy / iResolution.xy), normal3, uv3);   \n        \n        normal = CubicHermite(normal0,normal1,normal2,normal3,t);\n        normal = normalize(normal);\n        uv = CubicHermite(uv0,uv1,uv2,uv3,t);\n    }\n}\n\n//============================================================\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // get the state from the buffer\n    vec4 state = loadValue(txState);\n    int interpolationMode = int(state.x);\n    float frameLength = state.y;\n    \n    // get the encoded data and decode it\n    vec3 normal;\n    vec2 uv;\n    GetInterpolatedData(fragCoord, interpolationMode, frameLength, normal, uv);\n    \n    // get the ray info\n    vec3 rayOrigin;\n    vec3 rayDirection;\n    GetRayInfo(fragCoord, rayOrigin, rayDirection);  \n    \n    // lighting parameters\n    vec3 c_reverseLightDir = normalize(vec3(1.0,2.0,-3.0));   \n    const vec3 c_lightColor = vec3(0.95);\n    const vec3 c_ambientLight = vec3(0.00);\n    vec3 c_pointLightPos = vec3(cos(iTime), sin(iTime / 0.25) * 0.25, sin(iTime) + 5.5);\n    const vec3 c_pointLightColor = vec3(0.1, 0.1, 0.6);\n\n    // fake up a simple texture\n    vec3 materialDiffuse;\n    bool tileIsWhite = mod(floor(uv.x * 20.0) + floor(uv.y * 20.0), 2.0) < 1.0;\n    if (!tileIsWhite)\n        materialDiffuse = vec3(0.9, 0.1, 0.1);\n    else\n        materialDiffuse = vec3(0.1, 0.9, 0.1);\n    \n    // shade the pixel: diffuse, specular, ambient.\n    float dp = clamp(dot(normal, c_reverseLightDir), 0.0, 1.0);\n    vec3 pixelColor = (c_lightColor * dp * materialDiffuse);  \n    vec3 reflection = reflect(c_reverseLightDir, normal);\n    dp = clamp(dot(rayDirection, reflection), 0.0, 1.0);\n    pixelColor += pow(dp, 60.0);\n    pixelColor += c_ambientLight;     \n    \n    #if DEBUG_SHOW_NORMALS\n    pixelColor = normal * 0.5 + 0.5;\n    #endif\n    \n    // output gamma correct pixel color\n\tpixelColor = pow(pixelColor, vec3(1.0/c_gamma));\n    fragColor = vec4(pixelColor, 1.0);    \n}\n\n/*\n\nTODO:\n* fix uv coordinates on boxes\n* make uv coordinates on spheres be not so dense\n* animate uv's over time for some objects (big box in back?)\n* pull stuff out of todo below etc.\n* make buttons to choose between temporarly: nearest neighbor, linear, cubic\n* make buttons to choose time interpolation lengths.\n * have one for instantaneous which is always t = 0, and buf b renders the correct time.\n* render UI in this shader\n* compare to blending over time between the images directly\n * just have each buffer write the shaded color instead of gbuffer data each frame and have this shader blend them.\n\nNOTES:\n* doesn't seem to be very successful, even at 30fps.  Maybe you could hide it with motion blur though.\n* Adds latency to input causing effects\n* could add more details over time! Render new stuff onto the tiles.  Only recalculate screen space bounding box of new object.\n * true of any g-buffer\n* could pass rendered frames from buffer d to c to b to a, instead of re-rendering each frame\n * could then amortize cost of rendering over frames by rendering a new interpolation target frame over several frames.\n* interpolating a moving uv looks fine actually!\n * can't think of many other things that interpolate as well unfortnuately\n\n*/",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    },
                    {
                        "channel": 2,
                        "ctype": "buffer",
                        "id": 259,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer02.png"
                    },
                    {
                        "channel": 3,
                        "ctype": "buffer",
                        "id": 260,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer03.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "#define SHADER_INDEX -1.0\n\n/*============================================================\n\nThis shader calculates g buffer values for a point in time\nthat is relative to current time, based on SHADER_INDEX.\n\nThis shader is the same for Buf A,B,C,D and only the \nSHADER_INDEX is different.\n\n============================================================*/\n\n/*============================================================\n\nG-Buffer format:\nR, G: x,y part of normal.  z is derived and is always negative.\nB, A: u,v texture coordinates.\n\n============================================================*/\n\n//============================================================\n// SHARED CODE BEGIN\n//============================================================\n\nconst float c_pi = 3.14159265359;\n\n// Distance from the camera to the near plane\nconst float c_cameraDistance = 2.0; \n\n// The vertical field of view of the camera in radians\n// Horizontal is defined by accounting for aspect ratio\nconst float c_camera_FOV = c_pi / 2.0;  \n\n// camera orientation\nvec3 c_cameraPos   = vec3(0.0);\nvec3 c_cameraRight = vec3(1.0, 0.0, 0.0);    \nvec3 c_cameraUp    = vec3(0.0, 1.0, 0.0);\nvec3 c_cameraFwd   = vec3(0.0, 0.0, 1.0); \n\nconst vec2 txState = vec2(0.0,0.0);\n// x = interpolation mode: 0,1,2 = nearest, linear, cubic\n// y = time between frames\n// zw = unused\n\n//============================================================\nvoid GetRayInfo (in vec2 adjustedFragCoord, out vec3 rayOrigin, out vec3 rayDirection)\n{\n    // calculate a uv of the pixel such that:\n    // * the top of the screen is y = 0.5, \n    // * the bottom of the screen in y = -0.5\n    // * the left and right sides of the screen are extended based on aspect ratio.\n    // * left is -x, right is +x\n    float aspectRatio = iResolution.x / iResolution.y;\n    vec2 uv = (adjustedFragCoord / iResolution.xy) - vec2(0.5);\n    uv.x *= aspectRatio;\n    \n    // set up the ray for this pixel.\n    // It starts from the near plane, going in the direction from the camera to the spot on the near plane.\n    vec3 rayLocalDir = vec3(uv * sin(c_camera_FOV), c_cameraDistance);\n    rayOrigin =\n        c_cameraPos +\n        rayLocalDir.x * c_cameraRight * c_cameraDistance +\n        rayLocalDir.y * c_cameraUp * c_cameraDistance +\n        rayLocalDir.z * c_cameraFwd * c_cameraDistance;\n    rayDirection = normalize(rayOrigin - c_cameraPos);      \n}\n\n//============================================================\n// SHARED CODE END\n//============================================================\n\n//============================================================\n// save/load code from IQ's shader: https://www.shadertoy.com/view/MddGzf\n\nfloat isInside( vec2 p, vec2 c ) { vec2 d = abs(p-0.5-c) - 0.5; return -max(d.x,d.y); }\nfloat isInside( vec2 p, vec4 c ) { vec2 d = abs(p-0.5-c.xy-c.zw*0.5) - 0.5*c.zw - 0.5; return -max(d.x,d.y); }\n\nvec4 loadValue( in vec2 re )\n{\n    return texture( iChannel0, (0.5+re) / iChannelResolution[0].xy, -100.0 );\n}\n\nvoid storeValue( in vec2 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\nvoid storeValue( in vec4 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\n//============================================================\nvec4 EncodeData (in vec3 normal, in vec2 uv)\n{\n    return vec4\n\t(\n    \tnormal.x,\n        normal.y,\n        uv.x,\n        uv.y\n\t);\n}\n\n//============================================================\n// this is ibox() from https://www.shadertoy.com/view/ld23DV\n// Just renamed some things to be more clear\n// returns t and normal\nvec4 RayIntersectBox ( in vec3 rayOrigin, in vec3 rayDirection, in mat4 boxTransform, in mat4 inverseBoxTransform, in vec3 boxHalfSizes, out vec2 uv ) \n{\n    // convert from ray to box space\n\tvec3 rdd = (boxTransform*vec4(rayDirection,0.0)).xyz;\n\tvec3 roo = (boxTransform*vec4(rayOrigin,1.0)).xyz;\n\n\t// ray-box intersection in box space\n    vec3 m = 1.0/rdd;\n    vec3 n = m*roo;\n    vec3 k = abs(m)*boxHalfSizes;\n\t\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n\n\tfloat timeNear = max( max( t1.x, t1.y ), t1.z );\n\tfloat timeFar = min( min( t2.x, t2.y ), t2.z );\n\t\n\tif( timeNear > timeFar || timeFar < 0.0)\n        return vec4(-1.0);\n\n\tvec3 normal = -sign(rdd)*step(t1.yzx,t1.xyz)*step(t1.zxy,t1.xyz);\n    \n\t// texture coordinates \n\tvec3 uaxis = vec3(1.0,0.0,0.0);\n\tvec3 vaxis = vec3(0.0,1.0,0.0);\n\t\n\tif (abs(normal.x) > 0.9)\n\t{\n\t\tuaxis = vec3(0.0,1.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\n\t}\n\telse if (abs(normal.y) > 0.9)\n\t{\n\t\tuaxis = vec3(1.0,0.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\t\t\n\t}\n    \n    vec3 relPoint = roo + rdd * timeNear;\n    \n\tuv = vec2\n\t(\n\t\tdot(relPoint, uaxis) * 0.25,\n\t\tdot(relPoint, vaxis) * 0.25\n\t);    \n\n    // convert to ray space\n\t\n\tnormal = (inverseBoxTransform * vec4(normal,0.0)).xyz;\n\n\treturn vec4( timeNear, normal );\n}\n\n\n//============================================================\n// matrix functions also from https://www.shadertoy.com/view/ld23DV\nmat4 rotationAxisAngle( vec3 v, float angle )\n{\n    float s = sin( angle );\n    float c = cos( angle );\n    float ic = 1.0 - c;\n\n    return mat4( v.x*v.x*ic + c,     v.y*v.x*ic - s*v.z, v.z*v.x*ic + s*v.y, 0.0,\n                 v.x*v.y*ic + s*v.z, v.y*v.y*ic + c,     v.z*v.y*ic - s*v.x, 0.0,\n                 v.x*v.z*ic - s*v.y, v.y*v.z*ic + s*v.x, v.z*v.z*ic + c,     0.0,\n\t\t\t     0.0,                0.0,                0.0,                1.0 );\n}\n\nmat4 translate( float x, float y, float z )\n{\n    return mat4( 1.0, 0.0, 0.0, 0.0,\n\t\t\t\t 0.0, 1.0, 0.0, 0.0,\n\t\t\t\t 0.0, 0.0, 1.0, 0.0,\n\t\t\t\t x,   y,   z,   1.0 );\n}\n\nmat4 inverse( in mat4 m )\n{\n\treturn mat4(\n        m[0][0], m[1][0], m[2][0], 0.0,\n        m[0][1], m[1][1], m[2][1], 0.0,\n        m[0][2], m[1][2], m[2][2], 0.0,\n        -dot(m[0].xyz,m[3].xyz),\n        -dot(m[1].xyz,m[3].xyz),\n        -dot(m[2].xyz,m[3].xyz),\n        1.0 );\n}\n\n//============================================================\n// returns t and normal\n// sphere xyz = position, w = radius\nvec4 RayIntersectSphere (in vec3 rayPos, in vec3 rayDir, in vec4 sphere, out vec2 uv)\n{\n\t//get the vector from the center of this circle to where the ray begins.\n\tvec3 m = rayPos - sphere.xyz;\n\n    //get the dot product of the above vector and the ray's vector\n\tfloat b = dot(m, rayDir);\n\n\tfloat c = dot(m, m) - sphere.w * sphere.w;\n\n\t//exit if r's origin outside s (c > 0) and r pointing away from s (b > 0)\n\tif(c > 0.0 && b > 0.0)\n\t\treturn vec4(-1.0);\n\n\t//calculate discriminant\n\tfloat discr = b * b - c;\n\n\t//a negative discriminant corresponds to ray missing sphere\n\tif(discr < 0.0)\n\t\treturn vec4(-1.0);\n\n\t//ray now found to intersect sphere, compute smallest t value of intersection\n    // NOTE: this will report a miss if ray starts inside the sphere.\n\tfloat collisionTime = -b - sqrt(discr);\n    \n    vec3 normal = normalize((rayPos+rayDir*collisionTime) - sphere.xyz);\n    \n    // texture coordinates are just the angular part of spherical coordiantes of normal\n    uv = vec2\n\t(\n\t\tatan(normal.z, normal.x),\n\t\tacos(normal.y)\n\t);\n    \n    return vec4 (collisionTime, normal);\n}\n\n//============================================================\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // load, initialize and handle state\n    vec4 state = loadValue(txState);\n    if (iFrame == 0)\n        state = vec4(1.0, 1.0 / 10.0, 0.0, 0.0);   \n    \n    // set up our default ray hit info\n\tvec4 hitInfo = vec4(1000.0, -c_cameraFwd);\n    vec2 hitInfoUV = vec2(0.0);    \n    \n    // get the ray info\n    vec3 rayOrigin;\n    vec3 rayDirection;\n    GetRayInfo(fragCoord, rayOrigin, rayDirection);\n\n    // calculate the time of this buffer\n    float time = (floor(iTime / state.y) + SHADER_INDEX) * state.y;\n    \n    // raytrace a box\n    mat4 rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), time );\n    mat4 tra = translate( 0.0, 0.0, 5.0 );\n    mat4 txi = tra * rot; \n    mat4 txx = inverse( txi );    \n\tvec2 uv;\n    vec4 info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n    \n    // raytrace another box\n    rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), 0.5 );\n    tra = translate( -2.0, 0.0, 8.0 );\n    txi = tra * rot; \n    txx = inverse( txi );    \n    info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(2.0, 1.75, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv + vec2(sin(time*0.25), cos(time*0.25));\n    }    \n\n    // raytrace a sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(sin(time)*0.5-1.5, 0.0, 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n\n    // raytrace another sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(1.0, sin(time), 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }     \n    \n    // raytrace another sphere\n    vec3 c_pointLightPos = vec3(cos(time), sin(time / 0.25) * 0.25, sin(time) + 5.5);\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(c_pointLightPos, 0.0625), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }      \n    \n    // TODO: fix up materials so they are always in 0,1,2,3\n    \n    // write the gbuffer data\n    fragColor = EncodeData(hitInfo.yzw, hitInfoUV);\n    \n    // store state\n    storeValue(txState, state, fragColor, fragCoord);    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buf A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "#define SHADER_INDEX 0.0\n\n/*============================================================\n\nThis shader calculates g buffer values for a point in time\nthat is relative to current time, based on SHADER_INDEX.\n\nThis shader is the same for Buf A,B,C,D and only the \nSHADER_INDEX is different.\n\n============================================================*/\n\n/*============================================================\n\nG-Buffer format:\nR, G: x,y part of normal.  z is derived and is always negative.\nB, A: u,v texture coordinates.\n\n============================================================*/\n\n//============================================================\n// SHARED CODE BEGIN\n//============================================================\n\nconst float c_pi = 3.14159265359;\n\n// Distance from the camera to the near plane\nconst float c_cameraDistance = 2.0; \n\n// The vertical field of view of the camera in radians\n// Horizontal is defined by accounting for aspect ratio\nconst float c_camera_FOV = c_pi / 2.0;  \n\n// camera orientation\nvec3 c_cameraPos   = vec3(0.0);\nvec3 c_cameraRight = vec3(1.0, 0.0, 0.0);    \nvec3 c_cameraUp    = vec3(0.0, 1.0, 0.0);\nvec3 c_cameraFwd   = vec3(0.0, 0.0, 1.0); \n\nconst vec2 txState = vec2(0.0,0.0);\n// x = interpolation mode: 0,1,2 = nearest, linear, cubic\n// y = time between frames\n// zw = unused\n\n//============================================================\nvoid GetRayInfo (in vec2 adjustedFragCoord, out vec3 rayOrigin, out vec3 rayDirection)\n{\n    // calculate a uv of the pixel such that:\n    // * the top of the screen is y = 0.5, \n    // * the bottom of the screen in y = -0.5\n    // * the left and right sides of the screen are extended based on aspect ratio.\n    // * left is -x, right is +x\n    float aspectRatio = iResolution.x / iResolution.y;\n    vec2 uv = (adjustedFragCoord / iResolution.xy) - vec2(0.5);\n    uv.x *= aspectRatio;\n    \n    // set up the ray for this pixel.\n    // It starts from the near plane, going in the direction from the camera to the spot on the near plane.\n    vec3 rayLocalDir = vec3(uv * sin(c_camera_FOV), c_cameraDistance);\n    rayOrigin =\n        c_cameraPos +\n        rayLocalDir.x * c_cameraRight * c_cameraDistance +\n        rayLocalDir.y * c_cameraUp * c_cameraDistance +\n        rayLocalDir.z * c_cameraFwd * c_cameraDistance;\n    rayDirection = normalize(rayOrigin - c_cameraPos);      \n}\n\n//============================================================\n// SHARED CODE END\n//============================================================\n\n//============================================================\n// save/load code from IQ's shader: https://www.shadertoy.com/view/MddGzf\n\nfloat isInside( vec2 p, vec2 c ) { vec2 d = abs(p-0.5-c) - 0.5; return -max(d.x,d.y); }\nfloat isInside( vec2 p, vec4 c ) { vec2 d = abs(p-0.5-c.xy-c.zw*0.5) - 0.5*c.zw - 0.5; return -max(d.x,d.y); }\n\nvec4 loadValue( in vec2 re )\n{\n    return texture( iChannel0, (0.5+re) / iChannelResolution[0].xy, -100.0 );\n}\n\nvoid storeValue( in vec2 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\nvoid storeValue( in vec4 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\n//============================================================\nvec4 EncodeData (in vec3 normal, in vec2 uv)\n{\n    return vec4\n\t(\n    \tnormal.x,\n        normal.y,\n        uv.x,\n        uv.y\n\t);\n}\n\n//============================================================\n// this is ibox() from https://www.shadertoy.com/view/ld23DV\n// Just renamed some things to be more clear\n// returns t and normal\nvec4 RayIntersectBox ( in vec3 rayOrigin, in vec3 rayDirection, in mat4 boxTransform, in mat4 inverseBoxTransform, in vec3 boxHalfSizes, out vec2 uv ) \n{\n    // convert from ray to box space\n\tvec3 rdd = (boxTransform*vec4(rayDirection,0.0)).xyz;\n\tvec3 roo = (boxTransform*vec4(rayOrigin,1.0)).xyz;\n\n\t// ray-box intersection in box space\n    vec3 m = 1.0/rdd;\n    vec3 n = m*roo;\n    vec3 k = abs(m)*boxHalfSizes;\n\t\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n\n\tfloat timeNear = max( max( t1.x, t1.y ), t1.z );\n\tfloat timeFar = min( min( t2.x, t2.y ), t2.z );\n\t\n\tif( timeNear > timeFar || timeFar < 0.0)\n        return vec4(-1.0);\n\n\tvec3 normal = -sign(rdd)*step(t1.yzx,t1.xyz)*step(t1.zxy,t1.xyz);\n    \n\t// texture coordinates \n\tvec3 uaxis = vec3(1.0,0.0,0.0);\n\tvec3 vaxis = vec3(0.0,1.0,0.0);\n\t\n\tif (abs(normal.x) > 0.9)\n\t{\n\t\tuaxis = vec3(0.0,1.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\n\t}\n\telse if (abs(normal.y) > 0.9)\n\t{\n\t\tuaxis = vec3(1.0,0.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\t\t\n\t}\n    \n    vec3 relPoint = roo + rdd * timeNear;\n    \n\tuv = vec2\n\t(\n\t\tdot(relPoint, uaxis) * 0.25,\n\t\tdot(relPoint, vaxis) * 0.25\n\t);    \n\n    // convert to ray space\n\t\n\tnormal = (inverseBoxTransform * vec4(normal,0.0)).xyz;\n\n\treturn vec4( timeNear, normal );\n}\n\n\n//============================================================\n// matrix functions also from https://www.shadertoy.com/view/ld23DV\nmat4 rotationAxisAngle( vec3 v, float angle )\n{\n    float s = sin( angle );\n    float c = cos( angle );\n    float ic = 1.0 - c;\n\n    return mat4( v.x*v.x*ic + c,     v.y*v.x*ic - s*v.z, v.z*v.x*ic + s*v.y, 0.0,\n                 v.x*v.y*ic + s*v.z, v.y*v.y*ic + c,     v.z*v.y*ic - s*v.x, 0.0,\n                 v.x*v.z*ic - s*v.y, v.y*v.z*ic + s*v.x, v.z*v.z*ic + c,     0.0,\n\t\t\t     0.0,                0.0,                0.0,                1.0 );\n}\n\nmat4 translate( float x, float y, float z )\n{\n    return mat4( 1.0, 0.0, 0.0, 0.0,\n\t\t\t\t 0.0, 1.0, 0.0, 0.0,\n\t\t\t\t 0.0, 0.0, 1.0, 0.0,\n\t\t\t\t x,   y,   z,   1.0 );\n}\n\nmat4 inverse( in mat4 m )\n{\n\treturn mat4(\n        m[0][0], m[1][0], m[2][0], 0.0,\n        m[0][1], m[1][1], m[2][1], 0.0,\n        m[0][2], m[1][2], m[2][2], 0.0,\n        -dot(m[0].xyz,m[3].xyz),\n        -dot(m[1].xyz,m[3].xyz),\n        -dot(m[2].xyz,m[3].xyz),\n        1.0 );\n}\n\n//============================================================\n// returns t and normal\n// sphere xyz = position, w = radius\nvec4 RayIntersectSphere (in vec3 rayPos, in vec3 rayDir, in vec4 sphere, out vec2 uv)\n{\n\t//get the vector from the center of this circle to where the ray begins.\n\tvec3 m = rayPos - sphere.xyz;\n\n    //get the dot product of the above vector and the ray's vector\n\tfloat b = dot(m, rayDir);\n\n\tfloat c = dot(m, m) - sphere.w * sphere.w;\n\n\t//exit if r's origin outside s (c > 0) and r pointing away from s (b > 0)\n\tif(c > 0.0 && b > 0.0)\n\t\treturn vec4(-1.0);\n\n\t//calculate discriminant\n\tfloat discr = b * b - c;\n\n\t//a negative discriminant corresponds to ray missing sphere\n\tif(discr < 0.0)\n\t\treturn vec4(-1.0);\n\n\t//ray now found to intersect sphere, compute smallest t value of intersection\n    // NOTE: this will report a miss if ray starts inside the sphere.\n\tfloat collisionTime = -b - sqrt(discr);\n    \n    vec3 normal = normalize((rayPos+rayDir*collisionTime) - sphere.xyz);\n    \n    // texture coordinates are just the angular part of spherical coordiantes of normal\n    uv = vec2\n\t(\n\t\tatan(normal.z, normal.x),\n\t\tacos(normal.y)\n\t);\n    \n    return vec4 (collisionTime, normal);\n}\n\n//============================================================\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // load, initialize and handle state\n    vec4 state = loadValue(txState);\n    if (iFrame == 0)\n        state = vec4(1.0, 1.0 / 10.0, 0.0, 0.0);   \n    \n    // set up our default ray hit info\n\tvec4 hitInfo = vec4(1000.0, -c_cameraFwd);\n    vec2 hitInfoUV = vec2(0.0);    \n    \n    // get the ray info\n    vec3 rayOrigin;\n    vec3 rayDirection;\n    GetRayInfo(fragCoord, rayOrigin, rayDirection);\n\n    // calculate the time of this buffer\n    float time = (floor(iTime / state.y) + SHADER_INDEX) * state.y;\n    \n    // raytrace a box\n    mat4 rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), time );\n    mat4 tra = translate( 0.0, 0.0, 5.0 );\n    mat4 txi = tra * rot; \n    mat4 txx = inverse( txi );    \n\tvec2 uv;\n    vec4 info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n    \n    // raytrace another box\n    rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), 0.5 );\n    tra = translate( -2.0, 0.0, 8.0 );\n    txi = tra * rot; \n    txx = inverse( txi );    \n    info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(2.0, 1.75, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv + vec2(sin(time*0.25), cos(time*0.25));\n    }    \n\n    // raytrace a sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(sin(time)*0.5-1.5, 0.0, 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n\n    // raytrace another sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(1.0, sin(time), 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }     \n    \n    // raytrace another sphere\n    vec3 c_pointLightPos = vec3(cos(time), sin(time / 0.25) * 0.25, sin(time) + 5.5);\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(c_pointLightPos, 0.0625), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }      \n    \n    // TODO: fix up materials so they are always in 0,1,2,3\n    \n    // write the gbuffer data\n    fragColor = EncodeData(hitInfo.yzw, hitInfoUV);\n    \n    // store state\n    storeValue(txState, state, fragColor, fragCoord);    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buf B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "#define SHADER_INDEX 1.0\n\n/*============================================================\n\nThis shader calculates g buffer values for a point in time\nthat is relative to current time, based on SHADER_INDEX.\n\nThis shader is the same for Buf A,B,C,D and only the \nSHADER_INDEX is different.\n\n============================================================*/\n\n/*============================================================\n\nG-Buffer format:\nR, G: x,y part of normal.  z is derived and is always negative.\nB, A: u,v texture coordinates.\n\n============================================================*/\n\n//============================================================\n// SHARED CODE BEGIN\n//============================================================\n\nconst float c_pi = 3.14159265359;\n\n// Distance from the camera to the near plane\nconst float c_cameraDistance = 2.0; \n\n// The vertical field of view of the camera in radians\n// Horizontal is defined by accounting for aspect ratio\nconst float c_camera_FOV = c_pi / 2.0;  \n\n// camera orientation\nvec3 c_cameraPos   = vec3(0.0);\nvec3 c_cameraRight = vec3(1.0, 0.0, 0.0);    \nvec3 c_cameraUp    = vec3(0.0, 1.0, 0.0);\nvec3 c_cameraFwd   = vec3(0.0, 0.0, 1.0); \n\nconst vec2 txState = vec2(0.0,0.0);\n// x = interpolation mode: 0,1,2 = nearest, linear, cubic\n// y = time between frames\n// zw = unused\n\n//============================================================\nvoid GetRayInfo (in vec2 adjustedFragCoord, out vec3 rayOrigin, out vec3 rayDirection)\n{\n    // calculate a uv of the pixel such that:\n    // * the top of the screen is y = 0.5, \n    // * the bottom of the screen in y = -0.5\n    // * the left and right sides of the screen are extended based on aspect ratio.\n    // * left is -x, right is +x\n    float aspectRatio = iResolution.x / iResolution.y;\n    vec2 uv = (adjustedFragCoord / iResolution.xy) - vec2(0.5);\n    uv.x *= aspectRatio;\n    \n    // set up the ray for this pixel.\n    // It starts from the near plane, going in the direction from the camera to the spot on the near plane.\n    vec3 rayLocalDir = vec3(uv * sin(c_camera_FOV), c_cameraDistance);\n    rayOrigin =\n        c_cameraPos +\n        rayLocalDir.x * c_cameraRight * c_cameraDistance +\n        rayLocalDir.y * c_cameraUp * c_cameraDistance +\n        rayLocalDir.z * c_cameraFwd * c_cameraDistance;\n    rayDirection = normalize(rayOrigin - c_cameraPos);      \n}\n\n//============================================================\n// SHARED CODE END\n//============================================================\n\n//============================================================\n// save/load code from IQ's shader: https://www.shadertoy.com/view/MddGzf\n\nfloat isInside( vec2 p, vec2 c ) { vec2 d = abs(p-0.5-c) - 0.5; return -max(d.x,d.y); }\nfloat isInside( vec2 p, vec4 c ) { vec2 d = abs(p-0.5-c.xy-c.zw*0.5) - 0.5*c.zw - 0.5; return -max(d.x,d.y); }\n\nvec4 loadValue( in vec2 re )\n{\n    return texture( iChannel0, (0.5+re) / iChannelResolution[0].xy, -100.0 );\n}\n\nvoid storeValue( in vec2 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\nvoid storeValue( in vec4 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\n//============================================================\nvec4 EncodeData (in vec3 normal, in vec2 uv)\n{\n    return vec4\n\t(\n    \tnormal.x,\n        normal.y,\n        uv.x,\n        uv.y\n\t);\n}\n\n//============================================================\n// this is ibox() from https://www.shadertoy.com/view/ld23DV\n// Just renamed some things to be more clear\n// returns t and normal\nvec4 RayIntersectBox ( in vec3 rayOrigin, in vec3 rayDirection, in mat4 boxTransform, in mat4 inverseBoxTransform, in vec3 boxHalfSizes, out vec2 uv ) \n{\n    // convert from ray to box space\n\tvec3 rdd = (boxTransform*vec4(rayDirection,0.0)).xyz;\n\tvec3 roo = (boxTransform*vec4(rayOrigin,1.0)).xyz;\n\n\t// ray-box intersection in box space\n    vec3 m = 1.0/rdd;\n    vec3 n = m*roo;\n    vec3 k = abs(m)*boxHalfSizes;\n\t\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n\n\tfloat timeNear = max( max( t1.x, t1.y ), t1.z );\n\tfloat timeFar = min( min( t2.x, t2.y ), t2.z );\n\t\n\tif( timeNear > timeFar || timeFar < 0.0)\n        return vec4(-1.0);\n\n\tvec3 normal = -sign(rdd)*step(t1.yzx,t1.xyz)*step(t1.zxy,t1.xyz);\n    \n\t// texture coordinates \n\tvec3 uaxis = vec3(1.0,0.0,0.0);\n\tvec3 vaxis = vec3(0.0,1.0,0.0);\n\t\n\tif (abs(normal.x) > 0.9)\n\t{\n\t\tuaxis = vec3(0.0,1.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\n\t}\n\telse if (abs(normal.y) > 0.9)\n\t{\n\t\tuaxis = vec3(1.0,0.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\t\t\n\t}\n    \n    vec3 relPoint = roo + rdd * timeNear;\n    \n\tuv = vec2\n\t(\n\t\tdot(relPoint, uaxis) * 0.25,\n\t\tdot(relPoint, vaxis) * 0.25\n\t);    \n\n    // convert to ray space\n\t\n\tnormal = (inverseBoxTransform * vec4(normal,0.0)).xyz;\n\n\treturn vec4( timeNear, normal );\n}\n\n\n//============================================================\n// matrix functions also from https://www.shadertoy.com/view/ld23DV\nmat4 rotationAxisAngle( vec3 v, float angle )\n{\n    float s = sin( angle );\n    float c = cos( angle );\n    float ic = 1.0 - c;\n\n    return mat4( v.x*v.x*ic + c,     v.y*v.x*ic - s*v.z, v.z*v.x*ic + s*v.y, 0.0,\n                 v.x*v.y*ic + s*v.z, v.y*v.y*ic + c,     v.z*v.y*ic - s*v.x, 0.0,\n                 v.x*v.z*ic - s*v.y, v.y*v.z*ic + s*v.x, v.z*v.z*ic + c,     0.0,\n\t\t\t     0.0,                0.0,                0.0,                1.0 );\n}\n\nmat4 translate( float x, float y, float z )\n{\n    return mat4( 1.0, 0.0, 0.0, 0.0,\n\t\t\t\t 0.0, 1.0, 0.0, 0.0,\n\t\t\t\t 0.0, 0.0, 1.0, 0.0,\n\t\t\t\t x,   y,   z,   1.0 );\n}\n\nmat4 inverse( in mat4 m )\n{\n\treturn mat4(\n        m[0][0], m[1][0], m[2][0], 0.0,\n        m[0][1], m[1][1], m[2][1], 0.0,\n        m[0][2], m[1][2], m[2][2], 0.0,\n        -dot(m[0].xyz,m[3].xyz),\n        -dot(m[1].xyz,m[3].xyz),\n        -dot(m[2].xyz,m[3].xyz),\n        1.0 );\n}\n\n//============================================================\n// returns t and normal\n// sphere xyz = position, w = radius\nvec4 RayIntersectSphere (in vec3 rayPos, in vec3 rayDir, in vec4 sphere, out vec2 uv)\n{\n\t//get the vector from the center of this circle to where the ray begins.\n\tvec3 m = rayPos - sphere.xyz;\n\n    //get the dot product of the above vector and the ray's vector\n\tfloat b = dot(m, rayDir);\n\n\tfloat c = dot(m, m) - sphere.w * sphere.w;\n\n\t//exit if r's origin outside s (c > 0) and r pointing away from s (b > 0)\n\tif(c > 0.0 && b > 0.0)\n\t\treturn vec4(-1.0);\n\n\t//calculate discriminant\n\tfloat discr = b * b - c;\n\n\t//a negative discriminant corresponds to ray missing sphere\n\tif(discr < 0.0)\n\t\treturn vec4(-1.0);\n\n\t//ray now found to intersect sphere, compute smallest t value of intersection\n    // NOTE: this will report a miss if ray starts inside the sphere.\n\tfloat collisionTime = -b - sqrt(discr);\n    \n    vec3 normal = normalize((rayPos+rayDir*collisionTime) - sphere.xyz);\n    \n    // texture coordinates are just the angular part of spherical coordiantes of normal\n    uv = vec2\n\t(\n\t\tatan(normal.z, normal.x),\n\t\tacos(normal.y)\n\t);\n    \n    return vec4 (collisionTime, normal);\n}\n\n//============================================================\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // load, initialize and handle state\n    vec4 state = loadValue(txState);\n    if (iFrame == 0)\n        state = vec4(1.0, 1.0 / 10.0, 0.0, 0.0);   \n    \n    // set up our default ray hit info\n\tvec4 hitInfo = vec4(1000.0, -c_cameraFwd);\n    vec2 hitInfoUV = vec2(0.0);    \n    \n    // get the ray info\n    vec3 rayOrigin;\n    vec3 rayDirection;\n    GetRayInfo(fragCoord, rayOrigin, rayDirection);\n\n    // calculate the time of this buffer\n    float time = (floor(iTime / state.y) + SHADER_INDEX) * state.y;\n    \n    // raytrace a box\n    mat4 rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), time );\n    mat4 tra = translate( 0.0, 0.0, 5.0 );\n    mat4 txi = tra * rot; \n    mat4 txx = inverse( txi );    \n\tvec2 uv;\n    vec4 info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n    \n    // raytrace another box\n    rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), 0.5 );\n    tra = translate( -2.0, 0.0, 8.0 );\n    txi = tra * rot; \n    txx = inverse( txi );    \n    info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(2.0, 1.75, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv + vec2(sin(time*0.25), cos(time*0.25));\n    }    \n\n    // raytrace a sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(sin(time)*0.5-1.5, 0.0, 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n\n    // raytrace another sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(1.0, sin(time), 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }     \n    \n    // raytrace another sphere\n    vec3 c_pointLightPos = vec3(cos(time), sin(time / 0.25) * 0.25, sin(time) + 5.5);\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(c_pointLightPos, 0.0625), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }      \n    \n    // TODO: fix up materials so they are always in 0,1,2,3\n    \n    // write the gbuffer data\n    fragColor = EncodeData(hitInfo.yzw, hitInfoUV);\n    \n    // store state\n    storeValue(txState, state, fragColor, fragCoord);    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buf C",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 259
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "#define SHADER_INDEX 2.0\n\n/*============================================================\n\nThis shader calculates g buffer values for a point in time\nthat is relative to current time, based on SHADER_INDEX.\n\nThis shader is the same for Buf A,B,C,D and only the \nSHADER_INDEX is different.\n\n============================================================*/\n\n/*============================================================\n\nG-Buffer format:\nR, G: x,y part of normal.  z is derived and is always negative.\nB, A: u,v texture coordinates.\n\n============================================================*/\n\n//============================================================\n// SHARED CODE BEGIN\n//============================================================\n\nconst float c_pi = 3.14159265359;\n\n// Distance from the camera to the near plane\nconst float c_cameraDistance = 2.0; \n\n// The vertical field of view of the camera in radians\n// Horizontal is defined by accounting for aspect ratio\nconst float c_camera_FOV = c_pi / 2.0;  \n\n// camera orientation\nvec3 c_cameraPos   = vec3(0.0);\nvec3 c_cameraRight = vec3(1.0, 0.0, 0.0);    \nvec3 c_cameraUp    = vec3(0.0, 1.0, 0.0);\nvec3 c_cameraFwd   = vec3(0.0, 0.0, 1.0); \n\nconst vec2 txState = vec2(0.0,0.0);\n// x = interpolation mode: 0,1,2 = nearest, linear, cubic\n// y = time between frames\n// zw = unused\n\n//============================================================\nvoid GetRayInfo (in vec2 adjustedFragCoord, out vec3 rayOrigin, out vec3 rayDirection)\n{\n    // calculate a uv of the pixel such that:\n    // * the top of the screen is y = 0.5, \n    // * the bottom of the screen in y = -0.5\n    // * the left and right sides of the screen are extended based on aspect ratio.\n    // * left is -x, right is +x\n    float aspectRatio = iResolution.x / iResolution.y;\n    vec2 uv = (adjustedFragCoord / iResolution.xy) - vec2(0.5);\n    uv.x *= aspectRatio;\n    \n    // set up the ray for this pixel.\n    // It starts from the near plane, going in the direction from the camera to the spot on the near plane.\n    vec3 rayLocalDir = vec3(uv * sin(c_camera_FOV), c_cameraDistance);\n    rayOrigin =\n        c_cameraPos +\n        rayLocalDir.x * c_cameraRight * c_cameraDistance +\n        rayLocalDir.y * c_cameraUp * c_cameraDistance +\n        rayLocalDir.z * c_cameraFwd * c_cameraDistance;\n    rayDirection = normalize(rayOrigin - c_cameraPos);      \n}\n\n//============================================================\n// SHARED CODE END\n//============================================================\n\n//============================================================\n// save/load code from IQ's shader: https://www.shadertoy.com/view/MddGzf\n\nfloat isInside( vec2 p, vec2 c ) { vec2 d = abs(p-0.5-c) - 0.5; return -max(d.x,d.y); }\nfloat isInside( vec2 p, vec4 c ) { vec2 d = abs(p-0.5-c.xy-c.zw*0.5) - 0.5*c.zw - 0.5; return -max(d.x,d.y); }\n\nvec4 loadValue( in vec2 re )\n{\n    return texture( iChannel0, (0.5+re) / iChannelResolution[0].xy, -100.0 );\n}\n\nvoid storeValue( in vec2 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\nvoid storeValue( in vec4 re, in vec4 va, inout vec4 fragColor, in vec2 fragCoord )\n{\n    if (SHADER_INDEX < 0.0)\n    \tfragColor = ( isInside(fragCoord,re) > 0.0 ) ? va : fragColor;\n}\n\n//============================================================\nvec4 EncodeData (in vec3 normal, in vec2 uv)\n{\n    return vec4\n\t(\n    \tnormal.x,\n        normal.y,\n        uv.x,\n        uv.y\n\t);\n}\n\n//============================================================\n// this is ibox() from https://www.shadertoy.com/view/ld23DV\n// Just renamed some things to be more clear\n// returns t and normal\nvec4 RayIntersectBox ( in vec3 rayOrigin, in vec3 rayDirection, in mat4 boxTransform, in mat4 inverseBoxTransform, in vec3 boxHalfSizes, out vec2 uv ) \n{\n    // convert from ray to box space\n\tvec3 rdd = (boxTransform*vec4(rayDirection,0.0)).xyz;\n\tvec3 roo = (boxTransform*vec4(rayOrigin,1.0)).xyz;\n\n\t// ray-box intersection in box space\n    vec3 m = 1.0/rdd;\n    vec3 n = m*roo;\n    vec3 k = abs(m)*boxHalfSizes;\n\t\n    vec3 t1 = -n - k;\n    vec3 t2 = -n + k;\n\n\tfloat timeNear = max( max( t1.x, t1.y ), t1.z );\n\tfloat timeFar = min( min( t2.x, t2.y ), t2.z );\n\t\n\tif( timeNear > timeFar || timeFar < 0.0)\n        return vec4(-1.0);\n\n\tvec3 normal = -sign(rdd)*step(t1.yzx,t1.xyz)*step(t1.zxy,t1.xyz);\n    \n\t// texture coordinates \n\tvec3 uaxis = vec3(1.0,0.0,0.0);\n\tvec3 vaxis = vec3(0.0,1.0,0.0);\n\t\n\tif (abs(normal.x) > 0.9)\n\t{\n\t\tuaxis = vec3(0.0,1.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\n\t}\n\telse if (abs(normal.y) > 0.9)\n\t{\n\t\tuaxis = vec3(1.0,0.0,0.0);\n\t\tvaxis = vec3(0.0,0.0,1.0);\t\t\n\t}\n    \n    vec3 relPoint = roo + rdd * timeNear;\n    \n\tuv = vec2\n\t(\n\t\tdot(relPoint, uaxis) * 0.25,\n\t\tdot(relPoint, vaxis) * 0.25\n\t);    \n\n    // convert to ray space\n\t\n\tnormal = (inverseBoxTransform * vec4(normal,0.0)).xyz;\n\n\treturn vec4( timeNear, normal );\n}\n\n\n//============================================================\n// matrix functions also from https://www.shadertoy.com/view/ld23DV\nmat4 rotationAxisAngle( vec3 v, float angle )\n{\n    float s = sin( angle );\n    float c = cos( angle );\n    float ic = 1.0 - c;\n\n    return mat4( v.x*v.x*ic + c,     v.y*v.x*ic - s*v.z, v.z*v.x*ic + s*v.y, 0.0,\n                 v.x*v.y*ic + s*v.z, v.y*v.y*ic + c,     v.z*v.y*ic - s*v.x, 0.0,\n                 v.x*v.z*ic - s*v.y, v.y*v.z*ic + s*v.x, v.z*v.z*ic + c,     0.0,\n\t\t\t     0.0,                0.0,                0.0,                1.0 );\n}\n\nmat4 translate( float x, float y, float z )\n{\n    return mat4( 1.0, 0.0, 0.0, 0.0,\n\t\t\t\t 0.0, 1.0, 0.0, 0.0,\n\t\t\t\t 0.0, 0.0, 1.0, 0.0,\n\t\t\t\t x,   y,   z,   1.0 );\n}\n\nmat4 inverse( in mat4 m )\n{\n\treturn mat4(\n        m[0][0], m[1][0], m[2][0], 0.0,\n        m[0][1], m[1][1], m[2][1], 0.0,\n        m[0][2], m[1][2], m[2][2], 0.0,\n        -dot(m[0].xyz,m[3].xyz),\n        -dot(m[1].xyz,m[3].xyz),\n        -dot(m[2].xyz,m[3].xyz),\n        1.0 );\n}\n\n//============================================================\n// returns t and normal\n// sphere xyz = position, w = radius\nvec4 RayIntersectSphere (in vec3 rayPos, in vec3 rayDir, in vec4 sphere, out vec2 uv)\n{\n\t//get the vector from the center of this circle to where the ray begins.\n\tvec3 m = rayPos - sphere.xyz;\n\n    //get the dot product of the above vector and the ray's vector\n\tfloat b = dot(m, rayDir);\n\n\tfloat c = dot(m, m) - sphere.w * sphere.w;\n\n\t//exit if r's origin outside s (c > 0) and r pointing away from s (b > 0)\n\tif(c > 0.0 && b > 0.0)\n\t\treturn vec4(-1.0);\n\n\t//calculate discriminant\n\tfloat discr = b * b - c;\n\n\t//a negative discriminant corresponds to ray missing sphere\n\tif(discr < 0.0)\n\t\treturn vec4(-1.0);\n\n\t//ray now found to intersect sphere, compute smallest t value of intersection\n    // NOTE: this will report a miss if ray starts inside the sphere.\n\tfloat collisionTime = -b - sqrt(discr);\n    \n    vec3 normal = normalize((rayPos+rayDir*collisionTime) - sphere.xyz);\n    \n    // texture coordinates are just the angular part of spherical coordiantes of normal\n    uv = vec2\n\t(\n\t\tatan(normal.z, normal.x),\n\t\tacos(normal.y)\n\t);\n    \n    return vec4 (collisionTime, normal);\n}\n\n//============================================================\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // load, initialize and handle state\n    vec4 state = loadValue(txState);\n    if (iFrame == 0)\n        state = vec4(1.0, 1.0 / 10.0, 0.0, 0.0);   \n    \n    // set up our default ray hit info\n\tvec4 hitInfo = vec4(1000.0, -c_cameraFwd);\n    vec2 hitInfoUV = vec2(0.0);    \n    \n    // get the ray info\n    vec3 rayOrigin;\n    vec3 rayDirection;\n    GetRayInfo(fragCoord, rayOrigin, rayDirection);\n\n    // calculate the time of this buffer\n    float time = (floor(iTime / state.y) + SHADER_INDEX) * state.y;\n    \n    // raytrace a box\n    mat4 rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), time );\n    mat4 tra = translate( 0.0, 0.0, 5.0 );\n    mat4 txi = tra * rot; \n    mat4 txx = inverse( txi );    \n\tvec2 uv;\n    vec4 info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n    \n    // raytrace another box\n    rot = rotationAxisAngle( normalize(vec3(1.0,1.0,0.0)), 0.5 );\n    tra = translate( -2.0, 0.0, 8.0 );\n    txi = tra * rot; \n    txx = inverse( txi );    \n    info = RayIntersectBox(rayOrigin, rayDirection, txx, txi, vec3(2.0, 1.75, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv + vec2(sin(time*0.25), cos(time*0.25));\n    }    \n\n    // raytrace a sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(sin(time)*0.5-1.5, 0.0, 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }\n\n    // raytrace another sphere\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(1.0, sin(time), 5.0, 0.25), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }     \n    \n    // raytrace another sphere\n    vec3 c_pointLightPos = vec3(cos(time), sin(time / 0.25) * 0.25, sin(time) + 5.5);\n    info = RayIntersectSphere(rayOrigin, rayDirection, vec4(c_pointLightPos, 0.0625), uv);\n    if (info.x > 0.0 && info.x < hitInfo.x) {\n        hitInfo = info;\n        hitInfoUV = uv;\n    }      \n    \n    // TODO: fix up materials so they are always in 0,1,2,3\n    \n    // write the gbuffer data\n    fragColor = EncodeData(hitInfo.yzw, hitInfoUV);\n    \n    // store state\n    storeValue(txState, state, fragColor, fragCoord);    \n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buf D",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 260
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}