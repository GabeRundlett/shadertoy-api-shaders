{
    "Shader": {
        "info": {
            "date": "1526139281",
            "description": "Creating a wrappable Gray-Scott reaction-diffusion texture, then using 2D imaging software techniques to produce a faux-3D styled scene. It takes about 10 seconds for a legible pattern to form and roughly 30 seconds for it to stabilize.",
            "flags": 32,
            "hasliked": 0,
            "id": "Ms3fRX",
            "likes": 59,
            "name": "Gray-Scott Pattern",
            "published": 3,
            "tags": [
                "diffusion",
                "gray",
                "pattern",
                "laplacian",
                "reaction",
                "biology",
                "scott",
                "chemistry"
            ],
            "usePreview": 0,
            "username": "Shane",
            "viewed": 2076
        },
        "renderpass": [
            {
                "code": "/*\n\tGray-Scott Pattern\n\t------------------\n\n\tOf all the standard texturing algorithms, I probably like the look of reaction-diffusion textures most. \n\tUnfortunately, I find them a little cumbersome to work with inside realtime shader environments, so I tend \n\tto stick with the classics, like smooth noise and Voronoi.\n\n\tAnyway, this is just a basic example that I put together for my own amusement. For the really interesting \n    possibilities, take a look at some of Flexi and Cornusammonis's shaders. \n\n\tI restricted the pattern to something pretty simple, since I didn't want people having to wait for 20 years\n\tfor something legible to form. This particular pattern is recognizable in under ten seconds and tends to reach\n    a state of equilibrium in about 30 seconds -- Not instant gratification, but not too bad for just one extra\n\tbuffer. Obviously, outside of Shadertoy, the idea would be to prerender to a wrappable texture, then load it \n\tin.\t\n\n\tThere isn't just one way to perform diffusion, but there are some common ones that graphics programmers like\n    to employ. The Gray-Scott model is pretty popular, and that's the one I'm utilizing here. It's been done many \n    times before, but I wanted to post my own version. I went out of my way to make the formula as straight forward \n    as possible and to explain it. Thanks to the people on Shadertoy who posted examples before me, because having\n    working shader examples to refer to always makes life easier.\n\n\tIn regard to the rendering of the pattern, this is a just a bit of bump mapping. The lighting, shadows, etc,\n\tare all layered. 3D rendering can get a little repetitive, so just for fun, I occasionally enjoy applying 2D \n    techniques to imagery in an attempt to make them look 3D -- We all need our hobbies. :D\n\n\tAnyway, I have a proper 3D version that I'll put up at some stage.\n\n\t// Other diffusion examples:\n\n    // I have a 3D version of this that I might put up at some stage.\n\tViscous Fingering - cornusammonis\n\thttps://www.shadertoy.com/view/Xst3Dj\n\n\t// I remember Flexi's original from years ago. :)\n\texpansive reaction-diffusion - Flexi\n    https://www.shadertoy.com/view/4dcGW2\n\n\t// A nice all round example.\n\tReactDiff Experiment 1 - aiekick\n\thttps://www.shadertoy.com/view/XtlcDl\n\n\t// More interactive and fun than my example. :)\n\tGray-Scott Explorer 2 - Dr2\n\thttps://www.shadertoy.com/view/MtlfDN\n\n    // Fabrice has a pretty sharp mind. He whipped this up not long after reading a pretty esoteric paper. \n    // I remember perusing the paper briefly, then I put it on the \"I'll look at it later\" list, and we all \n    // know what that means. :D\n\tSeashells reaction-diffusion - FabriceNeyret2\n\thttps://www.shadertoy.com/view/MdGGRD\n\n*/\n\n// Global resolution variable: Kind of hacky, but necessary to accommodate a repeat texture created on a \n// variable sized buffer that needs to coincide with canvas size changes... Working with variable sized\n// buffers can be a little tiring. :)\nfloat gResY;\n\n// 2x2 matrix rotation. Note the absence of \"cos.\" It's there, but in disguise, and comes courtesy\n// of Fabrice Neyret's \"ouside the box\" thinking. :)\nmat2 rot2( float a ){ vec2 v = sin(vec2(1.570796, 0) + a);\treturn mat2(v, -v.y, v.x); }\n\n\n// Tri-Planar blending function. Based on an old Nvidia writeup:\n// GPU Gems 3 - Ryan Geiss: https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch01.html\nvec3 tex3D(sampler2D t, in vec3 p, in vec3 n){\n\n    \n    n = max(abs(n), 0.001);\n    n /= dot(n, vec3(1));\n\tvec3 tx = texture(t, p.yz).xyz;\n    vec3 ty = texture(t, p.zx).xyz;\n    vec3 tz = texture(t, p.xy).xyz;\n    \n    // Textures are stored in sRGB (I think), so you have to convert them to linear space \n    // (squaring is a rough approximation) prior to working with them... or something like that. :)\n    // Once the final color value is gamma corrected, you should see correct looking colors.\n    return (tx*tx*n.x + ty*ty*n.y + tz*tz*n.z);\n    \n}\n\n\n// Cheap and nasty 2D smooth noise function with inbuilt hash function - based on IQ's \n// original. Very trimmed down. In fact, I probably went a little overboard. I think it \n// might also degrade with large time values. I'll swap it for something more robust later.\nfloat n2D(vec2 p) {\n\n\tvec2 i = floor(p); p -= i; \n    //p *= p*p*(p*(p*6. - 15.) + 10.);\n    p *= p*(3. - p*2.);  \n    \n\treturn dot(mat2(fract(sin(vec4(0, 1, 113, 114) + dot(i, vec2(1, 113)))*43758.5453))*\n                vec2(1. - p.y, p.y), vec2(1. - p.x, p.x) );\n\n}\n\n// Gradient noise fBm.\nfloat fBm(in vec2 p){\n    \n    return n2D(p)*.57 + n2D(p*2.)*.28 + n2D(p*4.)*.15;\n    \n}\n\n// 2x2 hash algorithm.\nvec2 hash22(vec2 p) { \n\n    //p = mod(p, 24.);\n    // More concise, but wouldn't disperse things as nicely as the block below.\n    float n = sin(dot(p,vec2(1, 113))); \n    //return fract(vec2(2097152, 262144)*n);\n    \n    // Animation.\n    p = fract(vec2(2097152, 262144)*n);\n    return sin(p*6.2831853 + iTime)*0.5 + 0.5;\n}\n\n// 2D 2nd-order Voronoi: Obviously, this is just a rehash of IQ's original. I've tidied\n// up those if-statements. Since there's less writing, it should go faster. That's how \n// it works, right? :)\n//\nfloat Voronoi(vec2 p){\n    \n\tvec2 g = floor(p), o;\n\tp -= g;// p = fract(p);\n\t\n\tvec2 d = vec2(1); // 1.4, etc.\n    \n\tfor(int y = -1; y <= 1; y++){\n\t\tfor(int x = -1; x <= 1; x++){\n            \n\t\t\to = vec2(x, y);\n            o += hash22(g + o) - p;\n            \n\t\t\tfloat h = dot(o, o);\n            d.y = max(d.x, min(d.y, h)); \n            d.x = min(d.x, h);            \n\t\t}\n\t}\n    \n    \n\t\n\t//return sqrt(d.y) - sqrt(d.x);\n    return (d.y - d.x); // etc.\n}\n\n\n\nfloat ggs;\n\n// Bump mapping function. Put whatever you want here. In this case, \n// we're returning the length of the sinusoidal warp function.\nfloat bumpFunc(vec2 p){ \n\n    //vec3 tx = texture(iChannel1, p*2.).xyz; tx *= tx;\n    //float bump = dot(tx, vec3(.299, .587, .114));\n    \n \n    p = p/2.25*450./gResY;//*vec2(iResolution.y/ iResolution.x, 1)\n\tfloat gs = 1. - (texture(iChannel0, (p)).x);//*.9 + bump*.1; // Range: [0, 1]\n    \n\n    \n    ggs = gs;\n    \n   \n    \n    // Trick to smoothly flatten out the top a bit.\n    gs = mix(gs, smoothstep(0., .1, gs - .275), .75);\n    \n    //gs += smoothstep(0., .1, ggs - .125)*.05 - .025;\n    gs = mix(gs, smoothstep(0., .05, ggs - .525), .015);\n     \n    \n    // Subtly blend in a more detailed pattern over the top.\n    float difPat = texture(iChannel0, p*6., -100.).x;\n    difPat = smoothstep(0., .5, difPat - .65);\n    \n    //difPat *= smoothstep(0., .1, ggs - .525);\n    \n    gs = mix(gs, difPat, .015); //difPat*gs\n    \n    //gs += smoothstep(0., .05, ggs - .525)*.05 - .025;\n\n    \n    return clamp(gs, 0., 1.);//*.95 + bump*.05;\n\n}\n\nvec3 bump(vec3 sp, vec3 sn, float bumpFactor, inout float edge){\n    \n      // BUMP MAPPING - PERTURBING THE NORMAL\n    //\n    // Setting up the bump mapping variables. Normally, you'd amalgamate a lot of the following,\n    // and roll it into a single function, but I wanted to show the workings.\n    //\n    // f - Function value\n    // fx - Change in \"f\" in in the X-direction.\n    // fy - Change in \"f\" in in the Y-direction.\n    vec2 eps = vec2(1./iResolution.y, 0.);\n    \n    float f = bumpFunc(sp.xy); // Sample value multiplied by the amplitude.\n    float fx = bumpFunc(sp.xy - eps.xy); // Same for the nearby sample in the X-direction.\n    float fy = bumpFunc(sp.xy - eps.yx); // Same for the nearby sample in the Y-direction.\n    \n    \n    \n    // Using the above to determine the dx and dy function gradients.\n    fx = (fx - f)/eps.x; // Change in X\n    fy = (fy - f)/eps.x; // Change in Y.\n    // Using the gradient vector, \"vec3(fx, fy, 0),\" to perturb the XY plane normal \",vec3(0, 0, -1).\"\n    // By the way, there's a redundant step I'm skipping in this particular case, on account of the \n    // normal only having a Z-component. Normally, though, you'd need the commented stuff below.\n    //vec3 grad = vec3(fx, fy, 0);\n    //grad -= sn*dot(sn, grad);\n    //sn = normalize( sn + grad*bumpFactor ); \n      \n    sn = normalize( sn + vec3(fx, fy, 0)*bumpFactor ); \n    \n    \n    eps = vec2(6./iResolution.y, 0);\n    fx = bumpFunc(sp.xy - eps.xy);// - bumpFunc(sp.xy + eps.xy); // Same for the nearby sample in the X-direction.\n    fy = bumpFunc(sp.xy - eps.yx);// - bumpFunc(sp.xy + eps.yx);\n    edge = (abs(f*1. - fx) + abs(f*1. - fy)); // Edge value.\n \t\n \n    \n    return sn;\n    \n}\n\n\n// Standard ray-plane intersection.\nfloat rayPlane(vec3 p, vec3 o, vec3 n, vec3 rd) {\n    \n    float dn = dot(rd, n), t = 1e8;\n    \n    if (abs(dn)>.0001){\n        t = dot(p - o, n)/dn;\n        t += float(t<0.)*1e8;\n    }\n    \n    return t;\n}\n\n\n//vec3 smoothFract(vec3 x){ x = fract(x); return min(x, x*(1.-x)*12.); }\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n\n    // The following hack is necessary to accommodate a repeat texture created on a variable \n    // sized buffer. The reason it's capped between  350 and 800 pixels is because the \n    // pattern looks too bulky when moving to fullscreen and too busy on smaller canvases. \n    // Of course, on a phone, the  PPX can be double that of a laptop, so this figure would \n    // have to be set to double for the viewer to see the same size image I'm viewing... \n    // Unfortunately, I can't cater for every situation, so I don't. :)\n    gResY = clamp(iResolution.y, 350., 800.);\n    \n    // Centered, aspect-correct, screen coordinates. Only one line is necessary to\n    // accomplish this.\n\tvec2 uv = (fragCoord - iResolution.xy*.5)/gResY;\n\n    // BASIC SETUP - surface postion, ray origin, unit direction vector, and light postion.\n    //\n\t// Setup for a raytraced plane. Not all that necessary, since you could effect a tiled\n    // plane without any trace, but I didn't see the harm. :)\n    //\n\tvec3 rd = normalize(vec3(uv, 1.)); // Unit direction vector.\n    rd = normalize(vec3(rd.xy, sqrt(rd.z*rd.z - dot(rd.xy, rd.xy)*.05))); // Very subtle lens warping.\n    \n\tvec3 ro = vec3(0., 0., -1); // Camera position, ray origin, etc.\n\n\t// Plane normal -- Titled very slightly.\n    vec3 sn = normalize(vec3(.05, .07, -1)); \n\t// Hit point on the plane.\n\tfloat t = rayPlane(vec3(0), ro, sn, rd);\n    vec3 sp = ro + rd*t;\n     \n\n    vec3 lp = vec3(.125, .35, -1); // Light position - Back from the screen.\n    \n    sp.xy -= vec2(-1, -.5)*iTime/8.;\n    lp.xy -= vec2(-1, -.5)*iTime/8.;\n\t\n    //vec3 sn = vec3(0., 0., -1); // Plane normal. Z pointing toward the viewer.\n    \n    // Last term controls how much the bump is accentuated.\n    float edge = 0.;\n    sn = bump(sp, sn, 0.15, edge);\n    \n    // The main bump mapped pattern. It has already been calculated in the \"bump\" function\n    // above, so this double handling, but it's a pretty cheap example.\n    float mainPat = bumpFunc(sp.xy);      \n    \n    \n    // LIGHTING\n    //\n\t// Determine the light direction vector, calculate its distance, then normalize it.\n\tvec3 ld = lp - sp;\n\tfloat lDist = max(length(ld), 0.001);\n\tld /= lDist;\n\n    // Light attenuation.    \n    float atten = min(1./(1. + lDist*0.125 + lDist*lDist*0.05), 1.);\n\t//float atten = min(1./(lDist*lDist*1.), 1.);\n    \n    // Using the bump function, \"f,\" to darken the crevices. Completely optional, but I\n    // find it gives extra depth.\n    atten *= smoothstep(0., 1., mainPat*.5 + .5 - .25);//*.95 + .05; // Or... f*f*.5 + .5; //  pow(f, .75); // etc.\n\n\t\n\n\t// Diffuse value.\n\tfloat diff = max(dot(sn, ld), 0.);  \n    // Enhancing the diffuse value a bit. Made up.\n    diff = pow(diff, 2.)*0.66 + pow(diff, 4.)*0.34; \n    // Specular highlighting.\n    float spec = pow(max(dot( reflect(-ld, sn), -rd), 0.), 64.); \n\n\t\n    // TEXTURE COLOR\n    //\n    vec3 texCol = mix(vec3(.5), vec3(.6, .4, .2), dot(sin(sp.xy*4. - cos(sp.yx*4.)), vec2(.25)) + .5);//doColor(vor);\n    \n    \n    // Lightening the ground a little.\n    texCol = mix(vec3(1), texCol, mainPat);\n    \n    // Using the diffusion texture to create a more refined diffusion pattern to decorate the main object.\n    float difPat2 = texture(iChannel0, sp.xy/2.25*450./gResY*6.).x;\n    difPat2 = smoothstep(0., .05, -difPat2 + .5);\n    \n    // Small pattern edges. Comment it out to see what it does.\n    texCol = mix(texCol, vec3(0), (1. - smoothstep(0., .05, max(ggs - .525 - .025, -(ggs - .525 + .025))))*.35);\n    \n    // Coloring the main object yellow, and the ground brownish with some fine diffusion crevices,\n    // or something to that effect.\n    texCol = mix(vec3(.6, .48, .42)*(difPat2*.25 + .75), vec3(1, .45, .05)*1.5, mainPat)*texCol;\n    \n    // Darkening the fine grade diffusion crevices on the yellow object.\n    texCol *= mix(vec3(1), vec3(0), difPat2*smoothstep(0., .05, ggs - .525)*.6);//.525\n    //texCol *= mix(vec3(1), vec3(0), clamp(difPat2*mainPat*smoothstep(0., .05, ggs - .525)*.75, 0., 1.));\n    \n    // Applying some orangey patches.\n    texCol = mix(texCol*1.5, texCol.xzy/4., dot(sin(sp.xy*12. - cos(sp.yx*8.)), vec2(.2*.5)) + .2);\n    \n    //texCol = mix(texCol, texCol.yxz*mainPat*.7, fBm(sp.xy*3.));\n    // Greenish moldy weathering.\n    texCol = mix(texCol, texCol.yxz*mix(.2, .7, mainPat), smoothstep(.35, 1., fBm(sp.xy*7.))*.7);\n    \n    // Extra combinations.\n    //texCol = mix(texCol, texCol.xzy, smoothstep(.6, .8, fBm(sp.xy*3. + .5))*mainPat*.7);\n    //texCol = mix(texCol, texCol.zyx, smoothstep(.6, .8, fBm(sp.xy*3. - .5))*mainPat*.9);\n    //texCol = mix(vec3(1)*dot(texCol, vec3(.299, .587, .114)), texCol.zyx, smoothstep(.5, .7, fBm(sp.xy*3.))*mainPat*.8);\n\n    \n    // FINAL COLOR\n    // Using the values above to produce the final color.   \n    vec3 col = (texCol*(diff*2. + 0.25) + (texCol*.5 + .5)*vec3(.25, .5, 1)*spec)*atten;\n    \n    // Lightening the edges a bit -- Very subtle, but it enhances the pseudo 3D look a fraction.\n    col += col*vec3(1)*diff*edge;\n    \n    // Extra dark edging. Not needed here.\n    //col *= vec3(1)*(1. - edge*.75);\n    \n    \n    // Fake shadows. Just a bit of sampling and masking trickery. I made it up on the spot,\n    // but it works well enough. Obviously, the fake shadows are there to add false depth.\n    vec3 lp2 = lp + vec3(.5, 1.4, -.5);\n    vec2 dir = normalize(lp2 - sp).xy*1./min(800., iResolution.y);\n    float shad = max(1. - bumpFunc(sp.xy + dir*16.), mainPat);\n    float shad2 = max(bumpFunc(sp.xy - dir*16.), 1. - mainPat);\n    shad = min(shad, shad2);\n    // Applying the shadow layer. Comment this line out to see the difference. The image becomes\n    // very flat looking.\n    col *= vec3(1)*(shad*.75 + .25);\n\n    \n    // If you want to see just the plane diffusion pattern.\n    //vec4 reactDiff = texture(iChannel0, sp.xy/2.25*450./gResY);\n    //float sm = 1. - reactDiff.x;\n    //col = vec3(1)*smoothstep(0., .075, sm - .475);\n    \n     \n    // Subtle vignette.\n    //uv = fragCoord/iResolution.xy;\n    //col *= pow(16.*uv.x*uv.y*(1. - uv.x)*(1. - uv.y) , .125) + .1;\n    // Colored variation.\n    //col = mix(col.zyx/2., col, \n              //pow(16.*uv.x*uv.y*(1. - uv.x)*(1. - uv.y) , .125));\n\n    // Rough gamma correction, and we're done.\n\tfragColor = vec4(sqrt(min(col, 1.)), 1.);\n    \n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\n\tGray-Scott Pattern\n\t------------------\n\n    Diffusion reaction: The process is simple enough to understand, but whenever I'm \n    working through it, I often wonder which brainiac nerd poured a solution from one \n    beaker into another, then thought to themselves, \"That'd be a great way to make \n    procedural giraffe textures.\" :) ... Actually, I think the initial idea came from\n\tthe famous Engima code breaking guy, Alan Turing, but don't quote me on that. :)\n       \n    At its very core, diffusion textures are just a visual representation over time of \n    a particular kind of partial differential equation, nothing more, so in essence, you \n    could ignore all explanations and simply apply it. However, if you're like me and \n    you require a better understanding, refer to the articles below. If you're after a \n\tdecent summary, refer to the following article: \n     \n    http://www.karlsims.com/rd.html\n\n\tAnyway A lot of the code here is just some standard noise routines for anyone who\n\twants to experiment with different intial conditions. The actual code to produce the \n\tdiffusion texture is contained in the \"mainImage\" function and there isn't much of \n\tthat at all.\n\n\n\t// Articles that may be helpful:\n\n\tReaction Diffusion: The Gray-Scott Algorithm\n \thttp://www.algosome.com/articles/reaction-diffusion-gray-scott.html\n\t\n\tGray Scott Model of Reaction Diffusion\n\thttps://groups.csail.mit.edu/mac/projects/amorphous/GrayScott/\n    \n    Karl Sims - http://www.karlsims.com/rd.html\n\t\n\tRobert Munafo - http://mrob.com/pub/comp/xmorphia/\n\n\tReactionâ€“Diffusion System\n\thttps://en.wikipedia.org/wiki/Reaction%E2%80%93diffusion_system\n\n*/\n\nfloat hash21(vec2 p){\n    p = mod(p, 64.);\n    return fract(sin(dot(p, vec2(1.27, 113.93)))*43758.5453);\n}\n\n// 2x2 hash algorithm.\nvec2 hash22(vec2 p) { \n\n    p = mod(p, 64.);///vec2(iResolution.y/iResolution.x, 1)\n    // More concise, but wouldn't disperse things as nicely as the block below.\n    float n = sin(dot(p,vec2(113, 1))); \n    return fract(vec2(2097152, 262144)*n);\n    \n    // Animation.\n    //p = fract(vec2(2097152, 262144)*n);\n    //return sin(p*6.2831853 + iTime)*0.5 + 0.5;\n}\n\n/*\nvec3 hash33(in vec2 p){ \n    float n = sin(dot(p, vec2(41, 289)));    \n    return fract(vec3(2097152, 262144, 32768)*n); \n}\n*/\n\n/*\nvec3 sTexture(sampler2D smp, vec2 uv) {\n \n    vec2 textureResolution = iChannelResolution[1].yy;\n\tuv = uv*textureResolution + 0.5;\n\tvec2 iuv = floor( uv );\n\tuv -= iuv;\n\tuv = iuv + smoothstep(0., 1., uv); \n    //uv = iuv +  uv*uv*uv*(uv*(uv*6. - 15.) + 10.);\n\tuv = (uv - .5)/textureResolution;\n    return texture(smp, uv).xyz;\n    \n}\n*/\n\n/*\n// IQ's value noise formula.\nfloat noise( in vec2 p ){\n   \n    vec2 i = floor(p); p -= i; \n    p *= p*p*(p*(p*6. - 15.) + 10.);\n    //p *= p*(3. - p*2.);  \n\n    return mix( mix( hash21(i + vec2(0, 0)), \n                     hash21(i + vec2(1, 0)), p.x),\n                mix( hash21(i + vec2(0, 1)), \n                     hash21(i + vec2(1, 1)), p.x), p.y);\n}\n*/\n\n// 2D 2nd-order Voronoi: Obviously, this is just a rehash of IQ's original. I've tidied\n// up those if-statements. Since there's less writing, it should go faster. That's how \n// it works, right? :)\n//\nfloat Voronoi(vec2 p){\n    \n\tvec2 g = floor(p), o;\n\tp -= g;// p = fract(p);\n\t\n\tvec2 d = vec2(2); // 1.4, etc.\n    \n\tfor(int y = -1; y <= 1; y++){\n\t\tfor(int x = -1; x <= 1; x++){\n            \n\t\t\to = vec2(x, y);\n            o += hash22(g + o) - p;\n            \n\t\t\tfloat h = dot(o, o);\n            d.y = max(d.x, min(d.y, h)); \n            d.x = min(d.x, h);            \n\t\t}\n\t}\n\t\n\treturn min(sqrt(d.x), 1.);\n    //return min(d.y - d.x, 1.); // etc.\n}\n\n\n\n\n// Shorthand, so that the texture lines read a little better.\nvec4 tx(vec2 p){ return texture(iChannel0, p); }\n\n\n// 25 (or 9) tap Laplacian -- Gaussian Laplacian, to be more precise. I think of it as taking\n// the sum of the partial second derivatives of a blurry 2D height map... in each channel...\n// I think I'm making things more confusing, but it works anyway. :D Seriously, just look\n// up the Laplacian operator of a 2D function.\nvec4 Laplacian(vec2 p) {\n    \n\n\t// Kernel matrix dimension, and a half dimension calculation.\n    const int mDim = 5, halfDim = (mDim - 1)/2;\n\n    // You can experiment with different Laplacian related setups here. Obviously, when \n    // using the 3x3, you have to change \"mDim\" above to \"3.\" There are widely varying \n    // numerical variances as well, so that has to be considered also.\n    float kernel[mDim*mDim] = float[mDim*mDim](\n    \n \t\t//The Laplacian-Gaussian... I can't remember where I found this,\n        // but I've seen it in more than one place, and it seems about right.\n\t\t0.,  0., .25,  0.,  0.,\n        0., .25,  .5, .25,  0.,\n        .25, .5,  -4., .5, .25,\n        0., .25,  .5, .25,  0.,\n        0.,  0., .25,  0.,  0.);\n/*       \n        // Another variation -- Might need scaling first.\n        1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.,\n        1., 1.,-24.,1., 1.,\n        1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1.);\n*/\n\n/*      \n\n\t\t// 3x3 variation.\n        1., 2., 1.,\n        2., -12., 2.,\n        1., 2., 1.);\n*/\n    \n    \n/*      \n\t\t// 3x3 variation. Slightly different to above, and scaled differently,\n\t\t// so that has to be taken into account.\n        .05, .2, .05,\n        .2,  -1., .2,\n        .05, .2, .05);\n*/\n    \n    // Initiate the color. In this example, we only want the XY values, but just\n    // in case you'd like to apply this elsewhere, I've included all four texture\n    // channnels.\n    vec4 col = vec4(0);\n    \n    // We're indexing neighboring pixels, so make this a pixel width. In fact, these\n    // texture Laplacian calculations are annoyingly touchy, so it has to be one\n    // pixel width. Not two, not a half... Computers are tools. :D\n    float px = 1./iResolution.y; \n\n    \n    // There's a million boring ways to apply a kernal matrix to a pixel, and this \n    // is one of them. :)\n    for (int j=0; j<mDim; j++){\n        for (int i=0; i<mDim; i++){ \n            \n            col += kernel[j*mDim + i]*tx(p + vec2(i - halfDim, j - halfDim)*px);\n        }\n    }\n\n\n    return col;\n}\n\n\n/*\n// Nine tap Laplacian.\nvec4 Laplacian9(vec2 p) {\n    \n    vec2 px = 1./iResolution.yy;\n    // Four spots aren't required in this case, but are when the above isn't aspect correct.\n    vec4 e = vec4(px, 0, -px.x);\n \n    // Laplacian with some Gaussian smoothing applied... I'm guessing, so I probably wouldn't\n    // quote me on it. :)\n    return (tx(p - e.xy)*.5 +  tx(p - e.zy ) + tx(p - e.wy)*.5 + // First row.\n\t\t\ttx(p - e.xz) - tx(p)*6. + tx(p + e.xz) + \t\t     // Seond row.\n\t\t\ttx(p + e.wy)*.5 + tx(p + e.zy) +  tx(p + e.xy)*.5);  // Third row\n  \n    \n    // Laplacian with no Gaussian component... I think.\n    //return (tx(p - e.xy) +  tx(p - e.zy ) + tx(p - e.wy) +   // First row.\n\t//\t\ttx(p - e.xz) - tx(p)*8. + tx(p + e.xz) + \t\t // Seond row.\n\t//\t\ttx(p + e.wy) + tx(p + e.zy) +  tx(p + e.xy))/2.; // Third row\n \n}\n*/\n\n/*\n// Five tap Laplacian -- The simplest Laplacian filter... unless there's a more minimalistic one.\nvec4 Laplacian5( vec2 p) {\n    \n    vec3 e = vec3(1./iResolution.yy, 0);\n\n\treturn tx(p - e.zy) + tx(p - e.xz) - tx(p)*4. + tx(p + e.xz) + tx( p +  e.zy);\n}\n*/\n\n\n/*\n// Analytic Laplacian of sorts.\nvec4 grad(in vec2 uv) {\n    \n    vec2 e = vec2(1, 0)/iResolution.y/2.;\n\tvec2 dfdx = tx(uv + e).xy - tx(uv - e).xy;\n    vec2 dfdy = tx(uv + e.yx).xy - tx(uv - e.yx).xy;\n    return vec4(dfdx, dfdy)*iResolution.y;\n}\n\n// Divergence of gradient.\nvec2 LaplacianA(in vec2 uv) {\n \n    vec2 e = vec2(1, 0)/iResolution.y/2.;\n    vec2 dgdx = grad(uv + e).xy - grad(uv - e).xy;\n    vec2 dgdy = grad(uv + e.yx).zw - grad(uv - e.yx).zw;\n    vec2 lap = (dgdx + dgdy)*iResolution.y;\n    \n    return lap/iResolution.y/iResolution.y;\n}\n*/\n\n\n\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    \n    // Screen coordinates. I can't remember why I didn't want aspect correctness here...\n    // I'm sure there was a reason. Fixed size square buffers would make life a lot\n    // easier -- I know that much. :)\n    vec2 p = fragCoord.xy/iResolution.xy;\n    \n\n    // Grab the reaction diffusion values from the previous frame. These values are\n    // are representative of concentrations of hypothetical liquid, gas, etc, solutions,\n    // which are denoted by A and B. A is stored in the X channel, and B is stored in \n    // the Y channel.\n\tvec4 rdVal = texture(iChannel0, p);\n    \n    // The concentrations of elements A and B will tend to spread out in a smoother -- and\n    // sometimes, faster -- way if we smooth out the underlying values. Making that happen \n    // is as simple as blurring the A and B concoction (the X and Y texture values) every \n    // pass. The wider the blur, the better. You could achieve that by by adding \n    // an extra buffer and performing the blur in conjunction with the reaction \n    // diffusion calculations performed here, or you could combine a blur matrix with \n    // the Lapacian matrix all in one step, which is what we're doing here. In other \n    // words we're combining a 5x5 Gaussian matrix with a Laplacian matrix and \n    // using the resultant matrix in the Laplacian step.\n    //\n    // And yes, more buffers could be added to decrease equilibrium time, but I \n    // wanted to keep things simple.\n      \n    \n    // In regard to the form of the reaction-diffusion equation we're using, there's some \n\t// kind of physical flow involved, which tends to require second derivative measurements.\n\t// To get those from an underlying pixelated map, pixel samples from a spread of neighbors \n\t// will be required, so it's not a stretch to imagine that some kind of pixel matrix will \n\t// be involved. Hence, the Laplacian step below:\n    //\n    // 25 tap Laplacian to really smoothen things out.\n    vec2 lap = Laplacian(p).xy;\n    // Other Laplacian functions to experiment with. The different pixels arrangements\n    // produce subtle differences. Each function would need to be uncommented above.\n    //vec2 lap = Laplacian9(p).xy;\n    //vec2 lap = LaplacianA(p);\n    //vec2 lap = Laplacian5(p).xy;\n    \n    // Feed and kill rates. These are close to standard values that you see everywhere.\n    // You can change them, but they're sensitive.\n    const float feed = 0.0545, kill = 0.062;\n    // More constants to try. A lot of them are presets that I found using a handy pattern\n    // generator at this link: http://mrob.com/pub/comp/xmorphia/ogl/index.html\n    //const float feed = 0.058, kill = 0.065; // Lines and dots.\n    //const float feed = 0.046, kill = 0.063; // Lines and dots.\n    //const float feed = 0.098, kill = 0.057; // Solid cells.\n    //const float feed = 0.037, kill = 0.06; // Random joined lines.\n    //const float feed = 0.0353, kill = 0.06; // Random joined lines.\n    //const float feed = 0.03, kill = 0.063; // Self replicating spots.\n    //const float feed = 0.03, kill = 0.0565; // Maze.\n    \n    // Diffusion rates for concentrations A and B. The first component needs to be higher\n    // than the second. The amplitude depends on the size of the Laplacian. I've noticed \n    // that if \"dAB.x\" is exactly twice \"dAB.y,\" the pattern will form quicker, but won't\n    // vary greatly. Tiny changes in these values will widely change the pattern, but can\n    // also bring about a blank screen. I guess that's one of the downsides of diffusion \n    // patterns.\n\tvec2 dAB = vec2(.2, .106);\n    //vec2 dAB = vec2(.2, .1);\n    \n    // Time component. Kind of redundant here, but it can be used to control reaction rate.\n    // Unfortunately, like all the figures used here, just a tiny change can ruin the \n    // reaction, which results in no pattern at all. Either way, you should try to set \n    // this number as high as you can without trashing the pattern.\n    const float t = 1.; \n    \n    // The diffusion term: Just the constant diffusion rates multiplied by the Laplacian\n    // for each concentration.\n    vec2 diffusion = dAB*lap;\n    // The reaction term: The \"rdVal.x*rdVal.y*rdVal.y\" value is representative of the\n    // chance that a particle from concentration A will react with two particles from\n    // concentration B, which from probability theory is: A*B*B. This results in a decrease\n    // of concentration A and an increase in concentration B by that particular amount.\n    // Hence, the negative and positive vector terms on the end.\n    vec2 reaction = vec2(rdVal.x*rdVal.y*rdVal.y)*vec2(-1, 1);\n    \n    // Feed and kill rates. Substance A is added at a feed rate, and substance B is taken\n    // away at a kill rate. Hence, the positive and negative vector terms on the end.\n    // It took me a while to figure out why the \"1. - rdVal.x\" term was necessary. It's \n    // necessary to reduce the amount that is fed into the system as the concentration of\n    // A \"rdVal.x\" builds up, otherwise, we'd never reach equilibrium.\n    vec2 feedKill = vec2(feed*(1. - rdVal.x), (kill + feed)*rdVal.y)*vec2(1, -1);\n    // Try the following with just the \"rdVal.x\" and the initial condition:\n    // fragColor.xy = vec2(1, 0) + (hash22(p*64.).xy - .5)*.75;\n    //\n    // Interesting, but equilibrium is never attained.\n    //vec2 feedKill = vec2(feed*rdVal.x, (kill + feed)*rdVal.y)*vec2(1, -1);\n\n    // Calculating the change in concentration of A and B. This calculation the crux of the\n    // whole thing. It's just an applied partial differential equation... which is a little \n    // difficult to write in ASCII form, but easy to apply. To see the actual equations in\n    // mathematical or physical form, you can read about it in the sources I've provided above.\n    \n    // New u value: du\\dt = rU*LapU - u*v*v + f*(1. - u);\n    // New v value: dv\\dt = rV*LapV + u*v*v + (f + k)*v;  \n\tvec2 delta = diffusion + reaction + feedKill;\n    \n    // Updating the old A and B concentrations by adding the change in concentration\n    // over time.\n    fragColor.xy = clamp(rdVal.xy + delta*t, 0., 1.);\n    \n    // Cute trick to allow reinitialization whenever the user switches between window\n    // sizes. However, if all four channels were needed, you'd have to load in another\n    // buffer and store it there.\n    fragColor.zw = iResolution.xy; \n    \n    \n    // Initializing the substances A and B: It requires a little finesse.\n    //\n    // You could literally spend weeks playing around with concentration initialization and \n    // never quite understand what works and what doesn't... OK, maybe that's just me, but\n    // I've never been able to determine a general routine that enables a pattern to form.\n    // Either way, here are a bunch of different initial conditions that do produce patterns.\n    //\n    // Sometimes, the application won't recognize the first frame -- or something, so it's \n    // necessary to initialize for the first few frames to give it a chance to catch on.\n    // Also, check for changes in canvas size.\n    if(iFrame<10 || abs(rdVal.w - iResolution.y)>.001) {\n\n        fragColor.xy =  vec2(1, 0) +  (vec2(Voronoi(p*64.), Voronoi(p*64. + vec2(2.93, 19.37))) - .5);\n\n        // Required multi-channel noise texture in \"iChannel1.\"\n        //fragColor.xy =  vec2(1, 0) +  texture(iChannel1, fragCoord.xy/iResolution.y).xy -.5;   \n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(Voronoi(p*64.)*1.3 - .5);\n        // Some of these require functions above which need to be uncommented first.\n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(sTexture(iChannel1, p).xy - .5);\n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(noise(p*64.) - .5);\n        //fragColor.xy =  vec2(1, 0) +  vec2(-1, 1)*(abs(noise(p*64.) - .5)*2. - .5);\n        //fragColor.xy =  vec2(1, 0) + (hash22(p*64.).xy - .5); //(hash22(p*64.).xy - .5)*1.1, etc.\n        //fragColor.xy =  vec2(.5, -.5)*.75 + vec2(Voronoi(p*64.), Voronoi(p*64. + vec2(3, 7))); \n        //fragColor.xy =  vec2(.45, -.53) + dot(sin(p*9.*6.283 - cos(p.yx*7.*6.283 + 1.15)*3.14159), vec2(.25)) + .5;\n        \n    }\n}\n\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}