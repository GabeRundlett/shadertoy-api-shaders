{
    "Shader": {
        "info": {
            "date": "1575690912",
            "description": "Click (drag on PC) to move camera.\n\nFollowing [url=https://raytracing.github.io/books/RayTracingInOneWeekend.html]Ray Tracing in One Weekend[/url]\n\n[url=https://twitter.com/Xavier_Ho/status/1205110012374216705]2K screengrab[/url]\n\nTODO\n * fix mobile noise",
            "flags": 32,
            "hasliked": 0,
            "id": "WlcGRN",
            "likes": 1,
            "name": "Ray Tracing in One Weekend [B1]",
            "published": 3,
            "tags": [
                "raytracing",
                "exercise"
            ],
            "usePreview": 0,
            "username": "Spaxe",
            "viewed": 534
        },
        "renderpass": [
            {
                "code": "// WebGL GLSL implementation of Ray Tracing in One Weekend\n// online book at https://raytracing.github.io/books/RayTracingInOneWeekend.html\n\n// improved denoise technique by averaging over frames borrowed from https://www.shadertoy.com/view/XlycWh\n// see Buf A for raytracing code\n//     Buf B for memory management\n\n// If you're on a desktop and want less noise, go to Buffer A and set the quality based on the cards you have\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{    \n   \tvec4 buffer = texelFetch(iChannel0, ivec2(fragCoord), 0);\n    fragColor = vec4(sqrt(buffer.rgb/buffer.w), 1);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "#define RANGE uvec4(65535u)\n#define MAX_RANDOM float(RANGE-1u)\n#define FLT_MAX 3.402823466e+38\n#define FLT_E 0.001\n#define ZEROES vec4(0)\n#define LAMBERT 0u\n#define METAL 1u\n#define DIELECTRIC 2u\n\n#define MOUSE_DATA ivec2(0, 0)\n#define RESOLUTION_DATA ivec2(1, 0)\n\n// Noise generation from https://www.shadertoy.com/view/MtycWc\n// https://merlin3d.wordpress.com/2018/10/04/correlated-multi-jittered-sampling-on-gpu/\n// Generate an unsigned integer random vector in the range of [0..range-1]^3 \n// with uniform distribution from a linear seed using mixing functions.\n// Maximum valid value of range is 65535.\nuvec4 rand ( uvec4 s, uvec4 range ) {\n    s ^= uvec4(s.x >> 19, s.y >> 19, s.z >> 13, s.w >> 19);\n    s *= uvec4(1619700021, 3466831627, 923620057, 3466831627);\n    s ^= uvec4(s.x >> 16, s.y >> 12, s.z >> 18, s.w >> 17);\n    s *= uvec4(175973783, 2388179301, 3077236438, 2388179301);\n    s ^= uvec4(s.x >> 15, s.y >> 17, s.z >> 18, s.w >> 18);\n    \n    uvec4 f = s >> 16;\n    return (range * f + (s % range)) >> 16;    \n}\n\nuvec4 seed ( in vec2 fragCoord, in vec3 iResolution, in float iTime ) {\n    float fseed = fragCoord.x + fragCoord.y * iResolution.x + 1.0 + mod(iTime, 16.0f) * iResolution.x * iResolution.y;\n    return uvec4(fseed);\n}\n\n///// My code follows here\n\n// return a random point on or inside the unit sphere\nvec3 sampleUnitSphere ( inout uvec4 useed ) {\n    useed = rand(useed, RANGE);\n    vec3 noise3 = vec3(useed.xyz) / MAX_RANDOM - .5;\n    float noise = float(useed.w) / MAX_RANDOM;\n    return normalize(noise3) * noise;\n}\n\n// return a random point on a unit disk\nvec3 sampleUnitDisk ( inout uvec4 useed ) {\n    useed = rand(useed, RANGE);\n    vec3 noise3 = vec3(useed.xyz) / MAX_RANDOM - .5;\n    float noise = float(useed.w) / MAX_RANDOM;\n    return vec3((normalize(noise3) * noise).xy, 0);\n}\n\n// ray and scene structures\n\nstruct ray {\n\tvec3 origin;\n    vec3 direction;\n};\n\nstruct material {\n\tuint type;\n    vec3 albedo;\n    float roughness;\n    float refractIndex;\n};\n    \nstruct sphere {\n    vec3 pos;\n    float r;\n    material m;\n};\n\nstruct hitRecord {\n    float t;\n    vec3 p;\n    vec3 normal;\n    material m;\n};\n    \nstruct camera {\n\tvec3 origin;\n    vec3 lowerLeftCorner;\n    vec3 horizontal;\n    vec3 vertical;\n    vec3 u;\n    vec3 v;\n    vec3 w;\n    float lensRadius;\n};\n\n        \nvec3 pointAtParameter ( const ray r, const float t ) {\n\treturn r.origin + t * r.direction;\n}\n    \ncamera createCamera ( \n    const vec3 lookFrom,\n    const vec3 lookAt, \n    const vec3 vup, \n    const float vfov, \n    const float aspectRatio,\n    const float aperture,\n\tconst float focusDist\n) {\t\n    float lensRadius = aperture * .5;\n    vec3 u, v, w;\n    float theta = radians(vfov);\n    float halfHeight = tan(theta * .5);\n    float halfWidth = aspectRatio * halfHeight;\n    w = normalize(lookFrom - lookAt);\n    u = normalize(cross(vup, w));\n    v = cross(w, u);\n    \n    return camera(\n    \tlookFrom,\n        lookFrom - halfWidth * focusDist * u - halfHeight * focusDist * v - focusDist * w,\n        2. * halfWidth * focusDist * u,\n        2. * halfHeight * focusDist * v,\n        u,\n        v, \n        w,\n        lensRadius\n    );\n}\n\n// generate ray based on camera\nray getRay ( const vec2 fragCoord, const vec3 iResolution, const camera cam, inout uvec4 useed ) {\n    vec3 rd = cam.lensRadius * sampleUnitDisk(useed);\n    vec3 offset = cam.u * rd.x + cam.v * rd.y;\n    vec2 uv = fragCoord / iResolution.xy;\n    return ray(cam.origin + offset, \n               cam.lowerLeftCorner + uv.s * cam.horizontal + uv.t * cam.vertical - cam.origin - offset);\n}\n\n// intersection test with spheres\nhitRecord hit( const sphere s, const ray r, const float tmin, const float tmax ) {\n\tvec3 op = r.origin - s.pos;\n    float a = dot(r.direction, r.direction);\n    float b = dot(op, r.direction);\n    float c = dot(op, op) - s.r * s.r;\n        \n    float discriminant = b * b - a * c;\n    float t0 = (-b - sqrt(discriminant)) / a;\n    float t1 = (-b + sqrt(discriminant)) / a;\n    \n    // instead of using if statements for discriminats and range testing, we use branch-free logic\n    // t = 0 is a miss\n    float dtest = step(0., discriminant);\t\t\t\t\t\t// if discriminant > 0\n    float t0test = step(0., tmax - t0) * step(0., t0 - tmin);  \t// if t0 is between tmin and tmax\n    float t1test = step(0., tmax - t1) * step(0., t1 - tmin);  \t// if t1 is between tmin and tmax\n\n    float t = dtest * (t0test * t0 + step(FLT_E, 1. - t0test) * t1test * t1);\t// return t0 or t1, else 0\n    vec3 p = pointAtParameter(r, t);\n    float normalFacing = 2. * step(0., s.r) - 1.;\t// 1 for outside normal, or -1 for inside normal\n    \n    return hitRecord(t, p, normalFacing * normalize(p - s.pos), s.m);\n}\n\n// Schlick function is used to reject impossible refractions\nfloat schlick ( const float cosine, const float refractIndex ) {\n \tfloat r0 = pow((1. - refractIndex) / (1. + refractIndex), 2.);\n    return r0 + (1. - r0) * pow(1. - cosine, 5.);\n}\n\n// simulate ray scatter based on materials hit\n// return 0 if miss, otherwise hit\nfloat scatter ( const hitRecord rec, inout vec3 attenuation, inout ray r, inout uvec4 useed ) {\n    \n    if (rec.m.type == LAMBERT) {\n        \n        vec3 target = rec.p + rec.normal + sampleUnitSphere(useed);\n        r = ray(rec.p, target - rec.p);\n        attenuation = rec.m.albedo;\n        return 1.;\n        \n    } else if (rec.m.type == METAL) {\n        \n        vec3 reflected = reflect(normalize(r.direction), rec.normal);\n        r = ray(rec.p, reflected + clamp(rec.m.roughness, 0., 1.) * sampleUnitSphere(useed));\n        attenuation = rec.m.albedo;\n        return step(0., dot(r.direction, rec.normal));\n        \n    } else if (rec.m.type == DIELECTRIC) {\n        \n        vec3 outwardNormal;\n        float index;\n        attenuation = rec.m.albedo;\n        float reflectProbe;\n        float cosine;\n        \n        if (dot(r.direction, rec.normal) > 0.) {\n         \toutwardNormal = -rec.normal;\n            index = rec.m.refractIndex;\n            cosine = index * dot(r.direction, rec.normal) / length(r.direction);\n        } else {\n         \toutwardNormal = rec.normal;\n            index = 1. / rec.m.refractIndex;\n            cosine = -dot(r.direction, rec.normal) / length(r.direction);\n        }\n        \n        // test if refraction is possible\n        vec3 d = normalize(r.direction);\n        float dt = dot(d, outwardNormal);\n        float discriminant = 1. - index * index * (1. - dt * dt);\n        \n        if (discriminant > 0.) {\n         \treflectProbe = schlick(cosine, rec.m.refractIndex);   \n        } else {\n         \treflectProbe = 1.;   \n        }\n      \n        if (float(useed.x) / MAX_RANDOM < reflectProbe) {\n        \tr = ray(rec.p, reflect(d, rec.normal));\n        } else {\n            vec3 refracted = index * (d - outwardNormal * dt) - outwardNormal * sqrt(discriminant);\n            r = ray(rec.p, refracted);\n        }\n        return 1.;\n            \n    }\n    return 0.;\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// Recommended settings\n// Google Pixel      - 16u, 1u\n// MacBook Pro 15\"   - 16u, 8u\n// Desktop, GTX 1080 - 16u, 16u \n// Desktop, GTX 2080 - 16u, 64u\n#define MAX_RAY_DEPTH 16u\n#define MAX_SAMPLES 16u\n\n// objects in the scene\nconst sphere[5] world = sphere[](\n    sphere(vec3(0, 0, -1), .5, material(LAMBERT, vec3(0.8, 0.3, 0.3), 1., 0.)),\n    sphere(vec3(1, 0, -1), .5, material(METAL, vec3(0.8, 0.6, 0.2), .8, 0.)),\n    sphere(vec3(-1, 0, -1), .5, material(DIELECTRIC, vec3(1), 0., 1.5)),\n    sphere(vec3(-1, 0, -1), -.49, material(DIELECTRIC, vec3(1), 0., 1.5)),\n    // \"earth\"\n    sphere(vec3(0, -100.5, -1), 100., material(METAL, vec3(0.1, 0.2, 0.3), 0.2, 0.))\n);\n\n// raytracing \nvec3 trace ( ray r, inout uvec4 useed ) {\n    // can't do recursion, so we iterate to simulate ray bounces\n    vec3 outColor = vec3(1);\n    float missCount = 0.;\n    \n    for (uint d = 0u; d < MAX_RAY_DEPTH; ++d) {\n        vec3 attenuation;\n        hitRecord rec, tempRec;\n        float closestT = FLT_MAX;\n\n        // record nearest hit\n        for (int i = 0; i < world.length(); ++i) {\n            tempRec = hit(world[i], r, FLT_E, FLT_MAX);\n            if (tempRec.t > 0. && tempRec.t < closestT) {\n                closestT = tempRec.t;\n                rec = tempRec;\n            }\n        }\n\n        // on hit, gather material colours\n        if (FLT_MAX > closestT) {\n            float scatterTest = scatter(rec, attenuation, r, useed);\n            outColor *= mix(ZEROES.xxx, attenuation, scatterTest);\n        } else {\n            // sample bg sky colours\n            float t = .5 * (normalize(r.direction).y + 1.);\t\t\n            outColor *= mix(vec3(1), vec3(.5, .7, 1), t);\n            break;\n        }\n    }\n    return outColor;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{    \n    // initial seed generation\n    uvec4 useed = seed(fragCoord, iResolution, iTime);\n\n    // camera creation\n    vec3 cameraPos = vec3(iMouse.xy / iResolution.xy - vec2(.5, .25), 1);\n    vec3 cameraTarget = vec3(0, 0, -1);\n    float aperture = 0.1;\n    camera cam = createCamera(cameraPos, cameraTarget, vec3(0, 1, 0), 90., iResolution.x / iResolution.y, aperture, length(cameraTarget - cameraPos));\n\n    // monte carlo\n    vec3 col = vec3(0);\n    for (uint i = 0u; i < MAX_SAMPLES; ++i) {\n        useed = rand(useed, RANGE);\n        vec2 noise2 = vec2(useed.xy) / MAX_RANDOM - .5;\n        ray r = getRay(fragCoord + noise2, iResolution, cam, useed);\n        col += trace(r, useed); \n    }\n    col /= float(MAX_SAMPLES);\n\n   \t// Refresh buffer if camera moved\n    if (texelFetch(iChannel1,    MOUSE_DATA,      0).xy != iMouse.xy / iResolution.xy\t// mouse drag\n        || texelFetch(iChannel1, MOUSE_DATA,      0).zw != iMouse.zw / iResolution.xy\t// mouse click\n\t\t|| texelFetch(iChannel1, RESOLUTION_DATA, 0).xy != iResolution.xy\t\t\t\t// resolution changes\n    ) {\n\t\tfragColor = vec4(col, 1);\n    } else {\n        // write accumulated colour information\n        fragColor = vec4(col, 1) + texelFetch(iChannel0, ivec2(fragCoord), 0);\n    }\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "buffer",
                        "id": 258,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer01.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            },
            {
                "code": "// memory buffer\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // mousePosition\n    if (ivec2(fragCoord) == MOUSE_DATA) {\n    \tfragColor = iMouse / iResolution.xyxy;\n    }\n    \n    // screen resolution\n    else if (ivec2(fragCoord) == RESOLUTION_DATA) {\n        fragColor = iResolution.xyxy;\n    }\n    \n    // no data\n    else {\n     \tfragColor = vec4(0);   \n    }\n}",
                "description": "",
                "inputs": [],
                "name": "Buffer B",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 258
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}