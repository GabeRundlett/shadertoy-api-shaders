{
    "Shader": {
        "info": {
            "date": "1695202198",
            "description": "Audio input is weird, so this shader provides unofficial documentation of the Shadertoy audio inputs, especially the provided FFT.",
            "flags": 0,
            "hasliked": 0,
            "id": "dsjcRw",
            "likes": 4,
            "name": "Tut/Doc: Audio (Mitsync)",
            "published": 3,
            "tags": [
                "fft",
                "wave",
                "spectrum",
                "tutorial",
                "audio",
                "demo",
                "visualiser",
                "input",
                "docs",
                "documentation"
            ],
            "usePreview": 0,
            "username": "Mitsync",
            "viewed": 179
        },
        "renderpass": [
            {
                "code": "// Mitsync, 2023\n\n/*\n    I did some experiments with the audio inputs in Shadertoy and accidentally wrote documentation for it.\n    Most of this is purely theoretical and does not matter if you just want to draw a pretty graph.\n        The most important part for that is how the frequency axis works:\n            UV coordinates 0.0-1.0 correspond to 0 - 11/12 kHz, linearly.\n            Make this logarithmic to get prettier graphs, as done in helper function `fft_log()` below.\n    If you use code from this file it would be nice if you linked back here :)\n    All testing done in Google Chrome on Windows 10, using signals generated in Audacity:\n        Filetype: uncompressed WAV, samplerate: 44.1 and 48 kHz, sample format: 32-bit float\n    \n    Basics:\n        Audio inputs are accesible in shaders as a 512x2 texture with a single color channel (red).\n        The top row (y-coordinate 1) is the 512 most recent audio samples. Use this to draw a waveform.\n        The bottom row (y-coordinate 0) is 512 points of spectrum between 0 and 11/12 kHz. Use this to draw a spectrum/equaliser.\n        The stored values are medium precision floats between 0.0 and 1.0 inclusive for both the wave and FFT rows.\n            This means silence is a constant value of 0.5 (DC offset).\n        The easiest way to access values is using the `texture()` function:\n            For samples: `texture(iChannelX, vec2(x, 1.0)).r`\n            For spectrum: `texture(iChannelX, vec2(x, 0.0)).r`\n            Where `x` is a float between 0.0 and 1.0 inclusive. Replace `iChannelX` with the channel you're using. The `.r` makes these return a float.\n            Note that this does linear interpolation if you ask a value between two measured values (samples or bins).\n                This can't be disabled with the channel settings, use `texelFetch()` instead.\n        Another way is using the `texelFetch()` function:\n            For samples: `texelFetch(iChannelX, ivec2(x, 1), 0).r`\n            For spectrum: `texelFetch(iChannelX, ivec2(x, 0), 0).r`\n            Where `x` is an integer between 0 and 511 inclusive. Replace `iChannelX` with the channel you're using. The `.r` makes these return a float.\n                Eg: `int x = int(x_float*512.)`\n            This does not do interpolation (as you can only input integers).\n        Or just use the helper functions below. :)\n        All inputs get converted to the samplerate of the audio output on your device before they reach the shader:\n            Setting output to 44.1 kHz (in Windows in my case) means the FFT goes between 0 and 11 kHz for both 44.1 kHz AND 48 kHz sources.\n            The current samplerate is available in the uniform `iSampleRate` (even outside sound shaders, unlike what the official documentation implies)\n        You can import custom audio using this Chrome extension and just dropping a file on one of the input channels:\n            https://chrome.google.com/webstore/detail/shadertoy-custom-texures/jgeibpcndpjboeebilehgbpkopkgkjda\n            Supported filetypes depend on OS and browser.\n\n    FFT specifics:\n        The bottom row (y-coordinate 0) is 512 points of spectrum of the incoming audio signal.\n        The frequency axis is linear between 0 and 1/4 samplerate inclusive (so usually 11025 Hz or 12000 Hz):\n            Minimum UV coordinate (0.0) corresponds to 0 Hz (DC component, this is not removed!).\n            Maximum UV coordinate (1.0) corresponds to 1/4 times the output samplerate (so usually 11025 Hz or 12000 Hz).\n            Frequency resolution (bin size) is 21.5 Hz at 44.1 kHz samplerate, 23.4 Hz at 48 kHz samplerate.\n                These are approximately the differences between F#4 (370.0 Hz), G4 (392.0 Hz), and G#4 (415.3 Hz),\n                    Notes below that can't be accurately distinguished from neighbors.\n            All this implies Shadertoy is resampling, then doing a 2048-point FFT, but only making the first 512 points available.\n                (These are by far the most interesting anyway, we're not losing much)\n                This also means frequencies between 1/4 and 3/4 samplerate do NOT cause aliasing!\n                Frequencies above 3/4 samplerate DO cause aliasing (be careful with pure squarewaves for example).\n        Amplitude is linear with dB power between -87 and -17 dB:\n            Minimum returned value (0.0) corresponds to a signal power of -87 dB or lower.\n            Maximum returned value (1.0) corresponds to -17 dB or higher.\n            Values inbetween are linear with amplitude in dB.\n            Note: values are clipped! It is not possible to measure amplitudes outside this range!\n                Spectrum clipping is common, even (especially!) with properly mastered audio!\n            Amplitude is smoothed over time by what looks like decaying peak-hold.\n                A 0 dB sine takes approximately 0.5 seconds to drop below minimum amplitude (-87 dB).\n        Window is unknown but acts as follows:\n            A pure 0 dB sine at an exact bin frequency (aligned to the pixels) is 5 bins wide (total).\n            A pure 0 dB sine exactly between bins is also 5/6 pixels wide but with 5 extra bins of sidelobe on both sides.\n                So 15 bins around centre have significant value.\n            Harmonics are not surpressed (which is the correct way to do it).\n    \n    Contents of this demo:\n        Comments with example inputs and outputs assume constants as defined at the top of this file\n        Several helper functions for accessing and converting the audio data:\n            Getting amplitude of wave\n            Conversion between musical note, octave and frequency\n    \n    Useful links:\n        Table of notes and frequencies, also coupled to piano, organ and MIDI notes:\n            https://www.inspiredacoustics.com/en/MIDI_note_numbers_and_center_frequencies\n        More may come later\n*/\n\n\n\n/*  ------------------------\n      MACROS AND CONSTANTS\n    ------------------------*/\n\n// Constants\n#define INPUT iChannel0\n#define SAMPLERATE iSampleRate\n// These brackets are required because the preprocessor is dumb\n#define MAX_F (0.25*SAMPLERATE)\n// Reference note for the conversions between note/octave and frequency, a good default is C4, aka middle C, 261.63 Hz\n#define REF_NOTE 261.63\n\n// Macros\n#define ILN10 0.4343\n\n/*  --------------------\n      HELPER FUNCTIONS\n    --------------------*/\n\n// GETTING WAVE DATA\n// Get wave amplitude at UV coordinate (input between 0.0 and 1.0 inclusive)\nfloat wave(in float x)                  {  return texture(INPUT, vec2(x, 1.0)).r;  }\n// Get wave amplitude of sample, so not interpolated (input between 0 and 511 inclusive)\nfloat wave(in int s)                    {  return texelFetch(INPUT, ivec2(s, 0), 1).r;  }\n\n// GETTING FFT DATA\n// Get FFT at UV coordinate (input between 0.0 and 1.0 inclusive)\nfloat fft(in float x)                   {  return texture(INPUT, vec2(x, 0.0)).r;  }\n// Get FFT of frequency bin, so not interpolated (input between 0 and 511 inclusive)\nfloat fft(in int bin)                   {  return texelFetch(INPUT, ivec2(bin, 0), 0).r;  }\n// Get FFT of frequency (input between 0.0 and MAX_F)\nfloat fft_freq(in float freq)           {  return fft(freq/MAX_F);  }\n// Get FFT of log UV coordinate, between 50 and 10000 Hz (input between 0.0 and 1.0 inclusive) (!! use this one for pretty graphs !!)\nfloat fft_log(in float x)               {  return fft(50. * pow(10.0, 2.3*x) / MAX_F);  }\n\n// CONVERTING AMPLITUDE REPRESENTATIONS\n// Convert the amplitude returned from FFT to decibel power or amplitude\nfloat fft_to_db(in float val)           {  return 70.*val - 87.;  }\nfloat fft_to_amplitude(in float val)    {  return pow(10., fft_to_db(val)/10.);  }\n\n// Convert between decibel power and amplitude\nfloat amplitude_to_db(in float amp)     {  return 20.*log(amp)*ILN10;  }\nfloat db_to_amplitude(in float db)      {  return pow(10., db/20.);  }\n\n// CONVERTING FREQUENCY REPRESENTATIONS\n// Convert between octave relative to REF_NOTE and frequency (0.=C4, -1.=C3, (2./12.)=D4, etc.)\n// This is similar to volt/octave in modular synthesis\nfloat octave_to_freq(in float octave)   {  return REF_NOTE * exp2(octave);  }\nfloat freq_to_octave(in float freq)     {  return log2(freq / REF_NOTE);  }\n\n// Convert between note relative to REF_NOTE and frequency (0.=C4, -12.=C3, 2.=D4, etc.)\nfloat note_to_freq(in float note)       {  return REF_NOTE * exp2(note/12.);  }\nfloat freq_to_note(in float freq)       {  return log2(freq / REF_NOTE) * 12.;  }\n\n// Convert between note and octave (note 12. is octave 1., note -18. is octave -1.5)\nfloat note_to_octave(in float note)     {  return note / 12.;  }\nfloat octave_to_note(in float octave)   {  return octave * 12.;  }\n\n// Round frequency to that of nearest note\nfloat round_to_note(in float freq)      {  return note_to_freq(round(freq_to_note(freq)));  }\n\n// OTHER\n// Construct a grayscale colour from a single float\nvec4 col(in float val)                  {  return vec4(val, val, val, 1.0);  }\n// Construct a RG colour from a vec2\nvec4 col(in vec2 val)                   {  return vec4(val, 0.0, 1.0);  }\n// Construct a RGB colour from a vec3\nvec4 col(in vec3 val)                   {  return vec4(val, 1.0);  }\n\n// TODO: note with sum harmonics???\n// Summed power at first through fourth harmonics of this frequency (in dB)\nfloat freq_harmonic_power(in float freq) {\n    vec4 amp;\n    amp.x = fft_to_amplitude(fft_freq(freq));\n    amp.y = fft_to_amplitude(fft_freq(2. * freq));\n    amp.z = fft_to_amplitude(fft_freq(3. * freq));\n    amp.w = fft_to_amplitude(fft_freq(4. * freq));\n    return amplitude_to_db(amp.x + amp.y + amp.z + amp.w);\n}\n// Get FFT amplitude of note\nfloat fft_note(in float note)           {  return fft_freq(note_to_freq(note));  }\n\n// Get approximate total volume by summing FFT\nfloat total_power() {\n    float sum = 0.0;\n    for (int i = 32; i < 512; i += 8) {\n        sum += fft(i);\n    }\n    return 8. * sum / 480.;\n}\n\n\n\n/*  -----------------------\n      MAIN IMAGE FUNCTION\n    -----------------------*/\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // Normalized pixel coordinates (from 0 to 1)\n    vec2 uv = fragCoord/iResolution.xy;\n    \n    float avg_pwr = total_power();\n\n    float note = 72.*uv.x - 24.;\n    float p_cont = fft_note(note);\n    float p_note = fft_note(round(note));\n    \n    vec3 p_neighbors;\n    p_neighbors.x = fft_note(round(note)-1.0);\n    p_neighbors.y = fft_note(round(note));\n    p_neighbors.z = fft_note(round(note)+1.0);\n    float p_rel = dot(p_neighbors, vec3(-0.45, 1.0, -0.45));\n    p_rel = p_rel/(uv.x+1.);\n    \n    // Contrived example\n    float amp_c4 = fft_to_amplitude(fft_freq(note_to_freq(0.0)));\n    \n    fragColor = abs(uv.y-p_cont) < 0.005 ? col(1.0) : (abs(uv.y-p_rel) < 0.005 ? col(1.0) : col(pow(p_rel*1., 7.)));\n    fragColor += abs(uv.y-avg_pwr) < 0.005 ? col(1.0) : col(0.0);\n    //fragColor = col(fft(uv.x));\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "music",
                        "id": 19,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "false",
                            "wrap": "clamp"
                        },
                        "src": "/media/a/a6a1cf7a09adfed8c362492c88c30d74fb3d2f4f7ba180ba34b98556660fada1.mp3"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}