{
    "Shader": {
        "info": {
            "date": "1616032044",
            "description": "A basic implementation of Structured Volume Sampling: github.com/huwb/volsample (by twitter.com/hdb1)\nTab    - toggle Structured Volume Sampling off/on\nSpace - toggle sampling plane visualization on/off\nCamera controls via mouse + Shift.",
            "flags": 48,
            "hasliked": 0,
            "id": "ttVfDc",
            "likes": 48,
            "name": "Structured Volume Raymarching",
            "published": 3,
            "tags": [
                "raymarching",
                "volume"
            ],
            "usePreview": 0,
            "username": "TinyTexel",
            "viewed": 1591
        },
        "renderpass": [
            {
                "code": "// CC0 1.0 Universal https://creativecommons.org/publicdomain/zero/1.0/\n// To the extent possible under law, the author has waived all copyrights and related or neighboring rights to this work.\n\n/*\nA basic implementation of Structured Volume Sampling: github.com/huwb/volsample (by twitter.com/hdb1)\n\nTab   - toggle Structured Volume Sampling off/on\nSpace - toggle sampling plane visualization on/off (just shows ray direction if SVS is off)\n        if 'on' pressing Ctrl shows the number of active sampling planes (black: 1 | grey: 2 | white: 3)\n\nCamera controls via mouse + Shift.\n\n\nThe idea of structured volume sampling (SVS) is to restrict volume sampling locations to a set of \nworld space planes/virtual billboards in order to prevent temporal aliasing under camera movement. \nThe way these artifacts are traditionally resolved is by jittering the camera relative sampling locations along the rays.\nThis potentially reduces cache efficiency when sampling volume textures. \nHowever, this is only the case when the step size is larger than the voxel spacing. \nNo performance degradation occurs as long as the jittering does not scatter the texture access locations of adjacent pixels too much.\nMip-mapping the volume can help with that. \n\nBased on my (limited) experiments here it seems to me that SVS does not improve texture access patterns enough to offset its overhead.\nSVSs primary selling point appears to be that it can produce temporally stable results without the use of jittering.\n\nHowever, whether SVS works well or not very much depends on the characteristics of the volume: \nrestricting the raymarching sampling locations in a structured manner can lead to very noticeable _spatial_ aliasing artifacts \n(f.i. the sampling planes can become quite obvious for decently dense volumes that feature limb darkening).\n\nMy SVS implementation here tries to reduce these spatial aliasing artifacts by re-introducing per-ray jittering.\nHowever, the jittering is only used for oversampling the transfer function that is applied to a linear interpolation of the SVS samples.\nThe advantage over traditionally jittered raymarching is that details contained in the volume cross-sections are better retained.\nAlthough the line between what one would consider either a desireable detail or an undesireable artifact is, admittedly, rather ambiguous.\nIn that sense this experiment is somewhat of a mixed success.\n\nI set up two SVS implementations: \none that blends the results of up to 3 sets of sampling planes (RaymarchScene_Structured) and \none that stochastically selects a single set of sampling planes(RaymarchScene_StructuredStochastic).\n\nOnly the stochastic variant appears to be performant enough to be potentially useful, though.\n*/\n\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//--------------------------------------------------------------------------------------------------------------//\n\n// Common:\n\n/* dodecahedral/truncated icosahedral quantization of a given direction [dir]\n\n   [dir]: normalized vector | [rad]: blend radius [0,1] | [rnd]: random number [0,1]\n   \n   [doUseTruncIco]: quantize to face directions of truncated icosahedron instead of regular dodecahedron\n   [doUseKernB]:    instead of the simple spherical blend kernel use one that is more expensive but works better for small [rad]\n   [doSort]:        sort the found directions so that correlation structures in [rnd] do not break (use this if [rnd] is blue noise)\n\n   out:    the closest 3 directions [dirA/B/C] + their blend weights [w.xyz] \n   return: one of the 3 closest directions (sampled according to their weights [w.xyz] using [rnd])  \n*/\nvec3 QuantizeDirection(vec3 dir, float rad, float rnd, \n                       const bool useTruncIco, const bool useKernB, const bool sortDirs, \n                       out vec3 dirA, out vec3 dirB, out vec3 dirC, out vec3 w);\n\n// Image:\n\n// traditional volume raymarching\nvec3 RaymarchScene(vec3 rp, vec3 rd, vec2 uv);\n\n// structured volume raymarching | stochastically selects a single set of sampling planes\nvec3 RaymarchScene_StructuredStochastic(vec3 rp, vec3 rd, vec2 uv);\n\n// structured volume raymarching | blends results from up to 3 sampling planes\nvec3 RaymarchScene_Structured(vec3 rp, vec3 rd, vec2 uv);\n\n//--------------------------------------------------------------------------------------------------------------//\n//////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n// Jorge Jimenez http://www.iryoku.com/next-generation-post-processing-in-call-of-duty-advanced-warfare\nfloat IGN(vec2 uv) { return fract(52.9829189 * fract(dot(uv, vec2(0.06711056, 0.00583715)))); }\n\n// animated interleaved gradient noise - https://www.shadertoy.com/view/fdl3zn\nfloat EvalIGN(vec2 uv)\n{\n    uint frame = uint(iFrame);\n    \n    if((frame & 2u) != 0u) uv = vec2(-uv.y, uv.x);\n    if((frame & 1u) != 0u) uv.x = -uv.x;\n    \n    //return fract(IGN(uv)+float(frame)*0.41421356*1.0);\n\n    // http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/#dither\n    return fract(uv.x*0.7548776662 + uv.y*0.56984029 + float(frame)*0.41421356);\n}\n\nfloat SampleVolume(vec3 p)\n{\n    //float n = Fbm32(p*1.8, vec3(0.49, 0.91, 0.36), iTime, iChannel2).x;\n    vec4 n2 = Fbm32(p, vec3(0.49, 0.91, 0.36), iTime*0.5, iChannel2);\n    \n    //n = dot(n2, vec4(1.0, 0.5, 0.25, 0.125));\n    float n = n2.x * n2.y * 2.0;\n    //n = min(n, n2.z * n2.w * 2.0);\n    \n    return n * 0.5 + 0.5;\n}\n\nfloat VolumeMask(vec3 p)\n{\n    float l2 = dot(p,p)*0.5;\n    \n    //return max(smoothstep(0.45, 0.55, Pow2( (1.0-l2)*clamp01(1.0-l2*0.05) )), p.y < 0.0 ? 0.05 : 0.0);\n    return smoothstep(0.45, 0.55, Pow2( (1.0-l2)*clamp01(1.0-l2*0.05) )) + 0.01;\n}\n\n\n//----------------------------------------------------------------------------------------------------------------//\n\n// traditional volume raymarching\nvec3 RaymarchScene(vec3 rp, vec3 rd, vec2 uv)\n{\n    vec3 col = vec3(0.0);\n    \n    vec4 bnoise;// blue noise\n    {\n        // random offset per frame\n        uvec2 noff = uint(iFrame) * uvec2(3242174893u, 2447445397u);\n        \n        bnoise = texelFetch(iChannel3, ivec2((uvec2(uv-0.5) + noff) & 1023u), 0);\n        bnoise = MixBlueNoiseBits(bnoise);// use if 8 bits per channel are not enough\n    }\n\n   #if 1\n    bnoise.x = EvalIGN(uv);// interleaved gradient noise (more fine grained than blue noise but can cause aliasing)\n   #endif\n   \n    float count = 37.0;// max number of steps\n    float stepSize = 4.0/32.0;// dist between sampling planes\n    \n    float T_prev = 1.0;// transmittance\n    float tau = 0.0;// optical depth\n    \n    for(float i = 0.0; i < count; ++i)\n\t{\n        // dist to sample point\n        float d = i * stepSize + (bnoise.x * stepSize);\n        \n        // sample point\n        vec3 p = rp + rd * d;\n        \n        // volume sample\n        float n = SampleVolume(p);\n        \n        // apply transfer function to noise\n        n = smoothstep(0.42, 0.58, n);\n        n *= VolumeMask(p);\n        \n        // extinction coefficient\n        float sigma = n * 32.0;\n        \n        // optical depth\n        tau += sigma * stepSize;\n        \n        // transmittance\n        float T = exp2(-tau);\n        \n        // extinction probability\n        float extProp = T_prev - T;\n\n        // color\n        float limb = Pow2(1.0-exp2(-n*3.0));\n        \n        vec3 c  = normalize(p) * 0.5 + 0.5;\n             c *= mix(vec3((1.0-c.b)*0.25, 0., c.b*0.75), vec3(1.0, 0.9, 0.2), limb);\n             \n        col += extProp * c;\n\n        // break if transmittance gets low\n        if(T < 1.0/64.0) { break; }\n            \n        T_prev = T;\n    }\n    \n    return col * 1.5;\n}\n\n//----------------------------------------------------------------------------------------------------------------//\n\n// structured volume raymarching | stochastically selects a single set of sampling planes\nvec3 RaymarchScene_StructuredStochastic(vec3 rp, vec3 rd, vec2 uv)\n{\n    vec3 col = vec3(0.0);\n    \n    vec4 bnoise;// blue noise\n    {\n        // random offset per frame\n        uvec2 noff = uint(iFrame) * uvec2(3242174893u, 2447445397u);\n        \n        bnoise = texelFetch(iChannel3, ivec2((uvec2(uv-0.5) + noff*1u) & 1023u), 0);\n        bnoise = MixBlueNoiseBits(bnoise);// use if 8 bits per channel are not enough\n    }\n    \n   #if 1\n    bnoise.y = EvalIGN(uv);// interleaved gradient noise (more fine grained than blue noise but can cause aliasing)\n   #endif\n   \n    vec3 N0, N1, N2, w;\n    vec3 N = QuantizeDirection(rd, 0.25, bnoise.x, \n                               /*doUseTruncIco:*/ false, /*doUseKernB:*/ false, /*doSort:*/ true, \n                               /*out:*/ N0, N1, N2, w);\n\n    // number of active sampling planes\n    float countP = (w.x != 0.0 ? 1.0 : 0.0) + \n                   (w.y != 0.0 ? 1.0 : 0.0) + \n                   (w.z != 0.0 ? 1.0 : 0.0);\n\n    // number of samples used for oversampling the transfer function (depends on active planes)\n    // the jitter noise becomes worse when multiple sets of sampling planes are active so we need a higher count2 then\n    float count2 = countP == 1.0 ? 2.0 : 3.0;// 2 | 3 | 3\n    //float rcpCount2 = 1.0/count2;\n    float rcpCount2 = countP == 1.0 ? 1.0/2.0 : 1.0/3.0;\n    \n   #if 0\n   // debugging output\n    return vec3((countP-1.0)*0.5);\n    return N;\n   #endif\n    \n    \n    float count = 37.0;// max number of steps\n    float stepSize = 4.0/32.0;// dist between sampling planes\n\n\n    // stuff we need for stepping through evenly spaced planes\n    float ri, off;\n    {\n        vec3 ro = rp / stepSize;\n\n        float ro2 = dot(ro, N);\n        float rd2 = dot(rd, N);\n\n        ri = 1.0/rd2 * stepSize;// dist between planes\n        off = (-fract(ro2) + (rd2 < 0.0 ? 0.0 : 1.0)) * ri;// dist to first plane\n    }\n\n    // values from previous iteration\n    float T_prev = 1.0;\n    float tau = 0.0;\n    \n    float n0_prev = SampleVolume(rp);// probably works well enough in most cases\n    float d0_prev = 0.0;\n\n\n    count = min(count, iResolution.x);// prevent loop unroll\n    for(float i = 0.0; i < count; ++i)\n\t{\n        // dist to new sample point\n        float d0 = i * ri + off;\n        \n        // new sample point\n        vec3 p0 = rp + rd * d0;\n        \n        // new volume sample\n        float n0 = SampleVolume(p0);\n        \n        // this color is low frequency so no need to oversample it\n        vec3 c0  = normalize(rp + rd *  mix(d0_prev, d0, bnoise.y)) * 0.5 + 0.5;\n        \n        // oversample transfer function\n        for(float j = 0.0; j < count2; ++j)\n        {\n            float s = j * rcpCount2 + (bnoise.y * rcpCount2);\n            \n            float n = mix(n0_prev, n0, s);\n            float d = mix(d0_prev, d0, s);\n\n            // break if min march depth has been reached\n            if(d > (count-1.0)*stepSize) { i = count; break; }\n\n            vec3 p = rp + rd * d;\n            \n            // apply transfer function to noise\n            n = smoothstep(0.42, 0.58, n);\n            n *= VolumeMask(p);\n\n            // extinction coefficient\n            float sigma = n * 32.0;\n\n            // optical depth\n            tau += sigma * ((d0 - d0_prev) * rcpCount2);\n\n            // transmittance\n            float T = exp2(-tau);\n\n            // extinction probability\n            float extProp = T_prev - T;\n\n            // color\n            float limb = Pow2(1.0-exp2(-n*3.0));\n\n            vec3 c = c0 * mix(vec3((1.0-c0.b)*0.25, 0., c0.b*0.75), vec3(1.0, 0.9, 0.2), limb);\n\n            col += extProp * c;\n            \n            // break if transmittance gets low\n            if(T < 1.0/64.0) { i = count; break; }\n            \n            T_prev = T;\n        }\n        \n        n0_prev = n0;\n        d0_prev = d0;\n    }\n    \n    return col * 1.5;\n}\n\n//----------------------------------------------------------------------------------------------------------------//\n\nvec3 minmask(vec3 v)\n{\n    return vec3(v.x <= v.y && v.x <= v.z,\n                v.y <  v.z && v.y <  v.x,\n                v.z <  v.x && v.z <= v.y);\n}\n\n// structured volume raymarching | blends results from up to 3 sampling planes \n// I didn't clean this one up since it's the least useful one\nvec3 RaymarchScene_Structured(vec3 rp, vec3 rd, vec2 uv)\n{\n    vec3 col = vec3(0.0);\n    \n    vec4 bnoise;// blue noise\n    {\n        // random offset per frame\n        uvec2 noff = uint(iFrame) * uvec2(3242174893u, 2447445397u);\n        \n        bnoise = texelFetch(iChannel3, ivec2((uvec2(uv-0.5) + noff*1u) & 1023u), 0);\n        bnoise = MixBlueNoiseBits(bnoise);// use if 8 bits per channel are not enough\n    }\n    \n   #if 1\n    bnoise.x = EvalIGN(uv);// interleaved gradient noise (more fine grained than blue noise but can cause aliasing)\n   #endif\n   \n    vec3 N0, N1, N2, w;\n    QuantizeDirection(rd, 0.25, bnoise.x, \n                      /*doUseTruncIco:*/ false, /*doUseKernB:*/ false, /*doSort:*/ false, \n                      /*out:*/ N0, N1, N2, w);\n   #if 0\n   {\n       // debugging output\n\n       // show number of blended planes (black = 1 | grey = 2 | white = 3)\n       float count2 = (w.x != 0.0 ? 1.0 : 0.0) + \n                      (w.y != 0.0 ? 1.0 : 0.0) + \n                      (w.z != 0.0 ? 1.0 : 0.0);\n                      \n       //return normalize(N0*w.x + N1*w.y + N2*w.z) * 0.5 + 0.5;\n       \n       return vec3((count2 - 1.0)*0.5);\n   }\n   #endif\n   \n    \n    float count = 96.0;\n    float stepSize = 4.0/32.0*1.0;\n  \n    vec3 ro = rp / stepSize;\n    \n    vec3 ro2;\n    ro2.x = dot(ro, N0);\n    ro2.y = dot(ro, N1);\n    ro2.z = dot(ro, N2);\n    \n    vec3 rd2;\n    rd2.x = dot(rd, N0);\n    rd2.y = dot(rd, N1);\n    rd2.z = dot(rd, N2);\n    \n\n    float r = 0.0;\n\n    float T_prev = 1.0;\n    float tau = 0.0;\n\n    vec3 pos = vec3(0.0);\n\tvec3 ri = 1.0/rd2;\n\tvec3 off =  (vec3(rd2.x < 0.0 ? 0.0 : 1.0,\n                      rd2.y < 0.0 ? 0.0 : 1.0,\n                      rd2.z < 0.0 ? 0.0 : 1.0) - fract(ro2)) * ri;\n    \n    const float big = exp2(16.0);\n    if(w.x == 0.0) off.x += big;\n    if(w.y == 0.0) off.y += big;\n    if(w.z == 0.0) off.z += big;\n\n    vec3 n00 = vec3(SampleVolume(rp));\n\n    vec3 n0_prev = n00;\n    vec3 d0_prev = vec3(0.0);\n\n\n    vec3 col0 = vec3(0.0);\n    //float mxD = 0.0;\n    \n    count = min(count, iResolution.x);\n    for(float i = 0.0; i < count; ++i)\n    {\n        vec3 dis = pos * ri + off;\n        vec3 mm = minmask(dis);\n        pos += mm;\n        \n      //  #define SELECT_MODE_A\n        \n       #ifdef SELECT_MODE_A\n        float w0 = dot(w, mm);\n        float d0 = dot(dis, mm);\n       #else        \n        float type = mm.z * 2.0 + mm.y;\n       \n        float n0_prev0, d0_prev0, w0, d0;\n        if(type == 0.0)\n        {\n            n0_prev0 = n0_prev.x;\n            d0_prev0 = d0_prev.x;\n            \n            w0 = w.x; d0 = dis.x;\n        }\n        else if(type == 1.0)\n        {\n            n0_prev0 = n0_prev.y;\n            d0_prev0 = d0_prev.y;\n            \n            w0 = w.y; d0 = dis.y;\n        }\n        else if(type == 2.0)\n        {\n            n0_prev0 = n0_prev.z;\n            d0_prev0 = d0_prev.z;\n            \n            w0 = w.z; d0 = dis.z;\n        }\n       #endif\n        \n        vec3 p0 = rp + rd * (d0*stepSize);\n        float n0 = SampleVolume(p0);\n        \n        //mxD = max(mxD, d0);\n\n        float n = n0;\n        float d = d0;\n\n       #ifdef SELECT_MODE_A\n        // sample the linear reconstruction\n        n = mix(dot(n0_prev, mm), n0, bnoise.x);\n        d = mix(dot(d0_prev, mm), d0, bnoise.x);\n       #else\n        // sample the linear reconstruction\n        n = mix(n0_prev0, n0, bnoise.x);\n        d = mix(d0_prev0, d0, bnoise.x);\n       #endif\n       \n        /*\n        count: scale\n         8: 0.3\n        16: 0.35\n        32: 0.38\n        48: 0.39\n        64: 0.4\n        128: 0.41\n        256: 0.415\n        */\n        if(d > 0.4*count) break;\n\n        vec3 p = rp + rd * (d*stepSize);\n\n        // apply transfer function to noise\n        n = smoothstep(0.42, 0.58, n);\n        n *= VolumeMask(p);\n\n        // extinction coefficient\n        float sigma = n * 32.0;\n\n        // optical depth\n       #ifdef SELECT_MODE_A\n        float tau0 = tau + sigma * (stepSize * (d0 - dot(d0_prev, mm)));\n       #else\n        float tau0 = tau + sigma * (stepSize * (d0 - d0_prev0));\n       #endif\n       \n        // transmittance\n        float T0 = exp2(-tau0);\n\n        // extinction probability\n        float extProp = T_prev - T0;\n\n        // color\n        float limb = Pow2(1.0-exp2(-n*3.0));\n\n        vec3 c  = normalize(p) * 0.5 + 0.5;\n             c *= mix(vec3((1.0-c.b)*0.25, 0., c.b*0.75), vec3(1.0, 0.9, 0.2), limb);\n\n        col += extProp * c * w0;\n\n\n        tau    = mix(tau, tau0, w0);\n        T_prev = mix(T_prev, T0, w0);\n       \n        // break if transmittance gets low\n        if(T_prev < 1.0/64.0) { break; }\n            \n       #ifdef SELECT_MODE_A\n        n0_prev = mix(n0_prev, vec3(n0), mm);\n        d0_prev = mix(d0_prev, vec3(d0), mm);\n       #else\n        if(type == 0.0)\n        {\n            n0_prev.x = n0;\n            d0_prev.x = d0;\n        }\n        else if(type == 1.0)\n        {\n            n0_prev.y = n0;\n            d0_prev.y = d0;\n        }\n        else if(type == 2.0)\n        {\n            n0_prev.z = n0;\n            d0_prev.z = d0;\n        }\n       #endif\n    }\n\n\n//return vec3(mxD/count < 0.39 ? 1.0 : 0.0);\n\n    return col * 1.5;\n}\n\n//----------------------------------------------------------------------------------------------------------------//\n\n\n\n#define KEY_CTRL 17\n#define KEY_SHIFT 16\n#define KEY_SPACE 32\n#define KEY_TAB 9\n\nfloat ReadKeyToggle(int keyCode) {return texelFetch(iChannel1, ivec2(keyCode, 2), 0).x;}\n\n\nvoid mainImage(out vec4 outCol, in vec2 uv0)\n{\n    vec3 col = vec3(0.0);\n    vec2 uv = uv0.xy - 0.5;\n        \n    vec4 mouseAccu = texelFetch(iChannel0, ivec2(1, 0), 0); \n    //vec4 wasdAccu  = texelFetch(iChannel0, ivec2(2, 0), 0); \n        \n    vec2 ang = vec2(1.5 * Pi, Pi * -0.1);\n    ang += mouseAccu.xy * 0.008;\n\n    // orbit camera setup\n    mat3 cmat;\n    {\n        float sinPhi   = sin(ang.x);\n        float cosPhi   = cos(ang.x);\n        float sinTheta = sin(ang.y);\n        float cosTheta = cos(ang.y);    \n\n        vec3 front = vec3(cosPhi * cosTheta, \n                                   sinTheta, \n                          sinPhi * cosTheta);\n\n        vec3 right = vec3(-sinPhi, 0.0, cosPhi);\n        \n        vec3 up    = vec3(-cosPhi * sinTheta,\n                                    cosTheta,\n                          -sinPhi * sinTheta);\n        \n        cmat = mat3(right, up, front);\n    }\n    \n    // ray pos + dir\n    vec3 rp = -cmat[2] * exp2(0.75 + mouseAccu.w * 0.02);\n    //if(uv0.x>iResolution.x*0.5)uv0.x-=iResolution.x*0.5;\n    vec2 tc = uv0 * (1.0 / (iResolution.xx*0.5)) - vec2(1.0, iResolution.y/iResolution.x);\n\n    vec3 rd = normalize(cmat * vec3(tc, 0.9)); \n    \n    \n    bool useStructured = ReadKeyToggle(KEY_TAB) == 0.0;\n    \n    if(ReadKeyToggle(KEY_SPACE) != 0.0)\n    {\n        // show sampling planes\n        \n        vec4 bnoise;\n        {\n            uvec2 noff = uint(iFrame) * uvec2(3242174893u, 2447445397u);\n\n            bnoise = texelFetch(iChannel3, ivec2((uvec2(uv-0.5) + noff) & 1023u), 0);\n            bnoise = MixBlueNoiseBits(bnoise);// use if 8 bits per channel are not enough\n        }\n        \n        vec3 N0, N1, N2, w;\n        vec3 N = QuantizeDirection(rd, 0.25, bnoise.x, \n                                   /*doUseTruncIco:*/ false, /*doUseKernB:*/ false, /*doSort:*/ true, \n                                   /*out:*/ N0, N1, N2, w);\n       \n        float count = (w.x != 0.0 ? 1.0 : 0.0) + \n                      (w.y != 0.0 ? 1.0 : 0.0) + \n                      (w.z != 0.0 ? 1.0 : 0.0);\n        \n        if(ReadKeyToggle(KEY_CTRL) == 0.0)\n        {\n           if(useStructured)\n            col = N * 0.5 + 0.5;\n           else\n            col = rd*0.5+0.5;\n        }\n        else\n        {\n            col = vec3((count-1.0)*0.5);\n        }\n        \n        outCol = vec4(GammaEncode(clamp01(col)), 1.0);\n        return;\n    }\n    \n    \n#if 1\n    // select raymarching routine\n    \n   #if 1\n   \n   if(useStructured)\n    col = RaymarchScene_StructuredStochastic(rp, rd, uv);\n   else\n    col = RaymarchScene(rp, rd, uv);\n   \n   #elif 1\n   \n    col = RaymarchScene(rp, rd, uv);\n    \n   #elif 1\n   \n    col = RaymarchScene_StructuredStochastic(rp, rd, uv);\n    \n   #else\n   \n    col = RaymarchScene_Structured(rp, rd, uv);\n    \n   #endif\n    \n#else\n{\n    // testing performance; loop a few times to push under 60 fps\n    float count = 9.0;\n    \n    count = min(count, iResolution.x);// prevent loop unroll\n    for(float i = 0.0; i < count; ++i)\n    {\n        vec3 rp0 = rp + vec3(0.125) * i;\n        \n       #if 0\n\n        col += RaymarchScene(rp0, rd, uv);\n\n       #elif 1\n\n        col += RaymarchScene_StructuredStochastic(rp0, rd, uv);\n\n       #else\n\n        col += RaymarchScene_Structured(rp0, rd, uv);\n\n       #endif\n    }\n    col /= count;\n}\n#endif\n\n\toutCol = vec4(GammaEncode(clamp01(col)), 1.0);\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 2,
                        "ctype": "texture",
                        "id": 16,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png"
                    },
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    },
                    {
                        "channel": 3,
                        "ctype": "texture",
                        "id": 14854,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/cb49c003b454385aa9975733aff4571c62182ccdda480aaba9a8d250014f00ec.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// CC0 1.0 Universal https://creativecommons.org/publicdomain/zero/1.0/\n// To the extent possible under law, the author has waived all copyrights and related or neighboring rights to this work.\n\n#define rsqrt inversesqrt\n#define clamp01(x) clamp(x, 0.0, 1.0)\n#define If(cond, resT, resF) mix(resF, resT, cond)\n\n\nconst float Pi = 3.14159265359;\nconst float Pi2 = Pi * 2.0;\nconst float Pi05 = Pi * 0.5;\n\nconst float RcpPi  = 1.0 / (1.0 * Pi);\nconst float RcpPi2 = 1.0 / (2.0 * Pi);\nconst float RcpPi4 = 1.0 / (4.0 * Pi);\n\nfloat Pow2(float x) {return x*x;}\nfloat Pow3(float x) {return x*x*x;}\nfloat Pow4(float x) {return Pow2(Pow2(x));}\nfloat Pow5(float x) {return Pow4(x)*x;}\n\nfloat SqrLen(float v) {return v * v;}\nfloat SqrLen(vec2  v) {return dot(v, v);}\nfloat SqrLen(vec3  v) {return dot(v, v);}\nfloat SqrLen(vec4  v) {return dot(v, v);}\n\nvec3 GammaEncode(vec3 x) {return pow(x, vec3(1.0 / 2.2));}   \n\n\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n//====================================================================================================================================//\n// \n\n/* dodecahedral/truncated icosahedral quantization of a given direction [dir]\n\n   [dir]: normalized vector | [rad]: blend radius [0,1] | [rnd]: random number [0,1]\n   \n   [doUseTruncIco]: quantize to face directions of truncated icosahedron instead of regular dodecahedron\n   [doUseKernB]:    instead of the simple spherical blend kernel use one that is more expensive but works better for small [rad]\n   [doSort]:        sort the found directions so that correlation structures in [rnd] do not break (use this if [rnd] is blue noise)\n\n   out:    the closest 3 directions [dirA/B/C] + their blend weights [w.xyz] \n   return: one of the 3 closest directions (sampled according to their weights [w.xyz] using [rnd])  \n*/\nvec3 QuantizeDirection(vec3 dir, float rad, float rnd, \n                       const bool useTruncIco, const bool useKernB, const bool sortDirs, \n                       out vec3 dirA, out vec3 dirB, out vec3 dirC, out vec3 w)\n{\n    //--------------------------------------------------------------------------//\n    // this part is based on: https://www.ppsloan.org/publications/AmbientDice.pdf\n    const float kT = 0.618034;\n    const float kT2 = kT * kT;\n    \n    const float a = 0.850651; \n    const float b = 0.525731;\n    \n    vec3 octantSign = vec3(dir.x < 0.0 ? -1.0 : 1.0,\n                           dir.y < 0.0 ? -1.0 : 1.0,\n                           dir.z < 0.0 ? -1.0 : 1.0);\n                           \n    vec3 adir = abs(dir);\n    \n    // vertex coordinates\n    vec3 vertA = vec3(a, b, 0.0);\n    vec3 vertB = vec3(0.0, a, b);\n    vec3 vertC = vec3(b, 0.0, a);\n    \n    vec3 vertAflipped = vec3(-b, 0.0, a);\n    vec3 vertBflipped = vec3(a, -b, 0.0);\n    vec3 vertCflipped = vec3(0.0, a, -b);\n    \n    // selection\n    bool vertAselect = dot(adir, vec3(1.0, kT2, -kT)) > 0.0;\n    bool vertBselect = dot(adir, vec3(-kT, 1.0, kT2)) > 0.0;\n    bool vertCselect = dot(adir, vec3(kT2, -kT, 1.0)) > 0.0;\n    \n    vec3 v0 = vertAselect ? vertA : vertAflipped;\n    vec3 v1 = vertBselect ? vertB : vertBflipped;\n    vec3 v2 = vertCselect ? vertC : vertCflipped;\n\n    v0 *= octantSign;\n    v1 *= octantSign;\n    v2 *= octantSign;\n    //--------------------------------------------------------------------------//\n\n    if(useTruncIco)\n    {\n        {\n            // sort vertices\n            vec4 tmp;\n\n            vec4 t0 = vec4(v0, dot(v0, dir));\n            vec4 t1 = vec4(v1, dot(v1, dir));\n            vec4 t2 = vec4(v2, dot(v2, dir));\n\n            if(t0.w < t1.w) { tmp=t0; t0=t1; t1=tmp; }\n            if(t1.w < t2.w) { tmp=t1; t1=t2; t2=tmp; }\n            if(t0.w < t1.w) { tmp=t0; t0=t1; t1=tmp; }\n\n            v0 = t0.xyz;\n            v1 = t1.xyz;\n            v2 = t2.xyz;\n        }\n\n        // compute dodecahedron vertices vA and vB\n        vec3 vA = (v0 + v1 + v2) * 0.41947;\n\n        vec3 N = cross(v0, v1);// normal of mirror plane \n\n        //vec3 vB = vA - normalize(N) * (2.0 * dot(vA, normalize(N)));\n        vec3 vB = vA - N * (2.5 * dot(vA, N));// mirror vA\n\n        // new triangle {v0, vA, vB}\n        v1 = vA;\n        v2 = vB;    \n    }\n\n    if(sortDirs)\n    {\n        // sort vertices (to not break structure of correlated noise)\n        const vec3 dw = vec3(1.0, 1.0, 2.0);\n        vec4 tmp;\n        \n        vec4 t0 = vec4(v0, dot(v0, dw));\n        vec4 t1 = vec4(v1, dot(v1, dw));\n        vec4 t2 = vec4(v2, dot(v2, dw));\n        \n        if(t0.w < t1.w) { tmp=t0; t0=t1; t1=tmp; }\n        if(t1.w < t2.w) { tmp=t1; t1=t2; t2=tmp; }\n        if(t0.w < t1.w) { tmp=t0; t0=t1; t1=tmp; }\n        \n        v0 = t0.xyz;\n        v1 = t1.xyz;\n        v2 = t2.xyz;\n    }\n           \n    if(!useKernB)\n    {\n        // spherical kernel\n        float o = useTruncIco ? mix(0.9224, 0.8508  , rad) : \n                                mix(0.7944, 0.525731, rad);\n                                  \n        float a = 1.0 / (1.0 - o);\n        float b =  -o / (1.0 - o);\n        \n        w.x = clamp01(dot(dir, v0) * a + b);\n        w.y = clamp01(dot(dir, v1) * a + b);\n        w.z = clamp01(dot(dir, v2) * a + b);\n    \n       #if 1\n        w *= w;\n       #else\n        w = w*w * (1.5 - 0.5*w);\n       #endif     \n    }\n    else\n    {\n        // pentagonal/hexagonal kernel\n        if(useTruncIco)\n        {\n            // point on triangle\n            //vec3 p = length((v0+v1+v2)/3.0) / dot(normalize(v0+v1+v2), dir) * dir;\n            vec3 p = 2.556443 / dot(v0+v1+v2, dir) * dir;\n\n            // edge-relative coordinates\n            float l01 = dot(v1-v0, v1-v0);\n            float l02 = dot(v2-v0, v2-v0);\n            float l12 = dot(v2-v1, v2-v1);\n\n            float u01 = dot(p-v0, v1-v0) * (l01 < l02+0.0625 ? 2.434920 : 1.963525);\n            float u02 = dot(p-v0, v2-v0) * (l02 < l12+0.0625 ? 2.434920 : 1.963525);\n            float u12 = dot(p-v1, v2-v1) * (l12 < l02+0.0625 ? 2.434920 : 1.963525);\n\n            // hexa-/pentagonal vertex weights\n            float w0 = 1.0-max(u01, u02);\n            float w1 = min(u01, 1.0-u12);\n            float w2 = min(u02,     u12);\n\n             w = vec3(w0, w1, w2);\n        }\n        else\n        {\n            // point on triangle\n            vec3 p = 1.894427 / dot(v0+v1+v2, dir) * dir;\n\n            // edge-relative coordinates\n            float u01 = dot(p-v0, v1-v0) * 0.904508;\n            float u02 = dot(p-v0, v2-v0) * 0.904508;\n            float u12 = dot(p-v1, v2-v1) * 0.904508;\n\n            // pentagonal vertex weights\n            float w0 = 1.0-max(u01, u02);\n            float w1 = min(u01, 1.0-u12);\n            float w2 = min(u02,     u12);\n\n            w = vec3(w0, w1, w2);\n        }\n\n        // compress + shape weight falloffs\n        float a = 1.0 / (rad*0.5);\n        float b = -(0.5-rad*0.25) * a;\n\n        w = clamp01(w * a + b);// compress\n        w = w*w * (3.0 - 2.0 * w);// s-curve\n    }\n \n    // normalize weights\n    w *= 1.0 / (w.x + w.y + w.z);\n\n   #if 0\n    if(!sortDirs)\n    {\n        // sort vertices (_might_ improve execution efficiency (but breaks noise))\n        vec4 tmp;\n        \n        vec4 t0 = vec4(v0, w.x);\n        vec4 t1 = vec4(v1, w.y);\n        vec4 t2 = vec4(v2, w.z);\n        \n        if(t0.w < t1.w) { tmp=t0; t0=t1; t1=tmp; }\n        if(t1.w < t2.w) { tmp=t1; t1=t2; t2=tmp; }\n        if(t0.w < t1.w) { tmp=t0; t0=t1; t1=tmp; }\n        \n        v0 = t0.xyz;\n        v1 = t1.xyz;\n        v2 = t2.xyz;\n        \n        w = vec3(t0.w, t1.w, t2.w);\n    }\n   #endif\n    \n    dirA = v0;\n    dirB = v1;\n    dirC = v2;\n    \n    // draw a sample from the discrete probability distribution {w.x, w.y, w.z}\n    return rnd <  w.x        ? v0 : \n           rnd < (w.x + w.y) ? v1 : v2;\n}\n\n//====================================================================================================================================//\n////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n// increases bit depth of 8 bit per channel blue noise texture\nvec4 MixBlueNoiseBits(vec4 bnoise)\n{\n   const vec4 a = exp2(-vec4(0.0, 8.0, 16.0, 24));\n   const vec4 b = a / (a.x + a.y + a.z + a.w);\n\n   return vec4(dot(bnoise.xyzw, b), \n               dot(bnoise.yzwx, b), \n               dot(bnoise.zwxy, b), \n               dot(bnoise.wxyz, b));\n}\n\n\nvec2 CmplxMul(vec2 c0, vec2 c1)\n{\n    return vec2(c0.x*c1.x - c0.y*c1.y, c0.y*c1.x + c0.x*c1.y);\n}\n\nvec2 CmplxMul(vec2 c0, float ang)\n{\n    vec2 c1 = vec2(cos(ang), sin(ang));\n    \n    return vec2(c0.x*c1.x - c0.y*c1.y, c0.y*c1.x + c0.x*c1.y);\n}\n\nfloat cubic(float x) {return x*x * (3.0 - 2.0 * x);}\nvec2  cubic(vec2  x) {return x*x * (3.0 - 2.0 * x);}\nvec3  cubic(vec3  x) {return x*x * (3.0 - 2.0 * x);}\nvec4  cubic(vec4  x) {return x*x * (3.0 - 2.0 * x);}\n\nfloat quintic(float x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\nvec2  quintic(vec2  x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\nvec3  quintic(vec3  x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\nvec4  quintic(vec4  x){ return ((x * 6.0 - 15.0) * x + 10.0) * x*x*x;}\n\nvec4 VNoise4(vec3 p, vec4 aniS, float time, sampler2D noise64x64)\n{\n    vec3 ip = floor(p);\n    vec3 fp = p - ip;\n    \n    #if 1\n    fp = cubic(fp);\n    p = ip + fp;\n    #endif\n    \n    const float texDim = 64.0;\n    const vec2 prime = vec2(53.0, 41.0);// primes < texDim\n    \n    const float txlDim = 1.0 / texDim;\n    const vec2 pmul = prime * txlDim;\n    const float o0 = 0.5 * txlDim;\n    const vec2 o1 = (prime + 0.5) * txlDim;\n\n    vec2 tex = p.xz * txlDim + ip.y * pmul;\n\n    vec4 n0 = textureLod(noise64x64, tex + o0, 0.0);\n\tvec4 n1 = textureLod(noise64x64, tex + o1, 0.0);\n    \n    //float l0 = textureLod(iChannel1, (p.xz + ip.y         * prime + 0.5) * txlDim, 0.0).x;\n\t//float l1 = textureLod(iChannel1, (p.xz + (ip.y + 1.0) * prime + 0.5) * txlDim, 0.0).x;\n    \n    vec4 n = mix(n0, n1, fp.y);\n    \n    //float r = n.z;\n    //vec4 r = lerp(n.xyzw, n.zwxy, sin(Time * aniS + n.yzwx*Pi2)*.5+.5);\n    //vec4 r = lerp(n.xyzw, n.zxwy, sin(Time * aniS + n.wzyx*Pi2)*.5+.5);\n    vec4 r = mix(n.xyzw, 1.0-n.wzyx, sin(time * aniS + n.zxwy*Pi2)*.5+.5);\n   \n    return r * 2.0 - 1.0;\n}\n\nvec4 Fbm32(vec3 p, vec3 off, float time, sampler2D noise64x64)\n{\n    const float count = 4.0;\n\n    const float ang = Pi * (3.0 - sqrt(5.0));\n    const vec2 rot = vec2(cos(ang), sin(ang));\n    \n    vec4 res = vec4(0.0);\n    \n    float accu_w = 0.0;\n    vec2 w = vec2(1.0);\n    float aniS = 1.2;\n    \n   #if 1\n    res.yzw = VNoise4(p, vec4(0.8, 0.9, 1.1, 1.2) * aniS, time, noise64x64).wyz * 0.5;\n    p.xy = CmplxMul(p.xy, rot);\n    p = p.yzx;\n    p += off;\n   #endif\n    \n    for(float i = 0.0; i < count; ++i)\n    {\n       #if 0\n        vec3 p2 = p + ((res.yzw*res.zwy) - 0.)*8.0;\n       #else\n        vec3 p2 = p + (abs(res.yzw) - 0.5)*2.5;\n       #endif\n        \n        p2.z -= time * 0.2;\n        \n        vec4 v = VNoise4(p2, vec4(0.8, 0.9, 1.1, 1.2) * aniS, time, noise64x64);\n        \n        w.y *= 0.7;\n        \n        res += v * w.xyyy; \n        accu_w += w.x;\n        \n        //res.yz = res.zy;\n        res = res.xwyz;\n        \n        aniS *= 1.9;        \n        w.x *= 0.5;\n        p *= 2.4;\n        p.xy = CmplxMul(p.xy, rot);\n        p = p.yzx;\n        p += off;\n    }\n    \n    res /= accu_w;\n    \n    return res;\n}\n\n\nfloat TrigNoise(vec3 x, float a, float b)\n{\n    vec4 u = vec4(dot(x, vec3( 1.0, 1.0, 1.0)), \n                  dot(x, vec3( 1.0,-1.0,-1.0)), \n                  dot(x, vec3(-1.0, 1.0,-1.0)),\n                  dot(x, vec3(-1.0,-1.0, 1.0))) * a;\n\n    return dot(sin(x     + cos(u.xyz) * b), \n               cos(x.zxy + sin(u.zwx) * b));\n}\n\nfloat TrigNoise(vec3 x)\n{\n    return TrigNoise(x, 2.0, 1.0);\n}\n\n\nuint  asuint2(float x) { return x == 0.0 ? 0u : floatBitsToUint(x); }\nuvec2 asuint2(vec2 x) { return uvec2(asuint2(x.x ), asuint2(x.y)); }\nuvec3 asuint2(vec3 x) { return uvec3(asuint2(x.xy), asuint2(x.z)); }\nuvec4 asuint2(vec4 x) { return uvec4(asuint2(x.xy), asuint2(x.zw)); }\n\nfloat Float01(uint x) { return float(    x ) * (1.0 / 4294967296.0); }\nfloat Float11(uint x) { return float(int(x)) * (1.0 / 2147483648.0); }\n\nvec2 Float01(uvec2 x) { return vec2(      x ) * (1.0 / 4294967296.0); }\nvec2 Float11(uvec2 x) { return vec2(ivec2(x)) * (1.0 / 2147483648.0); }\n\nvec3 Float01(uvec3 x) { return vec3(      x ) * (1.0 / 4294967296.0); }\nvec3 Float11(uvec3 x) { return vec3(ivec3(x)) * (1.0 / 2147483648.0); }\n\nvec4 Float01(uvec4 x) { return vec4(      x ) * (1.0 / 4294967296.0); }\nvec4 Float11(uvec4 x) { return vec4(ivec4(x)) * (1.0 / 2147483648.0); }\n\nconst uint rPhi1  = 2654435761u;\n\nconst uint rPhi2a = 3242174893u;\nconst uint rPhi2b = 2447445397u;\n\nconst uint rPhi3a = 3518319149u;\nconst uint rPhi3b = 2882110339u;\nconst uint rPhi3c = 2360945581u;\n\nconst uint rPhi4a = 3679390609u;\nconst uint rPhi4b = 3152041517u;\nconst uint rPhi4c = 2700274807u;\nconst uint rPhi4d = 2313257579u;\n\nconst uvec2 rPhi2 = uvec2(rPhi2a, rPhi2b);\nconst uvec3 rPhi3 = uvec3(rPhi3a, rPhi3b, rPhi3c);\nconst uvec4 rPhi4 = uvec4(rPhi4a, rPhi4b, rPhi4c, rPhi4d);\n\nuint  Roberts(uint  off, uint n) { return off + rPhi1 * n; }\nuvec2 Roberts(uvec2 off, uint n) { return off + rPhi2 * n; }\nuvec3 Roberts(uvec3 off, uint n) { return off + rPhi3 * n; }\nuvec4 Roberts(uvec4 off, uint n) { return off + rPhi4 * n; }\n\n#define _SEED uvec4(0xCAF0FC2Eu, 0xEA18994Au, 0x4D86D399u, 0x10EB49F0u)\n\nuvec4 PhiHash(uint  v, uint seed) { return ((v   * rPhi2a)                                                    ^ (_SEED ^ uvec4(seed))) * rPhi1; }\nuvec4 PhiHash(uvec2 v, uint seed) { return ((v.x * rPhi2a) ^ (v.y * rPhi2b)                                   ^ (_SEED ^ uvec4(seed))) * rPhi1; }\nuvec4 PhiHash(uvec3 v, uint seed) { return ((v.x * rPhi3a) ^ (v.y * rPhi3b) ^ (v.z * rPhi3c)                  ^ (_SEED ^ uvec4(seed))) * rPhi1; }\nuvec4 PhiHash(uvec4 v, uint seed) { return ((v.x * rPhi4a) ^ (v.y * rPhi4b) ^ (v.z * rPhi4c) ^ (v.w * rPhi4d) ^ (_SEED ^ uvec4(seed))) * rPhi1; }\n\nvec4 PhiHash01(float v, uint seed) { return Float01(PhiHash(asuint2(v), seed)); }\nvec4 PhiHash01(vec2  v, uint seed) { return Float01(PhiHash(asuint2(v), seed)); }\nvec4 PhiHash01(vec3  v, uint seed) { return Float01(PhiHash(asuint2(v), seed)); }\nvec4 PhiHash01(vec4  v, uint seed) { return Float01(PhiHash(asuint2(v), seed)); }\n\nvec4 PhiHash11(float v, uint seed) { return Float11(PhiHash(asuint2(v), seed)); }\nvec4 PhiHash11(vec2  v, uint seed) { return Float11(PhiHash(asuint2(v), seed)); }\nvec4 PhiHash11(vec3  v, uint seed) { return Float11(PhiHash(asuint2(v), seed)); }\nvec4 PhiHash11(vec4  v, uint seed) { return Float11(PhiHash(asuint2(v), seed)); }\n\nuint MixHash(uvec2 h)\n{\n    return ((h.x ^ (h.y >> 16u)) * rPhi2.x) ^ \n           ((h.y ^ (h.x >> 16u)) * rPhi2.y);\n}\n\nuint MixHash(uvec3 h)\n{\n    return ((h.x ^ (h.y >> 16u) ^ (h.z << 15u)) * rPhi3.x) ^ \n           ((h.y ^ (h.z >> 16u) ^ (h.y << 15u)) * rPhi3.y) ^\n           ((h.z ^ (h.y >> 16u) ^ (h.x << 15u)) * rPhi3.z);\n}\n\nuint MixHash(uvec4 h)\n{\n    return ((h.x ^ (h.y >> 16u) ^ (h.z << 15u)) * rPhi4.x) ^ \n           ((h.y ^ (h.z >> 16u) ^ (h.w << 15u)) * rPhi4.y) ^\n           ((h.z ^ (h.w >> 16u) ^ (h.x << 15u)) * rPhi4.z) ^\n           ((h.w ^ (h.x >> 16u) ^ (h.y << 15u)) * rPhi4.w);\n}\n\n// low bias version https://nullprogram.com/blog/2018/07/31/\nuint WellonsHash(uint x)\n{\n    x ^= x >> 16u;\n    x *= 0x7feb352dU;\n    x ^= x >> 15u;\n    x *= 0x846ca68bU;\n    x ^= x >> 16u;\n\n    return x;\n}\n\nuvec2 WellonsHash(uvec2 h) { return uvec2(WellonsHash(h.x), WellonsHash(h.y)); }\nuvec3 WellonsHash(uvec3 h) { return uvec3(WellonsHash(h.x), WellonsHash(h.y), WellonsHash(h.z)); }\nuvec4 WellonsHash(uvec4 h) { return uvec4(WellonsHash(h.x), WellonsHash(h.y), WellonsHash(h.z), WellonsHash(h.w)); }\n\nuvec4 WellonsHash(uint  v, uint seed) { return WellonsHash(        v  ^ (_SEED ^ uvec4(seed))); }\nuvec4 WellonsHash(uvec2 v, uint seed) { return WellonsHash(MixHash(v) ^ (_SEED ^ uvec4(seed))); }\nuvec4 WellonsHash(uvec3 v, uint seed) { return WellonsHash(MixHash(v) ^ (_SEED ^ uvec4(seed))); }\nuvec4 WellonsHash(uvec4 v, uint seed) { return WellonsHash(MixHash(v) ^ (_SEED ^ uvec4(seed))); }\n\n// minimal bias version https://nullprogram.com/blog/2018/07/31/\nuint WellonsHash2(uint x)\n{\n    x ^= x >> 17u;\n    x *= 0xed5ad4bbU;\n    x ^= x >> 11u;\n    x *= 0xac4c1b51U;\n    x ^= x >> 15u;\n    x *= 0x31848babU;\n    x ^= x >> 14u;\n\n    return x;\n}\n\nuvec2 WellonsHash2(uvec2 h) { return uvec2(WellonsHash2(h.x), WellonsHash2(h.y)); }\nuvec3 WellonsHash2(uvec3 h) { return uvec3(WellonsHash2(h.x), WellonsHash2(h.y), WellonsHash2(h.z)); }\nuvec4 WellonsHash2(uvec4 h) { return uvec4(WellonsHash2(h.x), WellonsHash2(h.y), WellonsHash2(h.z), WellonsHash2(h.w)); }\n\nuvec4 WellonsHash2(uint  v, uint seed) { return WellonsHash2(        v  ^ (_SEED ^ uvec4(seed))); }\nuvec4 WellonsHash2(uvec2 v, uint seed) { return WellonsHash2(MixHash(v) ^ (_SEED ^ uvec4(seed))); }\nuvec4 WellonsHash2(uvec3 v, uint seed) { return WellonsHash2(MixHash(v) ^ (_SEED ^ uvec4(seed))); }\nuvec4 WellonsHash2(uvec4 v, uint seed) { return WellonsHash2(MixHash(v) ^ (_SEED ^ uvec4(seed))); }\n\n#undef _SEED\n\n\n// https://en.wikipedia.org/wiki/Linear_congruential_generator\nuint LCG(uint x) { return x * 22695477u + 1u; }\n\nfloat Hash01(inout uint h)\n{\n    h = LCG(h);\n\n    return Float01(h * rPhi1);\n}\n\nfloat Hash11(inout uint h)\n{\n    h = LCG(h);\n\n    return Float11(h * rPhi1);\n}\n\nuint HashU(inout uint h)\n{\n    h = LCG(h);\n\n    return h * rPhi1;\n}\n\nvec2 Hash01x2(inout uint h) { return vec2(Hash01(h), Hash01(h)); }\nvec3 Hash01x3(inout uint h) { return vec3(Hash01(h), Hash01(h), Hash01(h)); }\nvec4 Hash01x4(inout uint h) { return vec4(Hash01(h), Hash01(h), Hash01(h), Hash01(h)); }\n\nvec2 Hash11x2(inout uint h) { return vec2(Hash11(h), Hash11(h)); }\nvec3 Hash11x3(inout uint h) { return vec3(Hash11(h), Hash11(h), Hash11(h)); }\nvec4 Hash11x4(inout uint h) { return vec4(Hash11(h), Hash11(h), Hash11(h), Hash11(h)); }\n\nuvec2 HashUx2(inout uint h) { return uvec2(HashU(h), HashU(h)); }\nuvec3 HashUx3(inout uint h) { return uvec3(HashU(h), HashU(h), HashU(h)); }\nuvec4 HashUx4(inout uint h) { return uvec4(HashU(h), HashU(h), HashU(h), HashU(h)); }\n\n\nvec3 SphereFromDisk(vec2 u)\n{\n    float d = dot(u, u);\n    float l = sqrt(4.0 - 4.0 * d);\n    \n    return vec3(u.x * l, \n          1.0 - 2.0 * d, \n                u.y * l);\n}\n\nvec3 SphericalCapFromDisk(vec2 u, float cosAng)\n{\n    u *= sqrt(1.0 - cosAng);\n    \n    float d = dot(u, u);\n    float l = sqrt(2.0 - d);\n    \n    return vec3(u.x * l, \n                1.0 - d, \n                u.y * l);\n}\n\nvec2 DiskFromSphere(vec3 s)\n{\n    return s.xz * inversesqrt(s.y * 2.0 + 2.0);\n}\n\n// s0 [-1..1], s1 [-1..1]\n// samples spherical cap for s1 [cosAng05..1]\n// samples hemisphere if s1 [0..1]\nvec3 Sample_Sphere(float s0, float s1)\n{\n    float ang = Pi * s0;\n    float s1p = sqrt(1.0 - s1*s1);\n    \n    return vec3(cos(ang) * s1p, \n                           s1 , \n                sin(ang) * s1p);\n}\n\nvec3 Sample_Sphere(vec2 s) { return Sample_Sphere(s.x, s.y); }\n\nvec3 Sample_SphericalCap(float s0, float s1, vec3 N, float cosAng)\n{\n    vec3 p = Sample_Sphere(s0, s1);\n    \n    vec3 pN = N * dot(p, N);\n    vec3 pO = p - pN;\n    \n    vec3 u = pO * inversesqrt(dot(p, N) * 2.0 + 2.0);\n    \n    u *= sqrt(1.0 - cosAng);\n    \n    float d = dot(u, u);\n    float l = sqrt(2.0 - d);\n    \n    return u*l + N*(1.0-d);\n}\n\n\n// s [-1..1]\nfloat Sample_Triangle(float s) \n{ \n    float v = 1.0 - sqrt(1.0 - abs(s));\n    \n    return s < 0.0 ? -v : v; \n}\n\nvec2 Sample_Triangle(vec2 s) { return vec2(Sample_Triangle(s.x), Sample_Triangle(s.y)); }\n\nfloat Intersect_Ray_Cube(vec3 rp, vec3 rd, vec3 cth, out vec2 t)\n{\t\n\tvec3 m = 1.0 / -rd;\n\tvec3 o = If(lessThan(rd, vec3(0.0)), -cth, cth);\n\t\n\tvec3 uf = (rp + o) * m;\n\tvec3 ub = (rp - o) * m;\n\t\n\tt.x = max(uf.x, max(uf.y, uf.z));\n\tt.y = min(ub.x, min(ub.y, ub.z));\n\t\n\tbool inside = t.x < 0.0 && t.y > 0.0;\n    \n\tif(inside) {return 0.0;}\n\t\n\treturn t.y < t.x ? -1.0 : (t.x > 0.0 ? 1.0 : -1.0);\n}\n\nfloat Intersect_Ray_Sphere(\nvec3 rp, vec3 rd, \nvec3 sp, float sr2, \nout vec2 t)\n{\t\n\trp -= sp;\n\t\n\tfloat a = dot(rd, rd);\n\tfloat b = 2.0 * dot(rp, rd);\n\tfloat c = dot(rp, rp) - sr2;\n\t\n\tfloat D = b*b - 4.0*a*c;\n\t\n\tif(D < 0.0) return 0.0;\n\t\n\tfloat sqrtD = sqrt(D);\n\t// t = (-b + (c < 0.0 ? sqrtD : -sqrtD)) / a * 0.5;\n\tt = (-b + vec2(-sqrtD, sqrtD)) / a * 0.5;\n\t\n\t// if(start == inside) ...\n\tif(c < 0.0) t.xy = t.yx;\n\n\t// t.x > 0.0 || start == inside ? infront : behind\n\treturn t.x > 0.0 || c < 0.0 ? 1.0 : -1.0;\n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "/* program state */\nvoid mainImage( out vec4 col, in vec2 uv0 )\n{  \n    if(uv0.y != 0.5) discard;\n    \n    col = vec4(0.0);\n    \n    vec2 uv = uv0 - 0.5;\n    \n    vec4 iMouseLast      = texelFetch(iChannel0, ivec2(0, 0), 0);\n    vec4 iMouseAccuLast  = texelFetch(iChannel0, ivec2(1, 0), 0);\n    vec4 wasdAccuLast    = texelFetch(iChannel0, ivec2(2, 0), 0);\n    float angAccuLast = texelFetch(iChannel0, ivec2(3, 0), 0).x;\n\n    bool shift = texelFetch(iChannel1, ivec2(16, 0), 0).x != 0.0;\n    \n    float kW = texelFetch(iChannel1, ivec2(0x57, 0), 0).x;\n    float kA = texelFetch(iChannel1, ivec2(0x41, 0), 0).x;\n    float kS = texelFetch(iChannel1, ivec2(0x53, 0), 0).x;\n    float kD = texelFetch(iChannel1, ivec2(0x44, 0), 0).x;\n    \n    vec4 wasdAccu = wasdAccuLast + vec4(kW, kA, kS, kD);\n    float angAccu = clamp(angAccuLast + (kD - kA)*0.05, 0.0, Pi);\n    \n    if(iFrame == 0 || iFrame == 1) angAccu = Pi * 0.25;\n    \n    vec2 mouseDelta = iMouse.xy - iMouseLast.xy;\n    \n    bool cond0 = iMouse.z > 0.0 && iMouseLast.z > 0.0;\n    vec2 mouseDelta2 = cond0 && !shift ? mouseDelta.xy : vec2(0.0);\n    vec2 mouseDelta3 = cond0 &&  shift ? mouseDelta.xy : vec2(0.0);\n    \n    vec2 iMouseAccu1 = iMouseAccuLast.xy + mouseDelta2;\n    vec2 iMouseAccu2 = iMouseAccuLast.zw + mouseDelta3;\n    \n    if(uv.x == 0.0 && uv.y == 0.0) col = iMouse;  \n    if(uv.x == 1.0 && uv.y == 0.0) col = vec4(iMouseAccu1, iMouseAccu2);\n    if(uv.x == 2.0 && uv.y == 0.0) col = wasdAccu;\n    if(uv.x == 3.0 && uv.y == 0.0) col = vec4(angAccu);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 1,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 3,
                        "ctype": "texture",
                        "id": 49,
                        "published": 1,
                        "sampler": {
                            "filter": "mipmap",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "repeat"
                        },
                        "src": "/media/a/08b42b43ae9d3c0605da11d0eac86618ea888e62cdd9518ee8b9097488b31560.png"
                    },
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}