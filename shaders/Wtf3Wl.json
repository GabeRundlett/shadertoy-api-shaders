{
    "Shader": {
        "info": {
            "date": "1558049340",
            "description": "Ray tracing tutorial series for the CG discord, Chapter 1, Part 2:\nRay Casting: Adding Integrators\nChange: render mode: UP/DOWN; light: RIGHT/LEFT\nNext part: \nPrevious part: https://www.shadertoy.com/view/ttlGWX",
            "flags": 48,
            "hasliked": 0,
            "id": "Wtf3Wl",
            "likes": 3,
            "name": "RC2: Adding Integrators",
            "published": 3,
            "tags": [
                "raycasting",
                "sphere",
                "intersection"
            ],
            "usePreview": 0,
            "username": "vchizhov",
            "viewed": 936
        },
        "renderpass": [
            {
                "code": "/*\n\t@author: Vassillen Chizhov, 2019\n\tRay tracing tutorial series\n\tChapter 1, part 2:\n\tRay Casting: Adding Integrators\n\n\n\tModifications done from the previous version:\n\t- scene\n\t- lights\n\t- integrators\n\t- gamma correction\n\t- mode iteration through UP/DOWN, RIGHT/LEFT\n\n\n\tYou can find the tutorial series at:\n\thttps://vchizhov.github.io/resources/ray%20tracing/ray%20tracing%20tutorial%20series%20vchizhov/\n\n\tYou can find the shadertoy code for the next part at:\n\t\n\t\n\tYou can find the shadertoy code for the previous part at:\n\thttps://www.shadertoy.com/view/ttlGWX\n*/\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    // map pixel centers from [0,W) x [0,H) to [0,1)^2\n    // the 0.5 offset is precisely to get the pixel centers and not the corner\n    vec2 ndc = (fragCoord+vec2(0.5))/iResolution.xy;\n    float aspectRatio = iResolution.x / iResolution.y;\n    // map to [-1,1]^2\n    ndc = (2.0 * ndc - 1.0);\n    // map to [-aspectRatio,aspectRatio] x [-1,1] to avoid stretching\n    ndc *= vec2(aspectRatio,1.0);\n\n    /*\n\t\tSet up a camera centered at (0,0,0)\n\t\tWith an orthonormal basis\n\t*/\n    Camera cam;\n    cam.o = vec3(0.0,0.0,0.0);\n    cam.e0 = vec3(1.0,0.0,0.0);\n    cam.e1 = vec3(0.0,1.0,0.0);\n    cam.e2 = vec3(0.0,0.0,1.0);\n    \n    Scene scene = initScene();\n    scene.ambientLight.radiance = vec3(0.01f);\n    \n    // Add some scene geometry\n    add(scene, Sphere(vec3(0,0,4), 1.0, vec3(1,0.5,0.1)));\n    add(scene, Sphere(vec3(-1,0,2.5), 1.0, vec3(0.1,0.5,1)));\n    \n    // a large sphere for the ground\n    add(scene, Sphere(vec3(0,-1001,0), 1000.0, vec3(0.3,1,0.3)));\n    \n    // read state from BufferA\n    vec4 storedDataTexel00 = texelFetch( iChannel0, ivec2(0), 0).xyzw;\n    // We read the integrator type from the x channel of the (0,0) texel\n    int renderMode = int(storedDataTexel00.x);\n    // We read the light type from the y channel of the (0,0) texel\n    int lightMode = int(storedDataTexel00.y);\n    \n    // change light direction based on time\n    float offsetLightX = sin(iTime);\n    vec3 pointLightTo = vec3(1.0+2.0*offsetLightX,0,3);\n    // set the initial light mode to be the most impressive one:\n    lightMode = negPosMod(3+lightMode,LIGHT_MODE_COUNT);\n    // choose light mode based on stored sate\n    if(lightMode==0)\n    {\n        add(scene, PointLight(vec3(30.0),vec3(2.0*offsetLightX,2,2)));\n    }\n    else if(lightMode==1)\n    {\n        add(scene, DirectionalLight(vec3(3.0), normalize(pointLightTo - vec3(2,2,2))));\n    }\n    else if(lightMode==2)\n    {\n        add(scene, CylinderLight(vec3(3.0), vec3(2,2,2), normalize(pointLightTo-vec3(2,2,2)), 3.0));\n    }\n    else\n    {\n       \tvec3 lightPos = vec3(2.0*offsetLightX,2,2);\n        add(scene, ConeLight(vec3(30.0), lightPos, normalize(vec3(1,0,3)-lightPos), cos(0.25*PI)));\n    }\n    \n    // generate camera ray through the center of this pixel\n    Ray ray = generateRay(cam, ndc);\n\n    // pixel color (flux through this film pixel)\n    vec3 col = vec3(0);\n    \n    // set the initial render mode to be the most impressive one:\n    renderMode = negPosMod(int(5 + renderMode),RENDER_MODE_COUNT);\n    // choose integrator based on stored state\n    if(renderMode == 0)\n    {\n        col = binaryIntegrator(scene, ray);\n    }\n    else if (renderMode == 1)\n    {\n        col = colorIntegrator(scene, ray);\n    }\n    else if (renderMode==2)\n    {\n        col = inverseDistanceIntegrator(scene, ray);\n    }\n    else if (renderMode==3)\n    {\n        col = normalIntegrator(scene, ray);\n    }\n    else if (renderMode == 4)\n    {\n        col = diffuseLocalDirectIlluminationIntegrator(scene, ray);\n    }\n    else if( renderMode == 5)\n    {\n        col = diffuseDirectIlluminationIntegrator(scene, ray);\n    } \n    else\n    {\n        col = transparencyIntegrator(scene,ray);\n    }\n    // gamma correction\n    col = pow(col, vec3(1.0/2.2));\n    \n    // Output to screen\n    fragColor = vec4(col,1.0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "/*\n\t@author: Vassillen Chizhov, 2019\n\tRay tracing tutorial series\n\tChapter 1, part 2:\n\tRay Casting: Adding Integrators\n\n\tModifications done from the previous version:\n\n\t- added a vec3 color variable to Sphere\n\t- added an Intersection structure\n\t- intersect returns Intersection and not float\n\t- added a function to compute the sphere normal\n\t- the sphere intersection function computes the distance, normal, color, position\n\t- added Scene structure to hold multiple spheres and intersect them\n\t- added utility functions for the Intersection and Scene structures\n\t- added an intersectAny routine for \"optimization\" of shadow rays (early out, no intersection data computation)\n\t- added keyboard input to change rendering and light modes\n\n\t* Added integrators:\n\t- binary\n\t- inverse distance\n\t- color\n\t- normal\n\t- local diffuse\n\t- diffuse\n\n\t* Added lights:\n\t- ambient\n\t- point\n\t- directional\n\t- cone\n\t- cylinder\n\n\tTODO:\n\tnext part:\n\t- merge the direct illumination integrators into 1 with a bool flag\n\t- add transformations\n\t- add box, plane, parallelogram, triangle, disk\n\t- add uvs and textures\n\t- add quadrics morphing\n\t- add CSG\n\t\n*/\n\n/*\n\t2^24-1 fits in the mantissa nicely and converts to a 24bit int perfectly\n\tI use this as infinity since some GPUs do not like 1.0/0.0\n\tINFINITY is used mainly to filter out intersections, if dist >= INFINITY \n\twe evaluate it as there being no intersection\n*/\n#define INFINITY 16777215.0\n\n/*\n\tA small value that should ideally depend on the scale of the scene geometry\n\tIt serves as an offset to push intersections outside/inside a surface to compensate \n\tfor numerical error\n*/\n#define EPSILON\t0.0001\n\n// Used for shading\n#define PI 3.14159265358979323846264338327950288\n/*\n\tused to normalize the diffuse albedo (for convenience the color can be defined in [0,1]\n\tand is then normalized before shading by diving by PI)\n*/\n#define INV_PI 1.0/PI\n\n/*\n\tWe have added a functionality to iterate (cyclically) through rendering modes\n\tby pressing key up/key down, the RENDER_MODE_COUNT matches the number of integrators \n\tand we choose which to use from those depending on the current mode\n\tfor more details refer to BufferA and Image\n*/\n#define RENDER_MODE_COUNT 7\n\n// we have a similar choice for the light mode\n#define LIGHT_MODE_COUNT 4\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tUTILITY\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n// returns the modulo of x if it's withing the range [-m,2m)\nint negPosMod(in int x, in int m)\n{\n    return ((x >= m) ? (x-m) : ((x < 0) ? (x+m) : x));\n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tRAY\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n/*\n\t\\brief A ray defined through its origin and a unit-length direction vector\n*/\nstruct Ray\n{\n    vec3 o;\t//!< origin of the ray\n\tvec3 d;\t//!< direction of the ray\n\n};\n\n//! convenience function, returns the point along the ray direction at a distance t from the ray origin\nvec3 at(in Ray ray, in float t)\n{\n \treturn ray.o + t * ray.d;  \n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tCAMERA\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n/*\n\t\\brief A simple pinhole camera model\n*/\nstruct Camera\n{\n\tvec3 e0, e1, e2;\t//!< basis vectors of the camera: right, up, forward\n\tvec3 o;\t\t\t\t//!< the camera origin\n};\n    \n//! returns the normalized ray corresponding to the point (u,v) on the virtual film\nRay generateRay(in Camera cam, in vec2 uv)\n{\n    return Ray(cam.o, normalize(uv.x * cam.e0 + uv.y * cam.e1 + cam.e2));\n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tINTERSECTION\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n//! A structure containing intersection data\nstruct Intersection\n{\n    float dist;\t\t//!< distance from the ray origin to the intersection\n    vec3 pos;\t\t//!< position of the intersection point\n    vec3 normal;\t//!< surface normal at the intersection\n    vec3 color;\t\t//!< surface color at the intersection\n};\n\n// convenience function returning an invalid intersection\nIntersection noIntersection()\n{\n \treturn Intersection(INFINITY,vec3(0), vec3(0), vec3(0));   \n}\n\n// convenience function checking whether an intersection is valid\nbool valid(in Intersection intersection)\n{\n    return intersection.dist < INFINITY;\n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tSPHERE\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n    \n    \n/*\n\t\\brief A sphere defined through its origin and radius\n*/\nstruct Sphere\n{\n\tvec3 origin; \t//! sphere center\n\tfloat radius;\t//! sphere radius\n    \n    /*\n\t\tCurrently this represent the diffuse color of the sphere.\n\t\tFor energy conservation it should be in [0,1] (this will become \n\t\timportant for the first time in the ray tracing part).\n\t*/\n    vec3 color;\t\t//! the color (albedo) of the sphere\n\n};\n    \n// returns the normal at point p on the sphere\nvec3 normal(in Sphere s, in vec3 p)\n{\n    return (p-s.origin)/s.radius;\n}\n    \n// Evaluates whether the ray intersects the sphere within the ray segment (minT, maxT)\n// returns INFINITY if there is no intersection, so that a check for intersection can be performed as intersect(...)<INFINITY\n// otherwise returns the distance from the ray origin to the closest intersection\nIntersection intersect(in Sphere s, in Ray ray, in float minT, in float maxT)\n{\n    /*\n        |ray(t) - pos| == r <->\n        |ray(t) - pos|^2 == r^2 <->\n        <ray(t)-pos,ray(t)-pos> == r^2 <->\n        <ray.o-pos + t * ray.d, ray.o-pos + t * ray.d> == r^2 <->\n        <ray.d,ray.d> * t^2 - 2 * <ray.d, pos - ray.o> * t + <pos-ray.o,pos-ray.o> - r^2 == 0\n        A = <ray.d,ray.d>, but |ray.d|==1 if the direction is normalized -> A = 1\n        B = <ray.d, pos - ray.o>\n        C = <pos-ray.o,pos-ray.o> - r^2\n\n        D = B^2 - C\n        D<0  -> no intersection\n        D==0 -> grazing intersection\n        D>0  -> 2 intersections\n\n        One can ignore grazing intersections since they are actually numerical error.\n\n        D>0 -> sqrtD = sqrt(D)\n        t_1 = B - D\n        t_2 = B + D\n\n        If maxT>t_1>minT -> intersection at ray(t_1)\n        Else If maxT>t_2>min_t -> intersection at ray(t_2)\n        Else -> no intersection\n    */\n    vec3 oPos = s.origin - ray.o;\n    float b = dot(ray.d, oPos);\n    float c = dot(oPos, oPos) - s.radius * s.radius;\n    float d = b * b - c;\n\n    // If the discriminant is 0 or negative -> no (actual) intersection\n    if (d <= 0.0) return noIntersection();\n\n    float sqrtD = sqrt(d);\n    float t1 = b - sqrtD; // closer intersection\n    // is it within the defined ray segment by (minT,maxT) ?\n    if (t1 > minT && t1 < maxT)\n    {\n        vec3 pos = at(ray,t1);\n        return Intersection(t1, pos, normal(s, pos), s.color);\n    }\n\n    float t2 = b + sqrtD; // farther intersection\n    // is it within the defined ray segment by (minT,maxT) ?\n    if (t2 > minT && t2 < maxT)\n    {\n        vec3 pos = at(ray,t2);\n        return Intersection(t2, pos, normal(s, pos), s.color);\n    }\n\n    return noIntersection();\n}\n\n//! returns true only if there's an intersection without computing normals or extra intersection info\nbool intersectAny(in Sphere s, in Ray ray, in float minT, in float maxT)\n{\n    // the code is almost the same\n    vec3 oPos = s.origin - ray.o;\n    float b = dot(ray.d, oPos);\n    float c = dot(oPos, oPos) - s.radius * s.radius;\n    float d = b * b - c;\n\n    float sqrtD = sqrt(d);\n    float t1 = b - sqrtD;\n    float t2 = b + sqrtD;\n    return (d>0.0)&&((t1 > minT && t1 < maxT) || (t2 > minT && t2 < maxT));\n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tLIGHT\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n/*\n\t\\brief Holds sampled data from a light source, used for shading computations\n*/\nstruct LightSample\n{\n \tvec3 radiance;\t\t\t//!< radiance travelling toward the point being shaded\n    \n    // used for Lambert's cosine term and brdf evaluation\n    vec3 direction;\t\t\t//!< direction from the point being shaded to the light source sample\n    \n    // used for shadow rays tests\n    float distanceToLight;\t//!< distance to the light source sample along the direction\n};\n\n/*\n\t\\brief A light that emits constant light (radiance) from every point in the scene in every direction.\n\t\n\tThe ambient light aims to compensate for the lack of indirect illumination in local \n\trendering methods (similar to rasterization or the two diffuse integrators we have here).\n\tFor example it can make very dark regions of the image brighter, however, it makes ALL \n\tshaded points brighter, so it is simply like increasing the brightness.\n*/\nstruct AmbientLight\n{\n    vec3 radiance;\t//!< The color and strength of the light\n};\n\n/*\n\t\\brief Derives data from the light source and the position of the point to be shaded necessary for shading\n\n\tpos is the position of the point for which we called sampleRadiance \n\tin order to shade it\n*/\nLightSample sampleRadiance(in AmbientLight light, in vec3 pos)\n{\n    return LightSample(light.radiance, vec3(0), 0.0);\n}\n    \n/*\n\t\\brief A light with no area, defined only though its position and (isotropic) intensity\n\n\tThe point light aims to model very small light sources. Small light sources still \n\thave area, which requires sampling. On the other hand, a point light has no area \n\tso it allows for an efficient implementation since no sampling is required. \n\tObviously there's a trade-off between accuracy and efficiency, as point lights \n\tare not physical and do not produce soft shadows - infinite energy is concentrated \n\tin a single point. However point lights obey the inverse-square law, so the light energy \n\tdiminishes with the inverse square of the distance from the light source.\n\n\tNote: isotropic intensity means that the the light emits equal energy in all directions.\n\tIn comparison a textured light would be anisotropic.\n*/\nstruct PointLight\n{\n    vec3 intensity;\t\t//!< The color and strength of the light\n\tvec3 origin;\t\t//!< The position of the light\n};\n    \nLightSample sampleRadiance(in PointLight light, in vec3 pos)\n{\n    LightSample lightSample;\n    \n    // the vector pointing from the intersection to the light source\n    vec3 posToLight = light.origin - pos;\n    /*\n\t\twe also need to normalize this vector and compute the square of its \n        distance to account for the inverse-square light falloff \n\t*/\n    float distanceToLight = length(posToLight);\n    posToLight /= distanceToLight;\n    float squaredDistanceToLight = distanceToLight * distanceToLight;\n    \n    // the negated direction from which the light comes from\n    lightSample.direction = posToLight;\n    // the radiance from the light along that direction\n    lightSample.radiance = light.intensity / squaredDistanceToLight;\n    \n    // return the distance to the light for shadow ray tests\n    lightSample.distanceToLight = distanceToLight;\n    \n    return lightSample;\n}\n\n/*\n\t\\brief An infinitely distant light source emitting in a single direction\n\n    It aims to model far away light sources, so that the rays arriving at the scene are close \n\tto parallel. Examples of such emitters are the sun or the moon (as a reflector). \n    This light source is also not physical since it usually spans an infinite area (this can be \n    changed) and each point emits light only in a single direction. A less intuitive and more \n    accurate analogy would be an array of (infinitely many infinitely small) lasers oriented in \n\tthe exact same direction.\n\n    Note that the directional light we implement is homogeneous with regards to position - it \n\temits the exact same amount of light from all of its points. \n\tIn comparison a textured directional light would be non-homogeneous.\n*/\nstruct DirectionalLight\n{\n    vec3 radiosity;\t\t//!< The strength and color of the light\n    vec3 direction;\t\t//!< The direction of the light\n};\n    \nLightSample sampleRadiance(in DirectionalLight light, in vec3 pos)\n{\n    LightSample lightSample;\n    \n    lightSample.direction = - light.direction;\n    lightSample.radiance = light.radiosity;\n    \n    /*\n\t\twe consider the directional light to be situated at an infinite distance \n\t\tfrom the point being shaded\n\t*/\n    lightSample.distanceToLight = INFINITY;\n    \n    return lightSample;\n}\n\n/*\n\t\\brief An extension of the (isotropic) point light defined above\n\t\n\tWe relax the isotropy of the point light defined above and \n\tmake it emit light only in a cone of angle phi around the direction it's \n\tpointing at. The attenuation from the center to the outward angles is \n\tmodeled through a smoothstep and we apply a concentric texture.\n*/\nstruct ConeLight\n{\n    vec3 intensity; //!< The color and strength of the light\n  \tvec3 origin;\t//!< The position of the light\n    vec3 direction;\t//!< The direction of the light (the height vector of the cone)\n    float cosPhi;\t//!< The cosine of the maximum angle beyond which it emits no light\n};\n    \nLightSample sampleRadiance(in ConeLight light, in vec3 pos)\n{\n    // sample the cone light like you would a point light\n    PointLight pointLight = PointLight(light.intensity, light.origin);\n    LightSample lightSample = sampleRadiance(pointLight, pos);\n    \n    // apply attenuation based on angle:\n    float cosLightCone = -dot(lightSample.direction, light.direction);\n    /*\n\t\tuse a smoothstep to attenuate based on the angle from the direction vector\n        beyond the user defined phi angle there should be no contribution\n\t*/\n    float att = smoothstep(light.cosPhi, 1.0f, cosLightCone);\n    \n    // add a concentric texture to the light based on the angle\n    float tex = 0.5+0.5*sin(200.0 * cosLightCone);\n    lightSample.radiance *= att * tex;\n    \n    \n    return lightSample;\n}\n\n/*\n\t\\brief An extension of the (homogeneous) directional light defined above\n\t\n\tWe relax the homogeneity of the directional light defined above and introduce  \n\tvariable emissivity over its surface. We add a smoothstep attenuation from the \n\tcenter based on distance so that it is not infinite anymore, and the light rays \n\tform a cylinder. We additionally add a concentric texture.\n*/\nstruct CylinderLight\n{\n    vec3 radiosity;\t\t//!< The strength and color of the light\n  \tvec3 origin;\t\t//!< The center of the light (it's actually at infinity, so this is used as a direction to infinity)\n    vec3 direction;\t\t//!< The direction of the light\n    float radius;\t\t//!< The radius of the light cylinder\n};\n    \nLightSample sampleRadiance(in CylinderLight light, in vec3 pos)\n{\n    // sample the cylinder light like you would a directional light\n    DirectionalLight directionalLight = DirectionalLight(light.radiosity, light.direction);\n    LightSample lightSample = sampleRadiance(directionalLight, pos);\n    \n    // compute the projection of the current point on the light plane\n    vec3 lightToPos = pos-light.origin;\n    vec3 projOnLightDir = dot(lightToPos, light.direction) * light.direction;\n    vec3 projOnLightPlane = lightToPos - projOnLightDir;\n    \n    // use the magnitude of the projected vector to create varying radiance based on position:\n    float magnitudeProjectedVector = length(projOnLightPlane);\n    \n    // use a smoothstep to attenuate based on the distance from the \n    // \"center\" point on the light plane (becomes 0 outside of the radius)\n    float att = smoothstep(0.0,1.0, light.radius-magnitudeProjectedVector);\n    \n    // add a concentric texture to the light\n    float tex = 0.5+0.5*sin(15.0 * magnitudeProjectedVector);\n    \n    lightSample.radiance *= tex * att;\n\n    return lightSample;\n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tSCENE\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n\n\n/*\n\t\\brief A class holding the scene geometry and light sources\n\t\n\tA function is provided to intersect all of the objects\n\tAdditionally integrators accept a scene as an argument\n*/\nstruct Scene\n{\n\tSphere spheres[10];\n    int sphereCount;\n    \n    AmbientLight ambientLight;\n    \n    PointLight pointLights[10];\n    int pointLightCount;\n    \n    DirectionalLight directionalLights[10];\n    int directionalLightCount;\n    \n    ConeLight coneLights[10];\n    int coneLightCount;\n    \n    CylinderLight cylinderLights[10];\n    int cylinderLightCount;\n};\n\n// creates a correctly initialized scene object\nScene initScene()\n{\n    Scene scene;\n    scene.sphereCount = 0;\n    scene.ambientLight.radiance = vec3(0);\n    scene.pointLightCount = 0;\n    scene.directionalLightCount = 0;\n    scene.coneLightCount = 0;\n    scene.cylinderLightCount = 0;\n    \n    return scene;\n}\n\n// convenience function to add spheres to the scene\nvoid add(inout Scene scene, in Sphere sphere)\n{\n\tscene.spheres[scene.sphereCount] = sphere;\n    ++scene.sphereCount;\n}\n\n// convenience function to add point lights to the scene\nvoid add(inout Scene scene, in PointLight light)\n{\n    scene.pointLights[scene.pointLightCount] = light;\n    ++scene.pointLightCount;\n}\n\n// convenience function to add directional lights to the scene\nvoid add(inout Scene scene, in DirectionalLight light)\n{\n    scene.directionalLights[scene.directionalLightCount] = light;\n    ++scene.directionalLightCount;\n}\n\n// convenience function to add cone lights to the scene\nvoid add(inout Scene scene, in ConeLight light)\n{\n    scene.coneLights[scene.coneLightCount] = light;\n    ++scene.coneLightCount;\n}\n\n// convenience function to add cylinder lights to the scene\nvoid add(inout Scene scene, in CylinderLight light)\n{\n    scene.cylinderLights[scene.cylinderLightCount] = light;\n    ++scene.cylinderLightCount;\n}\n\n/*\n\t\\brief Returns the closest intersection in (minT,maxT), otherwise noIntersection()\n*/\nIntersection intersect(in Scene scene, in Ray ray, float minT, float maxT)\n{\n    Intersection result = noIntersection();\n    result.dist = maxT;\n    for(int i=0;i<scene.sphereCount;++i)\n    {\n        Intersection temp = intersect(scene.spheres[i], ray, minT, result.dist);\n        if(temp.dist < result.dist) result = temp;\n    }\n    if(result.dist<maxT)\n        return result;\n    else\n        return noIntersection();\n}\n\n/*\n\t\\brief Returns true if it intersects any object\n*/\nbool intersectAny(in Scene scene, in Ray ray, float minT, float maxT)\n{\n    for(int i=0;i<scene.sphereCount;++i)\n    {\n        if(intersectAny(scene.spheres[i], ray, minT, maxT)) return true;\n    }\n    return false;\n}\n\n\n\n\n\n/////////////////////////////////////////////////////////////////////////////////////////\n//\n//\t\t\t\t\t\t\t\t\t\tINTEGRATOR\n//\n/////////////////////////////////////////////////////////////////////////////////////////\n\n\n//! returns white/black for intersection/no intersection\nvec3 binaryIntegrator(in Scene scene, in Ray ray)\n{\n    return vec3(valid(intersect(scene, ray, 0.0, INFINITY)));\n}\n\n//! returns the color of objects \nvec3 colorIntegrator(in Scene scene, in Ray ray)\n{\n    return intersect(scene, ray, 0.0, INFINITY).color;\n}\n\n//! returns a greyscale color based on the reciprocal distance to intersections\nvec3 inverseDistanceIntegrator(in Scene scene, in Ray ray)\n{\n    return vec3(1.0/intersect(scene, ray, 0.0, INFINITY).dist);\n}\n\n//! returns an rgb color by mapping the normals from [-1,1]^3 to [0,1]^3\nvec3 normalIntegrator(in Scene scene, in Ray ray)\n{\n    Intersection intersection = intersect(scene, ray, 0.0, INFINITY);\n    \n    /*\n\t\tFind whether the normal is facing towards the camera or away from it\n\t\tA normal is facing towards the camera if the angle between the ray direction \n\t\tand the normal is greater than 90 degrees (if we set the ray direction origin \n\t\tat the intersection point).\n\n\t\tWe use the property of the dot product:\n\t\tdot(u,v) = length(u) * length(v) * cos(angle(u,v))\n\t\tSince length(ray.d) = 1 and length(intersection.normal) = 1\n\t\tWe get:\n\t\tcos(angle(ray.d, intersection.normal)) = dot(ray.d, intersection.normal)\n\t*/\n    float cosRayNormal = dot(ray.d, intersection.normal);\n    \n    /* \n\t\tIf the normal is facing away from the camera (for example if the ray \n    \torigin is inside a sphere), we need to flip it to get the correct \n\t\tfacing normal, since we treat our objects as 2-sided.\n\n    \tWe use the fact that the cosine of an angle greater than 90 degrees is negative.\n\t*/\n    vec3 normal = (cosRayNormal < 0.0) ? intersection.normal : -intersection.normal;\n    \n    /*\n\t\tReturn black if there is no intersection (valid(result) = 0 for no intersection)\n\t\tOtherwise return a color resulting from mapping the normal coordinates from\n\t\t[-1,1]^3 to [0,1]^3\n\t\tWith our conventions we have:\n\n\t\tPink for right facing normals: (1,0,0) -> (1,0.5,0.5)\n\t\tCyan for left facing normals: (-1,0,0) -> (0,0.5,0.5)\n\t\tLight green for up facing normals: (0,1,0) -> (0.5,1,0.5)\n\t\tPurple for down facing normals: (0,-1,0) -> (0.5,0,0.5)\n\t\tLight blue for forward facing normals: (0,0,1) -> (0.5,0.5,1)\n\t\tYellow/Orange for back facing normals: (0,0,-1) -> (0.5,0.5,0)\n\t\t\n\t*/\n    return float(valid(intersection))*(0.5*normal+0.5);\n}\n\n/*\n\t\\brief Computes the local (no shadows) direct illumination treating all objects as diffuse\n\n\tIterates over all light sources to compute the shading at the first ray-scene intersection.\n\tObjects cannot cast shadows, since we consider each object as if it was situated in a scene \n\twith no other objects. This is what rasterization graphics does (unless the visibility term \n\tis approximated by a shadow map/shadow volume).\n\n\tWe consider only direct illumination - that means that we ignore effects such as indirect \n\tillumination (some light bouncing off some other to illuminate our shading point). We will \n\tconsider some of those in an integrator introduced in the Whitted style ray tracing chapter, \n\tand most (if not all) of those in the path tracing chapter.\n*/\nvec3 diffuseLocalDirectIlluminationIntegrator(in Scene scene, in Ray ray)\n{\n    // compute the primary ray intersection with the scene\n    Intersection intersection = intersect(scene, ray, 0.0, INFINITY);\n    \n    // if there's no intersection return black\n    if(!valid(intersection)) return vec3(0);\n    \n    /*\n\t\tWe will accumulate the final color here (an estimation of the flux through a film pixel)\n\n\t\tIn the chapters on distributed ray tracing and path tracing we will elaborate more on the \n\t\tvirtual film, our camera model, and why it is precisely the flux that we are interested in.\n\t*/\n    vec3 color = vec3(0);\n    \n    // the position of the point being shaded\n    vec3 pos = intersection.pos;\n    /*\n\t\tthe INV_PI is so that the color of a material can be given in the range [0,1] and be\n    \tenergy conserving (we'll use this property later on with ray and path tracing, so that \n\t\twe can guarantee convergence with energy conserving materials)\n\t*/\n    vec3 albedo = intersection.color * INV_PI;\n    \n    /*\n\t\tSimilarly to the normal integrator we want to find the \n\t\tcorrect-facing normal, so that even if the camera is inside \n\t\ta sphere we get correct shading.\n\n\t\tNote that a light source may also be present inside of an object.\n\t*/\n    float cosRayNormal = dot(ray.d, intersection.normal);\n    vec3 normal = (cosRayNormal < 0.0) ? intersection.normal : -intersection.normal;\n    \n    \n    /*\n\t\tWe always add the ambient contribution since it's \"omnipresent\" in the scene.\n\t\tThe PI term comes from summing up all ambient contributions from all possible directions \n\t\ton the upper hemisphere around the normal of the intersection point.\n\n\t\tThis will become clear in the context of the rendering equation in the path tracing chapter.\n\t*/\n    color += PI * albedo * sampleRadiance(scene.ambientLight, pos).radiance;\n    \n    // iterate over all point light sources and accumulate their contribution\n    for(int i=0;i<scene.pointLightCount;++i)\n    {\n        // find the radiance travelling from the light to the intersection point\n        LightSample lightSample = sampleRadiance(scene.pointLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        /*\n\t\t\tthe (negative) direction along which light travels from our sample to the \n\t\t\tintersection point (it points from the intersection point to the light).\n\t\t*/\n        vec3 direction = lightSample.direction;\n        \n        /*\n\t\t\tThe foreshortening term due to Lambert's cosine law.\n\t\t\tWe limit it to non-negative values, since (with our assumptions \n\t\t\tabout opaque surfaces) light cannot arrive from the lower hemisphere \n\t\t\taround the normal of the intersection point. So we set the contribution \n\t\t\tto 0 in those cases.\n\t\t*/\n        float cosLambert = max(0.0,dot(normal, direction));\n        \n        /*\n\t\t\tIn the real world a light ray may intersect another object before reaching \n\t\t\ta specific point - meaning that if there is an object between our light source \n\t\t\tand the point being shaded, we should NOT add the light contribution. This allows \n\t\t\tfor shadows to be cast by objects.\n\n\t\t\tHowever, for this integrator we consider all objects locally - as if there were \n\t\t\tno other objects present in the scene. So we set the visibility term to 1.\n\t\t*/\n        float visibility = 1.0;\n        \n        /*\n\t\t\tHere we add the light contribution from point light i:\n        \t(this is simply the integrand of the rendering equation)\n        \tWe multiply by the visibility only to emphasize that this term \n\t\t\tshould actually be present in the general case (when we consider shadows).\n        */\n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // iterate over all directional light sources and accumulate their contribution\n    for(int i=0;i<scene.directionalLightCount;++i)\n    {\n        LightSample lightSample = sampleRadiance(scene.directionalLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        float cosLambert = max(0.0,dot(normal, direction));    \n        float visibility = 1.0;        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // iterate over all cone light sources and accumulate their contribution\n    for(int i=0;i<scene.coneLightCount;++i)\n    {\n       \tLightSample lightSample = sampleRadiance(scene.coneLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        float cosLambert = max(0.0,dot(normal, direction));    \n        float visibility = 1.0;        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // iterate over all cylinder light sources and accumulate their contribution\n    for(int i=0;i<scene.cylinderLightCount;++i)\n    {\n        LightSample lightSample = sampleRadiance(scene.cylinderLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        float cosLambert = max(0.0,dot(normal, direction));    \n        float visibility = 1.0;        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // return the accumulated color (flux)\n    return color;\n}\n\n/*\n\t\\brief Computes the direct illumination treating all objects as diffuse\n\n\tUnlike the local direct illumination integrator, this integrator considers visibility \n\tby shooting shadow rays. Thus objects can cast shadows in this case. It still does not \n\tmodel indirect illumination effects, hence the name.\n*/\nvec3 diffuseDirectIlluminationIntegrator(in Scene scene, in Ray ray)\n{\n    Intersection intersection = intersect(scene, ray, 0.0, INFINITY);\n    if(!valid(intersection)) return vec3(0);\n    \n    vec3 color = vec3(0);\n    \n    // normalize the material color\n    vec3 albedo = intersection.color * INV_PI;\n    \n    // flip the normal to face in the correct direction\n    float cosRayNormal = dot(ray.d, intersection.normal);\n    vec3 normal = (cosRayNormal < 0.0) ? intersection.normal : -intersection.normal;\n    \n    /*\n\t\tIn order to avoid self-intersection when shooting shadow rays, we offset the \n\t\tintersection point along the normal. This is necessary if one uses floating point \n\t\tnumbers, since round-off error may cause an intersection to end up on the \"wrong side\" \n\t\tof an object's surface. And if that happens, when shooting a shadow ray it will intersect \n\t\tthe surface we are trying to shade and it would be erroneously classified to be in shadow.\n\n\t\tA similar issue arises in rasterization graphics causing shadow acne. We encourage the reader \n\t\tto set EPSILON to 0, to see the self-intersection artifacts.\n\n\t\tWe use the normal since the direction in which the distance to the object sruface is \n\t\tshortest at this point is precisely the normal.\n\n\t\tNote that this is an issue inherent to floating point numbers and it does not arise \n\t\twhen one uses fixed-point or rational numbers. For more information see:\n\t\thttps://iquilezles.org/articles/floatingbar\n\t*/\n    vec3 pos = intersection.pos + EPSILON*normal;\n    \n    // add ambient light contribution\n    color += PI * albedo * sampleRadiance(scene.ambientLight, intersection.pos).radiance;\n    \n    // iterate over all point light sources and accumulate their contribution\n    for(int i=0;i<scene.pointLightCount;++i)\n    {\n        LightSample lightSample = sampleRadiance(scene.pointLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        // The term due to Lambert's cosine law\n        float cosLambert = max(0.0,dot(normal, direction));\n        \n        /*\n\t\t\tWe trace a ray segment from the (offset) intersection point until the light.\n\t\t\tIf we intersect any object in that range, this means that there is an object \n\t\t\toccluding the light source, so we set the visibility to 0.\n\t\t*/\n        Ray shadowRay = Ray(pos, direction);\n        float distanceToLight = lightSample.distanceToLight;\n        float visibility = float(!intersectAny(scene, shadowRay, 0.0, distanceToLight));\n        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // iterate over all directional light sources and accumulate their contribution\n    for(int i=0;i<scene.directionalLightCount;++i)\n    {\n        LightSample lightSample = sampleRadiance(scene.directionalLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        float cosLambert = max(0.0,dot(normal, direction));    \n        \n        Ray shadowRay = Ray(pos, direction);\n        float distanceToLight = lightSample.distanceToLight;\n        float visibility = float(!intersectAny(scene, shadowRay, 0.0, distanceToLight)); \n        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // iterate over all cone light sources and accumulate their contribution\n    for(int i=0;i<scene.coneLightCount;++i)\n    {\n       \tLightSample lightSample = sampleRadiance(scene.coneLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        float cosLambert = max(0.0,dot(normal, direction));   \n        \n        Ray shadowRay = Ray(pos, direction);\n        float distanceToLight = lightSample.distanceToLight;\n        float visibility = float(!intersectAny(scene, shadowRay, 0.0, distanceToLight)); \n        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // iterate over all cylinder light sources and accumulate their contribution\n    for(int i=0;i<scene.cylinderLightCount;++i)\n    {\n        LightSample lightSample = sampleRadiance(scene.cylinderLights[i], pos);\n        vec3 radiance = lightSample.radiance;\n        vec3 direction = lightSample.direction;\n        \n        float cosLambert = max(0.0,dot(normal, direction));    \n        \n        Ray shadowRay = Ray(pos, direction);\n        float distanceToLight = lightSample.distanceToLight;\n        float visibility = float(!intersectAny(scene, shadowRay, 0.0, distanceToLight));     \n        \n        color += albedo * radiance * cosLambert * visibility;\n    }\n    \n    // return the accumulated color (flux)\n    return color;\n}\n\n/*\n\t\\brief Treats all objects as transparent, with transparency defined by their color\n\n\tThis is the first integrator that spawns more than 1 ray, and it does so in succession.\n\tWe set the background to white in this case (in order for the transparency to be visible \n\twith the backdrop being empty space).\n\n\tNote that a valid optimization is finding all valid intersections just once, rather than the \n\tclosest one and attenuating based on that, however this requires modifying the intersect function \n\tfor the scene, or writing a custom loop here, which we avoid for simplicity. Albeit ineffcient, \n\tthe method that we use here will be used as a foundation to understand the algotihm we will \n\tuse for constructive solid geometry (CSG).\n*/\nvec3 transparencyIntegrator(in Scene scene, in Ray r)\n{ \n    /*\n\t\twe set the initial color to 1 and attenuate based on the color\n\t\tof the intersected surfaces\n\t*/\n    vec3 color = vec3(1);\n    \n    Ray ray = r;\n    \n    /*\n\t\tWe allow at most 10 iterations, which should be enough for 5 spheres (since each \n\t\tcan be intersected in at most 2 places by the same ray)\n\t*/\n    for(int i=0;i<10;++i)\n    {\n        // at each iteration find the new intersection\n        Intersection intersection = intersect(scene, ray, 0.0, INFINITY);\n        // if we intersect nothing return the current color\n        if(!valid(intersection)) return color;\n        \n        // flip the normal of the closest intersection to face in the correct direction\n    \tfloat cosRayNormal = dot(ray.d, intersection.normal);\n    \tvec3 normal = (cosRayNormal < 0.0) ? intersection.normal : -intersection.normal;\n        \n        /*\n\t\t\tThe ray below is the ray that will be used for the next intersection (it \n\t\t\tstarts off at the previous intersection and continues along the same direction).\n\n            Similar to the diffuse direct illumination integrator we perform an offset\n\t\t\tto avoid self-intersection, however, this time around we offset the \n\t\t\tintersection position to the other side of the surface, since we want to \n\t\t\tcontinue our ray on the opposite side.\n        */\n        ray = Ray(intersection.pos - EPSILON * normal, ray.d);\n        \n        // if we intersect an object, attenuate with its color:\n        color *= intersection.color;\n    }\n    // if we run out of iterations return black\n    return vec3(0);\n}",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "/*\n\t@author: Vassillen Chizhov, 2019\n\tRay tracing tutorial series\n\tChapter 1, part 2:\n\tRay Casting: Adding Integrators\n\n\tKeyboard input and state storage\n*/\n\n// ascii key codes\nconst int KEY_UP    = 38;\nconst int KEY_DOWN  = 40;\nconst int KEY_LEFT  = 37;\nconst int KEY_RIGHT = 39;\n\n/*\n\tThe function below checks whether a key has been just pressed (it was \n\tnot down last frame, but is down this frame).\n\n\tIn shadertoy we can access a texture with the current frame's key states\n\tThis is orthogonal to the goal of the tutorial series, so we do not go \n\tinto details on how to handle input in shadertoy. The interested reader \n\tmay refer to: \n\thttps://www.shadertoy.com/view/lsXGzf\n*/\nint keyPress(in int key)\n{\n \treturn int(texelFetch( iChannel0, ivec2(key,1), 0 ).x>0.0);\n}\n\n/*\n\tWe want to be able to save the state of the rendering mode and the light type to be used.\n\tFor that purpose we use the texture of BufferA, and we store our state in texel (0,0). \n\tIf no key is pressed we simply store the data from the previous frame.\n\tIf a key is pressed, we modify our data and store it.\n\n\tNote that the BufferA from which we are reading the previous frame's stored information, \n\tand the one we are writing to are actually two different buffers that get swapped after \n\teach frame (ping-ponging). For convenience they are presented as the same buffer in \n\tshadertoy.\n*/\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    /*\n\t\tLoad stored data from last frame from the (0,0) texel\n\t\tEach texel has 4 floating point channels, so we can store quite a bit of \n\t\tinformation (possibly encoded) in a single texel.\n\t*/\n    vec4 storedDataTexel00 = texelFetch( iChannel3, ivec2(0), 0).xyzw;\n    \n    // We store the integrator type in the x channel of the (0,0) texel\n    int renderMode = int(storedDataTexel00.x);\n    // We store the light type in the y channel of the (0,0) texel\n    int lightMode = int(storedDataTexel00.y);\n    \n    // poll rendering mode keys\n    renderMode += keyPress(KEY_UP) - keyPress(KEY_DOWN);\n    /*\n\t\tmodify rendering mode cyclically, we work in modulo RENDER_MODE_COUNT, \n\t\tthat is we only allow values: {0,1,2,..., RENDER_MODE_COUNT-1}\n\t*/\n    renderMode = negPosMod(renderMode, RENDER_MODE_COUNT);\n    \n    // poll the light mode keys\n    lightMode += keyPress(KEY_RIGHT) - keyPress(KEY_LEFT);\n    // modify light mode cyclically\n    lightMode = negPosMod(lightMode, LIGHT_MODE_COUNT);\n        \n    // store (updated) modes in the (0,0) texel\n    bool isTexel00 = all(equal(ivec2(fragCoord),ivec2(0)));\n    fragColor = vec4(isTexel00 ? vec4(float(renderMode),float(lightMode),0,0) : vec4(0));\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "keyboard",
                        "id": 33,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/presets/tex00.jpg"
                    },
                    {
                        "channel": 3,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}