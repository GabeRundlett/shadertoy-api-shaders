{
    "Shader": {
        "info": {
            "date": "1602686168",
            "description": "Comparison of some fast approximation (solid) and the actual reference implementation (dashed).",
            "flags": 32,
            "hasliked": 0,
            "id": "WdGcD1",
            "likes": 6,
            "name": "ACES Filmic Tonemapping",
            "published": 3,
            "tags": [
                "tonemapping",
                "filmic",
                "aces"
            ],
            "usePreview": 0,
            "username": "thepheer",
            "viewed": 1084
        },
        "renderpass": [
            {
                "code": "#define rep(m, x) (mod(x, 2.0*(m)) - (m))\n#define sdf(w, d) smoothstep(1.5*(w), 0.0, d)\n#define plot(w, x, y) sdf(w, abs((x) - (y)))\n#define range(x, a, b) ((a) <= (x) && (x) < (b))\n\nvoid mainImage(out vec4 rgba, vec2 xy) {\n    float dashed = sdf(1.0, abs(rep(6.0, xy.x)) - 4.0);\n    float dotted = sdf(1.0, abs(rep(2.0, xy.x)));\n    \n    vec2 px = 1.0/iResolution.xy;\n    vec2 uv = xy*px;\n\n    vec3 src = texture(iChannel0, vec2(xy.x, 0.5)*px).rgb;\n    vec3 ref = texture(iChannel0, vec2(xy.x, 1.5)*px).rgb;\n    vec3 apx = texture(iChannel0, vec2(xy.x, 2.5)*px).rgb;\n    \n    vec3 plots =\n        plot(px.y, uv.y, 0.7 + (apx - ref)) + // error\n        plot(px.y, uv.y, 0.7*ref)*dashed + // filmic\n        plot(px.y, uv.y, 0.7*apx); // filmic approx.\n\n    vec3 rgb =\n        range(uv.y, px.y + 0.95, 1.00) ? src : // source color\n    \trange(uv.y, px.y + 0.90, 0.95) ? ref : // filmic\n    \trange(uv.y, px.y + 0.85, 0.90) ? apx : // filmic approx.\n    \t0.5*plots;\n\n    rgba = vec4(linear_to_sRGB(rgb), 1.0);\n}\n",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "linear",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "// https://github.com/Unity-Technologies/PostProcessing/blob/v2/PostProcessing/Shaders/ACES.hlsl\n\n/**\n * https://github.com/ampas/aces-dev\n *\n * Academy Color Encoding System (ACES) software and tools are provided by the\n * Academy under the following terms and conditions: A worldwide, royalty-free,\n * non-exclusive right to copy, modify, create derivatives, and use, in source and\n * binary forms, is hereby granted, subject to acceptance of this license.\n *\n * Copyright 2015 Academy of Motion Picture Arts and Sciences (A.M.P.A.S.).\n * Portions contributed by others as indicated. All rights reserved.\n *\n * Performance of any of the aforementioned acts indicates acceptance to be bound\n * by the following terms and conditions:\n *\n * * Copies of source code, in whole or in part, must retain the above copyright\n * notice, this list of conditions and the Disclaimer of Warranty.\n *\n * * Use in binary form must retain the above copyright notice, this list of\n * conditions and the Disclaimer of Warranty in the documentation and/or other\n * materials provided with the distribution.\n *\n * * Nothing in this license shall be deemed to grant any rights to trademarks,\n * copyrights, patents, trade secrets or any other intellectual property of\n * A.M.P.A.S. or any contributors, except as expressly stated herein.\n *\n * * Neither the name \"A.M.P.A.S.\" nor the name of any other contributors to this\n * software may be used to endorse or promote products derivative of or based on\n * this software without express prior written permission of A.M.P.A.S. or the\n * contributors, as appropriate.\n *\n * This license shall be construed pursuant to the laws of the State of\n * California, and any disputes related thereto shall be subject to the\n * jurisdiction of the courts therein.\n *\n * Disclaimer of Warranty: THIS SOFTWARE IS PROVIDED BY A.M.P.A.S. AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,\n * THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND\n * NON-INFRINGEMENT ARE DISCLAIMED. IN NO EVENT SHALL A.M.P.A.S., OR ANY\n * CONTRIBUTORS OR DISTRIBUTORS, BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, RESITUTIONARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE\n * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF\n * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * WITHOUT LIMITING THE GENERALITY OF THE FOREGOING, THE ACADEMY SPECIFICALLY\n * DISCLAIMS ANY REPRESENTATIONS OR WARRANTIES WHATSOEVER RELATED TO PATENT OR\n * OTHER INTELLECTUAL PROPERTY RIGHTS IN THE ACADEMY COLOR ENCODING SYSTEM, OR\n * APPLICATIONS THEREOF, HELD BY PARTIES OTHER THAN A.M.P.A.S.,WHETHER DISCLOSED OR\n * UNDISCLOSED.\n */\n\n#define HALF float\n#define HALF2 vec2\n#define HALF3 vec3\n#define HALF4 vec4\n#define HALF3X3 mat3\n#define HALF4X4 mat4\n\n#define atan2 atan\n#define lerp mix\n#define log10(x) (log(x)/log(10.0))\n#define mul(a, b) ((b)*(a))\n#define saturate(x) clamp(x, 0.0, 1.0)\n\n// <include \"StdLib.hlsl\">\n#define HALF_MAX 65504.0 // (2 - 2^-10) * 2^15\n#define PI 3.14159265359\n#define FLT_MAX 3.402823466e+38 // Maximum representable floating-point number\nfloat FastSign(float x) { return saturate(x * FLT_MAX + 0.5) * 2.0 - 1.0; }\nfloat Min3(float a, float b, float c) { return min(min(a, b), c); }\nfloat Max3(float a, float b, float c) { return max(max(a, b), c); }\n// </include>\n\n#define ACEScc_MAX      1.4679964\n#define ACEScc_MIDGRAY  0.4135884\n\n//\n// Precomputed matrices (pre-transposed)\n// See https://github.com/ampas/aces-dev/blob/master/transforms/ctl/README-MATRIX.md\n//\n/*static*/ const HALF3X3 sRGB_2_AP0 = HALF3X3(\n    0.4397010, 0.3829780, 0.1773350,\n    0.0897923, 0.8134230, 0.0967616,\n    0.0175440, 0.1115440, 0.8707040\n);\n\n/*static*/ const HALF3X3 sRGB_2_AP1 = HALF3X3(\n    0.61319, 0.33951, 0.04737,\n    0.07021, 0.91634, 0.01345,\n    0.02062, 0.10957, 0.86961\n);\n\n/*static*/ const HALF3X3 AP0_2_sRGB = HALF3X3(\n    2.52169, -1.13413, -0.38756,\n    -0.27648, 1.37272, -0.09624,\n    -0.01538, -0.15298, 1.16835\n);\n\n/*static*/ const HALF3X3 AP1_2_sRGB = HALF3X3(\n    1.70505, -0.62179, -0.08326,\n    -0.13026, 1.14080, -0.01055,\n    -0.02400, -0.12897, 1.15297\n);\n\n/*static*/ const HALF3X3 AP0_2_AP1_MAT = HALF3X3(\n     1.4514393161, -0.2365107469, -0.2149285693,\n    -0.0765537734,  1.1762296998, -0.0996759264,\n     0.0083161484, -0.0060324498,  0.9977163014\n);\n\n/*static*/ const HALF3X3 AP1_2_AP0_MAT = HALF3X3(\n     0.6954522414, 0.1406786965, 0.1638690622,\n     0.0447945634, 0.8596711185, 0.0955343182,\n    -0.0055258826, 0.0040252103, 1.0015006723\n);\n\n/*static*/ const HALF3X3 AP1_2_XYZ_MAT = HALF3X3(\n     0.6624541811, 0.1340042065, 0.1561876870,\n     0.2722287168, 0.6740817658, 0.0536895174,\n    -0.0055746495, 0.0040607335, 1.0103391003\n);\n\n/*static*/ const HALF3X3 XYZ_2_AP1_MAT = HALF3X3(\n     1.6410233797, -0.3248032942, -0.2364246952,\n    -0.6636628587,  1.6153315917,  0.0167563477,\n     0.0117218943, -0.0082844420,  0.9883948585\n);\n\n/*static*/ const HALF3X3 XYZ_2_REC709_MAT = HALF3X3(\n     3.2409699419, -1.5373831776, -0.4986107603,\n    -0.9692436363,  1.8759675015,  0.0415550574,\n     0.0556300797, -0.2039769589,  1.0569715142\n);\n\n/*static*/ const HALF3X3 XYZ_2_REC2020_MAT = HALF3X3(\n     1.7166511880, -0.3556707838, -0.2533662814,\n    -0.6666843518,  1.6164812366,  0.0157685458,\n     0.0176398574, -0.0427706133,  0.9421031212\n);\n\n/*static*/ const HALF3X3 XYZ_2_DCIP3_MAT = HALF3X3(\n     2.7253940305, -1.0180030062, -0.4401631952,\n    -0.7951680258,  1.6897320548,  0.0226471906,\n     0.0412418914, -0.0876390192,  1.1009293786\n);\n\n/*static*/ const HALF3 AP1_RGB2Y = HALF3(0.272229, 0.674082, 0.0536895);\n\n/*static*/ const HALF3X3 RRT_SAT_MAT = HALF3X3(\n    0.9708890, 0.0269633, 0.00214758,\n    0.0108892, 0.9869630, 0.00214758,\n    0.0108892, 0.0269633, 0.96214800\n);\n\n/*static*/ const HALF3X3 ODT_SAT_MAT = HALF3X3(\n    0.949056, 0.0471857, 0.00375827,\n    0.019056, 0.9771860, 0.00375827,\n    0.019056, 0.0471857, 0.93375800\n);\n\n/*static*/ const HALF3X3 D60_2_D65_CAT = HALF3X3(\n     0.98722400, -0.00611327, 0.0159533,\n    -0.00759836,  1.00186000, 0.0053302,\n     0.00307257, -0.00509595, 1.0816800\n);\n\n//\n// Unity to ACES\n//\n// converts Unity raw (sRGB primaries) to\n//          ACES2065-1 (AP0 w/ linear encoding)\n//\nHALF3 unity_to_ACES(HALF3 x)\n{\n    x = mul(sRGB_2_AP0, x);\n    return x;\n}\n\n//\n// ACES to Unity\n//\n// converts ACES2065-1 (AP0 w/ linear encoding)\n//          Unity raw (sRGB primaries) to\n//\nHALF3 ACES_to_unity(HALF3 x)\n{\n    x = mul(AP0_2_sRGB, x);\n    return x;\n}\n\n//\n// Unity to ACEScg\n//\n// converts Unity raw (sRGB primaries) to\n//          ACEScg (AP1 w/ linear encoding)\n//\nHALF3 unity_to_ACEScg(HALF3 x)\n{\n    x = mul(sRGB_2_AP1, x);\n    return x;\n}\n\n//\n// ACEScg to Unity\n//\n// converts ACEScg (AP1 w/ linear encoding) to\n//          Unity raw (sRGB primaries)\n//\nHALF3 ACEScg_to_unity(HALF3 x)\n{\n    x = mul(AP1_2_sRGB, x);\n    return x;\n}\n\n//\n// ACES Color Space Conversion - ACES to ACEScc\n//\n// converts ACES2065-1 (AP0 w/ linear encoding) to\n//          ACEScc (AP1 w/ logarithmic encoding)\n//\n// This transform follows the formulas from section 4.4 in S-2014-003\n//\nHALF ACES_to_ACEScc(HALF x)\n{\n    if (x <= 0.0)\n        return -0.35828683; // = (log2(pow(2.0, -15.0) * 0.5) + 9.72) / 17.52\n    else if (x < pow(2.0, -15.0))\n        return (log2(pow(2.0, -16.0) + x * 0.5) + 9.72) / 17.52;\n    else // (x >= pow(2.0, -15.0))\n        return (log2(x) + 9.72) / 17.52;\n}\n\nHALF3 ACES_to_ACEScc(HALF3 x)\n{\n    x = clamp(x, 0.0, HALF_MAX);\n\n    // x is clamped to [0, HALF_MAX], skip the <= 0 check\n    //return (x < 0.00003051757) ? (log2(0.00001525878 + x * 0.5) + 9.72) / 17.52 : (log2(x) + 9.72) / 17.52;\n\n    return HALF3(\n        ACES_to_ACEScc(x.r),\n        ACES_to_ACEScc(x.g),\n        ACES_to_ACEScc(x.b)\n    );\n}\n\n//\n// ACES Color Space Conversion - ACEScc to ACES\n//\n// converts ACEScc (AP1 w/ ACESlog encoding) to\n//          ACES2065-1 (AP0 w/ linear encoding)\n//\n// This transform follows the formulas from section 4.4 in S-2014-003\n//\nHALF ACEScc_to_ACES(HALF x)\n{\n    // TODO: Optimize me\n    if (x < -0.3013698630) // (9.72 - 15) / 17.52\n        return (pow(2.0, x * 17.52 - 9.72) - pow(2.0, -16.0)) * 2.0;\n    else if (x < (log2(HALF_MAX) + 9.72) / 17.52)\n        return pow(2.0, x * 17.52 - 9.72);\n    else // (x >= (log2(HALF_MAX) + 9.72) / 17.52)\n        return HALF_MAX;\n}\n\nHALF3 ACEScc_to_ACES(HALF3 x)\n{\n    return HALF3(\n        ACEScc_to_ACES(x.r),\n        ACEScc_to_ACES(x.g),\n        ACEScc_to_ACES(x.b)\n    );\n}\n\n//\n// ACES Color Space Conversion - ACES to ACEScg\n//\n// converts ACES2065-1 (AP0 w/ linear encoding) to\n//          ACEScg (AP1 w/ linear encoding)\n//\nHALF3 ACES_to_ACEScg(HALF3 x)\n{\n    return mul(AP0_2_AP1_MAT, x);\n}\n\n//\n// ACES Color Space Conversion - ACEScg to ACES\n//\n// converts ACEScg (AP1 w/ linear encoding) to\n//          ACES2065-1 (AP0 w/ linear encoding)\n//\nHALF3 ACEScg_to_ACES(HALF3 x)\n{\n    return mul(AP1_2_AP0_MAT, x);\n}\n\n//\n// Reference Rendering Transform (RRT)\n//\n//   Input is ACES\n//   Output is OCES\n//\nHALF rgb_2_saturation(HALF3 rgb)\n{\n    const HALF TINY = 1e-4;\n    HALF mi = Min3(rgb.r, rgb.g, rgb.b);\n    HALF ma = Max3(rgb.r, rgb.g, rgb.b);\n    return (max(ma, TINY) - max(mi, TINY)) / max(ma, 1e-2);\n}\n\nHALF rgb_2_yc(HALF3 rgb)\n{\n    const HALF ycRadiusWeight = 1.75;\n\n    // Converts RGB to a luminance proxy, here called YC\n    // YC is ~ Y + K * Chroma\n    // Constant YC is a cone-shaped surface in RGB space, with the tip on the\n    // neutral axis, towards white.\n    // YC is normalized: RGB 1 1 1 maps to YC = 1\n    //\n    // ycRadiusWeight defaults to 1.75, although can be overridden in function\n    // call to rgb_2_yc\n    // ycRadiusWeight = 1 -> YC for pure cyan, magenta, yellow == YC for neutral\n    // of same value\n    // ycRadiusWeight = 2 -> YC for pure red, green, blue  == YC for  neutral of\n    // same value.\n\n    HALF r = rgb.x;\n    HALF g = rgb.y;\n    HALF b = rgb.z;\n    HALF chroma = sqrt(b * (b - g) + g * (g - r) + r * (r - b));\n    return (b + g + r + ycRadiusWeight * chroma) / 3.0;\n}\n\nHALF rgb_2_hue(HALF3 rgb)\n{\n    // Returns a geometric hue angle in degrees (0-360) based on RGB values.\n    // For neutral colors, hue is undefined and the function will return a quiet NaN value.\n    HALF hue;\n    if (rgb.x == rgb.y && rgb.y == rgb.z)\n        hue = 0.0; // RGB triplets where RGB are equal have an undefined hue\n    else\n        hue = (180.0 / PI) * atan2(sqrt(3.0) * (rgb.y - rgb.z), 2.0 * rgb.x - rgb.y - rgb.z);\n\n    if (hue < 0.0) hue = hue + 360.0;\n\n    return hue;\n}\n\nHALF center_hue(HALF hue, HALF centerH)\n{\n    HALF hueCentered = hue - centerH;\n    if (hueCentered < -180.0) hueCentered = hueCentered + 360.0;\n    else if (hueCentered > 180.0) hueCentered = hueCentered - 360.0;\n    return hueCentered;\n}\n\nHALF sigmoid_shaper(HALF x)\n{\n    // Sigmoid function in the range 0 to 1 spanning -2 to +2.\n\n    HALF t = max(1.0 - abs(x / 2.0), 0.0);\n    HALF y = 1.0 + FastSign(x) * (1.0 - t * t);\n\n    return y / 2.0;\n}\n\nHALF glow_fwd(HALF ycIn, HALF glowGainIn, HALF glowMid)\n{\n    HALF glowGainOut;\n\n    if (ycIn <= 2.0 / 3.0 * glowMid)\n        glowGainOut = glowGainIn;\n    else if (ycIn >= 2.0 * glowMid)\n        glowGainOut = 0.0;\n    else\n        glowGainOut = glowGainIn * (glowMid / ycIn - 1.0 / 2.0);\n\n    return glowGainOut;\n}\n\nHALF cubic_basis_shaper\n(\n    HALF x,\n    HALF w   // full base width of the shaper function (in degrees)\n)\n{\n    HALF4X4 M = HALF4X4(\n        HALF4( -1.0 / 6.0,  3.0 / 6.0, -3.0 / 6.0,  1.0 / 6.0 ),\n        HALF4(  3.0 / 6.0, -6.0 / 6.0,  3.0 / 6.0,  0.0 / 6.0 ),\n        HALF4( -3.0 / 6.0,  0.0 / 6.0,  3.0 / 6.0,  0.0 / 6.0 ),\n        HALF4(  1.0 / 6.0,  4.0 / 6.0,  1.0 / 6.0,  0.0 / 6.0 )\n    );\n\n    HALF knots[5] = HALF[](\n        -w / 2.0,\n        -w / 4.0,\n             0.0,\n         w / 4.0,\n         w / 2.0\n    );\n\n    HALF y = 0.0;\n    if ((x > knots[0]) && (x < knots[4]))\n    {\n        HALF knot_coord = (x - knots[0]) * 4.0 / w;\n        int j = int(knot_coord);\n        HALF t = knot_coord - HALF(j);\n\n        HALF monomials[4] = HALF[](t*t*t, t*t, t, 1.0);\n\n        // (if/else structure required for compatibility with CTL < v1.5.)\n        if (j == 3)\n        {\n            y = monomials[0] * M[0][0] + monomials[1] * M[1][0] +\n                monomials[2] * M[2][0] + monomials[3] * M[3][0];\n        }\n        else if (j == 2)\n        {\n            y = monomials[0] * M[0][1] + monomials[1] * M[1][1] +\n                monomials[2] * M[2][1] + monomials[3] * M[3][1];\n        }\n        else if (j == 1)\n        {\n            y = monomials[0] * M[0][2] + monomials[1] * M[1][2] +\n                monomials[2] * M[2][2] + monomials[3] * M[3][2];\n        }\n        else if (j == 0)\n        {\n            y = monomials[0] * M[0][3] + monomials[1] * M[1][3] +\n                monomials[2] * M[2][3] + monomials[3] * M[3][3];\n        }\n        else\n        {\n            y = 0.0;\n        }\n    }\n\n    return y * 3.0 / 2.0;\n}\n\n/*static*/ const HALF3X3 M = HALF3X3(\n     0.5, -1.0, 0.5,\n    -1.0,  1.0, 0.0,\n     0.5,  0.5, 0.0\n);\n\nHALF segmented_spline_c5_fwd(HALF x)\n{\n    const HALF coefsLow[6] = HALF[](-4.0000000000, -4.0000000000, -3.1573765773, -0.4852499958, 1.8477324706, 1.8477324706); // coefs for B-spline between minPoint and midPoint (units of log luminance)\n    const HALF coefsHigh[6] = HALF[](-0.7185482425, 2.0810307172, 3.6681241237, 4.0000000000, 4.0000000000, 4.0000000000); // coefs for B-spline between midPoint and maxPoint (units of log luminance)\n    const HALF2 minPoint = HALF2(0.18 * exp2(-15.0), 0.0001); // {luminance, luminance} linear extension below this\n    const HALF2 midPoint = HALF2(0.18, 0.48); // {luminance, luminance}\n    const HALF2 maxPoint = HALF2(0.18 * exp2(18.0), 10000.0); // {luminance, luminance} linear extension above this\n    const HALF slopeLow = 0.0; // log-log slope of low linear extension\n    const HALF slopeHigh = 0.0; // log-log slope of high linear extension\n\n    const int N_KNOTS_LOW = 4;\n    const int N_KNOTS_HIGH = 4;\n\n    // Check for negatives or zero before taking the log. If negative or zero,\n    // set to ACESMIN.1\n    float xCheck = x;\n    if (xCheck <= 0.0) xCheck = 0.00006103515; // = pow(2.0, -14.0);\n\n    HALF logx = log10(xCheck);\n    HALF logy;\n\n    if (logx <= log10(minPoint.x))\n    {\n        logy = logx * slopeLow + (log10(minPoint.y) - slopeLow * log10(minPoint.x));\n    }\n    else if ((logx > log10(minPoint.x)) && (logx < log10(midPoint.x)))\n    {\n        HALF knot_coord = HALF(N_KNOTS_LOW - 1) * (logx - log10(minPoint.x)) / (log10(midPoint.x) - log10(minPoint.x));\n        int j = int(knot_coord);\n        HALF t = knot_coord - HALF(j);\n\n        HALF3 cf = HALF3(coefsLow[j], coefsLow[j + 1], coefsLow[j + 2]);\n        HALF3 monomials = HALF3(t * t, t, 1.0);\n        logy = dot(monomials, mul(M, cf));\n    }\n    else if ((logx >= log10(midPoint.x)) && (logx < log10(maxPoint.x)))\n    {\n        HALF knot_coord = HALF(N_KNOTS_HIGH - 1) * (logx - log10(midPoint.x)) / (log10(maxPoint.x) - log10(midPoint.x));\n        int j = int(knot_coord);\n        HALF t = knot_coord - HALF(j);\n\n        HALF3 cf = HALF3(coefsHigh[j], coefsHigh[j + 1], coefsHigh[j + 2]);\n        HALF3 monomials = HALF3(t * t, t, 1.0);\n        logy = dot(monomials, mul(M, cf));\n    }\n    else\n    { //if (logIn >= log10(maxPoint.x)) {\n        logy = logx * slopeHigh + (log10(maxPoint.y) - slopeHigh * log10(maxPoint.x));\n    }\n\n    return pow(10.0, logy);\n}\n\nHALF segmented_spline_c9_fwd(HALF x)\n{\n    const HALF coefsLow[10] = HALF[](-1.6989700043, -1.6989700043, -1.4779000000, -1.2291000000, -0.8648000000, -0.4480000000, 0.0051800000, 0.4511080334, 0.9113744414, 0.9113744414); // coefs for B-spline between minPoint and midPoint (units of log luminance)\n    const HALF coefsHigh[10] = HALF[](0.5154386965, 0.8470437783, 1.1358000000, 1.3802000000, 1.5197000000, 1.5985000000, 1.6467000000, 1.6746091357, 1.6878733390, 1.6878733390); // coefs for B-spline between midPoint and maxPoint (units of log luminance)\n    /*const*/ HALF2 minPoint = HALF2(segmented_spline_c5_fwd(0.18 * exp2(-6.5)), 0.02); // {luminance, luminance} linear extension below this\n    /*const*/ HALF2 midPoint = HALF2(segmented_spline_c5_fwd(0.18), 4.8); // {luminance, luminance}\n    /*const*/ HALF2 maxPoint = HALF2(segmented_spline_c5_fwd(0.18 * exp2(6.5)), 48.0); // {luminance, luminance} linear extension above this\n    const HALF slopeLow = 0.0; // log-log slope of low linear extension\n    const HALF slopeHigh = 0.04; // log-log slope of high linear extension\n\n    const int N_KNOTS_LOW = 8;\n    const int N_KNOTS_HIGH = 8;\n\n    // Check for negatives or zero before taking the log. If negative or zero,\n    // set to OCESMIN.\n    HALF xCheck = x;\n    if (xCheck <= 0.0) xCheck = 1e-4;\n\n    HALF logx = log10(xCheck);\n    HALF logy;\n\n    if (logx <= log10(minPoint.x))\n    {\n        logy = logx * slopeLow + (log10(minPoint.y) - slopeLow * log10(minPoint.x));\n    }\n    else if ((logx > log10(minPoint.x)) && (logx < log10(midPoint.x)))\n    {\n        HALF knot_coord = HALF(N_KNOTS_LOW - 1) * (logx - log10(minPoint.x)) / (log10(midPoint.x) - log10(minPoint.x));\n        int j = int(knot_coord);\n        HALF t = knot_coord - HALF(j);\n\n        HALF3 cf = HALF3(coefsLow[j], coefsLow[j + 1], coefsLow[j + 2]);\n        HALF3 monomials = HALF3(t * t, t, 1.0);\n        logy = dot(monomials, mul(M, cf));\n    }\n    else if ((logx >= log10(midPoint.x)) && (logx < log10(maxPoint.x)))\n    {\n        HALF knot_coord = HALF(N_KNOTS_HIGH - 1) * (logx - log10(midPoint.x)) / (log10(maxPoint.x) - log10(midPoint.x));\n        int j = int(knot_coord);\n        HALF t = knot_coord - HALF(j);\n\n        HALF3 cf = HALF3(coefsHigh[j], coefsHigh[j + 1], coefsHigh[j + 2]);\n        HALF3 monomials = HALF3(t * t, t, 1.0);\n        logy = dot(monomials, mul(M, cf));\n    }\n    else\n    { //if (logIn >= log10(maxPoint.x)) {\n        logy = logx * slopeHigh + (log10(maxPoint.y) - slopeHigh * log10(maxPoint.x));\n    }\n\n    return pow(10.0, logy);\n}\n\n/*static*/ const HALF RRT_GLOW_GAIN = 0.05;\n/*static*/ const HALF RRT_GLOW_MID = 0.08;\n\n/*static*/ const HALF RRT_RED_SCALE = 0.82;\n/*static*/ const HALF RRT_RED_PIVOT = 0.03;\n/*static*/ const HALF RRT_RED_HUE = 0.0;\n/*static*/ const HALF RRT_RED_WIDTH = 135.0;\n\n/*static*/ const HALF RRT_SAT_FACTOR = 0.96;\n\nHALF3 RRT(HALF3 aces)\n{\n    // --- Glow module --- //\n    HALF saturation = rgb_2_saturation(aces);\n    HALF ycIn = rgb_2_yc(aces);\n    HALF s = sigmoid_shaper((saturation - 0.4) / 0.2);\n    HALF addedGlow = 1.0 + glow_fwd(ycIn, RRT_GLOW_GAIN * s, RRT_GLOW_MID);\n    aces *= addedGlow;\n\n    // --- Red modifier --- //\n    HALF hue = rgb_2_hue(aces);\n    HALF centeredHue = center_hue(hue, RRT_RED_HUE);\n    HALF hueWeight;\n    {\n        //hueWeight = cubic_basis_shaper(centeredHue, RRT_RED_WIDTH);\n        hueWeight = smoothstep(0.0, 1.0, 1.0 - abs(2.0 * centeredHue / RRT_RED_WIDTH));\n        hueWeight *= hueWeight;\n    }\n\n    aces.r += hueWeight * saturation * (RRT_RED_PIVOT - aces.r) * (1.0 - RRT_RED_SCALE);\n\n    // --- ACES to RGB rendering space --- //\n    aces = clamp(aces, 0.0, HALF_MAX);  // avoids saturated negative colors from becoming positive in the matrix\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, aces);\n    rgbPre = clamp(rgbPre, 0.0, HALF_MAX);\n\n    // --- Global desaturation --- //\n    //rgbPre = mul(RRT_SAT_MAT, rgbPre);\n    rgbPre = lerp(HALF3(dot(rgbPre, AP1_RGB2Y)), rgbPre, RRT_SAT_FACTOR);\n\n    // --- Apply the tonescale independently in rendering-space RGB --- //\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c5_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c5_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c5_fwd(rgbPre.z);\n\n    // --- RGB rendering space to OCES --- //\n    HALF3 rgbOces = mul(AP1_2_AP0_MAT, rgbPost);\n\n    return rgbOces;\n}\n\n//\n// Output Device Transform\n//\nHALF3 Y_2_linCV(HALF3 Y, HALF Ymax, HALF Ymin)\n{\n    return (Y - Ymin) / (Ymax - Ymin);\n}\n\nHALF3 XYZ_2_xyY(HALF3 XYZ)\n{\n    HALF divisor = max(dot(XYZ, HALF3(1.0)), 1e-4);\n    return HALF3(XYZ.xy / divisor, XYZ.y);\n}\n\nHALF3 xyY_2_XYZ(HALF3 xyY)\n{\n    HALF m = xyY.z / max(xyY.y, 1e-4);\n    HALF3 XYZ = HALF3(xyY.xz, (1.0 - xyY.x - xyY.y));\n    XYZ.xz *= m;\n    return XYZ;\n}\n\n/*static*/ const HALF DIM_SURROUND_GAMMA = 0.9811;\n\nHALF3 darkSurround_to_dimSurround(HALF3 linearCV)\n{\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    HALF3 xyY = XYZ_2_xyY(XYZ);\n    xyY.z = clamp(xyY.z, 0.0, HALF_MAX);\n    xyY.z = pow(xyY.z, DIM_SURROUND_GAMMA);\n    XYZ = xyY_2_XYZ(xyY);\n\n    return mul(XYZ_2_AP1_MAT, XYZ);\n}\n\nHALF moncurve_r(HALF y, HALF gamma, HALF offs)\n{\n    // Reverse monitor curve\n    HALF x;\n    /*const*/ HALF yb = pow(offs * gamma / ((gamma - 1.0) * (1.0 + offs)), gamma);\n    /*const*/ HALF rs = pow((gamma - 1.0) / offs, gamma - 1.0) * pow((1.0 + offs) / gamma, gamma);\n    if (y >= yb)\n        x = (1.0 + offs) * pow(y, 1.0 / gamma) - offs;\n    else\n        x = y * rs;\n    return x;\n}\n\nHALF bt1886_r(HALF L, HALF gamma, HALF Lw, HALF Lb)\n{\n    // The reference EOTF specified in Rec. ITU-R BT.1886\n    // L = a(max[(V+b),0])^g\n    HALF a = pow(pow(Lw, 1.0 / gamma) - pow(Lb, 1.0 / gamma), gamma);\n    HALF b = pow(Lb, 1.0 / gamma) / (pow(Lw, 1.0 / gamma) - pow(Lb, 1.0 / gamma));\n    HALF V = pow(max(L / a, 0.0), 1.0 / gamma) - b;\n    return V;\n}\n\nHALF roll_white_fwd(\n    HALF x,       // color value to adjust (white scaled to around 1.0)\n    HALF new_wht, // white adjustment (e.g. 0.9 for 10% darkening)\n    HALF width    // adjusted width (e.g. 0.25 for top quarter of the tone scale)\n    )\n{\n    const HALF x0 = -1.0;\n    /*const*/ HALF x1 = x0 + width;\n    /*const*/ HALF y0 = -new_wht;\n    /*const*/ HALF y1 = x1;\n    /*const*/ HALF m1 = (x1 - x0);\n    /*const*/ HALF a = y0 - y1 + m1;\n    /*const*/ HALF b = 2.0 * (y1 - y0) - m1;\n    /*const*/ HALF c = y0;\n    /*const*/ HALF t = (-x - x0) / (x1 - x0);\n    HALF o = 0.0;\n    if (t < 0.0)\n        o = -(t * b + c);\n    else if (t > 1.0)\n        o = x;\n    else\n        o = -((t * a + b) * t + c);\n    return o;\n}\n\nHALF3 linear_to_sRGB(HALF3 x)\n{\n    // return (x <= 0.0031308 ? (x * 12.9232102) : 1.055 * pow(x, 1.0 / 2.4) - 0.055);\n    return lerp(1.055 * pow(x, HALF3(1.0 / 2.4)) - 0.055, (x * 12.9232102), lessThanEqual(x, HALF3(0.0031308)));\n}\n\nHALF3 linear_to_bt1886(HALF3 x, HALF gamma, HALF Lw, HALF Lb)\n{\n    // Good enough approximation for now, may consider using the exact formula instead\n    // TODO: Experiment\n    return pow(max(x, 0.0), HALF3(1.0 / 2.4));\n\n    // Correct implementation (Reference EOTF specified in Rec. ITU-R BT.1886) :\n    // L = a(max[(V+b),0])^g\n    HALF invgamma = 1.0 / gamma;\n    HALF p_Lw = pow(Lw, invgamma);\n    HALF p_Lb = pow(Lb, invgamma);\n    HALF3 a = HALF3(pow(p_Lw - p_Lb, gamma));\n    HALF3 b = HALF3(p_Lb / p_Lw - p_Lb);\n    HALF3 V = pow(max(x / a, 0.0), HALF3(invgamma)) - b;\n    return V;\n}\n\n/*static*/ const HALF CINEMA_WHITE = 48.0;\n/*static*/ const HALF CINEMA_BLACK = CINEMA_WHITE / 2400.0;\n/*static*/ const HALF ODT_SAT_FACTOR = 0.93;\n\n// <ACEStransformID>ODT.Academy.RGBmonitor_100nits_dim.a1.0.3</ACEStransformID>\n// <ACESuserName>ACES 1.0 Output - sRGB</ACESuserName>\n\n//\n// Output Device Transform - RGB computer monitor\n//\n\n//\n// Summary :\n//  This transform is intended for mapping OCES onto a desktop computer monitor\n//  typical of those used in motion picture visual effects production. These\n//  monitors may occasionally be referred to as \"sRGB\" displays, however, the\n//  monitor for which this transform is designed does not exactly match the\n//  specifications in IEC 61966-2-1:1999.\n//\n//  The assumed observer adapted white is D65, and the viewing environment is\n//  that of a dim surround.\n//\n//  The monitor specified is intended to be more typical of those found in\n//  visual effects production.\n//\n// Device Primaries :\n//  Primaries are those specified in Rec. ITU-R BT.709\n//  CIE 1931 chromaticities:  x         y         Y\n//              Red:          0.64      0.33\n//              Green:        0.3       0.6\n//              Blue:         0.15      0.06\n//              White:        0.3127    0.329     100 cd/m^2\n//\n// Display EOTF :\n//  The reference electro-optical transfer function specified in\n//  IEC 61966-2-1:1999.\n//\n// Signal Range:\n//    This transform outputs full range code values.\n//\n// Assumed observer adapted white point:\n//         CIE 1931 chromaticities:    x            y\n//                                     0.3127       0.329\n//\n// Viewing Environment:\n//   This ODT has a compensation for viewing environment variables more typical\n//   of those associated with video mastering.\n//\nHALF3 ODT_RGBmonitor_100nits_dim(HALF3 oces)\n{\n    // OCES to RGB rendering space\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, oces);\n\n    // Apply the tonescale independently in rendering-space RGB\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c9_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c9_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c9_fwd(rgbPre.z);\n\n    // Scale luminance to linear code value\n    HALF3 linearCV = Y_2_linCV(rgbPost, CINEMA_WHITE, CINEMA_BLACK);\n\n     // Apply gamma adjustment to compensate for dim surround\n    linearCV = darkSurround_to_dimSurround(linearCV);\n\n    // Apply desaturation to compensate for luminance difference\n    //linearCV = mul(ODT_SAT_MAT, linearCV);\n    linearCV = lerp(HALF3(dot(linearCV, AP1_RGB2Y)), linearCV, ODT_SAT_FACTOR);\n\n    // Convert to display primary encoding\n    // Rendering space RGB to XYZ\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    // Apply CAT from ACES white point to assumed observer adapted white point\n    XYZ = mul(D60_2_D65_CAT, XYZ);\n\n    // CIE XYZ to display primaries\n    linearCV = mul(XYZ_2_REC709_MAT, XYZ);\n\n    // Handle out-of-gamut values\n    // Clip values < 0 or > 1 (i.e. projecting outside the display primaries)\n    linearCV = saturate(linearCV);\n\n    // TODO: Revisit when it is possible to deactivate Unity default framebuffer encoding\n    // with sRGB opto-electrical transfer function (OETF).\n    /*\n    // Encode linear code values with transfer function\n    HALF3 outputCV;\n    // moncurve_r with gamma of 2.4 and offset of 0.055 matches the EOTF found in IEC 61966-2-1:1999 (sRGB)\n    const HALF DISPGAMMA = 2.4;\n    const HALF OFFSET = 0.055;\n    outputCV.x = moncurve_r(linearCV.x, DISPGAMMA, OFFSET);\n    outputCV.y = moncurve_r(linearCV.y, DISPGAMMA, OFFSET);\n    outputCV.z = moncurve_r(linearCV.z, DISPGAMMA, OFFSET);\n\n    outputCV = linear_to_sRGB(linearCV);\n    */\n\n    // Unity already draws to a sRGB target\n    return linearCV;\n}\n\n// <ACEStransformID>ODT.Academy.RGBmonitor_D60sim_100nits_dim.a1.0.3</ACEStransformID>\n// <ACESuserName>ACES 1.0 Output - sRGB (D60 sim.)</ACESuserName>\n\n//\n// Output Device Transform - RGB computer monitor (D60 simulation)\n//\n\n//\n// Summary :\n//  This transform is intended for mapping OCES onto a desktop computer monitor\n//  typical of those used in motion picture visual effects production. These\n//  monitors may occasionally be referred to as \"sRGB\" displays, however, the\n//  monitor for which this transform is designed does not exactly match the\n//  specifications in IEC 61966-2-1:1999.\n//\n//  The assumed observer adapted white is D60, and the viewing environment is\n//  that of a dim surround.\n//\n//  The monitor specified is intended to be more typical of those found in\n//  visual effects production.\n//\n// Device Primaries :\n//  Primaries are those specified in Rec. ITU-R BT.709\n//  CIE 1931 chromaticities:  x         y         Y\n//              Red:          0.64      0.33\n//              Green:        0.3       0.6\n//              Blue:         0.15      0.06\n//              White:        0.3127    0.329     100 cd/m^2\n//\n// Display EOTF :\n//  The reference electro-optical transfer function specified in\n//  IEC 61966-2-1:1999.\n//\n// Signal Range:\n//    This transform outputs full range code values.\n//\n// Assumed observer adapted white point:\n//         CIE 1931 chromaticities:    x            y\n//                                     0.32168      0.33767\n//\n// Viewing Environment:\n//   This ODT has a compensation for viewing environment variables more typical\n//   of those associated with video mastering.\n//\nHALF3 ODT_RGBmonitor_D60sim_100nits_dim(HALF3 oces)\n{\n    // OCES to RGB rendering space\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, oces);\n\n    // Apply the tonescale independently in rendering-space RGB\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c9_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c9_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c9_fwd(rgbPre.z);\n\n    // Scale luminance to linear code value\n    HALF3 linearCV = Y_2_linCV(rgbPost, CINEMA_WHITE, CINEMA_BLACK);\n\n    // --- Compensate for different white point being darker  --- //\n    // This adjustment is to correct an issue that exists in ODTs where the device\n    // is calibrated to a white chromaticity other than D60. In order to simulate\n    // D60 on such devices, unequal code values are sent to the display to achieve\n    // neutrals at D60. In order to produce D60 on a device calibrated to the DCI\n    // white point (i.e. equal code values yield CIE x,y chromaticities of 0.314,\n    // 0.351) the red channel is higher than green and blue to compensate for the\n    // \"greenish\" DCI white. This is the correct behavior but it means that as\n    // highlight increase, the red channel will hit the device maximum first and\n    // clip, resulting in a chromaticity shift as the green and blue channels\n    // continue to increase.\n    // To avoid this clipping error, a slight scale factor is applied to allow the\n    // ODTs to simulate D60 within the D65 calibration white point.\n\n    // Scale and clamp white to avoid casted highlights due to D60 simulation\n    const HALF SCALE = 0.955;\n    linearCV = min(linearCV, 1.0) * SCALE;\n\n    // Apply gamma adjustment to compensate for dim surround\n    linearCV = darkSurround_to_dimSurround(linearCV);\n\n    // Apply desaturation to compensate for luminance difference\n    //linearCV = mul(ODT_SAT_MAT, linearCV);\n    linearCV = lerp(HALF3(dot(linearCV, AP1_RGB2Y)), linearCV, ODT_SAT_FACTOR);\n\n    // Convert to display primary encoding\n    // Rendering space RGB to XYZ\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    // CIE XYZ to display primaries\n    linearCV = mul(XYZ_2_REC709_MAT, XYZ);\n\n    // Handle out-of-gamut values\n    // Clip values < 0 or > 1 (i.e. projecting outside the display primaries)\n    linearCV = saturate(linearCV);\n\n    // TODO: Revisit when it is possible to deactivate Unity default framebuffer encoding\n    // with sRGB opto-electrical transfer function (OETF).\n    /*\n    // Encode linear code values with transfer function\n    HALF3 outputCV;\n    // moncurve_r with gamma of 2.4 and offset of 0.055 matches the EOTF found in IEC 61966-2-1:1999 (sRGB)\n    const HALF DISPGAMMA = 2.4;\n    const HALF OFFSET = 0.055;\n    outputCV.x = moncurve_r(linearCV.x, DISPGAMMA, OFFSET);\n    outputCV.y = moncurve_r(linearCV.y, DISPGAMMA, OFFSET);\n    outputCV.z = moncurve_r(linearCV.z, DISPGAMMA, OFFSET);\n\n    outputCV = linear_to_sRGB(linearCV);\n    */\n\n    // Unity already draws to a sRGB target\n    return linearCV;\n}\n\n// <ACEStransformID>ODT.Academy.Rec709_100nits_dim.a1.0.3</ACEStransformID>\n// <ACESuserName>ACES 1.0 Output - Rec.709</ACESuserName>\n\n//\n// Output Device Transform - Rec709\n//\n\n//\n// Summary :\n//  This transform is intended for mapping OCES onto a Rec.709 broadcast monitor\n//  that is calibrated to a D65 white point at 100 cd/m^2. The assumed observer\n//  adapted white is D65, and the viewing environment is a dim surround.\n//\n//  A possible use case for this transform would be HDTV/video mastering.\n//\n// Device Primaries :\n//  Primaries are those specified in Rec. ITU-R BT.709\n//  CIE 1931 chromaticities:  x         y         Y\n//              Red:          0.64      0.33\n//              Green:        0.3       0.6\n//              Blue:         0.15      0.06\n//              White:        0.3127    0.329     100 cd/m^2\n//\n// Display EOTF :\n//  The reference electro-optical transfer function specified in\n//  Rec. ITU-R BT.1886.\n//\n// Signal Range:\n//    By default, this transform outputs full range code values. If instead a\n//    SMPTE \"legal\" signal is desired, there is a runtime flag to output\n//    SMPTE legal signal. In ctlrender, this can be achieved by appending\n//    '-param1 legalRange 1' after the '-ctl odt.ctl' string.\n//\n// Assumed observer adapted white point:\n//         CIE 1931 chromaticities:    x            y\n//                                     0.3127       0.329\n//\n// Viewing Environment:\n//   This ODT has a compensation for viewing environment variables more typical\n//   of those associated with video mastering.\n//\nHALF3 ODT_Rec709_100nits_dim(HALF3 oces)\n{\n    // OCES to RGB rendering space\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, oces);\n\n    // Apply the tonescale independently in rendering-space RGB\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c9_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c9_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c9_fwd(rgbPre.z);\n\n    // Scale luminance to linear code value\n    HALF3 linearCV = Y_2_linCV(rgbPost, CINEMA_WHITE, CINEMA_BLACK);\n\n    // Apply gamma adjustment to compensate for dim surround\n    linearCV = darkSurround_to_dimSurround(linearCV);\n\n    // Apply desaturation to compensate for luminance difference\n    //linearCV = mul(ODT_SAT_MAT, linearCV);\n    linearCV = lerp(HALF3(dot(linearCV, AP1_RGB2Y)), linearCV, ODT_SAT_FACTOR);\n\n    // Convert to display primary encoding\n    // Rendering space RGB to XYZ\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    // Apply CAT from ACES white point to assumed observer adapted white point\n    XYZ = mul(D60_2_D65_CAT, XYZ);\n\n    // CIE XYZ to display primaries\n    linearCV = mul(XYZ_2_REC709_MAT, XYZ);\n\n    // Handle out-of-gamut values\n    // Clip values < 0 or > 1 (i.e. projecting outside the display primaries)\n    linearCV = saturate(linearCV);\n\n    // Encode linear code values with transfer function\n    const HALF DISPGAMMA = 2.4;\n    const HALF L_W = 1.0;\n    const HALF L_B = 0.0;\n    HALF3 outputCV = linear_to_bt1886(linearCV, DISPGAMMA, L_W, L_B);\n\n    // TODO: Implement support for legal range.\n\n    // NOTE: Unity framebuffer encoding is encoded with sRGB opto-electrical transfer function (OETF)\n    // by default which will result in double perceptual encoding, thus for now if one want to use\n    // this ODT, he needs to decode its output with sRGB electro-optical transfer function (EOTF) to\n    // compensate for Unity default behaviour.\n\n    return outputCV;\n}\n\n// <ACEStransformID>ODT.Academy.Rec709_D60sim_100nits_dim.a1.0.3</ACEStransformID>\n// <ACESuserName>ACES 1.0 Output - Rec.709 (D60 sim.)</ACESuserName>\n\n//\n// Output Device Transform - Rec709 (D60 simulation)\n//\n\n//\n// Summary :\n//  This transform is intended for mapping OCES onto a Rec.709 broadcast monitor\n//  that is calibrated to a D65 white point at 100 cd/m^2. The assumed observer\n//  adapted white is D60, and the viewing environment is a dim surround.\n//\n//  A possible use case for this transform would be cinema \"soft-proofing\".\n//\n// Device Primaries :\n//  Primaries are those specified in Rec. ITU-R BT.709\n//  CIE 1931 chromaticities:  x         y         Y\n//              Red:          0.64      0.33\n//              Green:        0.3       0.6\n//              Blue:         0.15      0.06\n//              White:        0.3127    0.329     100 cd/m^2\n//\n// Display EOTF :\n//  The reference electro-optical transfer function specified in\n//  Rec. ITU-R BT.1886.\n//\n// Signal Range:\n//    By default, this transform outputs full range code values. If instead a\n//    SMPTE \"legal\" signal is desired, there is a runtime flag to output\n//    SMPTE legal signal. In ctlrender, this can be achieved by appending\n//    '-param1 legalRange 1' after the '-ctl odt.ctl' string.\n//\n// Assumed observer adapted white point:\n//         CIE 1931 chromaticities:    x            y\n//                                     0.32168      0.33767\n//\n// Viewing Environment:\n//   This ODT has a compensation for viewing environment variables more typical\n//   of those associated with video mastering.\n//\nHALF3 ODT_Rec709_D60sim_100nits_dim(HALF3 oces)\n{\n    // OCES to RGB rendering space\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, oces);\n\n    // Apply the tonescale independently in rendering-space RGB\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c9_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c9_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c9_fwd(rgbPre.z);\n\n    // Scale luminance to linear code value\n    HALF3 linearCV = Y_2_linCV(rgbPost, CINEMA_WHITE, CINEMA_BLACK);\n\n    // --- Compensate for different white point being darker  --- //\n    // This adjustment is to correct an issue that exists in ODTs where the device\n    // is calibrated to a white chromaticity other than D60. In order to simulate\n    // D60 on such devices, unequal code values must be sent to the display to achieve\n    // the chromaticities of D60. More specifically, in order to produce D60 on a device\n    // calibrated to a D65 white point (i.e. equal code values yield CIE x,y\n    // chromaticities of 0.3127, 0.329) the red channel must be slightly higher than\n    // that of green and blue in order to compensate for the relatively more \"blue-ish\"\n    // D65 white. This unequalness of color channels is the correct behavior but it\n    // means that as neutral highlights increase, the red channel will hit the\n    // device maximum first and clip, resulting in a small chromaticity shift as the\n    // green and blue channels continue to increase to their maximums.\n    // To avoid this clipping error, a slight scale factor is applied to allow the\n    // ODTs to simulate D60 within the D65 calibration white point.\n\n    // Scale and clamp white to avoid casted highlights due to D60 simulation\n    const HALF SCALE = 0.955;\n    linearCV = min(linearCV, 1.0) * SCALE;\n\n    // Apply gamma adjustment to compensate for dim surround\n    linearCV = darkSurround_to_dimSurround(linearCV);\n\n    // Apply desaturation to compensate for luminance difference\n    //linearCV = mul(ODT_SAT_MAT, linearCV);\n    linearCV = lerp(HALF3(dot(linearCV, AP1_RGB2Y)), linearCV, ODT_SAT_FACTOR);\n\n    // Convert to display primary encoding\n    // Rendering space RGB to XYZ\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    // CIE XYZ to display primaries\n    linearCV = mul(XYZ_2_REC709_MAT, XYZ);\n\n    // Handle out-of-gamut values\n    // Clip values < 0 or > 1 (i.e. projecting outside the display primaries)\n    linearCV = saturate(linearCV);\n\n    // Encode linear code values with transfer function\n    const HALF DISPGAMMA = 2.4;\n    const HALF L_W = 1.0;\n    const HALF L_B = 0.0;\n    HALF3 outputCV = linear_to_bt1886(linearCV, DISPGAMMA, L_W, L_B);\n\n    // TODO: Implement support for legal range.\n\n    // NOTE: Unity framebuffer encoding is encoded with sRGB opto-electrical transfer function (OETF)\n    // by default which will result in double perceptual encoding, thus for now if one want to use\n    // this ODT, he needs to decode its output with sRGB electro-optical transfer function (EOTF) to\n    // compensate for Unity default behaviour.\n\n    return outputCV;\n}\n\n// <ACEStransformID>ODT.Academy.Rec2020_100nits_dim.a1.0.3</ACEStransformID>\n// <ACESuserName>ACES 1.0 Output - Rec.2020</ACESuserName>\n\n//\n// Output Device Transform - Rec2020\n//\n\n//\n// Summary :\n//  This transform is intended for mapping OCES onto a Rec.2020 broadcast\n//  monitor that is calibrated to a D65 white point at 100 cd/m^2. The assumed\n//  observer adapted white is D65, and the viewing environment is that of a dim\n//  surround.\n//\n//  A possible use case for this transform would be UHDTV/video mastering.\n//\n// Device Primaries :\n//  Primaries are those specified in Rec. ITU-R BT.2020\n//  CIE 1931 chromaticities:  x         y         Y\n//              Red:          0.708     0.292\n//              Green:        0.17      0.797\n//              Blue:         0.131     0.046\n//              White:        0.3127    0.329     100 cd/m^2\n//\n// Display EOTF :\n//  The reference electro-optical transfer function specified in\n//  Rec. ITU-R BT.1886.\n//\n// Signal Range:\n//    By default, this transform outputs full range code values. If instead a\n//    SMPTE \"legal\" signal is desired, there is a runtime flag to output\n//    SMPTE legal signal. In ctlrender, this can be achieved by appending\n//    '-param1 legalRange 1' after the '-ctl odt.ctl' string.\n//\n// Assumed observer adapted white point:\n//         CIE 1931 chromaticities:    x            y\n//                                     0.3127       0.329\n//\n// Viewing Environment:\n//   This ODT has a compensation for viewing environment variables more typical\n//   of those associated with video mastering.\n//\n\nHALF3 ODT_Rec2020_100nits_dim(HALF3 oces)\n{\n    // OCES to RGB rendering space\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, oces);\n\n    // Apply the tonescale independently in rendering-space RGB\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c9_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c9_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c9_fwd(rgbPre.z);\n\n    // Scale luminance to linear code value\n    HALF3 linearCV = Y_2_linCV(rgbPost, CINEMA_WHITE, CINEMA_BLACK);\n\n    // Apply gamma adjustment to compensate for dim surround\n    linearCV = darkSurround_to_dimSurround(linearCV);\n\n    // Apply desaturation to compensate for luminance difference\n    //linearCV = mul(ODT_SAT_MAT, linearCV);\n    linearCV = lerp(HALF3(dot(linearCV, AP1_RGB2Y)), linearCV, ODT_SAT_FACTOR);\n\n    // Convert to display primary encoding\n    // Rendering space RGB to XYZ\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    // Apply CAT from ACES white point to assumed observer adapted white point\n    XYZ = mul(D60_2_D65_CAT, XYZ);\n\n    // CIE XYZ to display primaries\n    linearCV = mul(XYZ_2_REC2020_MAT, XYZ);\n\n    // Handle out-of-gamut values\n    // Clip values < 0 or > 1 (i.e. projecting outside the display primaries)\n    linearCV = saturate(linearCV);\n\n    // Encode linear code values with transfer function\n    const HALF DISPGAMMA = 2.4;\n    const HALF L_W = 1.0;\n    const HALF L_B = 0.0;\n    HALF3 outputCV = linear_to_bt1886(linearCV, DISPGAMMA, L_W, L_B);\n\n    // TODO: Implement support for legal range.\n\n    // NOTE: Unity framebuffer encoding is encoded with sRGB opto-electrical transfer function (OETF)\n    // by default which will result in double perceptual encoding, thus for now if one want to use\n    // this ODT, he needs to decode its output with sRGB electro-optical transfer function (EOTF) to\n    // compensate for Unity default behaviour.\n\n    return outputCV;\n}\n\n// <ACEStransformID>ODT.Academy.P3DCI_48nits.a1.0.3</ACEStransformID>\n// <ACESuserName>ACES 1.0 Output - P3-DCI</ACESuserName>\n\n//\n// Output Device Transform - P3DCI (D60 Simulation)\n//\n\n//\n// Summary :\n//  This transform is intended for mapping OCES onto a P3 digital cinema\n//  projector that is calibrated to a DCI white point at 48 cd/m^2. The assumed\n//  observer adapted white is D60, and the viewing environment is that of a dark\n//  theater.\n//\n// Device Primaries :\n//  CIE 1931 chromaticities:  x         y         Y\n//              Red:          0.68      0.32\n//              Green:        0.265     0.69\n//              Blue:         0.15      0.06\n//              White:        0.314     0.351     48 cd/m^2\n//\n// Display EOTF :\n//  Gamma: 2.6\n//\n// Assumed observer adapted white point:\n//         CIE 1931 chromaticities:    x            y\n//                                     0.32168      0.33767\n//\n// Viewing Environment:\n//  Environment specified in SMPTE RP 431-2-2007\n//\nHALF3 ODT_P3DCI_48nits(HALF3 oces)\n{\n    // OCES to RGB rendering space\n    HALF3 rgbPre = mul(AP0_2_AP1_MAT, oces);\n\n    // Apply the tonescale independently in rendering-space RGB\n    HALF3 rgbPost;\n    rgbPost.x = segmented_spline_c9_fwd(rgbPre.x);\n    rgbPost.y = segmented_spline_c9_fwd(rgbPre.y);\n    rgbPost.z = segmented_spline_c9_fwd(rgbPre.z);\n\n    // Scale luminance to linear code value\n    HALF3 linearCV = Y_2_linCV(rgbPost, CINEMA_WHITE, CINEMA_BLACK);\n\n    // --- Compensate for different white point being darker  --- //\n    // This adjustment is to correct an issue that exists in ODTs where the device\n    // is calibrated to a white chromaticity other than D60. In order to simulate\n    // D60 on such devices, unequal code values are sent to the display to achieve\n    // neutrals at D60. In order to produce D60 on a device calibrated to the DCI\n    // white point (i.e. equal code values yield CIE x,y chromaticities of 0.314,\n    // 0.351) the red channel is higher than green and blue to compensate for the\n    // \"greenish\" DCI white. This is the correct behavior but it means that as\n    // highlight increase, the red channel will hit the device maximum first and\n    // clip, resulting in a chromaticity shift as the green and blue channels\n    // continue to increase.\n    // To avoid this clipping error, a slight scale factor is applied to allow the\n    // ODTs to simulate D60 within the D65 calibration white point. However, the\n    // magnitude of the scale factor required for the P3DCI ODT was considered too\n    // large. Therefore, the scale factor was reduced and the additional required\n    // compression was achieved via a reshaping of the highlight rolloff in\n    // conjunction with the scale. The shape of this rolloff was determined\n    // throught subjective experiments and deemed to best reproduce the\n    // \"character\" of the highlights in the P3D60 ODT.\n\n    // Roll off highlights to avoid need for as much scaling\n    const HALF NEW_WHT = 0.918;\n    const HALF ROLL_WIDTH = 0.5;\n    linearCV.x = roll_white_fwd(linearCV.x, NEW_WHT, ROLL_WIDTH);\n    linearCV.y = roll_white_fwd(linearCV.y, NEW_WHT, ROLL_WIDTH);\n    linearCV.z = roll_white_fwd(linearCV.z, NEW_WHT, ROLL_WIDTH);\n\n    // Scale and clamp white to avoid casted highlights due to D60 simulation\n    const HALF SCALE = 0.96;\n    linearCV = min(linearCV, NEW_WHT) * SCALE;\n\n    // Convert to display primary encoding\n    // Rendering space RGB to XYZ\n    HALF3 XYZ = mul(AP1_2_XYZ_MAT, linearCV);\n\n    // CIE XYZ to display primaries\n    linearCV = mul(XYZ_2_DCIP3_MAT, XYZ);\n\n    // Handle out-of-gamut values\n    // Clip values < 0 or > 1 (i.e. projecting outside the display primaries)\n    linearCV = saturate(linearCV);\n\n    // Encode linear code values with transfer function\n    const HALF DISPGAMMA = 2.6;\n    HALF3 outputCV = pow(linearCV, HALF3(1.0 / DISPGAMMA));\n\n    // NOTE: Unity framebuffer encoding is encoded with sRGB opto-electrical transfer function (OETF)\n    // by default which will result in double perceptual encoding, thus for now if one want to use\n    // this ODT, he needs to decode its output with sRGB electro-optical transfer function (EOTF) to\n    // compensate for Unity default behaviour.\n\n    return outputCV;\n}\n",
                "description": "",
                "inputs": [],
                "name": "Common",
                "outputs": [],
                "type": "common"
            },
            {
                "code": "// https://github.com/selfshadow/ltc_code/blob/master/webgl/shaders/ltc/ltc_blit.fs\n// https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl\nvec3 approx(vec3 color) {\n    const mat3 x = mat3(+0.59719, +0.07600, +0.02840, +0.35458, +0.90834, +0.13383, +0.04823, +0.01566, +0.83777);\n    const mat3 y = mat3(+1.60475, -0.10208, -0.00327, -0.53108, +1.10813, -0.07276, -0.07367, -0.00605, +1.07602);\n    vec3 v = x*color;    \n    vec3 a = v*(v + 0.0245786) - 0.000090537;\n    vec3 b = v*(0.983729*v + 0.4329510) + 0.238081;\n    return clamp(y*(a/b), 0.0, 1.0);\t\n}\n\nvec3 reference(vec3 color) {\n    vec3 aces = color*sRGB_2_AP0;\n    vec3 oces = RRT(aces);\n    vec3 srgb = ODT_RGBmonitor_100nits_dim(oces);\n    return srgb;\n}\n\nvoid mainImage(out vec4 rgba, vec2 xy) {\n    vec2 uv = xy/iResolution.xy;\n\n    vec3 a = PI*(3.0*uv.x + vec3(0.211,  0.313, 0.419)*iTime);\n    vec3 x = 2.0*(uv.x + uv.x*(1.0-uv.x)*sin(a));\n    vec3 y =\n        xy.y < 1.0 ? x :\n    \txy.y < 2.0 ? reference(x) :\n    \txy.y < 3.0 ? approx(x) :\n    \tvec3(0.0);\n\n    rgba = vec4(y, 1.0);\n}",
                "description": "",
                "inputs": [],
                "name": "Buffer A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}