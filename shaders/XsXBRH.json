{
    "Shader": {
        "info": {
            "date": "1494756798",
            "description": "testing if I can store and read 4x16 bits in 1 fragment between buffers.\ntesting if there is any implementations that fails on it, learning constrains.\nthis may need a WebGL version that supports the bit-wise operators.\nhas this been done before?",
            "flags": 32,
            "hasliked": 0,
            "id": "XsXBRH",
            "likes": 1,
            "name": "goddamn browser zoom, i forgot",
            "published": 3,
            "tags": [
                "buffer",
                "bitwise"
            ],
            "usePreview": 0,
            "username": "ollj",
            "viewed": 648
        },
        "renderpass": [
            {
                "code": "/*\n//using fragments as memory array, type is vec4(),assume 4 signed 16 bit floats.\n#define set(p,v) if(all(equal(U,p+.5)))O=v\n#define get0(p) texture(iChannel0,(p+.5)/iChannelResolution[0].xy,-100.)\n#define get1(p) texture(iChannel1,(p+.5)/iChannelResolution[1].xy,-100.)\n#define get2(p) texture(iChannel2,(p+.5)/iChannelResolution[2].xy,-100.)\n#define get3(p) texture(iChannel3,(p+.5)/iChannelResolution[3].xy,-100.)\n//for syntax click the \"?\" in the bottom right\n*/\n/*\nhttps://www.khronos.org/registry/OpenGL/extensions/EXT/EXT_texture_lod_bias.txt\n*/\n\n/*\n//for precision, dividing by iResolution early on is not a good idea.\nvec2 frame(vec2 u){//u/=iResolution.xy;\n //u-=.5;\n //u.x*=iResolution.x/iResolution.y;\n u/=8.;\n return u;}//2d view frame transform\n/**/\n\n//#define time1 (cos(iTime)*.5+.5)\n\nvoid mainImage(out vec4 O,in vec2 U){O=vec4(0);\n/*\n vec2 u=frame(U);\n O   =texture(iChannel0,(u+time1)/iResolution.xy,99999.);\n O.x+=texture(iChannel0,(U+time1)/iResolution.xy,99999.).x;\n //texelFetch( iChannel0, ivec2(uv) , 0);\n //for non-interpolated samples.\n //my ass, special functions with less backwards compatibility \n //that pretty much do the same than an older general function\n //i could barely care less.\n \n //below and above is similar buit not the same blurry shit\n //for time1==0.\n //and I hope its not just due to its offset [o]\n vec2 o=vec2(16.,0.);\n set(o+vec2(2),vec4(1));\n set(o+vec2(3),vec4(1));\n set(o+vec2(4),vec4(1));\n set(o+vec2(5),vec4(1));\n set(o+vec2(6),vec4(1));\n //why is this shit blurry?\n \n //lets try it overly explicit:\n //please do not question why i am using a function this inefficiently.\n //theye 4 little fragments build a house of hay.\n set(vec2(0,0),vec4(0,0,0,1));\n set(vec2(1,0),vec4(1,0,0,1));\n set(vec2(0,1),vec4(0,0,1,0));\n set(vec2(1,1),vec4(1,0,0,1));\n //3 fragments of a tiny green line:\n set(vec2(0,2),vec4(0,1,0,1));\n set(vec2(1,2),vec4(0,1,0,1));\n set(vec2(2,2),vec4(0,1,0,1));\n //why is this shit blurry?     \n    */\n //lets simply the rabbit hole\n float g=0.;\n //g=floor(fract(U.x/2.)*2.);//blurry grid\n if(U.x==128.5)g=1.;           //blurry single green line , WTF\n O+=vec4(g);\n //why is this shit blurry?   \n    \n //it doesnt get more basic than this without losing turing completeness..\n    \n //vec4 w=get0(vec2(2));\n  //damnit w.x ==0 for any U;\n //if(w.x==.0)O.y=1.;\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            },
            {
                "code": "//using fragments as memory array, type is vec4(),assume 4 signed 16 bit floats.\n#define set(p,v) if(all(equal(U,p+.5)))O=v\n/*\n#define get0(p) texture(iChannel1,(p+.5)/iChannelResolution[1].xy,-100.)\n#define get1(p) texture(iChannel1,(p+.5)/iChannelResolution[1].xy,-100.)\n#define get2(p) texture(iChannel2,(p+.5)/iChannelResolution[2].xy,-100.)\n#define get3(p) texture(iChannel3,(p+.5)/iChannelResolution[2].xy,-100.)\n*/\n\n//for precision, dividing by iResolution early on is not a good idea.\nvec2 frame(vec2 u){//u/=iResolution.xy;\n //u-=.5;\n //u.x*=iResolution.x/iResolution.y;\n //u*=4.;\n return u;}//2d view frame transform\n\n\n\nvoid mainImage(out vec4 O,in vec2 U){\n //O=vec4(1,0,0,1);\n vec2 u=frame(U);\n u=fract(u);\n set(vec2(2),vec4(1));\n set(vec2(3),vec4(1));\n set(vec2(4),vec4(1));\n set(vec2(5),vec4(1));\n set(vec2(6),vec4(1));\n //if(all(equal(u,U+.5)))O=vec4(1.);\n //vec4 r=get0(u);\n //O=vec4(r.x,0,0,0);\n}",
                "description": "",
                "inputs": [
                    {
                        "channel": 0,
                        "ctype": "buffer",
                        "id": 257,
                        "published": 1,
                        "sampler": {
                            "filter": "nearest",
                            "internal": "byte",
                            "srgb": "false",
                            "vflip": "true",
                            "wrap": "clamp"
                        },
                        "src": "/media/previz/buffer00.png"
                    }
                ],
                "name": "Buf A",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 257
                    }
                ],
                "type": "buffer"
            }
        ],
        "ver": "0.1"
    }
}