{
    "Shader": {
        "info": {
            "date": "1641229467",
            "description": "Experimenting with some ideas. NOT optiimized.\nTests :\n- combo sphere and rounded box with smoothmin\n- combo transparency with purpose made raymarcher and a reflection from source shader\n- added hash13() pseudo-rnd func to raymarcher to avoid banding",
            "flags": 0,
            "hasliked": 0,
            "id": "NlVXRd",
            "likes": 2,
            "name": "transparency and shading test",
            "published": 3,
            "tags": [
                "transparency",
                "cube",
                "sphere",
                "shading",
                "smoothmin"
            ],
            "usePreview": 0,
            "username": "terraquoia",
            "viewed": 295
        },
        "renderpass": [
            {
                "code": "/*\nmodified version of\n\nhttps://www.shadertoy.com/view/Xtd3z7\n\nmade by jlfwong\n\nit is a mess and not a priority. i'm publishing this modification so others can take a look at and use it.\nthere are other pieces of code borrowed from other shaders. not much of this is my \"original code\" :)\nthus same GPL/MIT freedom to use parts of this code applies.\n\nto reiterate in more detail from my comment box:\n- sphere and rounded box SDFs are animated by altering input point for box and radius for sphere\n- combined a sphere and a rounded edge box with smoothmin function smin() to form a metaball-like geometry\n- added transparency with a dedicated volume raymarcher\n- added hash13() pseudo-random function into volume raymarcher to avoid banding\n- combined the transparency with lighting code from source shader producing a nice surface reflection\n\ntake this apart, shut off parts of code, change parameters and generally have fun !\n*/\nconst int MAX_MARCHING_STEPS = 64;\nconst float MIN_DIST = 0.0;\nconst float MAX_DIST = 20.0;\nconst float EPSILON = 1e-2; // could go finer but artefacts show up, related to marching steps.\n\nfloat sdSphere( vec3 p, float s )\n{\n  return length(p)-s;\n}\n\nfloat sdRoundBox( vec3 p, vec3 b, float r )\n{\n  vec3 q = abs(p) - b;\n  return length(max(q,0.0)) + min(max(q.x,max(q.y,q.z)),0.0) - r;\n}\n\nfloat smin(float a, float b, float k)\n{\n    float h = clamp(0.5 + 0.5*(a-b)/k, 0.0, 1.0);\n    return mix(a, b, h) - k*h*(1.0-h);\n}\n\nfloat sceneSDF(vec3 samplePoint)\n{\n    float d = sdRoundBox(samplePoint-vec3(cos(iTime)*2.2,sin(iTime)*1.5,0.0), vec3(0.8), .1);\n    //last parameter 1.1 is smoothing factor. larger value = bigger \"weld\" between two SDFs\n    d = smin(sdSphere(samplePoint,cos(iTime)*0.3+0.6), d, 1.1);\n    return d;\n}\n\nvec4 applyFog(vec3 originalRGB,float dist)\n{\n    float b = .1;\n\tfloat c = .6 / b;\n\tfloat fogAmount = (1.0 - exp(-dist * b));\n\tvec3 fogColor = vec3 (0.5, 0.6, 0.7);\n\treturn vec4(mix(originalRGB, fogColor, fogAmount), fogAmount);\n}\n\nfloat hash13(vec3 p3)\n{\n\tp3  = fract(p3 * .1031);\n    p3 += dot(p3, p3.yzx + 33.33);\n    return fract((p3.x + p3.y) * p3.z);\n}\n\nvec4 rayMarchVolumetric (vec3 ro, vec3 rd)\n{\n    float depth = 0.0;\n    float entry = 0.0;\n    float exit = 0.0;\n    //find closest point\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++)\n    {\n        vec3 p = ro + depth * rd;\n        float d = sceneSDF(p);\n        if (d < EPSILON)\n        {\n            entry = depth;\n            break;\n        }\n        depth += d;\n    }\n    //if closest point beyond draw limit, exit with blank\n    if (depth > MAX_DIST) return vec4(0.0, 0.0, 0.0, 0.0);\n    //now find farthest point by working backwards until surface hit from behind\n    depth = MAX_DIST;\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++)\n    {\n        vec3 p = ro + depth * rd;\n        float d = sceneSDF(p);\n        if (d < EPSILON)\n        {\n            exit = depth;\n            break;\n        }\n        depth -= d;\n    }\n    float occlusion = 0.0;\n    depth = entry; //starting position\n    // depth step. take difference between closest and farthest points and slice it up into 20 segments\n    float dstep = abs(exit - entry) / 20.0;\n    int sanity = 0; //always but ALWAYS have this in your loops. else you may crash the machine :)\n    float occlusion_offsetted = 0.0;\n    //collect occlusion along the ray\n    while (depth <= exit && occlusion < 0.95) // occlusion capped to 0.95 so some transparency is always present\n    {\n        if (sanity++ > 100) break;\n        vec3 p = ro + depth * rd;\n        float d = sceneSDF(p);\n        if (d < EPSILON)\n        {\n            occlusion += dstep * hash13(p);\n            // slightly offsetted. note that offset will be relative to scene size (or total space being rendered)\n            occlusion_offsetted += dstep * hash13(p+vec3(1e-2, 1e-2,1e-2));\n        }\n        depth += dstep;// * hash13(p);\n    }\n    vec3 origColor = vec3(0.1, 0.2, 0.3);\n    //reuse existing variable. basically take average of the two samples\n    occlusion = occlusion + occlusion_offsetted / 2.0;\n    //now feed in the difference between closest and farthest points\n    return applyFog(origColor, occlusion);\n}\n\nfloat shortestDistanceToSurface(vec3 eye, vec3 marchingDirection, float start, float end)\n{\n    float depth = start;\n    for (int i = 0; i < MAX_MARCHING_STEPS; i++)\n    {\n        float dist = sceneSDF(eye + depth * marchingDirection);\n        if (dist < EPSILON)\n        {\n\t\t\treturn depth;\n        }\n        depth += dist;\n        if (depth >= end)\n        {\n            return end;\n        }\n    }\n    return end;\n}\n            \nvec3 rayDirection(float fieldOfView, vec2 size, vec2 fragCoord)\n{\n    vec2 xy = fragCoord - size / 2.0;\n    float z = size.y / tan(radians(fieldOfView) / 2.0);\n    return normalize(vec3(xy, -z));\n}\n\nvec3 estimateNormal(vec3 p)\n{\n    return normalize(vec3(\n        sceneSDF(vec3(p.x + EPSILON, p.y, p.z)) - sceneSDF(vec3(p.x - EPSILON, p.y, p.z)),        \n        sceneSDF(vec3(p.x, p.y + EPSILON, p.z)) - sceneSDF(vec3(p.x, p.y - EPSILON, p.z)),\n        sceneSDF(vec3(p.x, p.y, p.z  + EPSILON)) - sceneSDF(vec3(p.x, p.y, p.z - EPSILON))\n    ));\n}\n\n/**\n * Lighting contribution of a single point light source via Phong illumination.\n * \n * The vec3 returned is the RGB color of the light's contribution.\n *\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n * lightPos: the position of the light\n * lightIntensity: color/intensity of the light\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongContribForLight(vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye, vec3 lightPos, vec3 lightIntensity)\n{\n    vec3 N = estimateNormal(p);\n    vec3 L = normalize(lightPos - p);\n    vec3 V = normalize(eye - p);\n    vec3 R = normalize(reflect(-L, N));\n    \n    float dotLN = dot(L, N);\n    float dotRV = dot(R, V);\n    \n    if (dotLN < 0.0)\n    {\n        // Light not visible from this point on the surface\n        return vec3(0.0, 0.0, 0.0);\n    } \n    \n    if (dotRV < 0.0)\n    {\n        // Light reflection in opposite direction as viewer, apply only diffuse\n        // component\n        return lightIntensity * (k_d * dotLN);\n    }\n    return lightIntensity * (k_d * dotLN + k_s * pow(dotRV, alpha));\n}\n\n/**\n * Lighting via Phong illumination.\n * \n * The vec3 returned is the RGB color of that point after lighting is applied.\n * k_a: Ambient color\n * k_d: Diffuse color\n * k_s: Specular color\n * alpha: Shininess coefficient\n * p: position of point being lit\n * eye: the position of the camera\n *\n * See https://en.wikipedia.org/wiki/Phong_reflection_model#Description\n */\nvec3 phongIllumination(vec3 k_a, vec3 k_d, vec3 k_s, float alpha, vec3 p, vec3 eye)\n{\n    const vec3 ambientLight = 0.5 * vec3(1.0, 1.0, 1.0);\n    vec3 color = ambientLight * k_a;\n    \n    vec3 light1Pos = vec3(4.0 * sin(iTime),\n                          2.0,\n                          4.0 * cos(iTime));\n    vec3 light1Intensity = vec3(0.4, 0.4, 0.4);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light1Pos,\n                                  light1Intensity);\n    \n    vec3 light2Pos = vec3(2.0 * sin(0.37 * iTime),\n                          2.0 * cos(0.37 * iTime),\n                          2.0);\n    vec3 light2Intensity = vec3(0.4, 0.4, 0.4);\n    \n    color += phongContribForLight(k_d, k_s, alpha, p, eye,\n                                  light2Pos,\n                                  light2Intensity);    \n    return color;\n}\n\n/**\n * Return a transform matrix that will transform a ray from view space\n * to world coordinates, given the eye point, the camera target, and an up vector.\n *\n * This assumes that the center of the camera is aligned with the negative z axis in\n * view space when calculating the ray marching direction. See rayDirection.\n */\nmat4 viewMatrix(vec3 eye, vec3 center, vec3 up)\n{\n    // Based on gluLookAt man page\n    vec3 f = normalize(center - eye);\n    vec3 s = normalize(cross(f, up));\n    vec3 u = cross(s, f);\n    return mat4(\n        vec4(s, 0.0),\n        vec4(u, 0.0),\n        vec4(-f, 0.0),\n        vec4(0.0, 0.0, 0.0, 1)\n    );\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord)\n{\n\tvec3 viewDir = rayDirection(45.0, iResolution.xy, fragCoord);\n\n    vec3 eye = vec3(8.0, 5.0, 7.0);\n    \n    mat4 viewToWorld = viewMatrix(eye, vec3(0.0, 0.0, 0.0), vec3(0.0, 1.0, 0.0));\n    \n    vec3 worldDir = (viewToWorld * vec4(viewDir, 0.0)).xyz;\n    \n    float dist = shortestDistanceToSurface(eye, worldDir, MIN_DIST, MAX_DIST);\n    \n    if (dist > MAX_DIST - EPSILON)\n    {\n        // Didn't hit anything\n        fragColor = vec4(0.0, 0.0, 0.0, 0.0);\n\t\treturn;\n    }\n    \n    // The closest point on the surface to the eyepoint along the view ray\n    \n    vec3 p = eye + dist * worldDir;\n    \n    vec3 K_a = vec3(0.2, 0.2, 0.2);\n    vec3 K_d = vec3(0.7, 0.2, 0.2);\n    vec3 K_s = vec3(1.0, 1.0, 1.0);\n    float shininess = 10.0;\n    \n    vec3 color = phongIllumination(K_a, K_d, K_s, shininess, p, eye);\n    \n    //fragColor = vec4(color, 1.0);\n\n    vec4 color2 = rayMarchVolumetric (eye, worldDir);\n    \n    fragColor = vec4(mix(color2.xyz, color, color2.w), 1.0);\n}\n",
                "description": "",
                "inputs": [],
                "name": "Image",
                "outputs": [
                    {
                        "channel": 0,
                        "id": 37
                    }
                ],
                "type": "image"
            }
        ],
        "ver": "0.1"
    }
}